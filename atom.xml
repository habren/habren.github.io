<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>技术世界</title>
  <subtitle>分享交流大数据领域技术，包括但不限于Storm、Spark、Hadoop等流行分布式计算系统，Kafka、MetaQ等分布式消息系统，MongoDB、Cassandra等NoSQL，PostgreSQL、MySQL等RDBMS以及其它前沿技术</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.jasongj.com/"/>
  <updated>2017-11-12T00:01:01.000Z</updated>
  <id>http://www.jasongj.com/</id>
  
  <author>
    <name>郭俊 Jason</name>
    <email>jason.guo.vip@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深入浅出Zookeeper（一） Zookeeper架构及FastLeaderElection机制</title>
    <link href="http://www.jasongj.com/zookeeper/fastleaderelection/"/>
    <id>http://www.jasongj.com/zookeeper/fastleaderelection/</id>
    <published>2017-11-08T00:01:01.000Z</published>
    <updated>2017-11-12T00:01:01.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/zookeeper/fastleaderelection">原文链接</a>　<a href="http://www.jasongj.com/zookeeper/fastleaderelection">http://www.jasongj.com/zookeeper/fastleaderelection/</a></p>
</blockquote>
<h1 id="Zookeeper是什么"><a href="#Zookeeper是什么" class="headerlink" title="Zookeeper是什么"></a>Zookeeper是什么</h1><p>Zookeeper是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。</p>
<p>这一切的基础，都是Zookeeper提供了一个类似于Linux文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。</p>
<p>既然是一个文件系统，就不得不提Zookeeper是如何保证数据的一致性的。本文将介绍Zookeeper如何保证数据一致性，如何进行领导选举，以及数据监控/通知机制的语义保证。</p>
<h1 id="Zookeeper架构"><a href="#Zookeeper架构" class="headerlink" title="Zookeeper架构"></a>Zookeeper架构</h1><h2 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h2><p>Zookeeper集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种</p>
<ul>
<li><strong><em>Leader</em></strong> 一个Zookeeper集群同一时间只会有一个实际工作的Leader，它会发起并维护与各Follwer及Observer间的心跳。所有的写操作必须要通过Leader完成再由Leader将写操作广播给其它服务器。</li>
<li><strong><em>Follower</em></strong> 一个Zookeeper集群可能同时存在多个Follower，它会响应Leader的心跳。Follower可直接处理并返回客户端的读请求，同时会将写请求转发给Leader处理，并且负责在Leader处理写请求时对请求进行投票。</li>
<li><strong><em>Observer</em></strong> 角色与Follower类似，但是无投票权。</li>
</ul>
<!--
![Zookeeper Architecture](http://www.jasongj.com/img/zookeeper/1_architecture/architecture.png)
-->
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/architecture.png" alt="Zookeeper Architecture"><br></div>

<h2 id="原子广播（ZAB）"><a href="#原子广播（ZAB）" class="headerlink" title="原子广播（ZAB）"></a>原子广播（ZAB）</h2><p>为了保证写操作的一致性与可用性，Zookeeper专门设计了一种名为原子广播（ZAB）的支持崩溃恢复的一致性协议。基于该协议，Zookeeper实现了一种主从模式的系统架构来保持集群中各个副本之间的数据一致性。</p>
<p>根据ZAB协议，所有的写操作都必须通过Leader完成，Leader写入本地日志后再复制到所有的Follower节点。</p>
<p>一旦Leader节点无法工作，ZAB协议能够自动从Follower节点中重新选出一个合适的替代者，即新的Leader，该过程即为领导选举。该领导选举过程，是ZAB协议中最为重要和复杂的过程。</p>
<h2 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h2><h3 id="写Leader"><a href="#写Leader" class="headerlink" title="写Leader"></a>写Leader</h3><p>通过Leader进行写操作流程如下图所示<br><!--
![Zookeeper Leader Write](http://www.jasongj.com/img/zookeeper/1_architecture/writeleader.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/writeleader.png" alt="Zookeeper Leader Write"><br></div>

<p>由上图可见，通过Leader进行写操作，主要分为五步：</p>
<ol>
<li>客户端向Leader发起写请求</li>
<li>Leader将写请求以Proposal的形式发给所有Follower并等待ACK</li>
<li>Follower收到Leader的Proposal后返回ACK</li>
<li>Leader得到过半数的ACK（Leader对自己默认有一个ACK）后向所有的Follower和Observer发送Commmit</li>
<li>Leader将处理结果返回给客户端</li>
</ol>
<p>这里要注意</p>
<ul>
<li>Leader并不需要得到Observer的ACK，即Observer无投票权</li>
<li>Leader不需要得到所有Follower的ACK，只要收到过半的ACK即可，同时Leader本身对自己有一个ACK。上图中有4个Follower，只需其中两个返回ACK即可，因为(2+1) / (4+1) &gt; 1/2</li>
<li>Observer虽然无投票权，但仍须同步Leader的数据从而在处理读请求时可以返回尽可能新的数据</li>
</ul>
<h3 id="写Follower-Observer"><a href="#写Follower-Observer" class="headerlink" title="写Follower/Observer"></a>写Follower/Observer</h3><p>通过Follower/Observer进行写操作流程如下图所示：<br><!--
![Zookeeper Follower/Observer Write](http://www.jasongj.com/img/zookeeper/1_architecture/writefollower.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/writefollower.png" alt="Zookeeper Follower/Observer Write"><br></div>

<p>从上图可见</p>
<ul>
<li>Follower/Observer均可接受写请求，但不能直接处理，而需要将写请求转发给Leader处理</li>
<li>除了多了一步请求转发，其它流程与直接写Leader无任何区别</li>
</ul>
<h2 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h2><p>Leader/Follower/Observer都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。<br><!--
![Zookeeper Read](http://www.jasongj.com/img/zookeeper/1_architecture/read.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/read.png" alt="Zookeeper Read"><br></div>

<p>由于处理读请求不需要服务器之间的交互，Follower/Observer越多，整体可处理的读请求量越大，也即读性能越好。</p>
<h1 id="FastLeaderElection原理"><a href="#FastLeaderElection原理" class="headerlink" title="FastLeaderElection原理"></a>FastLeaderElection原理</h1><h2 id="术语介绍"><a href="#术语介绍" class="headerlink" title="术语介绍"></a>术语介绍</h2><p><strong><em>myid</em></strong><br>每个Zookeeper服务器，都需要在数据文件夹下创建一个名为myid的文件，该文件包含整个Zookeeper集群唯一的ID（整数）。例如某Zookeeper集群包含三台服务器，hostname分别为zoo1、zoo2和zoo3，其myid分别为1、2和3，则在配置文件中其ID与hostname必须一一对应，如下所示。在该配置文件中，<code>server.</code>后面的数据即为myid</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">server.1=zoo1:2888:3888</div><div class="line">server.2=zoo2:2888:3888</div><div class="line">server.3=zoo3:2888:3888</div></pre></td></tr></table></figure>
<p><strong><em>zxid</em></strong><br>类似于RDBMS中的事务ID，用于标识一次更新操作的Proposal ID。为了保证顺序性，该zkid必须单调递增。因此Zookeeper使用一个64位的数来表示，高32位是Leader的epoch，从1开始，每次选出新的Leader，epoch加一。低32位为该epoch内的序号，每次epoch变化，都将低32位的序号重置。这样保证了zkid的全局递增性。</p>
<h2 id="支持的领导选举算法"><a href="#支持的领导选举算法" class="headerlink" title="支持的领导选举算法"></a>支持的领导选举算法</h2><p>可通过<code>electionAlg</code>配置项设置Zookeeper用于领导选举的算法。</p>
<p>到3.4.10版本为止，可选项有  </p>
<ul>
<li><code>0</code> 基于UDP的LeaderElection</li>
<li><code>1</code> 基于UDP的FastLeaderElection</li>
<li><code>2</code> 基于UDP和认证的FastLeaderElection</li>
<li><code>3</code> 基于TCP的FastLeaderElection</li>
</ul>
<p>在3.4.10版本中，默认值为3，也即基于TCP的FastLeaderElection。另外三种算法已经被弃用，并且有计划在之后的版本中将它们彻底删除而不再支持。</p>
<h2 id="FastLeaderElection"><a href="#FastLeaderElection" class="headerlink" title="FastLeaderElection"></a>FastLeaderElection</h2><p>FastLeaderElection选举算法是标准的Fast Paxos算法实现，可解决LeaderElection选举算法收敛速度慢的问题。</p>
<h3 id="服务器状态"><a href="#服务器状态" class="headerlink" title="服务器状态"></a>服务器状态</h3><ul>
<li><strong><em>LOOKING</em></strong> 不确定Leader状态。该状态下的服务器认为当前集群中没有Leader，会发起Leader选举</li>
<li><strong><em>FOLLOWING</em></strong> 跟随者状态。表明当前服务器角色是Follower，并且它知道Leader是谁</li>
<li><strong><em>LEADING</em></strong> 领导者状态。表明当前服务器角色是Leader，它会维护与Follower间的心跳</li>
<li><strong><em>OBSERVING</em></strong> 观察者状态。表明当前服务器角色是Observer，与Folower唯一的不同在于不参与选举，也不参与集群写操作时的投票</li>
</ul>
<h3 id="选票数据结构"><a href="#选票数据结构" class="headerlink" title="选票数据结构"></a>选票数据结构</h3><p>每个服务器在进行领导选举时，会发送如下关键信息</p>
<ul>
<li><strong><em>logicClock</em></strong> 每个服务器会维护一个自增的整数，名为logicClock，它表示这是该服务器发起的第多少轮投票</li>
<li><strong><em>state</em></strong> 当前服务器的状态</li>
<li><strong><em>self_id</em></strong> 当前服务器的myid</li>
<li><strong><em>self_zxid</em></strong> 当前服务器上所保存的数据的最大zxid</li>
<li><strong><em>vote_id</em></strong> 被推举的服务器的myid</li>
<li><strong><em>vote_zxid</em></strong> 被推举的服务器上所保存的数据的最大zxid</li>
</ul>
<h3 id="投票流程"><a href="#投票流程" class="headerlink" title="投票流程"></a>投票流程</h3><p><strong><em>自增选举轮次</em></strong><br>Zookeeper规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的logicClock进行自增操作。</p>
<p><strong><em>初始化选票</em></strong><br>每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器2投票给服务器3，服务器3投票给服务器1，则服务器1的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。</p>
<p><strong><em>发送初始化选票</em></strong><br>每个服务器最开始都是通过广播把票投给自己。</p>
<p><strong><em>接收外部投票</em></strong><br>服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。</p>
<p><strong><em>判断选举轮次</em></strong><br>收到外部投票后，首先会根据投票信息中所包含的logicClock来进行不同处理</p>
<ul>
<li>外部投票的logicClock大于自己的logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的logicClock更新为收到的logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。</li>
<li>外部投票的logicClock小于自己的logicClock。当前服务器直接忽略该投票，继续处理下一个投票。</li>
<li>外部投票的logickClock与自己的相等。当时进行选票PK。</li>
</ul>
<p><strong><em>选票PK</em></strong><br>选票PK是基于(self_id, self_zxid)与(vote_id, vote_zxid)的对比</p>
<ul>
<li>外部投票的logicClock大于自己的logicClock，则将自己的logicClock及自己的选票的logicClock变更为收到的logicClock</li>
<li>若logicClock一致，则对比二者的vote_zxid，若外部投票的vote_zxid比较大，则将自己的票中的vote_zxid与vote_myid更新为收到的票中的vote_zxid与vote_myid并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖</li>
<li>若二者vote_zxid一致，则比较二者的vote_myid，若外部投票的vote_myid比较大，则将自己的票中的vote_myid更新为收到的票中的vote_myid并广播出去，另外将收到的票及自己更新后的票放入自己的票箱</li>
</ul>
<p><strong><em>统计选票</em></strong><br> 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。</p>
<p><strong><em>更新服务器状态</em></strong><br> 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为LEADING，否则将自己的状态更新为FOLLOWING</p>
<h2 id="几种领导选举场景"><a href="#几种领导选举场景" class="headerlink" title="几种领导选举场景"></a>几种领导选举场景</h2><h3 id="集群启动领导选举"><a href="#集群启动领导选举" class="headerlink" title="集群启动领导选举"></a>集群启动领导选举</h3><p><strong><em>初始投票给自己</em></strong><br>集群刚启动时，所有服务器的logicClock都为1，zxid都为0。</p>
<p>各服务器初始化后，都投票给自己，并将自己的一票存入自己的票箱，如下图所示。<br><!--
![Cluster start election step 1](http://www.jasongj.com/img/zookeeper/1_architecture/start_election_1.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/start_election_1.png" alt="Cluster start election step 1"><br></div><br>在上图中，(1, 1, 0)第一位数代表投出该选票的服务器的logicClock，第二位数代表被推荐的服务器的myid，第三位代表被推荐的服务器的最大的zxid。由于该步骤中所有选票都投给自己，所以第二位的myid即是自己的myid，第三位的zxid即是自己的zxid。<br><br>此时各自的票箱中只有自己投给自己的一票。<br><br><strong><em>更新选票</em></strong><br>服务器收到外部投票后，进行选票PK，相应更新自己的选票并广播出去，并将合适的选票存入自己的票箱，如下图所示。<br><!--
![Cluster start election step 2](http://www.jasongj.com/img/zookeeper/1_architecture/start_election_2.png)
--><br><div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/start_election_2.png" alt="Cluster start election step 2"><br></div><br>服务器1收到服务器2的选票（1, 2, 0）和服务器3的选票（1, 3, 0）后，由于所有的logicClock都相等，所有的zxid都相等，因此根据myid判断应该将自己的选票按照服务器3的选票更新为（1, 3, 0），并将自己的票箱全部清空，再将服务器3的选票与自己的选票存入自己的票箱，接着将自己更新后的选票广播出去。此时服务器1票箱内的选票为(1, 3)，(3, 3)。<br><br>同理，服务器2收到服务器3的选票后也将自己的选票更新为（1, 3, 0）并存入票箱然后广播。此时服务器2票箱内的选票为(2, 3)，(3, ,3)。<br><br>服务器3根据上述规则，无须更新选票，自身的票箱内选票仍为（3, 3）。<br><br>服务器1与服务器2更新后的选票广播出去后，由于三个服务器最新选票都相同，最后三者的票箱内都包含三张投给服务器3的选票。<br><br><strong><em>根据选票确定角色</em></strong><br>根据上述选票，三个服务器一致认为此时服务器3应该是Leader。因此服务器1和2都进入FOLLOWING状态，而服务器3进入LEADING状态。之后Leader发起并维护与Follower间的心跳。<br><!--
![Cluster start election step 3](http://www.jasongj.com/img/zookeeper/1_architecture/start_election_3.png)
--><br><div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/start_election_3.png" alt="Cluster start election step 3"><br></div>

<h3 id="Follower重启"><a href="#Follower重启" class="headerlink" title="Follower重启"></a>Follower重启</h3><p><strong><em>Follower重启投票给自己</em></strong><br>Follower重启，或者发生网络分区后找不到Leader，会进入LOOKING状态并发起新的一轮投票。<br><!--![Follower restart election step 1](http://www.jasongj.com/img/zookeeper/1_architecture/follower_restart_election_1.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/follower_restart_election_1.png" alt="Follower restart election step 1"><br></div>

<p><strong><em>发现已有Leader后成为Follower</em></strong><br>服务器3收到服务器1的投票后，将自己的状态LEADING以及选票返回给服务器1。服务器2收到服务器1的投票后，将自己的状态FOLLOWING及选票返回给服务器1。此时服务器1知道服务器3是Leader，并且通过服务器2与服务器3的选票可以确定服务器3确实得到了超过半数的选票。因此服务器1进入FOLLOWING状态。<br><!--
![Follower restart election step 1](http://www.jasongj.com/img/zookeeper/1_architecture/follower_restart_election_1.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/follower_restart_election_2.png" alt="Follower restart election step 2"><br></div>

<h3 id="Leader重启"><a href="#Leader重启" class="headerlink" title="Leader重启"></a>Leader重启</h3><p><strong><em>Follower发起新投票</em></strong><br>Leader（服务器3）宕机后，Follower（服务器1和2）发现Leader不工作了，因此进入LOOKING状态并发起新的一轮投票，并且都将票投给自己。</p>
<!--
![Leader restart election step 1](http://www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_1.png)
-->
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_1.png" alt="Leader restart election step 1"><br></div>

<p><strong><em>广播更新选票</em></strong><br>服务器1和2根据外部投票确定是否要更新自身的选票。这里有两种情况</p>
<ul>
<li>服务器1和2的zxid相同。例如在服务器3宕机前服务器1与2完全与之同步。此时选票的更新主要取决于myid的大小</li>
<li>服务器1和2的zxid不同。在旧Leader宕机之前，其所主导的写操作，只需过半服务器确认即可，而不需所有服务器确认。换句话说，服务器1和2可能一个与旧Leader同步（即zxid与之相同）另一个不同步（即zxid比之小）。此时选票的更新主要取决于谁的zxid较大</li>
</ul>
<p>在上图中，服务器1的zxid为11，而服务器2的zxid为10，因此服务器2将自身选票更新为（3, 1, 11），如下图所示。<br><!--
![Leader restart election step 2](http://www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_2.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_2.png" alt="Leader restart election step 2"><br></div>

<p><strong><em>选出新Leader</em></strong><br>经过上一步选票更新后，服务器1与服务器2均将选票投给服务器1，因此服务器2成为Follower，而服务器1成为新的Leader并维护与服务器2的心跳。<br><!--
![Leader restart election step 3](http://www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_3.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_3.png" alt="Leader restart election step 3"><br></div>


<p><strong><em>旧Leader恢复后发起选举</em></strong><br>旧的Leader恢复后，进入LOOKING状态并发起新一轮领导选举，并将选票投给自己。此时服务器1会将自己的LEADING状态及选票（3, 1, 11）返回给服务器3，而服务器2将自己的FOLLOWING状态及选票（3, 1, 11）返回给服务器3。如下图所示。<br><!--
![Leader restart election step 4](http://www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_4.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_4.png" alt="Leader restart election step 4"><br></div>

<p><strong><em>旧Leader成为Follower</em></strong><br>服务器3了解到Leader为服务器1，且根据选票了解到服务器1确实得到过半服务器的选票，因此自己进入FOLLOWING状态。<br><!--
![Leader restart election step 5](http://www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_5.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/leader_restart_election_5.png" alt="Leader restart election step 5"><br></div>

<h1 id="一致性保证"><a href="#一致性保证" class="headerlink" title="一致性保证"></a>一致性保证</h1><p>ZAB协议保证了在Leader选举的过程中，已经被Commit的数据不会丢失，未被Commit的数据对客户端不可见。</p>
<h2 id="Commit过的数据不丢失"><a href="#Commit过的数据不丢失" class="headerlink" title="Commit过的数据不丢失"></a>Commit过的数据不丢失</h2><p><strong><em>Failover前状态</em></strong><br>为更好演示Leader Failover过程，本例中共使用5个Zookeeper服务器。A作为Leader，共收到P1、P2、P3三条消息，并且Commit了1和2，且总体顺序为P1、P2、C1、P3、C2。根据顺序性原则，其它Follower收到的消息的顺序肯定与之相同。其中B与A完全同步，C收到P1、P2、C1，D收到P1、P2，E收到P1，如下图所示。<br><!--
![Leader Failover step 1](http://www.jasongj.com/img/zookeeper/1_architecture/recovery_1.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/recovery_1.png" alt="Leader Failover step 1"><br></div>

<p>这里要注意</p>
<ul>
<li>由于A没有C3，意味着收到P3的服务器的总个数不会超过一半，也即包含A在内最多只有两台服务器收到P3。在这里A和B收到P3，其它服务器均未收到P3</li>
<li>由于A已写入C1、C2，说明它已经Commit了P1、P2，因此整个集群有超过一半的服务器，即最少三个服务器收到P1、P2。在这里所有服务器都收到了P1，除E外其它服务器也都收到了P2</li>
</ul>
<p><strong><em>选出新Leader</em></strong><br>旧Leader也即A宕机后，其它服务器根据上述FastLeaderElection算法选出B作为新的Leader。C、D和E成为Follower且以B为Leader后，会主动将自己最大的zxid发送给B，B会将Follower的zxid与自身zxid间的所有被Commit过的消息同步给Follower，如下图所示。</p>
<!--
![Leader Failover step 2](http://www.jasongj.com/img/zookeeper/1_architecture/recovery_2.png)
-->
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/recovery_2.png" alt="Leader Failover step 2"><br></div>

<p>在上图中</p>
<ul>
<li>P1和P2都被A Commit，因此B会通过同步保证P1、P2、C1与C2都存在于C、D和E中</li>
<li>P3由于未被A Commit，同时幸存的所有服务器中P3未存在于大多数据服务器中，因此它不会被同步到其它Follower</li>
</ul>
<p><strong><em>通知Follower可对外服务</em></strong><br>同步完数据后，B会向D、C和E发送NEWLEADER命令并等待大多数服务器的ACK（下图中D和E已返回ACK，加上B自身，已经占集群的大多数），然后向所有服务器广播UPTODATE命令。收到该命令后的服务器即可对外提供服务。<br><!--
![Leader Failover step 3](http://www.jasongj.com/img/zookeeper/1_architecture/recovery_3.png)
--></p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/recovery_3.png" alt="Leader Failover step 3"><br></div>

<h2 id="未Commit过的消息对客户端不可见"><a href="#未Commit过的消息对客户端不可见" class="headerlink" title="未Commit过的消息对客户端不可见"></a>未Commit过的消息对客户端不可见</h2><p>在上例中，P3未被A Commit过，同时因为没有过半的服务器收到P3，因此B也未Commit P3（如果有过半服务器收到P3，即使A未Commit P3，B会主动Commit P3，即C3），所以它不会将P3广播出去。</p>
<p>具体做法是，B在成为Leader后，先判断自身未Commit的消息（本例中即P3）是否存在于大多数服务器中从而决定是否要将其Commit。然后B可得出自身所包含的被Commit过的消息中的最小zxid（记为min_zxid）与最大zxid（记为max_zxid）。C、D和E向B发送自身Commit过的最大消息zxid（记为max_zxid）以及未被Commit过的所有消息（记为zxid_set）。B根据这些信息作出如下操作</p>
<ul>
<li>如果Follower的max_zxid与Leader的max_zxid相等，说明该Follower与Leader完全同步，无须同步任何数据</li>
<li>如果Follower的max_zxid在Leader的(min_zxid，max_zxid)范围内，Leader会通过TRUNC命令通知Follower将其zxid_set中大于Follower的max_zxid（如果有）的所有消息全部删除</li>
</ul>
<p>上述操作保证了未被Commit过的消息不会被Commit从而对外不可见。</p>
<p>上述例子中Follower上并不存在未被Commit的消息。但可考虑这种情况，如果将上述例子中的服务器数量从五增加到七，服务器F包含P1、P2、C1、P3，服务器G包含P1、P2。此时服务器F、A和B都包含P3，但是因为票数未过半，因此B作为Leader不会Commit P3，而会通过TRUNC命令通知F删除P3。如下图所示。</p>
<!--
![Leader Failover step 4](http://www.jasongj.com/img/zookeeper/1_architecture/recovery_4.png)
-->
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/zookeeper/1_architecture/recovery_4.png" alt="Leader Failover step 4"><br></div>

<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>由于使用主从复制模式，所有的写操作都要由Leader主导完成，而读操作可通过任意节点完成，因此Zookeeper读性能远好于写性能，更适合读多写少的场景</li>
<li>虽然使用主从复制模式，同一时间只有一个Leader，但是Failover机制保证了集群不存在单点失败（SPOF）的问题</li>
<li>ZAB协议保证了Failover过程中的数据一致性</li>
<li>服务器收到数据后先写本地文件再进行处理，保证了数据的持久性</li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Zookeeper的架构，并组合实例分析了原子广播(ZAB)协议的原理，包括但不限于Zookeeper的读写流程，FastLeaderElection算法的原理，ZAB如何保证Leader Failover过程中的数据一致性。
    
    </summary>
    
      <category term="zookeeper" scheme="http://www.jasongj.com/categories/zookeeper/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/zookeeper/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/zookeeper/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/zookeeper/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="zookeeper" scheme="http://www.jasongj.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（八）- Exactly Once语义与事务机制原理</title>
    <link href="http://www.jasongj.com/kafka/transaction/"/>
    <id>http://www.jasongj.com/kafka/transaction/</id>
    <published>2017-11-04T00:01:01.000Z</published>
    <updated>2017-11-05T00:01:01.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/kafka/transaction/">原文链接</a>　<a href="http://www.jasongj.com/kafka/transaction/">http://www.jasongj.com/kafka/transaction/</a></p>
</blockquote>
<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><p>本文所有Kafka原理性的描述除特殊说明外均基于Kafka 1.0.0版本。</p>
<h1 id="为什么要提供事务机制"><a href="#为什么要提供事务机制" class="headerlink" title="为什么要提供事务机制"></a>为什么要提供事务机制</h1><p>Kafka事务机制的实现主要是为了支持</p>
<ul>
<li><code>Exactly Once</code>即正好一次语义</li>
<li>操作的原子性</li>
<li>有状态操作的可恢复性</li>
</ul>
<h2 id="Exactly-Once"><a href="#Exactly-Once" class="headerlink" title="Exactly Once"></a><code>Exactly Once</code></h2><p>《<a href="/2015/03/10/KafkaColumn1/#Kafka-delivery-guarantee">Kafka背景及架构介绍</a>》一文中有说明Kafka在0.11.0.0之前的版本中只支持<code>At Least Once</code>和<code>At Most Once</code>语义，尚不支持<code>Exactly Once</code>语义。</p>
<p>但是在很多要求严格的场景下，如使用Kafka处理交易数据，<code>Exactly Once</code>语义是必须的。我们可以通过让下游系统具有幂等性来配合Kafka的<code>At Least Once</code>语义来间接实现<code>Exactly Once</code>。但是：</p>
<ul>
<li>该方案要求下游系统支持幂等操作，限制了Kafka的适用场景</li>
<li>实现门槛相对较高，需要用户对Kafka的工作机制非常了解</li>
<li>对于Kafka Stream而言，Kafka本身即是自己的下游系统，但Kafka在0.11.0.0版本之前不具有幂等发送能力</li>
</ul>
<p>因此，Kafka本身对<code>Exactly Once</code>语义的支持就非常必要。</p>
<h2 id="操作原子性"><a href="#操作原子性" class="headerlink" title="操作原子性"></a>操作原子性</h2><p>操作的原子性是指，多个操作要么全部成功要么全部失败，不存在部分成功部分失败的可能。</p>
<p>实现原子性操作的意义在于：</p>
<ul>
<li>操作结果更可控，有助于提升数据一致性</li>
<li>便于故障恢复。因为操作是原子的，从故障中恢复时只需要重试该操作（如果原操作失败）或者直接跳过该操作（如果原操作成功），而不需要记录中间状态，更不需要针对中间状态作特殊处理</li>
</ul>
<h1 id="实现事务机制的几个阶段"><a href="#实现事务机制的几个阶段" class="headerlink" title="实现事务机制的几个阶段"></a>实现事务机制的几个阶段</h1><h2 id="幂等性发送"><a href="#幂等性发送" class="headerlink" title="幂等性发送"></a>幂等性发送</h2><p>上文提到，实现<code>Exactly Once</code>的一种方法是让下游系统具有幂等处理特性，而在Kafka Stream中，Kafka Producer本身就是“下游”系统，因此如果能让Producer具有幂等处理特性，那就可以让Kafka Stream在一定程度上支持<code>Exactly once</code>语义。</p>
<p>为了实现Producer的幂等语义，Kafka引入了<code>Producer ID</code>（即<code>PID</code>）和<code>Sequence Number</code>。每个新的Producer在初始化的时候会被分配一个唯一的PID，该PID对用户完全透明而不会暴露给用户。</p>
<p>对于每个PID，该Producer发送数据的每个<code>&lt;Topic, Partition&gt;</code>都对应一个从0开始单调递增的<code>Sequence Number</code>。</p>
<p>类似地，Broker端也会为每个<code>&lt;PID, Topic, Partition&gt;</code>维护一个序号，并且每次Commit一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比Broker维护的序号（即最后一次Commit的消息的序号）大一，则Broker会接受它，否则将其丢弃：</p>
<ul>
<li>如果消息序号比Broker维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时Broker拒绝该消息，Producer抛出<code>InvalidSequenceNumber</code></li>
<li>如果消息序号小于等于Broker维护的序号，说明该消息已被保存，即为重复消息，Broker直接丢弃该消息，Producer抛出<code>DuplicateSequenceNumber</code></li>
</ul>
<p>上述设计解决了0.11.0.0之前版本中的两个问题：</p>
<ul>
<li>Broker保存消息后，发送ACK前宕机，Producer认为消息未发送成功并重试，造成数据重复</li>
<li>前一条消息发送失败，后一条消息发送成功，前一条消息重试后成功，造成数据乱序</li>
</ul>
<h2 id="事务性保证"><a href="#事务性保证" class="headerlink" title="事务性保证"></a>事务性保证</h2><p>上述幂等设计只能保证单个Producer对于同一个<code>&lt;Topic, Partition&gt;</code>的<code>Exactly Once</code>语义。</p>
<p>另外，它并不能保证写操作的原子性——即多个写操作，要么全部被Commit要么全部不被Commit。</p>
<p>更不能保证多个读写操作的的原子性。尤其对于Kafka Stream应用而言，典型的操作即是从某个Topic消费数据，经过一系列转换后写回另一个Topic，保证从源Topic的读取与向目标Topic的写入的原子性有助于从故障中恢复。</p>
<p>事务保证可使得应用程序将生产数据和消费数据当作一个原子单元来处理，要么全部成功，要么全部失败，即使该生产或消费跨多个<code>&lt;Topic, Partition&gt;</code>。</p>
<p>另外，有状态的应用也可以保证重启后从断点处继续处理，也即事务恢复。</p>
<p>为了实现这种效果，应用程序必须提供一个稳定的（重启后不变）唯一的ID，也即<code>Transaction ID</code>。<code>Transactin ID</code>与<code>PID</code>可能一一对应。区别在于<code>Transaction ID</code>由用户提供，而<code>PID</code>是内部的实现对用户透明。</p>
<p>另外，为了保证新的Producer启动后，旧的具有相同<code>Transaction ID</code>的Producer即失效，每次Producer通过<code>Transaction ID</code>拿到PID的同时，还会获取一个单调递增的epoch。由于旧的Producer的epoch比新Producer的epoch小，Kafka可以很容易识别出该Producer是老的Producer并拒绝其请求。</p>
<p>有了<code>Transaction ID</code>后，Kafka可保证：</p>
<ul>
<li>跨Session的数据幂等发送。当具有相同<code>Transaction ID</code>的新的Producer实例被创建且工作时，旧的且拥有相同<code>Transaction ID</code>的Producer将不再工作。</li>
<li>跨Session的事务恢复。如果某个应用实例宕机，新的实例可以保证任何未完成的旧的事务要么Commit要么Abort，使得新实例从一个正常状态开始工作。</li>
</ul>
<p>需要注意的是，上述的事务保证是从Producer的角度去考虑的。从Consumer的角度来看，该保证会相对弱一些。尤其是不能保证所有被某事务Commit过的所有消息都被一起消费，因为：</p>
<ul>
<li>对于压缩的Topic而言，同一事务的某些消息可能被其它版本覆盖</li>
<li>事务包含的消息可能分布在多个Segment中（即使在同一个Partition内），当老的Segment被删除时，该事务的部分数据可能会丢失</li>
<li>Consumer在一个事务内可能通过seek方法访问任意Offset的消息，从而可能丢失部分消息</li>
<li>Consumer可能并不需要消费某一事务内的所有Partition，因此它将永远不会读取组成该事务的所有消息</li>
</ul>
<h1 id="事务机制原理"><a href="#事务机制原理" class="headerlink" title="事务机制原理"></a>事务机制原理</h1><h2 id="事务性消息传递"><a href="#事务性消息传递" class="headerlink" title="事务性消息传递"></a>事务性消息传递</h2><p>这一节所说的事务主要指原子性，也即Producer将多条消息作为一个事务批量发送，要么全部成功要么全部失败。</p>
<p>为了实现这一点，Kafka 0.11.0.0引入了一个服务器端的模块，名为<code>Transaction Coordinator</code>，用于管理Producer发送的消息的事务性。</p>
<p>该<code>Transaction Coordinator</code>维护<code>Transaction Log</code>，该log存于一个内部的Topic内。由于Topic数据具有持久性，因此事务的状态也具有持久性。</p>
<p>Producer并不直接读写<code>Transaction Log</code>，它与<code>Transaction Coordinator</code>通信，然后由<code>Transaction Coordinator</code>将该事务的状态插入相应的<code>Transaction Log</code>。</p>
<p><code>Transaction Log</code>的设计与<code>Offset Log</code>用于保存Consumer的Offset类似。</p>
<h2 id="事务中Offset的提交"><a href="#事务中Offset的提交" class="headerlink" title="事务中Offset的提交"></a>事务中Offset的提交</h2><p>许多基于Kafka的应用，尤其是Kafka Stream应用中同时包含Consumer和Producer，前者负责从Kafka中获取消息，后者负责将处理完的数据写回Kafka的其它Topic中。</p>
<p>为了实现该场景下的事务的原子性，Kafka需要保证对Consumer Offset的Commit与Producer对发送消息的Commit包含在同一个事务中。否则，如果在二者Commit中间发生异常，根据二者Commit的顺序可能会造成数据丢失和数据重复：</p>
<ul>
<li>如果先Commit Producer发送数据的事务再Commit Consumer的Offset，即<code>At Least Once</code>语义，可能造成数据重复。</li>
<li>如果先Commit Consumer的Offset，再Commit Producer数据发送事务，即<code>At Most Once</code>语义，可能造成数据丢失。</li>
</ul>
<h2 id="用于事务特性的控制型消息"><a href="#用于事务特性的控制型消息" class="headerlink" title="用于事务特性的控制型消息"></a>用于事务特性的控制型消息</h2><p>为了区分写入Partition的消息被Commit还是Abort，Kafka引入了一种特殊类型的消息，即<code>Control Message</code>。该类消息的Value内不包含任何应用相关的数据，并且不会暴露给应用程序。它只用于Broker与Client间的内部通信。</p>
<p>对于Producer端事务，Kafka以Control Message的形式引入一系列的<code>Transaction Marker</code>。Consumer即可通过该标记判定对应的消息被Commit了还是Abort了，然后结合该Consumer配置的隔离级别决定是否应该将该消息返回给应用程序。</p>
<h2 id="事务处理样例代码"><a href="#事务处理样例代码" class="headerlink" title="事务处理样例代码"></a>事务处理样例代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</div><div class="line">    </div><div class="line"><span class="comment">// 初始化事务，包括结束该Transaction ID对应的未完成的事务（如果有）</span></div><div class="line"><span class="comment">// 保证新的事务在一个正确的状态下启动</span></div><div class="line">producer.initTransactions();</div><div class="line"></div><div class="line"><span class="comment">// 开始事务</span></div><div class="line">producer.beginTransaction();</div><div class="line"></div><div class="line"><span class="comment">// 消费数据</span></div><div class="line">ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</div><div class="line"></div><div class="line"><span class="keyword">try</span>&#123;</div><div class="line">    <span class="comment">// 发送数据</span></div><div class="line">    producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"Topic"</span>, <span class="string">"Key"</span>, <span class="string">"Value"</span>));</div><div class="line">    </div><div class="line">    <span class="comment">// 发送消费数据的Offset，将上述数据消费与数据发送纳入同一个Transaction内</span></div><div class="line">    producer.sendOffsetsToTransaction(offsets, <span class="string">"group1"</span>);</div><div class="line"></div><div class="line">    <span class="comment">// 数据发送及Offset发送均成功的情况下，提交事务</span></div><div class="line">    producer.commitTransaction();</div><div class="line">&#125; <span class="keyword">catch</span> (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) &#123;</div><div class="line">    <span class="comment">// 数据发送或者Offset发送出现异常时，终止事务</span></div><div class="line">    producer.abortTransaction();</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">    <span class="comment">// 关闭Producer和Consumer</span></div><div class="line">    producer.close();</div><div class="line">    consumer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="完整事务过程"><a href="#完整事务过程" class="headerlink" title="完整事务过程"></a>完整事务过程</h2><p><img src="http://www.jasongj.com/img/kafka/KafkaColumn8/KafkaTransaction.png" alt="Kafka Transaction"></p>
<h3 id="找到Transaction-Coordinator"><a href="#找到Transaction-Coordinator" class="headerlink" title="找到Transaction Coordinator"></a>找到<code>Transaction Coordinator</code></h3><p>由于<code>Transaction Coordinator</code>是分配PID和管理事务的核心，因此Producer要做的第一件事情就是通过向任意一个Broker发送<code>FindCoordinator</code>请求找到<code>Transaction Coordinator</code>的位置。</p>
<p>注意：只有应用程序为Producer配置了<code>Transaction ID</code>时才可使用事务特性，也才需要这一步。另外，由于事务性要求Producer开启幂等特性，因此通过将<code>transactional.id</code>设置为非空从而开启事务特性的同时也需要通过将<code>enable.idempotence</code>设置为true来开启幂等特性。</p>
<h3 id="获取PID"><a href="#获取PID" class="headerlink" title="获取PID"></a>获取PID</h3><p>找到<code>Transaction Coordinator</code>后，具有幂等特性的Producer必须发起<code>InitPidRequest</code>请求以获取PID。</p>
<p>注意：只要开启了幂等特性即必须执行该操作，而无须考虑该Producer是否开启了事务特性。</p>
<p><strong><em> 如果事务特性被开启 </em></strong><br><code>InitPidRequest</code>会发送给<code>Transaction Coordinator</code>。如果<code>Transaction Coordinator</code>是第一次收到包含有该<code>Transaction ID</code>的InitPidRequest请求，它将会把该<code>&lt;TransactionID, PID&gt;</code>存入<code>Transaction Log</code>，如上图中步骤2.1所示。这样可保证该对应关系被持久化，从而保证即使<code>Transaction Coordinator</code>宕机该对应关系也不会丢失。</p>
<p>除了返回PID外，<code>InitPidRequest</code>还会执行如下任务：</p>
<ul>
<li>增加该PID对应的epoch。具有相同PID但epoch小于该epoch的其它Producer（如果有）新开启的事务将被拒绝。</li>
<li>恢复（Commit或Abort）之前的Producer未完成的事务（如果有）。</li>
</ul>
<p>注意：<code>InitPidRequest</code>的处理过程是同步阻塞的。一旦该调用正确返回，Producer即可开始新的事务。</p>
<p>另外，如果事务特性未开启，<code>InitPidRequest</code>可发送至任意Broker，并且会得到一个全新的唯一的PID。该Producer将只能使用幂等特性以及单一Session内的事务特性，而不能使用跨Session的事务特性。</p>
<h3 id="开启事务"><a href="#开启事务" class="headerlink" title="开启事务"></a>开启事务</h3><p>Kafka从0.11.0.0版本开始，提供<code>beginTransaction()</code>方法用于开启一个事务。调用该方法后，Producer本地会记录已经开启了事务，但<code>Transaction Coordinator</code>只有在Producer发送第一条消息后才认为事务已经开启。</p>
<h3 id="Consume-Transform-Produce"><a href="#Consume-Transform-Produce" class="headerlink" title="Consume-Transform-Produce"></a>Consume-Transform-Produce</h3><p>这一阶段，包含了整个事务的数据处理过程，并且包含了多种请求。</p>
<p><strong><em>AddPartitionsToTxnRequest</em></strong><br>一个Producer可能会给多个<code>&lt;Topic, Partition&gt;</code>发送数据，给一个新的<code>&lt;Topic, Partition&gt;</code>发送数据前，它需要先向<code>Transaction Coordinator</code>发送<code>AddPartitionsToTxnRequest</code>。</p>
<p><code>Transaction Coordinator</code>会将该<code>&lt;Transaction, Topic, Partition&gt;</code>存于<code>Transaction Log</code>内，并将其状态置为<code>BEGIN</code>，如上图中步骤4.1所示。有了该信息后，我们才可以在后续步骤中为每个<code>Topic, Partition&gt;</code>设置COMMIT或者ABORT标记（如上图中步骤5.2所示）。</p>
<p>另外，如果该<code>&lt;Topic, Partition&gt;</code>为该事务中第一个<code>&lt;Topic, Partition&gt;</code>，<code>Transaction Coordinator</code>还会启动对该事务的计时（每个事务都有自己的超时时间）。</p>
<p><strong><em>ProduceRequest</em></strong><br>Producer通过一个或多个<code>ProduceRequest</code>发送一系列消息。除了应用数据外，该请求还包含了PID，epoch，和<code>Sequence Number</code>。该过程如上图中步骤4.2所示。</p>
<p><strong><em>AddOffsetsToTxnRequest</em></strong><br>为了提供事务性，Producer新增了<code>sendOffsetsToTransaction</code>方法，该方法将多组消息的发送和消费放入同一批处理内。</p>
<p>该方法先判断在当前事务中该方法是否已经被调用并传入了相同的Group ID。若是，直接跳到下一步；若不是，则向<code>Transaction Coordinator</code>发送<code>AddOffsetsToTxnRequests</code>请求，<code>Transaction Coordinator</code>将对应的所有<code>&lt;Topic, Partition&gt;</code>存于<code>Transaction Log</code>中，并将其状态记为<code>BEGIN</code>，如上图中步骤4.3所示。该方法会阻塞直到收到响应。</p>
<p><strong><em>TxnOffsetCommitRequest</em></strong><br>作为<code>sendOffsetsToTransaction</code>方法的一部分，在处理完<code>AddOffsetsToTxnRequest</code>后，Producer也会发送<code>TxnOffsetCommit</code>请求给<code>Consumer Coordinator</code>从而将本事务包含的与读操作相关的各<code>&lt;Topic, Partition&gt;</code>的Offset持久化到内部的<code>__consumer_offsets</code>中，如上图步骤4.4所示。</p>
<p>在此过程中，<code>Consumer Coordinator</code>会通过PID和对应的epoch来验证是否应该允许该Producer的该请求。</p>
<p>这里需要注意：</p>
<ul>
<li>写入<code>__consumer_offsets</code>的Offset信息在当前事务Commit前对外是不可见的。也即在当前事务被Commit前，可认为该Offset尚未Commit，也即对应的消息尚未被完成处理。</li>
<li><code>Consumer Coordinator</code>并不会立即更新缓存中相应<code>&lt;Topic, Partition&gt;</code>的Offset，因为此时这些更新操作尚未被COMMIT或ABORT。</li>
</ul>
<h3 id="Commit或Abort事务"><a href="#Commit或Abort事务" class="headerlink" title="Commit或Abort事务"></a>Commit或Abort事务</h3><p>一旦上述数据写入操作完成，应用程序必须调用<code>KafkaProducer</code>的<code>commitTransaction</code>方法或者<code>abortTransaction</code>方法以结束当前事务。</p>
<p><strong><em>EndTxnRequest</em></strong><br><code>commitTransaction</code>方法使得Producer写入的数据对下游Consumer可见。<code>abortTransaction</code>方法通过<code>Transaction Marker</code>将Producer写入的数据标记为<code>Aborted</code>状态。下游的Consumer如果将<code>isolation.level</code>设置为<code>READ_COMMITTED</code>，则它读到被Abort的消息后直接将其丢弃而不会返回给客户程序，也即被Abort的消息对应用程序不可见。</p>
<p>无论是Commit还是Abort，Producer都会发送<code>EndTxnRequest</code>请求给<code>Transaction Coordinator</code>，并通过标志位标识是应该Commit还是Abort。</p>
<p>收到该请求后，<code>Transaction Coordinator</code>会进行如下操作</p>
<ol>
<li>将<code>PREPARE_COMMIT</code>或<code>PREPARE_ABORT</code>消息写入<code>Transaction Log</code>，如上图中步骤5.1所示</li>
<li>通过<code>WriteTxnMarker</code>请求以<code>Transaction Marker</code>的形式将<code>COMMIT</code>或<code>ABORT</code>信息写入用户数据日志以及<code>Offset Log</code>中，如上图中步骤5.2所示</li>
<li>最后将<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>信息写入<code>Transaction Log</code>中，如上图中步骤5.3所示</li>
</ol>
<p>补充说明：对于<code>commitTransaction</code>方法，它会在发送<code>EndTxnRequest</code>之前先调用flush方法以确保所有发送出去的数据都得到相应的ACK。对于<code>abortTransaction</code>方法，在发送<code>EndTxnRequest</code>之前直接将当前Buffer中的事务性消息（如果有）全部丢弃，但必须等待所有被发送但尚未收到ACK的消息发送完成。</p>
<p>上述第二步是实现将一组读操作与写操作作为一个事务处理的关键。因为Producer写入的数据Topic以及记录Comsumer Offset的Topic会被写入相同的<code>Transactin Marker</code>，所以这一组读操作与写操作要么全部COMMIT要么全部ABORT。</p>
<p><strong><em>WriteTxnMarkerRequest</em></strong><br>上面提到的<code>WriteTxnMarkerRequest</code>由<code>Transaction Coordinator</code>发送给当前事务涉及到的每个<code>&lt;Topic, Partition&gt;</code>的Leader。收到该请求后，对应的Leader会将对应的<code>COMMIT(PID)</code>或者<code>ABORT(PID)</code>控制信息写入日志，如上图中步骤5.2所示。</p>
<p>该控制消息向Broker以及Consumer表明对应PID的消息被Commit了还是被Abort了。</p>
<p>这里要注意，如果事务也涉及到<code>__consumer_offsets</code>，即该事务中有消费数据的操作且将该消费的Offset存于<code>__consumer_offsets</code>中，<code>Transaction Coordinator</code>也需要向该内部Topic的各Partition的Leader发送<code>WriteTxnMarkerRequest</code>从而写入<code>COMMIT(PID)</code>或<code>COMMIT(PID)</code>控制信息。</p>
<p><strong><em>写入最终的<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>消息</em></strong><br>写完所有的<code>Transaction Marker</code>后，<code>Transaction Coordinator</code>会将最终的<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>消息写入<code>Transaction Log</code>中以标明该事务结束，如上图中步骤5.3所示。</p>
<p>此时，<code>Transaction Log</code>中所有关于该事务的消息全部可以移除。当然，由于Kafka内数据是Append Only的，不可直接更新和删除，这里说的移除只是将其标记为null从而在Log Compact时不再保留。</p>
<p>另外，<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>的写入并不需要得到所有Rreplica的ACK，因为如果该消息丢失，可以根据事务协议重发。</p>
<p>补充说明，如果参与该事务的某些<code>&lt;Topic, Partition&gt;</code>在被写入<code>Transaction Marker</code>前不可用，它对<code>READ_COMMITTED</code>的Consumer不可见，但不影响其它可用<code>&lt;Topic, Partition&gt;</code>的COMMIT或ABORT。在该<code>&lt;Topic, Partition&gt;</code>恢复可用后，<code>Transaction Coordinator</code>会重新根据<code>PREPARE_COMMIT</code>或<code>PREPARE_ABORT</code>向该<code>&lt;Topic, Partition&gt;</code>发送<code>Transaction Marker</code>。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li><code>PID</code>与<code>Sequence Number</code>的引入实现了写操作的幂等性</li>
<li>写操作的幂等性结合<code>At Least Once</code>语义实现了单一Session内的<code>Exactly Once</code>语义</li>
<li><code>Transaction Marker</code>与<code>PID</code>提供了识别消息是否应该被读取的能力，从而实现了事务的隔离性</li>
<li>Offset的更新标记了消息是否被读取，从而将对读操作的事务处理转换成了对写（Offset）操作的事务处理</li>
<li>Kafka事务的本质是，将一组写操作（如果有）对应的消息与一组读操作（如果有）对应的Offset的更新进行同样的标记（即<code>Transaction Marker</code>）来实现事务中涉及的所有读写操作同时对外可见或同时对外不可见</li>
<li>Kafka只提供对Kafka本身的读写操作的事务性，不提供包含外部系统的事务性</li>
</ul>
<h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><h2 id="Exception处理"><a href="#Exception处理" class="headerlink" title="Exception处理"></a>Exception处理</h2><p><strong><em>InvalidProducerEpoch</em></strong><br>这是一种Fatal Error，它说明当前Producer是一个过期的实例，有<code>Transaction ID</code>相同但epoch更新的Producer实例被创建并使用。此时Producer会停止并抛出Exception。</p>
<p><strong><em>InvalidPidMapping</em></strong><br><code>Transaction Coordinator</code>没有与该<code>Transaction ID</code>对应的PID。此时Producer会通过包含有<code>Transaction ID</code>的<code>InitPidRequest</code>请求创建一个新的PID。</p>
<p><strong><em>NotCorrdinatorForGTransactionalId</em></strong><br>该<code>Transaction Coordinator</code>不负责该当前事务。Producer会通过<code>FindCoordinatorRequest</code>请求重新寻找对应的<code>Transaction Coordinator</code>。</p>
<p><strong><em>InvalidTxnRequest</em></strong><br>违反了事务协议。正确的Client实现不应该出现这种Exception。如果该异常发生了，用户需要检查自己的客户端实现是否有问题。</p>
<p><strong><em>CoordinatorNotAvailable</em></strong><br><code>Transaction Coordinator</code>仍在初始化中。Producer只需要重试即可。</p>
<p><strong><em>DuplicateSequenceNumber</em></strong><br>发送的消息的序号低于Broker预期。该异常说明该消息已经被成功处理过，Producer可以直接忽略该异常并处理下一条消息</p>
<p><strong><em>InvalidSequenceNumber</em></strong><br>这是一个Fatal Error，它说明发送的消息中的序号大于Broker预期。此时有两种可能</p>
<ul>
<li>数据乱序。比如前面的消息发送失败后重试期间，新的消息被接收。正常情况下不应该出现该问题，因为当幂等发送启用时，<code>max.inflight.requests.per.connection</code>被强制设置为1，而<code>acks</code>被强制设置为all。故前面消息重试期间，后续消息不会被发送，也即不会发生乱序。并且只有ISR中所有Replica都ACK，Producer才会认为消息已经被发送，也即不存在Broker端数据丢失问题。</li>
<li>服务器由于日志被Truncate而造成数据丢失。此时应该停止Producer并将此Fatal Error报告给用户。</li>
</ul>
<p><strong><em>InvalidTransactionTimeout</em></strong><br><code>InitPidRequest</code>调用出现的Fatal Error。它表明Producer传入的timeout时间不在可接受范围内，应该停止Producer并报告给用户。</p>
<h2 id="处理Transaction-Coordinator失败"><a href="#处理Transaction-Coordinator失败" class="headerlink" title="处理Transaction Coordinator失败"></a>处理<code>Transaction Coordinator</code>失败</h2><h3 id="写PREPARE-COMMIT-PREPARE-ABORT前失败"><a href="#写PREPARE-COMMIT-PREPARE-ABORT前失败" class="headerlink" title="写PREPARE_COMMIT/PREPARE_ABORT前失败"></a>写<code>PREPARE_COMMIT/PREPARE_ABORT</code>前失败</h3><p>Producer通过<code>FindCoordinatorRequest</code>找到新的<code>Transaction Coordinator</code>，并通过<code>EndTxnRequest</code>请求发起<code>COMMIT</code>或<code>ABORT</code>流程，新的<code>Transaction Coordinator</code>继续处理<code>EndTxnRequest</code>请求——写<code>PREPARE_COMMIT</code>或<code>PREPARE_ABORT</code>，写<code>Transaction Marker</code>，写<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>。</p>
<h3 id="写完PREPARE-COMMIT-PREPARE-ABORT后失败"><a href="#写完PREPARE-COMMIT-PREPARE-ABORT后失败" class="headerlink" title="写完PREPARE_COMMIT/PREPARE_ABORT后失败"></a>写完<code>PREPARE_COMMIT/PREPARE_ABORT</code>后失败</h3><p>此时旧的<code>Transaction Coordinator</code>可能已经成功写入部分<code>Transaction Marker</code>。新的<code>Transaction Coordinator</code>会重复这些操作，所以部分Partition中可能会存在重复的<code>COMMIT</code>或<code>ABORT</code>，但只要该Producer在此期间没有发起新的事务，这些重复的<code>Transaction Marker</code>就不是问题。</p>
<h3 id="写完COMPLETE-COMMIT-ABORT后失败"><a href="#写完COMPLETE-COMMIT-ABORT后失败" class="headerlink" title="写完COMPLETE_COMMIT/ABORT后失败"></a>写完<code>COMPLETE_COMMIT/ABORT</code>后失败</h3><p>旧的<code>Transaction Coordinator</code>可能已经写完了<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>但在返回<code>EndTxnRequest</code>之前失败。该场景下，新的<code>Transaction Coordinator</code>会直接给Producer返回成功。</p>
<h2 id="事务过期机制"><a href="#事务过期机制" class="headerlink" title="事务过期机制"></a>事务过期机制</h2><h3 id="事务超时"><a href="#事务超时" class="headerlink" title="事务超时"></a>事务超时</h3><p><code>transaction.timeout.ms</code></p>
<h3 id="终止过期事务"><a href="#终止过期事务" class="headerlink" title="终止过期事务"></a>终止过期事务</h3><p>当Producer失败时，<code>Transaction Coordinator</code>必须能够主动的让某些进行中的事务过期。否则没有Producer的参与，<code>Transaction Coordinator</code>无法判断这些事务应该如何处理，这会造成：</p>
<ul>
<li>如果这种进行中事务太多，会造成<code>Transaction Coordinator</code>需要维护大量的事务状态，大量占用内存</li>
<li><code>Transaction Log</code>内也会存在大量数据，造成新的<code>Transaction Coordinator</code>启动缓慢</li>
<li><code>READ_COMMITTED</code>的Consumer需要缓存大量的消息，造成不必要的内存浪费甚至是OOM</li>
<li>如果多个<code>Transaction ID</code>不同的Producer交叉写同一个Partition，当一个Producer的事务状态不更新时，<code>READ_COMMITTED</code>的Consumer为了保证顺序消费而被阻塞</li>
</ul>
<p>为了避免上述问题，<code>Transaction Coordinator</code>会周期性遍历内存中的事务状态Map，并执行如下操作</p>
<ul>
<li>如果状态是<code>BEGIN</code>并且其最后更新时间与当前时间差大于<code>transaction.remove.expired.transaction.cleanup.interval.ms</code>（默认值为1小时），则主动将其终止：1）未避免原Producer临时恢复与当前终止流程冲突，增加该Producer对应的PID的epoch，并确保将该更新的信息写入<code>Transaction Log</code>；2）以更新后的epoch回滚事务，从而使得该事务相关的所有Broker都更新其缓存的该PID的epoch从而拒绝旧Producer的写操作</li>
<li>如果状态是<code>PREPARE_COMMIT</code>，完成后续的COMMIT流程————向各<code>&lt;Topic, Partition&gt;</code>写入<code>Transaction Marker</code>，在<code>Transaction Log</code>内写入<code>COMPLETE_COMMIT</code></li>
<li>如果状态是<code>PREPARE_ABORT</code>，完成后续ABORT流程</li>
</ul>
<h3 id="终止Transaction-ID"><a href="#终止Transaction-ID" class="headerlink" title="终止Transaction ID"></a>终止<code>Transaction ID</code></h3><p>某<code>Transaction ID</code>的Producer可能很长时间不再发送数据，<code>Transaction Coordinator</code>没必要再保存该<code>Transaction ID</code>与<code>PID</code>等的映射，否则可能会造成大量的资源浪费。因此需要有一个机制探测不再活跃的<code>Transaction ID</code>并将其信息删除。</p>
<p><code>Transaction Coordinator</code>会周期性遍历内存中的<code>Transaction ID</code>与<code>PID</code>映射，如果某<code>Transaction ID</code>没有对应的正在进行中的事务并且它对应的最后一个事务的结束时间与当前时间差大于<code>transactional.id.expiration.ms</code>（默认值是7天），则将其从内存中删除并在<code>Transaction Log</code>中将其对应的日志的值设置为null从而使得Log Compact可将其记录删除。</p>
<h1 id="与其它系统事务机制对比"><a href="#与其它系统事务机制对比" class="headerlink" title="与其它系统事务机制对比"></a>与其它系统事务机制对比</h1><h2 id="PostgreSQL-MVCC"><a href="#PostgreSQL-MVCC" class="headerlink" title="PostgreSQL MVCC"></a>PostgreSQL MVCC</h2><p>Kafka的事务机制与《<a href="/sql/mvcc/">MVCC PostgreSQL实现事务和多版本并发控制的精华</a>》一文中介绍的PostgreSQL通过MVCC实现事务的机制非常类似，对于事务的回滚，并不需要删除已写入的数据，都是将写入数据的事务标记为Rollback/Abort从而在读数据时过滤该数据。</p>
<h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>Kafka的事务机制与《<a href="/big_data/two_phase_commit/#两阶段提交原理">分布式事务（一）两阶段提交及JTA</a>》一文中所介绍的两阶段提交机制看似相似，都分PREPARE阶段和最终COMMIT阶段，但又有很大不同。</p>
<ul>
<li>Kafka事务机制中，PREPARE时即要指明是<code>PREPARE_COMMIT</code>还是<code>PREPARE_ABORT</code>，并且只须在<code>Transaction Log</code>中标记即可，无须其它组件参与。而两阶段提交的PREPARE需要发送给所有的分布式事务参与方，并且事务参与方需要尽可能准备好，并根据准备情况返回<code>Prepared</code>或<code>Non-Prepared</code>状态给事务管理器。</li>
<li>Kafka事务中，一但发起<code>PREPARE_COMMIT</code>或<code>PREPARE_ABORT</code>，则确定该事务最终的结果应该是被<code>COMMIT</code>或<code>ABORT</code>。而分布式事务中，PREPARE后由各事务参与方返回状态，只有所有参与方均返回<code>Prepared</code>状态才会真正执行COMMIT，否则执行ROLLBACK</li>
<li>Kafka事务机制中，某几个Partition在COMMIT或ABORT过程中变为不可用，只影响该Partition不影响其它Partition。两阶段提交中，若唯一收到COMMIT命令参与者Crash，其它事务参与方无法判断事务状态从而使得整个事务阻塞</li>
<li>Kafka事务机制引入事务超时机制，有效避免了挂起的事务影响其它事务的问题</li>
<li>Kafka事务机制中存在多个<code>Transaction Coordinator</code>实例，而分布式事务中只有一个事务管理器</li>
</ul>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>Zookeeper的原子广播协议与两阶段提交以及Kafka事务机制有相似之处，但又有各自的特点</p>
<ul>
<li>Kafka事务可COMMIT也可ABORT。而Zookeeper原子广播协议只有COMMIT没有ABORT。当然，Zookeeper不COMMIT某消息也即等效于ABORT该消息的更新。</li>
<li>Kafka存在多个<code>Transaction Coordinator</code>实例，扩展性较好。而Zookeeper写操作只能在Leader节点进行，所以其写性能远低于读性能。</li>
<li>Kafka事务是COMMIT还是ABORT完全取决于Producer即客户端。而Zookeeper原子广播协议中某条消息是否被COMMIT取决于是否有一大半FOLLOWER ACK该消息。</li>
</ul>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="//www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="//www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="//www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="//www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="//www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
<li><a href="//www.jasongj.com/kafka/high_throughput/">Kafka设计解析（六）- Kafka高性能架构之道</a></li>
<li><a href="//www.jasongj.com/kafka/kafka_stream/">Kafka设计解析（七）- Kafka Stream</a></li>
<li><a href="//www.jasongj.com/kafka/transaction/">Kafka设计解析（八）- Kafka Exactly Once语义与事务机制原理</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Kafka实现事务性的几个阶段——正好一次语义与原子操作。之后详细分析了Kafka事务机制的实现原理，并介绍了Kafka如何处理事务相关的异常情况，如Transaction Coordinator宕机。最后介绍了Kafka的事务机制与PostgreSQL的MVCC以及Zookeeper的原子广播实现事务的异同
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（七）- Kafka Stream</title>
    <link href="http://www.jasongj.com/kafka/kafka_stream/"/>
    <id>http://www.jasongj.com/kafka/kafka_stream/</id>
    <published>2017-08-07T00:01:01.000Z</published>
    <updated>2017-08-07T00:01:01.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/kafka/kafka_stream/">原文链接</a>　<a href="http://www.jasongj.com/kafka/kafka_stream/">http://www.jasongj.com/kafka/kafka_stream/</a></p>
</blockquote>
<h1 id="Kafka-Stream背景"><a href="#Kafka-Stream背景" class="headerlink" title="Kafka Stream背景"></a>Kafka Stream背景</h1><h2 id="Kafka-Stream是什么"><a href="#Kafka-Stream是什么" class="headerlink" title="Kafka Stream是什么"></a>Kafka Stream是什么</h2><p>Kafka Stream是Apache Kafka从0.10版本引入的一个新Feature。它是提供了对存储于Kafka内的数据进行流式处理和分析的功能。</p>
<p>Kafka Stream的特点如下：</p>
<ul>
<li>Kafka Stream提供了一个非常简单而轻量的Library，它可以非常方便地嵌入任意Java应用中，也可以任意方式打包和部署</li>
<li>除了Kafka外，无任何外部依赖</li>
<li>充分利用Kafka分区机制实现水平扩展和顺序性保证</li>
<li>通过可容错的state store实现高效的状态操作（如windowed join和aggregation）</li>
<li>支持正好一次处理语义</li>
<li>提供记录级的处理能力，从而实现毫秒级的低延迟</li>
<li>支持基于事件时间的窗口操作，并且可处理晚到的数据（late arrival of records）</li>
<li>同时提供底层的处理原语Processor（类似于Storm的spout和bolt），以及高层抽象的DSL（类似于Spark的map/group/reduce）</li>
</ul>
<h2 id="什么是流式计算"><a href="#什么是流式计算" class="headerlink" title="什么是流式计算"></a>什么是流式计算</h2><p>一般流式计算会与批量计算相比较。在流式计算模型中，输入是持续的，可以认为在时间上是无界的，也就意味着，永远拿不到全量数据去做计算。同时，计算结果是持续输出的，也即计算结果在时间上也是无界的。流式计算一般对实时性要求较高，同时一般是先定义目标计算，然后数据到来之后将计算逻辑应用于数据。同时为了提高计算效率，往往尽可能采用增量计算代替全量计算。</p>
<div align="center"><br><img width="70%" src="//www.jasongj.com/img/kafka/KafkaColumn7/stream_procissing.png" alt="Stream Processing"><br></div>

<p>批量处理模型中，一般先有全量数据集，然后定义计算逻辑，并将计算应用于全量数据。特点是全量计算，并且计算结果一次性全量输出。</p>
<div align="center"><br><img width="70%" src="//www.jasongj.com/img/kafka/KafkaColumn7/batch_procissing.png" alt="Batch Processing"><br></div>

<h2 id="为什么要有Kafka-Stream"><a href="#为什么要有Kafka-Stream" class="headerlink" title="为什么要有Kafka Stream"></a>为什么要有Kafka Stream</h2><p>当前已经有非常多的流式处理系统，最知名且应用最多的开源流式处理系统有Spark Streaming和Apache Storm。Apache Storm发展多年，应用广泛，提供记录级别的处理能力，当前也支持SQL on Stream。而Spark Streaming基于Apache Spark，可以非常方便与图计算，SQL处理等集成，功能强大，对于熟悉其它Spark应用开发的用户而言使用门槛低。另外，目前主流的Hadoop发行版，如MapR，Cloudera和Hortonworks，都集成了Apache Storm和Apache Spark，使得部署更容易。</p>
<p>既然Apache Spark与Apache Storm拥用如此多的优势，那为何还需要Kafka Stream呢？笔者认为主要有如下原因。</p>
<p>第一，Spark和Storm都是流式处理<strong>框架</strong>，而Kafka Stream提供的是一个基于Kafka的流式处理<strong>类库</strong>。框架要求开发者按照特定的方式去开发逻辑部分，供框架调用。开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限。而Kafka Stream作为流式处理<strong>类库</strong>，直接提供具体的类给开发者调用，整个应用的运行方式主要由开发者控制，方便使用和调试。</p>
<div align="center"><br><img width="60%" src="//www.jasongj.com/img/kafka/KafkaColumn7/library.png" alt="Library vs. Framework"><br></div>

<p>第二，虽然Cloudera与Hortonworks方便了Storm和Spark的部署，但是这些框架的部署仍然相对复杂。而Kafka Stream作为类库，可以非常方便的嵌入应用程序中，它对应用的打包和部署基本没有任何要求。更为重要的是，Kafka Stream充分利用了<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/#Topic-amp-Partition">Kafka的分区机制</a>和<a href="//www.jasongj.com/2015/08/09/KafkaColumn4/#High-Level-Consumer-Rebalance">Consumer的Rebalance机制</a>，使得Kafka Stream可以非常方便的水平扩展，并且各个实例可以使用不同的部署方式。具体来说，每个运行Kafka Stream的应用程序实例都包含了Kafka Consumer实例，多个同一应用的实例之间并行处理数据集。而不同实例之间的部署方式并不要求一致，比如部分实例可以运行在Web容器中，部分实例可运行在Docker或Kubernetes中。</p>
<p>第三，就流式处理系统而言，基本都支持Kafka作为数据源。例如Storm具有专门的kafka-spout，而Spark也提供专门的spark-streaming-kafka模块。事实上，Kafka基本上是主流的流式处理系统的标准数据源。换言之，大部分流式系统中都已部署了Kafka，此时使用Kafka Stream的成本非常低。</p>
<p>第四，使用Storm或Spark Streaming时，需要为框架本身的进程预留资源，如Storm的supervisor和Spark on YARN的node manager。即使对于应用实例而言，框架本身也会占用部分资源，如Spark Streaming需要为shuffle和storage预留内存。</p>
<p>第五，由于Kafka本身提供数据持久化，因此Kafka Stream提供滚动部署和滚动升级以及重新计算的能力。</p>
<p>第六，由于Kafka Consumer Rebalance机制，Kafka Stream可以在线动态调整并行度。</p>
<h1 id="Kafka-Stream架构"><a href="#Kafka-Stream架构" class="headerlink" title="Kafka Stream架构"></a>Kafka Stream架构</h1><h2 id="Kafka-Stream整体架构"><a href="#Kafka-Stream整体架构" class="headerlink" title="Kafka Stream整体架构"></a>Kafka Stream整体架构</h2><p>Kafka Stream的整体架构图如下所示。</p>
<div align="center"><br><img width="80%" src="//www.jasongj.com/img/kafka/KafkaColumn7/Kafka%20Stream%20Architecture.png" alt="Kafka Stream Architecture"><br></div>

<p>目前（Kafka 0.11.0.0）Kafka Stream的数据源只能如上图所示是Kafka。但是处理结果并不一定要如上图所示输出到Kafka。实际上KStream和Ktable的实例化都需要指定Topic。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">KStream&lt;String, String&gt; stream = builder.stream(<span class="string">"words-stream"</span>);</div><div class="line"></div><div class="line">KTable&lt;String, String&gt; table = builder.table(<span class="string">"words-table"</span>, <span class="string">"words-store"</span>);</div></pre></td></tr></table></figure></p>
<p>另外，上图中的Consumer和Producer并不需要开发者在应用中显示实例化，而是由Kafka Stream根据参数隐式实例化和管理，从而降低了使用门槛。开发者只需要专注于开发核心业务逻辑，也即上图中Task内的部分。</p>
<h2 id="Processor-Topology"><a href="#Processor-Topology" class="headerlink" title="Processor Topology"></a>Processor Topology</h2><p>基于Kafka Stream的流式应用的业务逻辑全部通过一个被称为Processor Topology的地方执行。它与Storm的Topology和Spark的DAG类似，都定义了数据在各个处理单元（在Kafka Stream中被称作Processor）间的流动方式，或者说定义了数据的处理逻辑。</p>
<p>下面是一个Processor的示例，它实现了Word Count功能，并且每秒输出一次结果。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountProcessor</span> <span class="keyword">implements</span> <span class="title">Processor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> ProcessorContext context;</div><div class="line">  <span class="keyword">private</span> KeyValueStore&lt;String, Integer&gt; kvStore;</div><div class="line"></div><div class="line">  <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(ProcessorContext context)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.context = context;</div><div class="line">    <span class="keyword">this</span>.context.schedule(<span class="number">1000</span>);</div><div class="line">    <span class="keyword">this</span>.kvStore = (KeyValueStore&lt;String, Integer&gt;) context.getStateStore(<span class="string">"Counts"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(String key, String value)</span> </span>&#123;</div><div class="line">    Stream.of(value.toLowerCase().split(<span class="string">" "</span>)).forEach((String word) -&gt; &#123;</div><div class="line">      Optional&lt;Integer&gt; counts = Optional.ofNullable(kvStore.get(word));</div><div class="line">      <span class="keyword">int</span> count = counts.map(wordcount -&gt; wordcount + <span class="number">1</span>).orElse(<span class="number">1</span>);</div><div class="line">      kvStore.put(word, count);</div><div class="line">    &#125;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">punctuate</span><span class="params">(<span class="keyword">long</span> timestamp)</span> </span>&#123;</div><div class="line">    KeyValueIterator&lt;String, Integer&gt; iterator = <span class="keyword">this</span>.kvStore.all();</div><div class="line">    iterator.forEachRemaining(entry -&gt; &#123;</div><div class="line">      context.forward(entry.key, entry.value);</div><div class="line">      <span class="keyword">this</span>.kvStore.delete(entry.key);</div><div class="line">    &#125;);</div><div class="line">    context.commit();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.kvStore.close();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上述代码中可见</p>
<ul>
<li><code>process</code>定义了对每条记录的处理逻辑，也印证了Kafka可具有记录级的数据处理能力。</li>
<li>context.scheduler定义了punctuate被执行的周期，从而提供了实现窗口操作的能力。</li>
<li>context.getStateStore提供的状态存储为有状态计算（如窗口，聚合）提供了可能。</li>
</ul>
<h2 id="Kafka-Stream并行模型"><a href="#Kafka-Stream并行模型" class="headerlink" title="Kafka Stream并行模型"></a>Kafka Stream并行模型</h2><p>Kafka Stream的并行模型中，最小粒度为Task，而每个Task包含一个特定子Topology的所有Processor。因此每个Task所执行的代码完全一样，唯一的不同在于所处理的数据集互补。这一点跟Storm的Topology完全不一样。Storm的Topology的每一个Task只包含一个Spout或Bolt的实例。因此Storm的一个Topology内的不同Task之间需要通过网络通信传递数据，而Kafka Stream的Task包含了完整的子Topology，所以Task之间不需要传递数据，也就不需要网络通信。这一点降低了系统复杂度，也提高了处理效率。</p>
<p>如果某个Stream的输入Topic有多个(比如2个Topic，1个Partition数为4，另一个Partition数为3)，则总的Task数等于Partition数最多的那个Topic的Partition数（max(4,3)=4）。这是因为Kafka Stream使用了Consumer的Rebalance机制，每个Partition对应一个Task。</p>
<p>下图展示了在一个进程（Instance）中以2个Topic（Partition数均为4）为数据源的Kafka Stream应用的并行模型。从图中可以看到，由于Kafka Stream应用的默认线程数为1，所以4个Task全部在一个线程中运行。</p>
<div align="center"><br><img width="80%" alt="1 thread" src="//www.jasongj.com/img/kafka/KafkaColumn7/1%20thread.png"><br></div>

<p>为了充分利用多线程的优势，可以设置Kafka Stream的线程数。下图展示了线程数为2时的并行模型。</p>
<div align="center"><br><img width="80%" alt="2 threads" src="//www.jasongj.com/img/kafka/KafkaColumn7/2%20threads.png"><br></div>

<p>前文有提到，Kafka Stream可被嵌入任意Java应用（理论上基于JVM的应用都可以）中，下图展示了在同一台机器的不同进程中同时启动同一Kafka Stream应用时的并行模型。注意，这里要保证两个进程的<code>StreamsConfig.APPLICATION_ID_CONFIG</code>完全一样。因为Kafka Stream将APPLICATION_ID_CONFIG作为隐式启动的Consumer的Group ID。只有保证APPLICATION_ID_CONFIG相同，才能保证这两个进程的Consumer属于同一个Group，从而可以通过Consumer Rebalance机制拿到互补的数据集。</p>
<div align="center"><br><img width="80%" alt="2 instances" src="//www.jasongj.com/img/kafka/KafkaColumn7/2%20instances.png"><br></div>

<p>既然实现了多进程部署，可以以同样的方式实现多机器部署。该部署方式也要求所有进程的APPLICATION_ID_CONFIG完全一样。从图上也可以看到，每个实例中的线程数并不要求一样。但是无论如何部署，Task总数总会保证一致。</p>
<div align="center"><br><img width="80%" alt="2 servers" src="//www.jasongj.com/img/kafka/KafkaColumn7/2%20servers.png"><br></div>

<p>注意：Kafka Stream的并行模型，非常依赖于《<a href="//www.jasongj.com/2015/03/10/KafkaColumn1">Kafka设计解析（一）- Kafka背景及架构介绍</a>》一文中介绍的<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/#Topic-amp-Partition">Kafka分区机制</a>和《<a href="//www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a>》中介绍的<a href="//www.jasongj.com/2015/08/09/KafkaColumn4/#High-Level-Consumer-Rebalance">Consumer的Rebalance机制</a>。强烈建议不太熟悉这两种机制的朋友，先行阅读这两篇文章。</p>
<p>这里对比一下Kafka Stream的Processor Topology与Storm的Topology。</p>
<ul>
<li>Storm的Topology由Spout和Bolt组成，Spout提供数据源，而Bolt提供计算和数据导出。Kafka Stream的Processor Topology完全由Processor组成，因为它的数据固定由Kafka的Topic提供。</li>
<li>Storm的不同Bolt运行在不同的Executor中，很可能位于不同的机器，需要通过网络通信传输数据。而Kafka Stream的Processor Topology的不同Processor完全运行于同一个Task中，也就完全处于同一个线程，无需网络通信。</li>
<li>Storm的Topology可以同时包含Shuffle部分和非Shuffle部分，并且往往一个Topology就是一个完整的应用。而Kafka Stream的一个物理Topology只包含非Shuffle部分，而Shuffle部分需要通过<code>through</code>操作显示完成，该操作将一个大的Topology分成了2个子Topology。</li>
<li>Storm的Topology内，不同Bolt/Spout的并行度可以不一样，而Kafka Stream的子Topology内，所有Processor的并行度完全一样。</li>
<li>Storm的一个Task只包含一个Spout或者Bolt的实例，而Kafka Stream的一个Task包含了一个子Topology的所有Processor。</li>
</ul>
<h2 id="KTable-vs-KStream"><a href="#KTable-vs-KStream" class="headerlink" title="KTable vs. KStream"></a>KTable vs. KStream</h2><p>KTable和KStream是Kafka Stream中非常重要的两个概念，它们是Kafka实现各种语义的基础。因此这里有必要分析下二者的区别。</p>
<p>KStream是一个数据流，可以认为所有记录都通过Insert only的方式插入进这个数据流里。而KTable代表一个完整的数据集，可以理解为数据库中的表。由于每条记录都是Key-Value对，这里可以将Key理解为数据库中的Primary Key，而Value可以理解为一行记录。可以认为KTable中的数据都是通过Update only的方式进入的。也就意味着，如果KTable对应的Topic中新进入的数据的Key已经存在，那么从KTable只会取出同一Key对应的最后一条数据，相当于新的数据更新了旧的数据。</p>
<p>以下图为例，假设有一个KStream和KTable，基于同一个Topic创建，并且该Topic中包含如下图所示5条数据。此时遍历KStream将得到与Topic内数据完全一样的所有5条数据，且顺序不变。而此时遍历KTable时，因为这5条记录中有3个不同的Key，所以将得到3条记录，每个Key对应最新的值，并且这三条数据之间的顺序与原来在Topic中的顺序保持一致。这一点与Kafka的日志compact相同。</p>
<div align="center"><br><img width="60%" alt="KStream vs. KTable" src="//www.jasongj.com/img/kafka/KafkaColumn7/ktable_kstream.png"><br></div>

<p>此时如果对该KStream和KTable分别基于key做Group，对Value进行Sum，得到的结果将会不同。对KStream的计算结果是<code>&lt;Jack，4&gt;</code>，<code>&lt;Lily，7&gt;</code>，<code>&lt;Mike，4&gt;</code>。而对Ktable的计算结果是<code>&lt;Mike，4&gt;</code>，<code>&lt;Jack，3&gt;</code>，<code>&lt;Lily，5&gt;</code>。</p>
<h2 id="State-store"><a href="#State-store" class="headerlink" title="State store"></a>State store</h2><p>流式处理中，部分操作是无状态的，例如过滤操作（Kafka Stream DSL中用<code>filer</code>方法实现）。而部分操作是有状态的，需要记录中间状态，如Window操作和聚合计算。State store被用来存储中间状态。它可以是一个持久化的Key-Value存储，也可以是内存中的HashMap，或者是数据库。Kafka提供了基于Topic的状态存储。</p>
<p>Topic中存储的数据记录本身是Key-Value形式的，同时Kafka的log compaction机制可对历史数据做compact操作，保留每个Key对应的最后一个Value，从而在保证Key不丢失的前提下，减少总数据量，从而提高查询效率。</p>
<p>构造KTable时，需要指定其state store name。默认情况下，该名字也即用于存储该KTable的状态的Topic的名字，遍历KTable的过程，实际就是遍历它对应的state store，或者说遍历Topic的所有key，并取每个Key最新值的过程。为了使得该过程更加高效，默认情况下会对该Topic进行compact操作。</p>
<p>另外，除了KTable，所有状态计算，都需要指定state store name，从而记录中间状态。</p>
<h1 id="Kafka-Stream如何解决流式系统中关键问题"><a href="#Kafka-Stream如何解决流式系统中关键问题" class="headerlink" title="Kafka Stream如何解决流式系统中关键问题"></a>Kafka Stream如何解决流式系统中关键问题</h1><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><p>在流式数据处理中，时间是数据的一个非常重要的属性。从Kafka 0.10开始，每条记录除了Key和Value外，还增加了<code>timestamp</code>属性。目前Kafka Stream支持三种时间</p>
<ul>
<li>事件发生时间。事件发生的时间，包含在数据记录中。发生时间由Producer在构造ProducerRecord时指定。并且需要Broker或者Topic将<code>message.timestamp.type</code>设置为<code>CreateTime</code>（默认值）才能生效。</li>
<li>消息接收时间，也即消息存入Broker的时间。当Broker或Topic将<code>message.timestamp.type</code>设置为<code>LogAppendTime</code>时生效。此时Broker会在接收到消息后，存入磁盘前，将其<code>timestamp</code>属性值设置为当前机器时间。一般消息接收时间比较接近于事件发生时间，部分场景下可代替事件发生时间。</li>
<li>消息处理时间，也即Kafka Stream处理消息时的时间。</li>
</ul>
<p>注：Kafka Stream允许通过实现<code>org.apache.kafka.streams.processor.TimestampExtractor</code>接口自定义记录时间。</p>
<h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><p>前文提到，流式数据是在时间上无界的数据。而聚合操作只能作用在特定的数据集，也即有界的数据集上。因此需要通过某种方式从无界的数据集上按特定的语义选取出有界的数据。窗口是一种非常常用的设定计算边界的方式。不同的流式处理系统支持的窗口类似，但不尽相同。</p>
<p>Kafka Stream支持的窗口如下。</p>
<ol>
<li><p><code>Hopping Time Window</code> 该窗口定义如下图所示。它有两个属性，一个是Window size，一个是Advance interval。Window size指定了窗口的大小，也即每次计算的数据集的大小。而Advance interval定义输出的时间间隔。一个典型的应用场景是，每隔5秒钟输出一次过去1个小时内网站的PV或者UV。</p>
<div align="center"><br><img width="60%" alt="Hopping Time Window" src="//www.jasongj.com/img/kafka/KafkaColumn7/Hopping%20Time%20Window.gif"><br></div>
</li>
<li><p><code>Tumbling Time Window</code>该窗口定义如下图所示。可以认为它是Hopping Time Window的一种特例，也即Window size和Advance interval相等。它的特点是各个Window之间完全不相交。</p>
<div align="center"><br><img width="60%" alt="Tumbling Time Window" src="//www.jasongj.com/img/kafka/KafkaColumn7/Tumbling Time Window.gif"><br></div>
</li>
<li><p><code>Sliding Window</code>该窗口只用于2个KStream进行Join计算时。该窗口的大小定义了Join两侧KStream的数据记录被认为在同一个窗口的最大时间差。假设该窗口的大小为5秒，则参与Join的2个KStream中，记录时间差小于5的记录被认为在同一个窗口中，可以进行Join计算。</p>
</li>
<li><p><code>Session Window</code>该窗口用于对Key做Group后的聚合操作中。它需要对Key做分组，然后对组内的数据根据业务需求定义一个窗口的起始点和结束点。一个典型的案例是，希望通过Session Window计算某个用户访问网站的时间。对于一个特定的用户（用Key表示）而言，当发生登录操作时，该用户（Key）的窗口即开始，当发生退出操作或者超时时，该用户（Key）的窗口即结束。窗口结束时，可计算该用户的访问时间或者点击次数等。</p>
</li>
</ol>
<h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h2><p>Kafka Stream由于包含KStream和Ktable两种数据集，因此提供如下Join计算</p>
<ul>
<li><code>KTable Join KTable</code> 结果仍为KTable。任意一边有更新，结果KTable都会更新。</li>
<li><code>KStream Join KStream</code> 结果为KStream。必须带窗口操作，否则会造成Join操作一直不结束。</li>
<li><code>KStream Join KTable / GlobalKTable</code> 结果为KStream。只有当KStream中有新数据时，才会触发Join计算并输出结果。KStream无新数据时，KTable的更新并不会触发Join计算，也不会输出数据。并且该更新只对下次Join生效。一个典型的使用场景是，KStream中的订单信息与KTable中的用户信息做关联计算。</li>
</ul>
<p>对于Join操作，如果要得到正确的计算结果，需要保证参与Join的KTable或KStream中Key相同的数据被分配到同一个Task。具体方法是</p>
<ul>
<li>参与Join的KTable或KStream的Key类型相同（实际上，业务含意也应该相同）</li>
<li>参与Join的KTable或KStream对应的Topic的Partition数相同</li>
<li>Partitioner策略的最终结果等效（实现不需要完全一样，只要效果一样即可），也即Key相同的情况下，被分配到ID相同的Partition内</li>
</ul>
<p>如果上述条件不满足，可通过调用如下方法使得它满足上述条件。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function">KStream&lt;K, V&gt; <span class="title">through</span><span class="params">(Serde&lt;K&gt; keySerde, Serde&lt;V&gt; valSerde, StreamPartitioner&lt;K, V&gt; partitioner, String topic)</span></span></div></pre></td></tr></table></figure></p>
<h2 id="聚合与乱序处理"><a href="#聚合与乱序处理" class="headerlink" title="聚合与乱序处理"></a>聚合与乱序处理</h2><p>聚合操作可应用于KStream和KTable。当聚合发生在KStream上时必须指定窗口，从而限定计算的目标数据集。</p>
<p>需要说明的是，聚合操作的结果肯定是KTable。因为KTable是可更新的，可以在晚到的数据到来时（也即发生数据乱序时）更新结果KTable。</p>
<p>这里举例说明。假设对KStream以5秒为窗口大小，进行Tumbling Time Window上的Count操作。并且KStream先后出现时间为1秒, 3秒, 5秒的数据，此时5秒的窗口已达上限，Kafka Stream关闭该窗口，触发Count操作并将结果3输出到KTable中（假设该结果表示为<1-5,3>）。若1秒后，又收到了时间为2秒的记录，由于1-5秒的窗口已关闭，若直接抛弃该数据，则可认为之前的结果<1-5,3>不准确。而如果直接将完整的结果<1-5,4>输出到KStream中，则KStream中将会包含该窗口的2条记录，<1-5,3>, <1-5,4>，也会存在肮数据。因此Kafka Stream选择将聚合结果存于KTable中，此时新的结果<1-5,4>会替代旧的结果<1-5,3>。用户可得到完整的正确的结果。</1-5,3></1-5,4></1-5,4></1-5,3></1-5,4></1-5,3></1-5,3></p>
<p>这种方式保证了数据准确性，同时也提高了容错性。</p>
<p>但需要说明的是，Kafka Stream并不会对所有晚到的数据都重新计算并更新结果集，而是让用户设置一个<code>retention period</code>，将每个窗口的结果集在内存中保留一定时间，该窗口内的数据晚到时，直接合并计算，并更新结果KTable。超过<code>retention period</code>后，该窗口结果将从内存中删除，并且晚到的数据即使落入窗口，也会被直接丢弃。</p>
<h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>Kafka Stream从如下几个方面进行容错</p>
<ul>
<li>高可用的Partition保证无数据丢失。每个Task计算一个Partition，而Kafka数据复制机制保证了Partition内数据的高可用性，故无数据丢失风险。同时由于数据是持久化的，即使任务失败，依然可以重新计算。</li>
<li>状态存储实现快速故障恢复和从故障点继续处理。对于Join和聚合及窗口等有状态计算，状态存储可保存中间状态。即使发生Failover或Consumer Rebalance，仍然可以通过状态存储恢复中间状态，从而可以继续从Failover或Consumer Rebalance前的点继续计算。</li>
<li>KTable与<code>retention period</code>提供了对乱序数据的处理能力。</li>
</ul>
<h1 id="Kafka-Stream应用示例"><a href="#Kafka-Stream应用示例" class="headerlink" title="Kafka Stream应用示例"></a>Kafka Stream应用示例</h1><p>下面结合一个案例来讲解如何开发Kafka Stream应用。本例完整代码可从<a href="https://github.com/habren/KafkaExample" target="_blank" rel="external">作者Github</a>获取。</p>
<p>订单KStream（名为orderStream），底层Topic的Partition数为3，Key为用户名，Value包含用户名，商品名，订单时间，数量。用户KTable（名为userTable），底层Topic的Partition数为3，Key为用户名，Value包含性别，地址和年龄。商品KTable（名为itemTable），底层Topic的Partition数为6，Key为商品名，价格，种类和产地。现在希望计算每小时购买产地与自己所在地相同的用户总数。</p>
<p>首先由于希望使用订单时间，而它包含在orderStream的Value中，需要通过提供一个实现TimestampExtractor接口的类从orderStream对应的Topic中抽取出订单时间。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderTimestampExtractor</span> <span class="keyword">implements</span> <span class="title">TimestampExtractor</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extract</span><span class="params">(ConsumerRecord&lt;Object, Object&gt; record)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span>(record <span class="keyword">instanceof</span> Order) &#123;</div><div class="line">      <span class="keyword">return</span> ((Order)record).getTS();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>接着通过将orderStream与userTable进行Join，来获取订单用户所在地。由于二者对应的Topic的Partition数相同，且Key都为用户名，再假设Producer往这两个Topic写数据时所用的Partitioner实现相同，则此时上文所述Join条件满足，可直接进行Join。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">orderUserStream = orderStream</div><div class="line">    .leftJoin(userTable, </div><div class="line">         <span class="comment">// 该lamda表达式定义了如何从orderStream与userTable生成结果集的Value</span></div><div class="line">        (Order order, User user) -&gt; OrderUser.fromOrderUser(order, user), </div><div class="line">         <span class="comment">// 结果集Key序列化方式</span></div><div class="line">        Serdes.String(),</div><div class="line">         <span class="comment">// 结果集Value序列化方式</span></div><div class="line">         SerdesFactory.serdFrom(Order.class))</div><div class="line">    .filter((String userName, OrderUser orderUser) -&gt; orderUser.userAddress != <span class="keyword">null</span>)</div></pre></td></tr></table></figure></p>
<p>从上述代码中，可以看到，Join时需要指定如何从参与Join双方的记录生成结果记录的Value。Key不需要指定，因为结果记录的Key与Join Key相同，故无须指定。Join结果存于名为orderUserStream的KStream中。</p>
<p>接下来需要将orderUserStream与itemTable进行Join，从而获取商品产地。此时orderUserStream的Key仍为用户名，而itemTable对应的Topic的Key为产品名，并且二者的Partition数不一样，因此无法直接Join。此时需要通过through方法，对其中一方或双方进行重新分区，使得二者满足Join条件。这一过程相当于Spark的Shuffle过程和Storm的FieldGrouping。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">orderUserStrea</div><div class="line">    .through(</div><div class="line">        <span class="comment">// Key的序列化方式</span></div><div class="line">        Serdes.String(),</div><div class="line">        <span class="comment">// Value的序列化方式 </span></div><div class="line">        SerdesFactory.serdFrom(OrderUser.class), </div><div class="line">        <span class="comment">// 重新按照商品名进行分区，具体取商品名的哈希值，然后对分区数取模</span></div><div class="line">        (String key, OrderUser orderUser, <span class="keyword">int</span> numPartitions) -&gt; (orderUser.getItemName().hashCode() &amp; <span class="number">0x7FFFFFFF</span>) % numPartitions, </div><div class="line">        <span class="string">"orderuser-repartition-by-item"</span>)</div><div class="line">    .leftJoin(itemTable, (OrderUser orderUser, Item item) -&gt; OrderUserItem.fromOrderUser(orderUser, item), Serdes.String(), SerdesFactory.serdFrom(OrderUser.class))</div></pre></td></tr></table></figure></p>
<p>从上述代码可见，through时需要指定Key的序列化器，Value的序列化器，以及分区方式和结果集所在的Topic。这里要注意，该Topic（orderuser-repartition-by-item）的Partition数必须与itemTable对应Topic的Partition数相同，并且through使用的分区方法必须与iteamTable对应Topic的分区方式一样。经过这种<code>through</code>操作，orderUserStream与itemTable满足了Join条件，可直接进行Join。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>Kafka Stream的并行模型完全基于Kafka的分区机制和Rebalance机制，实现了在线动态调整并行度</li>
<li>同一Task包含了一个子Topology的所有Processor，使得所有处理逻辑都在同一线程内完成，避免了不必的网络通信开销，从而提高了效率。</li>
<li><code>through</code>方法提供了类似Spark的Shuffle机制，为使用不同分区策略的数据提供了Join的可能</li>
<li>log compact提高了基于Kafka的state store的加载效率</li>
<li>state store为状态计算提供了可能</li>
<li>基于offset的计算进度管理以及基于state store的中间状态管理为发生Consumer rebalance或Failover时从断点处继续处理提供了可能，并为系统容错性提供了保障</li>
<li>KTable的引入，使得聚合计算拥用了处理乱序问题的能力</li>
</ul>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="//www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="//www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="//www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="//www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="//www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
<li><a href="//www.jasongj.com/kafka/high_throughput/">Kafka设计解析（六）- Kafka高性能架构之道</a></li>
<li><a href="//www.jasongj.com/kafka/kafka_stream/">Kafka设计解析（七）- Kafka Stream</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Kafka Stream的背景，如Kafka Stream是什么，什么是流式计算，以及为什么要有Kafka Stream。接着介绍了Kafka Stream的整体架构，并行模型，状态存储，以及主要的两种数据集KStream和KTable。并且分析了Kafka Stream如何解决流式系统中的关键问题，如时间定义，窗口操作，Join操作，聚合操作，以及如何处理乱序和提供容错能力。最后结合示例讲解了如何使用Kafka Stream。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</title>
    <link href="http://www.jasongj.com/java/concurrenthashmap/"/>
    <id>http://www.jasongj.com/java/concurrenthashmap/</id>
    <published>2017-05-30T22:42:26.000Z</published>
    <updated>2017-05-30T22:42:26.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/java/concurrenthashmap/">原文链接</a>　<a href="http://www.jasongj.com/java/concurrenthashmap/">http://www.jasongj.com/java/concurrenthashmap/</a></p>
</blockquote>
<h1 id="线程不安全的HashMap"><a href="#线程不安全的HashMap" class="headerlink" title="线程不安全的HashMap"></a>线程不安全的HashMap</h1><p>众所周知，HashMap是非线程安全的。而HashMap的线程不安全主要体现在resize时的死循环及使用迭代器时的fast-fail上。</p>
<p>注：本章的代码均基于JDK 1.7.0_67</p>
<h2 id="HashMap工作原理"><a href="#HashMap工作原理" class="headerlink" title="HashMap工作原理"></a>HashMap工作原理</h2><h3 id="HashMap数据结构"><a href="#HashMap数据结构" class="headerlink" title="HashMap数据结构"></a>HashMap数据结构</h3><p>常用的底层数据结构主要有数组和链表。数组存储区间连续，占用内存较多，寻址容易，插入和删除困难。链表存储区间离散，占用内存较少，寻址困难，插入和删除容易。</p>
<p>HashMap要实现的是哈希表的效果，尽量实现O(1)级别的增删改查。它的具体实现则是同时使用了数组和链表，可以认为最外层是一个数组，数组的每个元素是一个链表的表头。</p>
<h3 id="HashMap寻址方式"><a href="#HashMap寻址方式" class="headerlink" title="HashMap寻址方式"></a>HashMap寻址方式</h3><p>对于新插入的数据或者待读取的数据，HashMap将Key的哈希值对数组长度取模，结果作为该Entry在数组中的index。在计算机中，取模的代价远高于位操作的代价，因此HashMap要求数组的长度必须为2的N次方。此时将Key的哈希值对2^N-1进行与运算，其效果即与取模等效。HashMap并不要求用户在指定HashMap容量时必须传入一个2的N次方的整数，而是会通过Integer.highestOneBit算出比指定整数小的最大的2^N值，其实现方法如下。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">highestOneBit</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</div><div class="line">  i |= (i &gt;&gt;  <span class="number">1</span>);</div><div class="line">  i |= (i &gt;&gt;  <span class="number">2</span>);</div><div class="line">  i |= (i &gt;&gt;  <span class="number">4</span>);</div><div class="line">  i |= (i &gt;&gt;  <span class="number">8</span>);</div><div class="line">  i |= (i &gt;&gt; <span class="number">16</span>);</div><div class="line">  <span class="keyword">return</span> i - (i &gt;&gt;&gt; <span class="number">1</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由于Key的哈希值的分布直接决定了所有数据在哈希表上的分布或者说决定了哈希冲突的可能性，因此为防止糟糕的Key的hashCode实现（例如低位都相同，只有高位不相同，与2^N-1取与后的结果都相同），JDK 1.7的HashMap通过如下方法使得最终的哈希值的二进制形式中的1尽量均匀分布从而尽可能减少哈希冲突。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> h = hashSeed;</div><div class="line">h ^= k.hashCode();</div><div class="line">h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>);</div><div class="line"><span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>);</div></pre></td></tr></table></figure></p>
<h2 id="resize死循环"><a href="#resize死循环" class="headerlink" title="resize死循环"></a>resize死循环</h2><h3 id="transfer方法"><a href="#transfer方法" class="headerlink" title="transfer方法"></a>transfer方法</h3><p>当HashMap的size超过Capacity*loadFactor时，需要对HashMap进行扩容。具体方法是，创建一个新的，长度为原来Capacity两倍的数组，保证新的Capacity仍为2的N次方，从而保证上述寻址方式仍适用。同时需要通过如下transfer方法将原来的所有数据全部重新插入（rehash）到新的数组中。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable, <span class="keyword">boolean</span> rehash)</span> </span>&#123;</div><div class="line">  <span class="keyword">int</span> newCapacity = newTable.length;</div><div class="line">  <span class="keyword">for</span> (Entry&lt;K,V&gt; e : table) &#123;</div><div class="line">    <span class="keyword">while</span>(<span class="keyword">null</span> != e) &#123;</div><div class="line">      Entry&lt;K,V&gt; next = e.next;</div><div class="line">      <span class="keyword">if</span> (rehash) &#123;</div><div class="line">        e.hash = <span class="keyword">null</span> == e.key ? <span class="number">0</span> : hash(e.key);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);</div><div class="line">      e.next = newTable[i];</div><div class="line">      newTable[i] = e;</div><div class="line">      e = next;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该方法并不保证线程安全，而且在多线程并发调用时，可能出现死循环。其执行过程如下。从步骤2可见，转移时链表顺序反转。</p>
<ol>
<li>遍历原数组中的元素</li>
<li>对链表上的每一个节点遍历：用next取得要转移那个元素的下一个，将e转移到新数组的头部，使用头插法插入节点</li>
<li>循环2，直到链表节点全部转移</li>
<li>循环1，直到所有元素全部转移</li>
</ol>
<h3 id="单线程rehash"><a href="#单线程rehash" class="headerlink" title="单线程rehash"></a>单线程rehash</h3><p>单线程情况下，rehash无问题。下图演示了单线程条件下的rehash过程<br><img src="http://www.jasongj.com/img/java/concurrenthashmap/single_thread_rehash.png" alt="HashMap rehash single thread"></p>
<h3 id="多线程并发下的rehash"><a href="#多线程并发下的rehash" class="headerlink" title="多线程并发下的rehash"></a>多线程并发下的rehash</h3><p>这里假设有两个线程同时执行了put操作并引发了rehash，执行了transfer方法，并假设线程一进入transfer方法并执行完next = e.next后，因为线程调度所分配时间片用完而“暂停”，此时线程二完成了transfer方法的执行。此时状态如下。</p>
<p><img src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_1.png" alt="HashMap rehash multi thread step 1"></p>
<p>接着线程1被唤醒，继续执行第一轮循环的剩余部分<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">e.next = newTable[<span class="number">1</span>] = <span class="keyword">null</span></div><div class="line">newTable[<span class="number">1</span>] = e = key(<span class="number">5</span>)</div><div class="line">e = next = key(<span class="number">9</span>)</div></pre></td></tr></table></figure></p>
<p>结果如下图所示<br><img src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_2.png" alt="HashMap rehash multi thread step 2"></p>
<p>接着执行下一轮循环，结果状态图如下所示<br><img src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_3.png" alt="HashMap rehash multi thread step 3"></p>
<p>继续下一轮循环，结果状态图如下所示<br><img src="http://www.jasongj.com/img/java/concurrenthashmap/multi_thread_rehash_4.png" alt="HashMap rehash multi thread step 4"></p>
<p>此时循环链表形成，并且key(11)无法加入到线程1的新数组。在下一次访问该链表时会出现死循环。</p>
<h2 id="Fast-fail"><a href="#Fast-fail" class="headerlink" title="Fast-fail"></a>Fast-fail</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p>在使用迭代器的过程中如果HashMap被修改，那么<code>ConcurrentModificationException</code>将被抛出，也即Fast-fail策略。</p>
<p>当HashMap的iterator()方法被调用时，会构造并返回一个新的EntryIterator对象，并将EntryIterator的expectedModCount设置为HashMap的modCount（该变量记录了HashMap被修改的次数）。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">HashIterator() &#123;</div><div class="line">  expectedModCount = modCount;</div><div class="line">  <span class="keyword">if</span> (size &gt; <span class="number">0</span>) &#123; <span class="comment">// advance to first entry</span></div><div class="line">  Entry[] t = table;</div><div class="line">  <span class="keyword">while</span> (index &lt; t.length &amp;&amp; (next = t[index++]) == <span class="keyword">null</span>)</div><div class="line">    ;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在通过该Iterator的next方法访问下一个Entry时，它会先检查自己的expectedModCount与HashMap的modCount是否相等，如果不相等，说明HashMap被修改，直接抛出<code>ConcurrentModificationException</code>。该Iterator的remove方法也会做类似的检查。该异常的抛出意在提醒用户及早意识到线程安全问题。</p>
<h3 id="线程安全解决方案"><a href="#线程安全解决方案" class="headerlink" title="线程安全解决方案"></a>线程安全解决方案</h3><p>单线程条件下，为避免出现<code>ConcurrentModificationException</code>，需要保证只通过HashMap本身或者只通过Iterator去修改数据，不能在Iterator使用结束之前使用HashMap本身的方法修改数据。因为通过Iterator删除数据时，HashMap的modCount和Iterator的expectedModCount都会自增，不影响二者的相等性。如果是增加数据，只能通过HashMap本身的方法完成，此时如果要继续遍历数据，需要重新调用iterator()方法从而重新构造出一个新的Iterator，使得新Iterator的expectedModCount与更新后的HashMap的modCount相等。</p>
<p>多线程条件下，可使用<code>Collections.synchronizedMap</code>方法构造出一个同步Map，或者直接使用线程安全的ConcurrentHashMap。</p>
<h1 id="Java-7基于分段锁的ConcurrentHashMap"><a href="#Java-7基于分段锁的ConcurrentHashMap" class="headerlink" title="Java 7基于分段锁的ConcurrentHashMap"></a>Java 7基于分段锁的ConcurrentHashMap</h1><p>注：本章的代码均基于JDK 1.7.0_67</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>Java 7中的ConcurrentHashMap的底层数据结构仍然是数组和链表。与HashMap不同的是，ConcurrentHashMap最外层不是一个大的数组，而是一个Segment的数组。每个Segment包含一个与HashMap数据结构差不多的链表数组。整体数据结构如下图所示。<br><img src="http://www.jasongj.com/img/java/concurrenthashmap/concurrenthashmap_java7.png" alt="JAVA 7 ConcurrentHashMap"></p>
<h2 id="寻址方式"><a href="#寻址方式" class="headerlink" title="寻址方式"></a>寻址方式</h2><p>在读写某个Key时，先取该Key的哈希值。并将哈希值的高N位对Segment个数取模从而得到该Key应该属于哪个Segment，接着如同操作HashMap一样操作这个Segment。为了保证不同的值均匀分布到不同的Segment，需要通过如下方法计算哈希值。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object k)</span> </span>&#123;</div><div class="line">  <span class="keyword">int</span> h = hashSeed;</div><div class="line">  <span class="keyword">if</span> ((<span class="number">0</span> != h) &amp;&amp; (k <span class="keyword">instanceof</span> String)) &#123;</div><div class="line">    <span class="keyword">return</span> sun.misc.Hashing.stringHash32((String) k);</div><div class="line">  &#125;</div><div class="line">  h ^= k.hashCode();</div><div class="line">  h += (h &lt;&lt;  <span class="number">15</span>) ^ <span class="number">0xffffcd7d</span>;</div><div class="line">  h ^= (h &gt;&gt;&gt; <span class="number">10</span>);</div><div class="line">  h += (h &lt;&lt;   <span class="number">3</span>);</div><div class="line">  h ^= (h &gt;&gt;&gt;  <span class="number">6</span>);</div><div class="line">  h += (h &lt;&lt;   <span class="number">2</span>) + (h &lt;&lt; <span class="number">14</span>);</div><div class="line">  <span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">16</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>同样为了提高取模运算效率，通过如下计算，ssize即为大于concurrencyLevel的最小的2的N次方，同时segmentMask为2^N-1。这一点跟上文中计算数组长度的方法一致。对于某一个Key的哈希值，只需要向右移segmentShift位以取高sshift位，再与segmentMask取与操作即可得到它在Segment数组上的索引。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> sshift = <span class="number">0</span>;</div><div class="line"><span class="keyword">int</span> ssize = <span class="number">1</span>;</div><div class="line"><span class="keyword">while</span> (ssize &lt; concurrencyLevel) &#123;</div><div class="line">  ++sshift;</div><div class="line">  ssize &lt;&lt;= <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">this</span>.segmentShift = <span class="number">32</span> - sshift;</div><div class="line"><span class="keyword">this</span>.segmentMask = ssize - <span class="number">1</span>;</div><div class="line">Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])<span class="keyword">new</span> Segment[ssize];</div></pre></td></tr></table></figure></p>
<h2 id="同步方式"><a href="#同步方式" class="headerlink" title="同步方式"></a>同步方式</h2><p>Segment继承自ReentrantLock，所以我们可以很方便的对每一个Segment上锁。</p>
<p>对于读操作，获取Key所在的Segment时，需要保证可见性(请参考<a href="http://www.jasongj.com/java/thread_safe/#Java如何保证可见性">如何保证多线程条件下的可见性</a>)。具体实现上可以使用volatile关键字，也可使用锁。但使用锁开销太大，而使用volatile时每次写操作都会让所有CPU内缓存无效，也有一定开销。ConcurrentHashMap使用如下方法保证可见性，取得最新的Segment。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Segment&lt;K,V&gt; s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)</div></pre></td></tr></table></figure></p>
<p>获取Segment中的HashEntry时也使用了类似方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile</div><div class="line">  (tab, ((<span class="keyword">long</span>)(((tab.length - <span class="number">1</span>) &amp; h)) &lt;&lt; TSHIFT) + TBASE)</div></pre></td></tr></table></figure></p>
<p>对于写操作，并不要求同时获取所有Segment的锁，因为那样相当于锁住了整个Map。它会先获取该Key-Value对所在的Segment的锁，获取成功后就可以像操作一个普通的HashMap一样操作该Segment，并保证该Segment的安全性。<br>同时由于其它Segment的锁并未被获取，因此理论上可支持concurrencyLevel（等于Segment的个数）个线程安全的并发读写。</p>
<p>获取锁时，并不直接使用lock来获取，因为该方法获取锁失败时会挂起（参考<a href="http://www.jasongj.com/java/multi_thread/#重入锁">可重入锁</a>）。事实上，它使用了自旋锁，如果tryLock获取锁失败，说明锁被其它线程占用，此时通过循环再次以tryLock的方式申请锁。如果在循环过程中该Key所对应的链表头被修改，则重置retry次数。如果retry次数超过一定值，则使用lock方法申请锁。</p>
<p>这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗CPU资源比较多，因此在自旋次数超过阈值时切换为互斥锁。</p>
<h2 id="size操作"><a href="#size操作" class="headerlink" title="size操作"></a>size操作</h2><p>put、remove和get操作只需要关心一个Segment，而size操作需要遍历所有的Segment才能算出整个Map的大小。一个简单的方案是，先锁住所有Sgment，计算完后再解锁。但这样做，在做size操作时，不仅无法对Map进行写操作，同时也无法进行读操作，不利于对Map的并行操作。</p>
<p>为更好支持并发操作，ConcurrentHashMap会在不上锁的前提逐个Segment计算3次size，如果某相邻两次计算获取的所有Segment的更新次数（每个Segment都与HashMap一样通过modCount跟踪自己的修改次数，Segment每修改一次其modCount加一）相等，说明这两次计算过程中无更新操作，则这两次计算出的总size相等，可直接作为最终结果返回。如果这三次计算过程中Map有更新，则对所有Segment加锁重新计算Size。该计算方法代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">final</span> Segment&lt;K,V&gt;[] segments = <span class="keyword">this</span>.segments;</div><div class="line">  <span class="keyword">int</span> size;</div><div class="line">  <span class="keyword">boolean</span> overflow; <span class="comment">// true if size overflows 32 bits</span></div><div class="line">  <span class="keyword">long</span> sum;         <span class="comment">// sum of modCounts</span></div><div class="line">  <span class="keyword">long</span> last = <span class="number">0L</span>;   <span class="comment">// previous sum</span></div><div class="line">  <span class="keyword">int</span> retries = -<span class="number">1</span>; <span class="comment">// first iteration isn't retry</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">for</span> (;;) &#123;</div><div class="line">      <span class="keyword">if</span> (retries++ == RETRIES_BEFORE_LOCK) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j)</div><div class="line">          ensureSegment(j).lock(); <span class="comment">// force creation</span></div><div class="line">      &#125;</div><div class="line">      sum = <span class="number">0L</span>;</div><div class="line">      size = <span class="number">0</span>;</div><div class="line">      overflow = <span class="keyword">false</span>;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j) &#123;</div><div class="line">        Segment&lt;K,V&gt; seg = segmentAt(segments, j);</div><div class="line">        <span class="keyword">if</span> (seg != <span class="keyword">null</span>) &#123;</div><div class="line">          sum += seg.modCount;</div><div class="line">          <span class="keyword">int</span> c = seg.count;</div><div class="line">          <span class="keyword">if</span> (c &lt; <span class="number">0</span> || (size += c) &lt; <span class="number">0</span>)</div><div class="line">            overflow = <span class="keyword">true</span>;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (sum == last)</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      last = sum;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">finally</span> &#123;</div><div class="line">    <span class="keyword">if</span> (retries &gt; RETRIES_BEFORE_LOCK) &#123;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; segments.length; ++j)</div><div class="line">        segmentAt(segments, j).unlock();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> overflow ? Integer.MAX_VALUE : size;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="不同之处"><a href="#不同之处" class="headerlink" title="不同之处"></a>不同之处</h2><p>ConcurrentHashMap与HashMap相比，有以下不同点</p>
<ul>
<li>ConcurrentHashMap线程安全，而HashMap非线程安全</li>
<li>HashMap允许Key和Value为null，而ConcurrentHashMap不允许</li>
<li>HashMap不允许通过Iterator遍历的同时通过HashMap修改，而ConcurrentHashMap允许该行为，并且该更新对后续的遍历可见</li>
</ul>
<h1 id="Java-8基于CAS的ConcurrentHashMap"><a href="#Java-8基于CAS的ConcurrentHashMap" class="headerlink" title="Java 8基于CAS的ConcurrentHashMap"></a>Java 8基于CAS的ConcurrentHashMap</h1><p>注：本章的代码均基于JDK 1.8.0_111</p>
<h2 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h2><p>Java 7为实现并行访问，引入了Segment这一结构，实现了分段锁，理论上最大并发度与Segment个数相等。Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))）。其数据结构如下图所示</p>
<div align="center"><br><img width="50%" src="http://www.jasongj.com/img/java/concurrenthashmap/concurrenthashmap_java8.png" alt="JAVA 8 ConcurrentHashMap"><br></div>

<h2 id="寻址方式-1"><a href="#寻址方式-1" class="headerlink" title="寻址方式"></a>寻址方式</h2><p>Java 8的ConcurrentHashMap同样是通过Key的哈希值与数组长度取模确定该Key在数组中的索引。同样为了避免不太好的Key的hashCode设计，它通过如下方法计算得到Key的最终哈希值。不同的是，Java 8的ConcurrentHashMap作者认为引入红黑树后，即使哈希冲突比较严重，寻址效率也足够高，所以作者并未在哈希值的计算上做过多设计，只是将Key的hashCode值与其高16位作异或并保证最高位为0（从而保证最终结果为正整数）。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">spread</span><span class="params">(<span class="keyword">int</span> h)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="number">16</span>)) &amp; HASH_BITS;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="同步方式-1"><a href="#同步方式-1" class="headerlink" title="同步方式"></a>同步方式</h2><p>对于put操作，如果Key对应的数组元素为null，则通过<a href="http://www.jasongj.com/java/thread_safe/#CAS（compare-and-swap）">CAS操作</a>将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为树，从而提高寻址效率。</p>
<p>对于读操作，由于数组被volatile关键字修饰，因此不用担心数组的可见性问题。同时每个元素是一个Node实例（Java 7中每个元素是一个HashEntry），它的Key值和hash值都由final修饰，不可变更，无须关心它们被修改后的可见性问题。而其Value及对下一个元素的引用由volatile修饰，可见性也有保障。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</div><div class="line">  <span class="keyword">final</span> <span class="keyword">int</span> hash;</div><div class="line">  <span class="keyword">final</span> K key;</div><div class="line">  <span class="keyword">volatile</span> V val;</div><div class="line">  <span class="keyword">volatile</span> Node&lt;K,V&gt; next;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>对于Key对应的数组元素的可见性，由Unsafe的getObjectVolatile方法保证。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">final</span> &lt;K,V&gt; <span class="function">Node&lt;K,V&gt; <span class="title">tabAt</span><span class="params">(Node&lt;K,V&gt;[] tab, <span class="keyword">int</span> i)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((<span class="keyword">long</span>)i &lt;&lt; ASHIFT) + ABASE);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="size操作-1"><a href="#size操作-1" class="headerlink" title="size操作"></a>size操作</h2><p>put方法和remove方法都会通过addCount方法维护Map的size。size方法通过sumCount获取由addCount方法维护的Map的size。</p>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文分析了HashMap的实现原理，以及resize可能引起死循环和Fast-fail等线程不安全行为。同时结合源码从数据结构，寻址方式，同步方式，计算size等角度分析了JDK 1.7和JDK 1.8中ConcurrentHashMap的实现原理。
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（六）- Kafka高性能架构之道</title>
    <link href="http://www.jasongj.com/kafka/high_throughput/"/>
    <id>http://www.jasongj.com/kafka/high_throughput/</id>
    <published>2017-04-17T01:53:13.000Z</published>
    <updated>2017-11-12T02:52:40.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/kafka/high_throughput/">原文链接</a>　<a href="http://www.jasongj.com/kafka/high_throughput/">http://www.jasongj.com/kafka/high_throughput/</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>上一篇文章《<a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a>》从测试角度说明了Kafka的性能。本文从宏观架构层面和具体实现层面分析了Kafka如何实现高性能。</p>
<h1 id="宏观架构层面"><a href="#宏观架构层面" class="headerlink" title="宏观架构层面"></a>宏观架构层面</h1><h2 id="利用Partition实现并行处理"><a href="#利用Partition实现并行处理" class="headerlink" title="利用Partition实现并行处理"></a>利用Partition实现并行处理</h2><h3 id="Partition提供并行处理的能力"><a href="#Partition提供并行处理的能力" class="headerlink" title="Partition提供并行处理的能力"></a>Partition提供并行处理的能力</h3><p>Kafka是一个Pub-Sub的消息系统，无论是发布还是订阅，都须指定Topic。如《<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1">Kafka设计解析（一）- Kafka背景及架构介绍</a>》一文所述，Topic只是一个逻辑的概念。每个Topic都包含一个或多个Partition，不同Partition可位于不同节点。同时Partition在物理上对应一个本地文件夹，每个Partition包含一个或多个Segment，每个Segment包含一个数据文件和一个与之对应的索引文件。在逻辑上，可以把一个Partition当作一个非常长的数组，可通过这个“数组”的索引（offset）去访问其数据。  </p>
<p>一方面，由于不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于Partition在物理上对应一个文件夹，即使多个Partition位于同一个节点，也可通过配置让同一节点上的不同Partition置于不同的disk drive上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。  </p>
<p>利用多磁盘的具体方法是，将不同磁盘mount到不同目录，然后在server.properties中，将<code>log.dirs</code>设置为多目录（用逗号分隔）。Kafka会自动将所有Partition尽可能均匀分配到不同目录也即不同目录（也即不同disk）上。  </p>
<p>注：虽然物理上最小单位是Segment，但Kafka并不提供同一Partition内不同Segment间的并行处理。因为对于写而言，每次只会写Partition内的一个Segment，而对于读而言，也只会顺序读取同一Partition内的不同Segment。  </p>
<h3 id="Partition是最小并发粒度"><a href="#Partition是最小并发粒度" class="headerlink" title="Partition是最小并发粒度"></a>Partition是最小并发粒度</h3><p>如同《<a href="http://www.jasongj.com/2015/08/09/KafkaColumn4">Kafka设计解析（四）- Kafka Consumer设计解析</a>》一文所述，多Consumer消费同一个Topic时，同一条消息只会被同一Consumer Group内的一个Consumer所消费。而数据并非按消息为单位分配，而是以Partition为单位分配，也即同一个Partition的数据只会被一个Consumer所消费（在不考虑Rebalance的前提下）。  </p>
<p>如果Consumer的个数多于Partition的个数，那么会有部分Consumer无法消费该Topic的任何数据，也即当Consumer个数超过Partition后，增加Consumer并不能增加并行度。  </p>
<p>简而言之，Partition个数决定了可能的最大并行度。如下图所示，由于Topic 2只包含3个Partition，故group2中的Consumer 3、Consumer 4、Consumer 5 可分别消费1个Partition的数据，而Consumer 6消费不到Topic 2的任何数据。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn6/kafka-consumer.png" alt="Kafka Consumer"></p>
<p>以Spark消费Kafka数据为例，如果所消费的Topic的Partition数为N，则有效的Spark最大并行度也为N。即使将Spark的Executor数设置为N+M，最多也只有N个Executor可同时处理该Topic的数据。</p>
<h2 id="ISR实现可用性与数据一致性的动态平衡"><a href="#ISR实现可用性与数据一致性的动态平衡" class="headerlink" title="ISR实现可用性与数据一致性的动态平衡"></a>ISR实现可用性与数据一致性的动态平衡</h2><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><p>CAP理论是指，分布式系统中，一致性、可用性和分区容忍性最多只能同时满足两个。  </p>
<p><strong><em>一致性</em></strong>  </p>
<ul>
<li>通过某个节点的写操作结果对后面通过其它节点的读操作可见</li>
<li>如果更新数据后，并发访问情况下后续读操作可立即感知该更新，称为强一致性</li>
<li>如果允许之后部分或者全部感知不到该更新，称为弱一致性</li>
<li>若在之后的一段时间（通常该时间不固定）后，一定可以感知到该更新，称为最终一致性</li>
</ul>
<p><strong><em>可用性</em></strong>  </p>
<ul>
<li>任何一个没有发生故障的节点必须在有限的时间内返回合理的结果</li>
</ul>
<p><strong><em>分区容忍性</em></strong></p>
<ul>
<li>部分节点宕机或者无法与其它节点通信时，各分区间还可保持分布式系统的功能</li>
</ul>
<p>一般而言，都要求保证分区容忍性。所以在CAP理论下，更多的是需要在可用性和一致性之间做权衡。</p>
<h3 id="常用数据复制及一致性方案"><a href="#常用数据复制及一致性方案" class="headerlink" title="常用数据复制及一致性方案"></a>常用数据复制及一致性方案</h3><p><strong><em>Master-Slave</em></strong></p>
<ul>
<li>RDBMS的读写分离即为典型的Master-Slave方案</li>
<li>同步复制可保证强一致性但会影响可用性</li>
<li>异步复制可提供高可用性但会降低一致性</li>
</ul>
<p><strong><em>WNR</em></strong></p>
<ul>
<li>主要用于去中心化的分布式系统中。DynamoDB与Cassandra即采用此方案或其变种</li>
<li>N代表总副本数，W代表每次写操作要保证的最少写成功的副本数，R代表每次读至少要读取的副本数</li>
<li>当W+R&gt;N时，可保证每次读取的数据至少有一个副本拥有最新的数据</li>
<li>多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致。Dynamo通过向量时钟保证最终一致性</li>
</ul>
<p><strong><em>Paxos及其变种</em></strong></p>
<ul>
<li>Google的Chubby，Zookeeper的原子广播协议（Zab），RAFT等</li>
</ul>
<p><strong><em>基于ISR的数据复制方案</em></strong><br>如《<a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/#ACK前需要保证有多少个备份"> Kafka High Availability（上）</a>》一文所述，Kafka的数据复制是以Partition为单位的。而多个备份间的数据复制，通过Follower向Leader拉取数据完成。从一这点来讲，Kafka的数据复制方案接近于上文所讲的Master-Slave方案。不同的是，Kafka既不是完全的同步复制，也不是完全的异步复制，而是基于ISR的动态复制方案。</p>
<p>ISR，也即In-sync Replica。每个Partition的Leader都会维护这样一个列表，该列表中，包含了所有与之同步的Replica（包含Leader自己）。每次数据写入时，只有ISR中的所有Replica都复制完，Leader才会将其置为Commit，它才能被Consumer所消费。</p>
<p>这种方案，与同步复制非常接近。但不同的是，这个ISR是由Leader动态维护的。如果Follower不能紧“跟上”Leader，它将被Leader从ISR中移除，待它又重新“跟上”Leader后，会被Leader再次加加ISR中。每次改变ISR后，Leader都会将最新的ISR持久化到Zookeeper中。</p>
<p>至于如何判断某个Follower是否“跟上”Leader，不同版本的Kafka的策略稍微有些区别。</p>
<ul>
<li>对于0.8.*版本，如果Follower在<code>replica.lag.time.max.ms</code>时间内未向Leader发送Fetch请求（也即数据复制请求），则Leader会将其从ISR中移除。如果某Follower持续向Leader发送Fetch请求，但是它与Leader的数据差距在<code>replica.lag.max.messages</code>以上，也会被Leader从ISR中移除。</li>
<li>从0.9.0.0版本开始，<code>replica.lag.max.messages</code>被移除，故Leader不再考虑Follower落后的消息条数。另外，Leader不仅会判断Follower是否在<code>replica.lag.time.max.ms</code>时间内向其发送Fetch请求，同时还会考虑Follower是否在该时间内与之保持同步。</li>
<li>0.10.* 版本的策略与0.9.*版一致</li>
</ul>
<p>对于0.8.*版本的<code>replica.lag.max.messages</code>参数，很多读者曾留言提问，既然只有ISR中的所有Replica复制完后的消息才被认为Commit，那为何会出现Follower与Leader差距过大的情况。原因在于，Leader并不需要等到前一条消息被Commit才接收后一条消息。事实上，Leader可以按顺序接收大量消息，最新的一条消息的Offset被记为High Wartermark。而只有被ISR中所有Follower都复制过去的消息才会被Commit，Consumer只能消费被Commit的消息。由于Follower的复制是严格按顺序的，所以被Commit的消息之前的消息肯定也已经被Commit过。换句话说，High Watermark标记的是Leader所保存的最新消息的offset，而Commit Offset标记的是最新的可被消费的（已同步到ISR中的Follower）消息。而Leader对数据的接收与Follower对数据的复制是异步进行的，因此会出现Commit Offset与High Watermark存在一定差距的情况。0.8.*版本中<code>replica.lag.max.messages</code>限定了Leader允许的该差距的最大值。</p>
<p>Kafka基于ISR的数据复制方案原理如下图所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn6/kafka-replication.png" alt="Kafka Replication"></p>
<p>如上图所示，在第一步中，Leader A总共收到3条消息，故其high watermark为3，但由于ISR中的Follower只同步了第1条消息（m1），故只有m1被Commit，也即只有m1可被Consumer消费。此时Follower B与Leader A的差距是1，而Follower C与Leader A的差距是2，均未超过默认的<code>replica.lag.max.messages</code>，故得以保留在ISR中。在第二步中，由于旧的Leader A宕机，新的Leader B在<code>replica.lag.time.max.ms</code>时间内未收到来自A的Fetch请求，故将A从ISR中移除，此时ISR={B，C}。同时，由于此时新的Leader B中只有2条消息，并未包含m3（m3从未被任何Leader所Commit），所以m3无法被Consumer消费。第四步中，Follower A恢复正常，它先将宕机前未Commit的所有消息全部删除，然后从最后Commit过的消息的下一条消息开始追赶新的Leader B，直到它“赶上”新的Leader，才被重新加入新的ISR中。</p>
<h3 id="使用ISR方案的原因"><a href="#使用ISR方案的原因" class="headerlink" title="使用ISR方案的原因"></a>使用ISR方案的原因</h3><ul>
<li>由于Leader可移除不能及时与之同步的Follower，故与同步复制相比可避免最慢的Follower拖慢整体速度，也即ISR提高了系统可用性。</li>
<li>ISR中的所有Follower都包含了所有Commit过的消息，而只有Commit过的消息才会被Consumer消费，故从Consumer的角度而言，ISR中的所有Replica都始终处于同步状态，从而与异步复制方案相比提高了数据一致性。</li>
<li>ISR可动态调整，极限情况下，可以只包含Leader，极大提高了可容忍的宕机的Follower的数量。与<code>Majority Quorum</code>方案相比，容忍相同个数的节点失败，所要求的总节点数少了近一半。</li>
</ul>
<h3 id="ISR相关配置说明"><a href="#ISR相关配置说明" class="headerlink" title="ISR相关配置说明"></a>ISR相关配置说明</h3><ul>
<li>Broker的<code>min.insync.replicas</code>参数指定了Broker所要求的ISR最小长度，默认值为1。也即极限情况下ISR可以只包含Leader。但此时如果Leader宕机，则该Partition不可用，可用性得不到保证。</li>
<li>只有被ISR中所有Replica同步的消息才被Commit，但Producer发布数据时，Leader并不需要ISR中的所有Replica同步该数据才确认收到数据。Producer可以通过<code>acks</code>参数指定最少需要多少个Replica确认收到该消息才视为该消息发送成功。<code>acks</code>的默认值是1，即Leader收到该消息后立即告诉Producer收到该消息，此时如果在ISR中的消息复制完该消息前Leader宕机，那该条消息会丢失。而如果将该值设置为0，则Producer发送完数据后，立即认为该数据发送成功，不作任何等待，而实际上该数据可能发送失败，并且Producer的Retry机制将不生效。更推荐的做法是，将<code>acks</code>设置为<code>all</code>或者<code>-1</code>，此时只有ISR中的所有Replica都收到该数据（也即该消息被Commit），Leader才会告诉Producer该消息发送成功，从而保证不会有未知的数据丢失。</li>
</ul>
<h1 id="具体实现层面"><a href="#具体实现层面" class="headerlink" title="具体实现层面"></a>具体实现层面</h1><h2 id="高效使用磁盘"><a href="#高效使用磁盘" class="headerlink" title="高效使用磁盘"></a>高效使用磁盘</h2><h3 id="顺序写磁盘"><a href="#顺序写磁盘" class="headerlink" title="顺序写磁盘"></a>顺序写磁盘</h3><p>根据《<a href="http://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg" title="一些场景下顺序写磁盘快于随机写内存" target="_blank" rel="external nofollow">一些场景下顺序写磁盘快于随机写内存</a>》所述，将写磁盘的过程变为顺序写，可极大提高对磁盘的利用率。</p>
<p>Kafka的整个设计中，Partition相当于一个非常长的数组，而Broker接收到的所有消息顺序写入这个大数组中。同时Consumer通过Offset顺序消费这些数据，并且不删除已经消费的数据，从而避免了随机写磁盘的过程。</p>
<p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统Kafka也没必要保存所有数据，需要删除旧的数据。而这个删除过程，并非通过使用“读-写”模式去修改文件，而是将Partition分为多个Segment，每个Segment对应一个物理文件，通过删除整个文件的方式去删除Partition内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p>
<p>通过如下代码可知，Kafka删除Segment的方式，是直接删除Segment对应的整个log文件和整个index文件而非删除文件中的部分内容。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Delete this log segment from the filesystem.</div><div class="line"> *</div><div class="line"> * @throws KafkaStorageException if the delete fails.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete</span></span>() &#123;</div><div class="line">  <span class="keyword">val</span> deletedLog = log.delete()</div><div class="line">  <span class="keyword">val</span> deletedIndex = index.delete()</div><div class="line">  <span class="keyword">val</span> deletedTimeIndex = timeIndex.delete()</div><div class="line">  <span class="keyword">if</span>(!deletedLog &amp;&amp; log.file.exists)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">"Delete of log "</span> + log.file.getName + <span class="string">" failed."</span>)</div><div class="line">  <span class="keyword">if</span>(!deletedIndex &amp;&amp; index.file.exists)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">"Delete of index "</span> + index.file.getName + <span class="string">" failed."</span>)</div><div class="line">  <span class="keyword">if</span>(!deletedTimeIndex &amp;&amp; timeIndex.file.exists)</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">"Delete of time index "</span> + timeIndex.file.getName + <span class="string">" failed."</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="充分利用Page-Cache"><a href="#充分利用Page-Cache" class="headerlink" title="充分利用Page Cache"></a>充分利用Page Cache</h3><p>使用Page Cache的好处如下</p>
<ul>
<li>I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能</li>
<li>I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li>
<li>充分利用所有空闲内存（非JVM内存）。如果使用应用层Cache（即JVM堆内存），会增加GC负担</li>
<li>读操作可直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过Page Cache）交换数据</li>
<li>如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用</li>
</ul>
<p>Broker收到数据后，写磁盘时只是将数据写入Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由Kafka层面的Replication机制去解决。如果为了保证这种情况下数据不丢失而强制将Page Cache中的数据Flush到磁盘，反而会降低性能。也正因如此，Kafka虽然提供了<code>flush.messages</code>和<code>flush.ms</code>两个参数将Page Cache中的数据强制Flush到磁盘，但是Kafka并不建议使用。</p>
<p>如果数据消费速度与生产速度相当，甚至不需要通过物理磁盘交换数据，而是直接通过Page Cache交换数据。同时，Follower从Leader Fetch数据时，也可通过Page Cache完成。下图为某Partition的Leader节点的网络/磁盘读写信息。</p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn6/kafka_IO.png" alt="Kafka I/O page cache"></p>
<p>从上图可以看到，该Broker每秒通过网络从Producer接收约35MB数据，虽然有Follower从该Broker Fetch数据，但是该Broker基本无读磁盘。这是因为该Broker直接从Page Cache中将数据取出返回给了Follower。</p>
<h3 id="支持多Disk-Drive"><a href="#支持多Disk-Drive" class="headerlink" title="支持多Disk Drive"></a>支持多Disk Drive</h3><p>Broker的<code>log.dirs</code>配置项，允许配置多个文件夹。如果机器上有多个Disk Drive，可将不同的Disk挂载到不同的目录，然后将这些目录都配置到<code>log.dirs</code>里。Kafka会尽可能将不同的Partition分配到不同的目录，也即不同的Disk上，从而充分利用了多Disk的优势。</p>
<h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>Kafka中存在大量的网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程。这一过程的性能直接影响Kafka的整体吞吐量。  </p>
<h3 id="传统模式下的四次拷贝与四次上下文切换"><a href="#传统模式下的四次拷贝与四次上下文切换" class="headerlink" title="传统模式下的四次拷贝与四次上下文切换"></a>传统模式下的四次拷贝与四次上下文切换</h3><p>以将磁盘文件通过网络发送为例。传统模式下，一般使用如下伪代码所示的方法先将文件数据读入内存，然后通过Socket将内存中的数据发送出去。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">buffer = File.read</div><div class="line">Socket.send(buffer)</div></pre></td></tr></table></figure></p>
<p>这一过程实际上发生了四次数据拷贝。首先通过系统调用将文件数据读入到内核态Buffer（DMA拷贝），然后应用程序将内存态Buffer数据读入到用户态Buffer（CPU拷贝），接着用户程序通过Socket发送数据时将用户态Buffer数据拷贝到内核态Buffer（CPU拷贝），最后通过DMA拷贝将数据拷贝到NIC Buffer。同时，还伴随着四次上下文切换，如下图所示。  </p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn6/BIO.png" alt="BIO 四次拷贝 四次上下文切换"> </p>
<h3 id="sendfile和transferTo实现零拷贝"><a href="#sendfile和transferTo实现零拷贝" class="headerlink" title="sendfile和transferTo实现零拷贝"></a>sendfile和transferTo实现零拷贝</h3><p>Linux 2.4+内核通过<code>sendfile</code>系统调用，提供了零拷贝。数据通过DMA拷贝到内核态Buffer后，直接通过DMA拷贝到NIC Buffer，无需CPU拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个<code>sendfile</code>调用完成，整个过程只有两次上下文切换，因此大大提高了性能。零拷贝过程如下图所示。</p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn6/NIO.png" alt="BIO 零拷贝 两次上下文切换"> </p>
<p>从具体实现来看，Kafka的数据传输通过TransportLayer来完成，其子类<code>PlaintextTransportLayer</code>通过<a href="http://www.jasongj.com/java/nio_reactor/">Java NIO</a>的FileChannel的<code>transferTo</code>和<code>transferFrom</code>方法实现零拷贝，如下所示。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">transferFrom</span><span class="params">(FileChannel fileChannel, <span class="keyword">long</span> position, <span class="keyword">long</span> count)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">return</span> fileChannel.transferTo(position, count, socketChannel);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>注：</strong> <code>transferTo</code>和<code>transferFrom</code>并不保证一定能使用零拷贝。实际上是否能使用零拷贝与操作系统相关，如果操作系统提供<code>sendfile</code>这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。</p>
<h2 id="减少网络开销"><a href="#减少网络开销" class="headerlink" title="减少网络开销"></a>减少网络开销</h2><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>批处理是一种常用的用于提高I/O性能的方式。对Kafka而言，批处理既减少了网络传输的Overhead，又提高了写磁盘的效率。</p>
<p>Kafka 0.8.1及以前的Producer区分同步Producer和异步Producer。同步Producer的send方法主要分两种形式。一种是接受一个KeyedMessage作为参数，一次发送一条消息。另一种是接受一批KeyedMessage作为参数，一次性发送多条消息。而对于异步发送而言，无论是使用哪个send方法，实现上都不会立即将消息发送给Broker，而是先存到内部的队列中，直到消息条数达到阈值或者达到指定的Timeout才真正的将消息发送出去，从而实现了消息的批量发送。</p>
<p>Kafka 0.8.2开始支持新的Producer API，将同步Producer和异步Producer结合。虽然从send接口来看，一次只能发送一个ProducerRecord，而不能像之前版本的send方法一样接受消息列表，但是send方法并非立即将消息发送出去，而是通过<code>batch.size</code>和<code>linger.ms</code>控制实际发送频率，从而实现批量发送。</p>
<p>由于每次网络传输，除了传输消息本身以外，还要传输非常多的网络协议本身的一些内容（称为Overhead），所以将多条消息合并到一起传输，可有效减少网络传输的Overhead，进而提高了传输效率。  </p>
<p>从<a href="http://www.jasongj.com/img/kafka/KafkaColumn6/kafka_IO.png">零拷贝章节的图</a>中可以看到，虽然Broker持续从网络接收数据，但是写磁盘并非每秒都在发生，而是间隔一段时间写一次磁盘，并且每次写磁盘的数据量都非常大（最高达到718MB/S）。</p>
<h3 id="数据压缩降低网络负载"><a href="#数据压缩降低网络负载" class="headerlink" title="数据压缩降低网络负载"></a>数据压缩降低网络负载</h3><p>Kafka从0.7开始，即支持将数据压缩后再传输给Broker。除了可以将每条消息单独压缩然后传输外，Kafka还支持在批量发送时，将整个Batch的消息一起压缩后传输。数据压缩的一个基本原理是，重复数据越多压缩效果越好。因此将整个Batch的数据一起压缩能更大幅度减小数据量，从而更大程度提高网络传输效率。</p>
<p>Broker接收消息后，并不直接解压缩，而是直接将消息以压缩后的形式持久化到磁盘。Consumer Fetch到数据后再解压缩。因此Kafka的压缩不仅减少了Producer到Broker的网络传输负载，同时也降低了Broker磁盘操作的负载，也降低了Consumer与Broker间的网络传输量，从而极大得提高了传输效率，提高了吞吐量。</p>
<h3 id="高效的序列化方式"><a href="#高效的序列化方式" class="headerlink" title="高效的序列化方式"></a>高效的序列化方式</h3><p>Kafka消息的Key和Payload（或者说Value）的类型可自定义，只需同时提供相应的序列化器和反序列化器即可。因此用户可以通过使用快速且紧凑的序列化-反序列化方式（如Avro，Protocal Buffer）来减少实际网络传输和磁盘存储的数据规模，从而提高吞吐率。这里要注意，如果使用的序列化方法太慢，即使压缩比非常高，最终的效率也不一定高。</p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
<li><a href="http://www.jasongj.com/kafka/high_throughput/">Kafka设计解析（六）- Kafka高性能架构之道</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文从宏观架构层面和微观实现层面分析了Kafka如何实现高性能。包含Kafka如何利用Partition实现并行处理和提供水平扩展能力，如何通过ISR实现可用性和数据一致性的动态平衡，如何使用NIO和Linux的sendfile实现零拷贝以及如何通过顺序读写和数据压缩实现磁盘的高效利用。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（二） 如何做到Kaggle排名前2%</title>
    <link href="http://www.jasongj.com/ml/classification/"/>
    <id>http://www.jasongj.com/ml/classification/</id>
    <published>2017-04-11T23:02:13.000Z</published>
    <updated>2017-05-13T00:25:14.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/ml/classification/">原文链接</a> <a href="http://www.jasongj.com/ml/classification/">http://www.jasongj.com/ml/classification/</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文详述了如何通过数据预览，探索式数据分析，缺失数据填补，删除关联特征以及派生新特征等方法，在<a href="https://www.kaggle.com/c/titanic" title="Kaggle的Titanic幸存预测" target="_blank" rel="external nofollow">Kaggle的Titanic幸存预测</a>这一分类问题竞赛中获得前2%排名的具体方法。  </p>
<h1 id="竞赛内容介绍"><a href="#竞赛内容介绍" class="headerlink" title="竞赛内容介绍"></a>竞赛内容介绍</h1><p><a href="https://www.kaggle.com/c/titanic" title="Kaggle的Titanic幸存预测" target="_blank" rel="external nofollow">Titanic幸存预测</a>是Kaggle上参赛人数最多的竞赛之一。它要求参赛选手通过训练数据集分析出什么类型的人更可能幸存，并预测出测试数据集中的所有乘客是否生还。</p>
<p>该项目是一个二元分类问题</p>
<h1 id="如何取得排名前2-的成绩"><a href="#如何取得排名前2-的成绩" class="headerlink" title="如何取得排名前2%的成绩"></a>如何取得排名前2%的成绩</h1><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><p>在加载数据之前，先通过如下代码加载之后会用到的所有R库</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">library</span>(readr) <span class="comment"># File read / write</span></div><div class="line"><span class="keyword">library</span>(ggplot2) <span class="comment"># Data visualization</span></div><div class="line"><span class="keyword">library</span>(ggthemes) <span class="comment"># Data visualization</span></div><div class="line"><span class="keyword">library</span>(scales) <span class="comment"># Data visualization</span></div><div class="line"><span class="keyword">library</span>(plyr)</div><div class="line"><span class="keyword">library</span>(stringr) <span class="comment"># String manipulation</span></div><div class="line"><span class="keyword">library</span>(InformationValue) <span class="comment"># IV / WOE calculation</span></div><div class="line"><span class="keyword">library</span>(MLmetrics) <span class="comment"># Mache learning metrics.e.g. Recall, Precision, Accuracy, AUC</span></div><div class="line"><span class="keyword">library</span>(rpart) <span class="comment"># Decision tree utils</span></div><div class="line"><span class="keyword">library</span>(randomForest) <span class="comment"># Random Forest</span></div><div class="line"><span class="keyword">library</span>(dplyr) <span class="comment"># Data manipulation</span></div><div class="line"><span class="keyword">library</span>(e1071) <span class="comment"># SVM</span></div><div class="line"><span class="keyword">library</span>(Amelia) <span class="comment"># Missing value utils</span></div><div class="line"><span class="keyword">library</span>(party) <span class="comment"># Conditional inference trees</span></div><div class="line"><span class="keyword">library</span>(gbm) <span class="comment"># AdaBoost</span></div><div class="line"><span class="keyword">library</span>(class) <span class="comment"># KNN</span></div><div class="line"><span class="keyword">library</span>(scales)</div></pre></td></tr></table></figure>
<p>通过如下代码将训练数据和测试数据分别加载到名为train和test的data.frame中</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train &lt;- read_csv(<span class="string">"train.csv"</span>)</div><div class="line">test &lt;- read_csv(<span class="string">"test.csv"</span>)</div></pre></td></tr></table></figure>
<p>由于之后需要对训练数据和测试数据做相同的转换，为避免重复操作和出现不一至的情况，更为了避免可能碰到的Categorical类型新level的问题，这里建议将训练数据和测试数据合并，统一操作。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">data &lt;- bind_rows(train, test)</div><div class="line">train.row &lt;- <span class="number">1</span>:nrow(train)</div><div class="line">test.row &lt;- (<span class="number">1</span> + nrow(train)):(nrow(train) + nrow(test))</div></pre></td></tr></table></figure>
<h2 id="数据预览"><a href="#数据预览" class="headerlink" title="数据预览"></a>数据预览</h2><p>先观察数据</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">str(data)</div></pre></td></tr></table></figure>
<pre><code>## Classes &apos;tbl_df&apos;, &apos;tbl&apos; and &apos;data.frame&apos;:    1309 obs. of  12 variables:
##  $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
##  $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
##  $ Name       : chr  &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ...
##  $ Sex        : chr  &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;female&quot; ...
##  $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
##  $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
##  $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
##  $ Ticket     : chr  &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ...
##  $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
##  $ Cabin      : chr  NA &quot;C85&quot; NA &quot;C123&quot; ...
##  $ Embarked   : chr  &quot;S&quot; &quot;C&quot; &quot;S&quot; &quot;S&quot; ...
</code></pre><p>从上可见，数据集包含12个变量，1309条数据，其中891条为训练数据，418条为测试数据</p>
<ul>
<li>PassengerId 整型变量，标识乘客的ID，递增变量，对预测无帮助</li>
<li>Survived 整型变量，标识该乘客是否幸存。0表示遇难，1表示幸存。将其转换为factor变量比较方便处理</li>
<li>Pclass 整型变量，标识乘客的社会-经济状态，1代表Upper，2代表Middle，3代表Lower</li>
<li>Name 字符型变量，除包含姓和名以外，还包含Mr. Mrs. Dr.这样的具有西方文化特点的信息</li>
<li>Sex 字符型变量，标识乘客性别，适合转换为factor类型变量</li>
<li>Age 整型变量，标识乘客年龄，有缺失值</li>
<li>SibSp 整型变量，代表兄弟姐妹及配偶的个数。其中Sib代表Sibling也即兄弟姐妹，Sp代表Spouse也即配偶</li>
<li>Parch 整型变量，代表父母或子女的个数。其中Par代表Parent也即父母，Ch代表Child也即子女</li>
<li>Ticket 字符型变量，代表乘客的船票号</li>
<li>Fare 数值型，代表乘客的船票价</li>
<li>Cabin 字符型，代表乘客所在的舱位，有缺失值</li>
<li>Embarked 字符型，代表乘客登船口岸，适合转换为factor型变量</li>
</ul>
<h2 id="探索式数据分析"><a href="#探索式数据分析" class="headerlink" title="探索式数据分析"></a>探索式数据分析</h2><h3 id="乘客社会等级越高，幸存率越高"><a href="#乘客社会等级越高，幸存率越高" class="headerlink" title="乘客社会等级越高，幸存率越高"></a>乘客社会等级越高，幸存率越高</h3><p>对于第一个变量Pclass，先将其转换为factor类型变量。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data$Survived &lt;- factor(data$Survived)</div></pre></td></tr></table></figure>
<p>可通过如下方式统计出每个Pclass幸存和遇难人数，如下</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = Pclass, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">"count"</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'Pclass'</span>) + </div><div class="line">  ylab(<span class="string">'Count'</span>) + </div><div class="line">  ggtitle(<span class="string">'How Pclass impact survivor'</span>) + </div><div class="line">  scale_fill_manual(values=c(<span class="string">"#FF0000"</span>, <span class="string">"#00FF00"</span>)) +</div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Pclass-1.png" alt=""></p>
<p>从上图可见，Pclass=1的乘客大部分幸存，Pclass=2的乘客接近一半幸存，而Pclass=3的乘客只有不到25%幸存。</p>
<p>为了更为定量的计算Pclass的预测价值，可以算出Pclass的WOE和IV如下。从结果可以看出，Pclass的IV为0.5，且“Highly Predictive”。由此可以暂时将Pclass作为预测模型的特征变量之一。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=factor(data$Pclass[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL     PCT_G     PCT_B        WOE         IV
## 1   1   136   80   216 0.3976608 0.1457195  1.0039160 0.25292792
## 2   2    87   97   184 0.2543860 0.1766849  0.3644848 0.02832087
## 3   3   119  372   491 0.3479532 0.6775956 -0.6664827 0.21970095
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=factor(data$Pclass[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.5009497
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="不同Title的乘客幸存率不同"><a href="#不同Title的乘客幸存率不同" class="headerlink" title="不同Title的乘客幸存率不同"></a>不同Title的乘客幸存率不同</h3><p>乘客姓名重复度太低，不适合直接使用。而姓名中包含Mr. Mrs. Dr.等具有文化特征的信息，可将之抽取出来。</p>
<p>本文使用如下方式从姓名中抽取乘客的Title</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">data$Title &lt;- sapply(data$Name, FUN=<span class="keyword">function</span>(x) &#123;strsplit(x, split=<span class="string">'[,.]'</span>)[[<span class="number">1</span>]][<span class="number">2</span>]&#125;)</div><div class="line">data$Title &lt;- sub(<span class="string">' '</span>, <span class="string">''</span>, data$Title)</div><div class="line">data$Title[data$Title %<span class="keyword">in</span>% c(<span class="string">'Mme'</span>, <span class="string">'Mlle'</span>)] &lt;- <span class="string">'Mlle'</span></div><div class="line">data$Title[data$Title %<span class="keyword">in</span>% c(<span class="string">'Capt'</span>, <span class="string">'Don'</span>, <span class="string">'Major'</span>, <span class="string">'Sir'</span>)] &lt;- <span class="string">'Sir'</span></div><div class="line">data$Title[data$Title %<span class="keyword">in</span>% c(<span class="string">'Dona'</span>, <span class="string">'Lady'</span>, <span class="string">'the Countess'</span>, <span class="string">'Jonkheer'</span>)] &lt;- <span class="string">'Lady'</span></div><div class="line">data$Title &lt;- factor(data$Title)</div></pre></td></tr></table></figure>
<p>抽取完乘客的Title后，统计出不同Title的乘客的幸存与遇难人数</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = Title, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">"count"</span>, position=<span class="string">'stack'</span>) + </div><div class="line">  xlab(<span class="string">'Title'</span>) + </div><div class="line">  ylab(<span class="string">'Count'</span>) + </div><div class="line">  ggtitle(<span class="string">'How Title impact survivor'</span>) + </div><div class="line">  scale_fill_discrete(name=<span class="string">"Survived"</span>, breaks=c(<span class="number">0</span>, <span class="number">1</span>), labels=c(<span class="string">"Perish"</span>, <span class="string">"Survived"</span>)) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_stack(vjust = <span class="number">0.5</span>)) +</div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Title-1.png" alt=""></p>
<p>从上图可看出，Title为Mr的乘客幸存比例非常小，而Title为Mrs和Miss的乘客幸存比例非常大。这里使用WOE和IV来定量计算Title这一变量对于最终的预测是否有用。从计算结果可见，IV为1.520702，且”Highly Predictive”。因此，可暂将Title作为预测模型中的一个特征变量。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=data$Title[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##       CAT GOODS BADS TOTAL       PCT_G       PCT_B         WOE            IV
## 1     Col     1    1     2 0.002873563 0.001808318  0.46315552  4.933741e-04
## 2      Dr     3    4     7 0.008620690 0.007233273  0.17547345  2.434548e-04
## 3    Lady     2    1     3 0.005747126 0.001808318  1.15630270  4.554455e-03
## 4  Master    23   17    40 0.066091954 0.030741410  0.76543639  2.705859e-02
## 5    Miss   127   55   182 0.364942529 0.099457505  1.30000942  3.451330e-01
## 6    Mlle     3    3     3 0.008620690 0.005424955  0.46315552  1.480122e-03
## 7      Mr    81  436   517 0.232758621 0.788426763 -1.22003757  6.779360e-01
## 8     Mrs    99   26   125 0.284482759 0.047016275  1.80017883  4.274821e-01
## 9      Ms     1    1     1 0.002873563 0.001808318  0.46315552  4.933741e-04
## 10    Rev     6    6     6 0.017241379 0.010849910  0.46315552  2.960244e-03
## 11    Sir     2    3     5 0.005747126 0.005424955  0.05769041  1.858622e-05
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=data$Title[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 1.487853
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="女性幸存率远高于男性"><a href="#女性幸存率远高于男性" class="headerlink" title="女性幸存率远高于男性"></a>女性幸存率远高于男性</h3><p>对于Sex变量，由Titanic号沉没的背景可知，逃生时遵循“妇女与小孩先走”的规则，由此猜想，Sex变量应该对预测乘客幸存有帮助。</p>
<p>如下数据验证了这一猜想，大部分女性（233/(233+81)=74.20%）得以幸存，而男性中只有很小部分（109/(109+468)=22.85%）幸存。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">data$Sex &lt;- as.factor(data$Sex)</div><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = Sex, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'Sex'</span>) + </div><div class="line">  ylab(<span class="string">'Count'</span>) + </div><div class="line">  ggtitle(<span class="string">'How Sex impact survivo'</span>) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Sex-1.png" alt=""></p>
<p>通过计算WOE和IV可知，Sex的IV为1.34且”Highly Predictive”，可暂将Sex作为特征变量。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=data$Sex[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##      CAT GOODS BADS TOTAL     PCT_G    PCT_B        WOE        IV
## 1 female   233   81   314 0.6812865 0.147541  1.5298770 0.8165651
## 2   male   109  468   577 0.3187135 0.852459 -0.9838327 0.5251163
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=data$Sex[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 1.341681
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="未成年人幸存率高于成年人"><a href="#未成年人幸存率高于成年人" class="headerlink" title="未成年人幸存率高于成年人"></a>未成年人幸存率高于成年人</h3><p>结合背景，按照“妇女与小孩先走”的规则，未成年人应该有更大可能幸存。如下图所示，Age &lt; 18的乘客中，幸存人数确实高于遇难人数。同时青壮年乘客中，遇难人数远高于幸存人数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[(!is.na(data$Age)) &amp; row(data[, <span class="string">'Age'</span>]) &lt;= <span class="number">891</span>, ], aes(x = Age, color=Survived)) + </div><div class="line">  geom_line(aes(label=..count..), stat = <span class="string">'bin'</span>, binwidth=<span class="number">5</span>)  + </div><div class="line">  labs(title = <span class="string">"How Age impact survivor"</span>, x = <span class="string">"Age"</span>, y = <span class="string">"Count"</span>, fill = <span class="string">"Survived"</span>)</div></pre></td></tr></table></figure>
<pre><code>## Warning: Ignoring unknown aesthetics: label
</code></pre><p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Age-1.png" alt=""></p>
<h3 id="配偶及兄弟姐妹数适中的乘客更易幸存"><a href="#配偶及兄弟姐妹数适中的乘客更易幸存" class="headerlink" title="配偶及兄弟姐妹数适中的乘客更易幸存"></a>配偶及兄弟姐妹数适中的乘客更易幸存</h3><p>对于SibSp变量，分别统计出幸存与遇难人数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = SibSp, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  labs(title = <span class="string">"How SibSp impact survivor"</span>, x = <span class="string">"Sibsp"</span>, y = <span class="string">"Count"</span>, fill = <span class="string">"Survived"</span>) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20SibSp-1.png" alt=""></p>
<p>从上图可见，SibSp为0的乘客，幸存率低于1/3；SibSp为1或2的乘客，幸存率高于50%；SibSp大于等于3的乘客，幸存率非常低。可通过计算WOE与IV定量计算SibSp对预测的贡献。IV为0.1448994，且”Highly Predictive”。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=as.factor(data$SibSp[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL       PCT_G       PCT_B        WOE          IV
## 1   0   210  398   608 0.593220339 0.724954463 -0.2005429 0.026418349
## 2   1   112   97   209 0.316384181 0.176684882  0.5825894 0.081387334
## 3   2    13   15    28 0.036723164 0.027322404  0.2957007 0.002779811
## 4   3     4   12    16 0.011299435 0.021857923 -0.6598108 0.006966604
## 5   4     3   15    18 0.008474576 0.027322404 -1.1706364 0.022063953
## 6   5     5    5     5 0.014124294 0.009107468  0.4388015 0.002201391
## 7   8     7    7     7 0.019774011 0.012750455  0.4388015 0.003081947
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=as.factor(data$SibSp[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.1448994
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="父母与子女数为1到3的乘客更可能幸存"><a href="#父母与子女数为1到3的乘客更可能幸存" class="headerlink" title="父母与子女数为1到3的乘客更可能幸存"></a>父母与子女数为1到3的乘客更可能幸存</h3><p>对于Parch变量，分别统计出幸存与遇难人数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = Parch, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  labs(title = <span class="string">"How Parch impact survivor"</span>, x = <span class="string">"Parch"</span>, y = <span class="string">"Count"</span>, fill = <span class="string">"Survived"</span>) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Parch-1.png" alt=""></p>
<p>从上图可见，Parch为0的乘客，幸存率低于1/3；Parch为1到3的乘客，幸存率高于50%；Parch大于等于4的乘客，幸存率非常低。可通过计算WOE与IV定量计算Parch对预测的贡献。IV为0.1166611，且”Highly Predictive”。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=as.factor(data$Parch[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL       PCT_G       PCT_B        WOE          IV
## 1   0   233  445   678 0.671469741 0.810564663 -0.1882622 0.026186312
## 2   1    65   53   118 0.187319885 0.096539162  0.6628690 0.060175728
## 3   2    40   40    80 0.115273775 0.072859745  0.4587737 0.019458440
## 4   3     3    2     5 0.008645533 0.003642987  0.8642388 0.004323394
## 5   4     4    4     4 0.011527378 0.007285974  0.4587737 0.001945844
## 6   5     1    4     5 0.002881844 0.007285974 -0.9275207 0.004084922
## 7   6     1    1     1 0.002881844 0.001821494  0.4587737 0.000486461
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=as.factor(data$Parch[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.1166611
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="FamilySize为2到4的乘客幸存可能性较高"><a href="#FamilySize为2到4的乘客幸存可能性较高" class="headerlink" title="FamilySize为2到4的乘客幸存可能性较高"></a>FamilySize为2到4的乘客幸存可能性较高</h3><p>SibSp与Parch都说明，当乘客无亲人时，幸存率较低，乘客有少数亲人时，幸存率高于50%，而当亲人数过高时，幸存率反而降低。在这里，可以考虑将SibSp与Parch相加，生成新的变量，FamilySize。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">data$FamilySize &lt;- data$SibSp + data$Parch + <span class="number">1</span></div><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = FamilySize, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'FamilySize'</span>) + </div><div class="line">  ylab(<span class="string">'Count'</span>) + </div><div class="line">  ggtitle(<span class="string">'How FamilySize impact survivor'</span>) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20FamilySize-1.png" alt=""></p>
<p>计算FamilySize的WOE和IV可知，IV为0.3497672，且“Highly Predictive”。由SibSp与Parch派生出来的新变量FamilySize的IV高于SibSp与Parch的IV，因此，可将这个派生变量FamilySize作为特征变量。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=as.factor(data$FamilySize[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL       PCT_G      PCT_B        WOE           IV
## 1   1   163  374   537 0.459154930 0.68123862 -0.3945249 0.0876175539
## 2   2    89   72   161 0.250704225 0.13114754  0.6479509 0.0774668616
## 3   3    59   43   102 0.166197183 0.07832423  0.7523180 0.0661084057
## 4   4    21    8    29 0.059154930 0.01457195  1.4010615 0.0624634998
## 5   5     3   12    15 0.008450704 0.02185792 -0.9503137 0.0127410643
## 6   6     3   19    22 0.008450704 0.03460838 -1.4098460 0.0368782940
## 7   7     4    8    12 0.011267606 0.01457195 -0.2571665 0.0008497665
## 8   8     6    6     6 0.016901408 0.01092896  0.4359807 0.0026038712
## 9  11     7    7     7 0.019718310 0.01275046  0.4359807 0.0030378497
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=as.factor(data$FamilySize[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.3497672
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="共票号乘客幸存率高"><a href="#共票号乘客幸存率高" class="headerlink" title="共票号乘客幸存率高"></a>共票号乘客幸存率高</h3><p>对于Ticket变量，重复度非常低，无法直接利用。先统计出每张票对应的乘客数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ticket.count &lt;- aggregate(data$Ticket, by = list(data$Ticket), <span class="keyword">function</span>(x) sum(!is.na(x)))</div></pre></td></tr></table></figure>
<p>这里有个猜想，票号相同的乘客，是一家人，很可能同时幸存或者同时遇难。现将所有乘客按照Ticket分为两组，一组是使用单独票号，另一组是与他人共享票号，并统计出各组的幸存与遇难人数。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">data$TicketCount &lt;- apply(data, <span class="number">1</span>, <span class="keyword">function</span>(x) ticket.count[which(ticket.count[, <span class="number">1</span>] == x[<span class="string">'Ticket'</span>]), <span class="number">2</span>])</div><div class="line">data$TicketCount &lt;- factor(sapply(data$TicketCount, <span class="keyword">function</span>(x) ifelse(x &gt; <span class="number">1</span>, <span class="string">'Share'</span>, <span class="string">'Unique'</span>)))</div><div class="line">ggplot(data = data[<span class="number">1</span>:nrow(train),], mapping = aes(x = TicketCount, y = ..count.., fill=Survived)) + </div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'TicketCount'</span>) + </div><div class="line">  ylab(<span class="string">'Count'</span>) + </div><div class="line">  ggtitle(<span class="string">'How TicketCount impact survivor'</span>) + </div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20TicketCount-1.png" alt=""></p>
<p>由上图可见，未与他人同票号的乘客，只有130/(130+351)=27%幸存，而与他人同票号的乘客有212/(212+198)=51.7%幸存。计算TicketCount的WOE与IV如下。其IV为0.2751882，且”Highly Predictive”</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=data$TicketCount[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##      CAT GOODS BADS TOTAL    PCT_G     PCT_B        WOE        IV
## 1  Share   212  198   410 0.619883 0.3606557  0.5416069 0.1403993
## 2 Unique   130  351   481 0.380117 0.6393443 -0.5199641 0.1347889
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=data$TicketCount[<span class="number">1</span>:nrow(train)], Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.2751882
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="支出船票费越高幸存率越高"><a href="#支出船票费越高幸存率越高" class="headerlink" title="支出船票费越高幸存率越高"></a>支出船票费越高幸存率越高</h3><p>对于Fare变量，由下图可知，Fare越大，幸存率越高。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ggplot(data = data[(!is.na(data$Fare)) &amp; row(data[, <span class="string">'Fare'</span>]) &lt;= <span class="number">891</span>, ], aes(x = Fare, color=Survived)) + </div><div class="line">  geom_line(aes(label=..count..), stat = <span class="string">'bin'</span>, binwidth=<span class="number">10</span>)  + </div><div class="line">  labs(title = <span class="string">"How Fare impact survivor"</span>, x = <span class="string">"Fare"</span>, y = <span class="string">"Count"</span>, fill = <span class="string">"Survived"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Fare-1.png" alt=""></p>
<h3 id="不同仓位的乘客幸存率不同"><a href="#不同仓位的乘客幸存率不同" class="headerlink" title="不同仓位的乘客幸存率不同"></a>不同仓位的乘客幸存率不同</h3><p>对于Cabin变量，其值以字母开始，后面伴以数字。这里有一个猜想，字母代表某个区域，数据代表该区域的序号。类似于火车票即有车箱号又有座位号。因此，这里可尝试将Cabin的首字母提取出来，并分别统计出不同首字母仓位对应的乘客的幸存率。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ggplot(data[<span class="number">1</span>:nrow(train), ], mapping = aes(x = as.factor(sapply(data$Cabin[<span class="number">1</span>:nrow(train)], <span class="keyword">function</span>(x) str_sub(x, start = <span class="number">1</span>, end = <span class="number">1</span>))), y = ..count.., fill = Survived)) +</div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'Cabin'</span>) +</div><div class="line">  ylab(<span class="string">'Count'</span>) +</div><div class="line">  ggtitle(<span class="string">'How Cabin impact survivor'</span>) +</div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Cabin-1.png" alt=""></p>
<p>由上图可见，仓位号首字母为B，C，D，E，F的乘客幸存率均高于50%，而其它仓位的乘客幸存率均远低于50%。仓位变量的WOE及IV计算如下。由此可见，Cabin的IV为0.1866526，且“Highly Predictive”</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data$Cabin &lt;- sapply(data$Cabin, <span class="keyword">function</span>(x) str_sub(x, start = <span class="number">1</span>, end = <span class="number">1</span>))</div><div class="line">WOETable(X=as.factor(data$Cabin[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL      PCT_G      PCT_B        WOE          IV
## 1   A     7    8    15 0.05109489 0.11764706 -0.8340046 0.055504815
## 2   B    35   12    47 0.25547445 0.17647059  0.3699682 0.029228917
## 3   C    35   24    59 0.25547445 0.35294118 -0.3231790 0.031499197
## 4   D    25    8    33 0.18248175 0.11764706  0.4389611 0.028459906
## 5   E    24    8    32 0.17518248 0.11764706  0.3981391 0.022907100
## 6   F     8    5    13 0.05839416 0.07352941 -0.2304696 0.003488215
## 7   G     2    2     4 0.01459854 0.02941176 -0.7004732 0.010376267
## 8   T     1    1     1 0.00729927 0.01470588 -0.7004732 0.005188134
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=as.factor(data$Cabin[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.1866526
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><h3 id="Embarked为S的乘客幸存率较低"><a href="#Embarked为S的乘客幸存率较低" class="headerlink" title="Embarked为S的乘客幸存率较低"></a>Embarked为S的乘客幸存率较低</h3><p>Embarked变量代表登船码头，现通过统计不同码头登船的乘客幸存率来判断Embarked是否可用于预测乘客幸存情况。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ggplot(data[<span class="number">1</span>:nrow(train), ], mapping = aes(x = Embarked, y = ..count.., fill = Survived)) +</div><div class="line">  geom_bar(stat = <span class="string">'count'</span>, position=<span class="string">'dodge'</span>) + </div><div class="line">  xlab(<span class="string">'Embarked'</span>) +</div><div class="line">  ylab(<span class="string">'Count'</span>) +</div><div class="line">  ggtitle(<span class="string">'How Embarked impact survivor'</span>) +</div><div class="line">  geom_text(stat = <span class="string">"count"</span>, aes(label = ..count..), position=position_dodge(width=<span class="number">1</span>), , vjust=-<span class="number">0.5</span>) + </div><div class="line">  theme(plot.title = element_text(hjust = <span class="number">0.5</span>), legend.position=<span class="string">"bottom"</span>)</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Survived%20vs.%20Embarked-1.png" alt=""></p>
<p>从上图可见，Embarked为S的乘客幸存率仅为217/(217+427)=33.7%，而Embarked为C或为NA的乘客幸存率均高于50%。初步判断Embarked可用于预测乘客是否幸存。Embarked的WOE和IV计算如下。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">WOETable(X=as.factor(data$Embarked[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>##   CAT GOODS BADS TOTAL      PCT_G     PCT_B        WOE           IV
## 1   C    93   75   168 0.27352941 0.1366120  0.6942642 9.505684e-02
## 2   Q    30   47    77 0.08823529 0.0856102  0.0302026 7.928467e-05
## 3   S   217  427   644 0.63823529 0.7777778 -0.1977338 2.759227e-02
</code></pre><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">IV(X=as.factor(data$Embarked[<span class="number">1</span>:nrow(train)]), Y=data$Survived[<span class="number">1</span>:nrow(train)])</div></pre></td></tr></table></figure>
<pre><code>## [1] 0.1227284
## attr(,&quot;howgood&quot;)
## [1] &quot;Highly Predictive&quot;
</code></pre><p>从上述计算结果可见，IV为0.1227284，且“Highly Predictive”。</p>
<h2 id="填补缺失值"><a href="#填补缺失值" class="headerlink" title="填补缺失值"></a>填补缺失值</h2><h3 id="列出所有缺失数据"><a href="#列出所有缺失数据" class="headerlink" title="列出所有缺失数据"></a>列出所有缺失数据</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">attach</span>(data)</div><div class="line">  missing &lt;- list(Pclass=nrow(data[is.na(Pclass), ]))</div><div class="line">  missing$Name &lt;- nrow(data[is.na(Name), ])</div><div class="line">  missing$Sex &lt;- nrow(data[is.na(Sex), ])</div><div class="line">  missing$Age &lt;- nrow(data[is.na(Age), ])</div><div class="line">  missing$SibSp &lt;- nrow(data[is.na(SibSp), ])</div><div class="line">  missing$Parch &lt;- nrow(data[is.na(Parch), ])</div><div class="line">  missing$Ticket &lt;- nrow(data[is.na(Ticket), ])</div><div class="line">  missing$Fare &lt;- nrow(data[is.na(Fare), ])</div><div class="line">  missing$Cabin &lt;- nrow(data[is.na(Cabin), ])</div><div class="line">  missing$Embarked &lt;- nrow(data[is.na(Embarked), ])</div><div class="line">  <span class="keyword">for</span> (name <span class="keyword">in</span> names(missing)) &#123;</div><div class="line">    <span class="keyword">if</span> (missing[[name]][<span class="number">1</span>] &gt; <span class="number">0</span>) &#123;</div><div class="line">      print(paste(<span class="string">''</span>, name, <span class="string">' miss '</span>, missing[[name]][<span class="number">1</span>], <span class="string">' values'</span>, sep = <span class="string">''</span>))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"><span class="keyword">detach</span>(data)</div></pre></td></tr></table></figure>
<pre><code>## [1] &quot;Age miss 263 values&quot;
## [1] &quot;Fare miss 1 values&quot;
## [1] &quot;Cabin miss 1014 values&quot;
## [1] &quot;Embarked miss 2 values&quot;
</code></pre><h3 id="预测乘客年龄"><a href="#预测乘客年龄" class="headerlink" title="预测乘客年龄"></a>预测乘客年龄</h3><p>缺失年龄信息的乘客数为263，缺失量比较大，不适合使用中位数或者平均值填补。一般通过使用其它变量预测或者直接将缺失值设置为默认值的方法填补，这里通过其它变量来预测缺失的年龄信息。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">age.model &lt;- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize, data=data[!is.na(data$Age), ], method=<span class="string">'anova'</span>)</div><div class="line">data$Age[is.na(data$Age)] &lt;- predict(age.model, data[is.na(data$Age), ])</div></pre></td></tr></table></figure>
<h3 id="中位数填补缺失的Embarked值"><a href="#中位数填补缺失的Embarked值" class="headerlink" title="中位数填补缺失的Embarked值"></a>中位数填补缺失的Embarked值</h3><p>从如下数据可见，缺失Embarked信息的乘客的Pclass均为1，且Fare均为80。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data[is.na(data$Embarked), c(<span class="string">'PassengerId'</span>, <span class="string">'Pclass'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>)]</div></pre></td></tr></table></figure>
<pre><code>## # A tibble: 2 × 4
##   PassengerId Pclass  Fare Embarked
##         &lt;int&gt;  &lt;int&gt; &lt;dbl&gt;    &lt;chr&gt;
## 1          62      1    80     &lt;NA&gt;
## 2         830      1    80     &lt;NA&gt;
</code></pre><p>由下图所见，Embarked为C且Pclass为1的乘客的Fare中位数为80。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ggplot(data[!is.na(data$Embarked),], aes(x=Embarked, y=Fare, fill=factor(Pclass))) +</div><div class="line">  geom_boxplot() +</div><div class="line">  geom_hline(aes(yintercept=<span class="number">80</span>), color=<span class="string">'red'</span>, linetype=<span class="string">'dashed'</span>, lwd=<span class="number">2</span>) +</div><div class="line">  scale_y_continuous(labels=dollar_format()) + theme_few()</div></pre></td></tr></table></figure>
<p><img src="http://www.jasongj.com/img/ml/classification/Fare%20median%20value%20of%20each%20Embarked%20and%20Pclass-1.png" alt="Fare median value of each Embarked and Pclass"></p>
<p>因此可以将缺失的Embarked值设置为’C’。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data$Embarked[is.na(data$Embarked)] &lt;- <span class="string">'C'</span></div><div class="line">data$Embarked &lt;- as.factor(data$Embarked)</div></pre></td></tr></table></figure>
<h3 id="中位数填补一个缺失的Fare值"><a href="#中位数填补一个缺失的Fare值" class="headerlink" title="中位数填补一个缺失的Fare值"></a>中位数填补一个缺失的Fare值</h3><p>由于缺失Fare值的记录非常少，一般可直接使用平均值或者中位数填补该缺失值。这里使用乘客的Fare中位数填补缺失值。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data$Fare[is.na(data$Fare)] &lt;- median(data$Fare, na.rm=<span class="literal">TRUE</span>)</div></pre></td></tr></table></figure>
<h3 id="将缺失的Cabin设置为默认值"><a href="#将缺失的Cabin设置为默认值" class="headerlink" title="将缺失的Cabin设置为默认值"></a>将缺失的Cabin设置为默认值</h3><p>缺失Cabin信息的记录数较多，不适合使用中位数或者平均值填补，一般通过使用其它变量预测或者直接将缺失值设置为默认值的方法填补。由于Cabin信息不太容易从其它变量预测，并且在上一节中，将NA单独对待时，其IV已经比较高。因此这里直接将缺失的Cabin设置为一个默认值。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data$Cabin &lt;- as.factor(sapply(data$Cabin, <span class="keyword">function</span>(x) ifelse(is.na(x), <span class="string">'X'</span>, str_sub(x, start = <span class="number">1</span>, end = <span class="number">1</span>))))</div></pre></td></tr></table></figure>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">model &lt;- cforest(Survived ~ Pclass + Title + Sex + Age + SibSp + Parch + FamilySize + TicketCount + Fare + Cabin + Embarked, data = data[train.row, ], controls=cforest_unbiased(ntree=<span class="number">2000</span>, mtry=<span class="number">3</span>))</div></pre></td></tr></table></figure>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>一般情况下，应该将训练数据分为两部分，一部分用于训练，另一部分用于验证。或者使用k-fold交叉验证。本文将所有训练数据都用于训练，然后随机选取30%数据集用于验证。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">cv.summarize &lt;- <span class="keyword">function</span>(data.true, data.predict) &#123;</div><div class="line">  print(paste(<span class="string">'Recall:'</span>, Recall(data.true, data.predict)))</div><div class="line">  print(paste(<span class="string">'Precision:'</span>, Precision(data.true, data.predict)))</div><div class="line">  print(paste(<span class="string">'Accuracy:'</span>, Accuracy(data.predict, data.true)))</div><div class="line">  print(paste(<span class="string">'AUC:'</span>, AUC(data.predict, data.true)))</div><div class="line">&#125;</div><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">cv.test.sample &lt;- sample(<span class="number">1</span>:nrow(train), as.integer(<span class="number">0.3</span> * nrow(train)), replace = <span class="literal">TRUE</span>)</div><div class="line">cv.test &lt;- data[cv.test.sample,]</div><div class="line">cv.prediction &lt;- predict(model, cv.test, OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">cv.summarize(cv.test$Survived, cv.prediction)</div></pre></td></tr></table></figure>
<pre><code>## [1] &quot;Recall: 0.947976878612717&quot;
## [1] &quot;Precision: 0.841025641025641&quot;
## [1] &quot;Accuracy: 0.850187265917603&quot;
## [1] &quot;AUC: 0.809094822285082&quot;
</code></pre><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">predict.result &lt;- predict(model, data[(<span class="number">1</span>+nrow(train)):(nrow(data)), ], OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">output &lt;- data.frame(PassengerId = test$PassengerId, Survived = predict.result)</div><div class="line">write.csv(output, file = <span class="string">"cit1.csv"</span>, row.names = <span class="literal">FALSE</span>)</div></pre></td></tr></table></figure>
<p>该模型预测结果在Kaggle的得分为0.80383，排第992名，前992/6292=15.8%。</p>
<h2 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h2><h3 id="去掉关联特征"><a href="#去掉关联特征" class="headerlink" title="去掉关联特征"></a>去掉关联特征</h3><p>由于FamilySize结合了SibSp与Parch的信息，因此可以尝试将SibSp与Parch从特征变量中移除。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">model &lt;- cforest(Survived ~ Pclass + Title + Sex + Age + FamilySize + TicketCount + Fare + Cabin + Embarked, data = data[train.row, ], controls=cforest_unbiased(ntree=<span class="number">2000</span>, mtry=<span class="number">3</span>))</div><div class="line">predict.result &lt;- predict(model, data[test.row, ], OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">submit &lt;- data.frame(PassengerId = test$PassengerId, Survived = predict.result)</div><div class="line">write.csv(submit, file = <span class="string">"cit2.csv"</span>, row.names = <span class="literal">FALSE</span>)</div></pre></td></tr></table></figure>
<p>该模型预测结果在Kaggle的得分仍为0.80383。</p>
<h3 id="去掉IV较低的Cabin"><a href="#去掉IV较低的Cabin" class="headerlink" title="去掉IV较低的Cabin"></a>去掉IV较低的Cabin</h3><p>由于Cabin的IV值相对较低，因此可以考虑将其从模型中移除。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">model &lt;- cforest(Survived ~ Pclass + Title + Sex + Age + FamilySize + TicketCount + Fare + Embarked, data = data[train.row, ], controls=cforest_unbiased(ntree=<span class="number">2000</span>, mtry=<span class="number">3</span>))</div><div class="line">predict.result &lt;- predict(model, data[test.row, ], OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">submit &lt;- data.frame(PassengerId = test$PassengerId, Survived = predict.result)</div><div class="line">write.csv(submit, file = <span class="string">"cit3.csv"</span>, row.names = <span class="literal">FALSE</span>)</div></pre></td></tr></table></figure>
<p>该模型预测结果在Kaggle的得分仍为0.80383。</p>
<h3 id="增加派生特征"><a href="#增加派生特征" class="headerlink" title="增加派生特征"></a>增加派生特征</h3><p>对于Name变量，上文从中派生出了Title变量。由于以下原因，可推测乘客的姓氏可能具有一定的预测作用</p>
<ul>
<li>部分西方国家中人名的重复度较高，而姓氏重复度较低，姓氏具有一定辨识度</li>
<li>部分国家的姓氏具有一定的身份识别作用</li>
<li>姓氏相同的乘客，可能是一家人（这一点也基于西方国家姓氏重复度较低这一特点），而一家人同时幸存或遇难的可能性较高</li>
</ul>
<p>考虑到只出现一次的姓氏不可能同时出现在训练集和测试集中，不具辨识度和预测作用，因此将只出现一次的姓氏均命名为’Small’</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">data$Surname &lt;- sapply(data$Name, FUN=<span class="keyword">function</span>(x) &#123;strsplit(x, split=<span class="string">'[,.]'</span>)[[<span class="number">1</span>]][<span class="number">1</span>]&#125;)</div><div class="line">data$FamilyID &lt;- paste(as.character(data$FamilySize), data$Surname, sep=<span class="string">""</span>)</div><div class="line">data$FamilyID[data$FamilySize &lt;= <span class="number">2</span>] &lt;- <span class="string">'Small'</span></div><div class="line"><span class="comment"># Delete erroneous family IDs</span></div><div class="line">famIDs &lt;- data.frame(table(data$FamilyID))</div><div class="line">famIDs &lt;- famIDs[famIDs$Freq &lt;= <span class="number">2</span>,]</div><div class="line">data$FamilyID[data$FamilyID %<span class="keyword">in</span>% famIDs$Var1] &lt;- <span class="string">'Small'</span></div><div class="line"><span class="comment"># Convert to a factor</span></div><div class="line">data$FamilyID &lt;- factor(data$FamilyID)</div></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">model &lt;- cforest(as.factor(Survived) ~ Pclass + Sex + Age + Fare + Embarked + Title + FamilySize + FamilyID + TicketCount, data = data[train.row, ], controls=cforest_unbiased(ntree=<span class="number">2000</span>, mtry=<span class="number">3</span>))</div><div class="line">predict.result &lt;- predict(model, data[test.row, ], OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">submit &lt;- data.frame(PassengerId = test$PassengerId, Survived = predict.result)</div><div class="line">write.csv(submit, file = <span class="string">"cit4.csv"</span>, row.names = <span class="literal">FALSE</span>)</div></pre></td></tr></table></figure>
<p>该模型预测结果在Kaggle的得分为0.82297，排第207名，前207/6292=3.3%</p>
<h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><p>经试验，将缺失的Embarked补充为出现最多的S而非C，成绩有所提升。但该方法理论依据不强，并且该成绩只是Public排行榜成绩，并非最终成绩，并不能说明该方法一定优于其它方法。因此本文并不推荐该方法，只是作为一种可能的思路，供大家参考学习。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data$Embarked[c(<span class="number">62</span>,<span class="number">830</span>)] = <span class="string">"S"</span></div><div class="line">data$Embarked &lt;- factor(data$Embarked)</div></pre></td></tr></table></figure></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">set.seed(<span class="number">415</span>)</div><div class="line">model &lt;- cforest(as.factor(Survived) ~ Pclass + Sex + Age + Fare + Embarked + Title + FamilySize + FamilyID + TicketCount, data = data[train.row, ], controls=cforest_unbiased(ntree=<span class="number">2000</span>, mtry=<span class="number">3</span>))</div><div class="line">predict.result &lt;- predict(model, data[test.row, ], OOB=<span class="literal">TRUE</span>, type = <span class="string">"response"</span>)</div><div class="line">submit &lt;- data.frame(PassengerId = test$PassengerId, Survived = predict.result)</div><div class="line">write.csv(submit, file = <span class="string">"cit5.csv"</span>, row.names = <span class="literal">FALSE</span>)</div></pre></td></tr></table></figure>
<p>该模型预测结果在Kaggle的得分仍为0.82775，排第114名，前114/6292=1.8%<br><img src="http://www.jasongj.com/img/ml/classification/kaggle_rank.png" alt="Kaggle rank first 2%"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文详述了如何通过数据预览，探索式数据分析，缺失数据填补，删除关联特征以及派生新特征等方法，在Kaggle的Titanic幸存预测这一分类问题竞赛中获得前2%排名的具体方法。  </p>
<h1 id="下篇预告"><a href="#下篇预告" class="headerlink" title="下篇预告"></a>下篇预告</h1><p>下一篇文章将侧重讲解使用机器学习解决工程问题的一般思路和方法。</p>
]]></content>
    
    <summary type="html">
    
      本文详述了如何通过数据预览，探索式数据分析，缺失数据填补，删除关联特征以及派生新特征等方法，在Kaggle的Titanic幸存预测这一分类问题竞赛中获得前2%排名的具体方法。
    
    </summary>
    
      <category term="machine learning" scheme="http://www.jasongj.com/categories/machine-learning/"/>
    
      <category term="机器学习" scheme="http://www.jasongj.com/categories/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://www.jasongj.com/categories/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AI/"/>
    
    
      <category term="machine learning" scheme="http://www.jasongj.com/tags/machine-learning/"/>
    
      <category term="机器学习" scheme="http://www.jasongj.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://www.jasongj.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Spark性能优化之道——解决Spark数据倾斜（Data Skew）的N种姿势</title>
    <link href="http://www.jasongj.com/spark/skew/"/>
    <id>http://www.jasongj.com/spark/skew/</id>
    <published>2017-02-28T01:02:13.000Z</published>
    <updated>2017-10-17T00:24:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/spark/skew">原文链接</a>　<a href="http://www.jasongj.com/spark/skew">http://www.jasongj.com/spark/skew/</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文结合实例详细阐明了Spark数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义Partitioner，使用Map侧Join代替Reduce侧Join，给倾斜Key加上随机前缀等。</p>
<h1 id="为何要处理数据倾斜（Data-Skew）"><a href="#为何要处理数据倾斜（Data-Skew）" class="headerlink" title="为何要处理数据倾斜（Data Skew）"></a>为何要处理数据倾斜（Data Skew）</h1><h2 id="什么是数据倾斜"><a href="#什么是数据倾斜" class="headerlink" title="什么是数据倾斜"></a>什么是数据倾斜</h2><p>对Spark/Hadoop这样的大数据系统来讲，数据量大并不可怕，可怕的是数据倾斜。</p>
<p>何谓数据倾斜？数据倾斜指的是，并行处理的数据集中，某一部分（如Spark或Kafka的一个Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。</p>
<p>对于分布式系统而言，理想情况下，随着系统规模（节点数量）的增加，应用整体耗时线性下降。如果一台机器处理一批大量数据需要120分钟，当机器数量增加到三时，理想的耗时为120 / 3 = 40分钟，如下图所示。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/non_skew_time.png" alt="ideal scale out"><br>　　<br>但是，上述情况只是理想情况，实际上将单机任务转换成分布式任务后，会有overhead，使得总的任务量较之单机时有所增加，所以每台机器的执行时间加起来比单台机器时更大。这里暂不考虑这些overhead，假设单机任务转换成分布式任务后，总任务量不变。<br>　　<br>但即使如此，想做到分布式情况下每台机器执行时间是单机时的<code>1 / N</code>，就必须保证每台机器的任务量相等。不幸的是，很多时候，任务的分配是不均匀的，甚至不均匀到大部分任务被分配到个别机器上，其它大部分机器所分配的任务量只占总得的小部分。比如一台机器负责处理80%的任务，另外两台机器各处理10%的任务，如下图所示。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/non_skew_time.png" alt="ideal scale out"><br>　　<br>在上图中，机器数据增加为三倍，但执行时间只降为原来的80%，远低于理想值。
　　</p>
<h2 id="数据倾斜的危害"><a href="#数据倾斜的危害" class="headerlink" title="数据倾斜的危害"></a>数据倾斜的危害</h2><p>从上图可见，当出现数据倾斜时，小量任务耗时远高于其它任务，从而使得整体耗时过大，未能充分发挥分布式系统的并行计算优势。<br>　　<br>另外，当发生数据倾斜时，部分任务处理的数据量过大，可能造成内存不足使得任务失败，并进而引进整个应用失败。
　　</p>
<h2 id="数据倾斜是如何造成的"><a href="#数据倾斜是如何造成的" class="headerlink" title="数据倾斜是如何造成的"></a>数据倾斜是如何造成的</h2><p>在Spark中，同一个Stage的不同Partition可以并行处理，而具有依赖关系的不同Stage之间是串行处理的。假设某个Spark Job分为Stage 0和Stage 1两个Stage，且Stage 1依赖于Stage 0，那Stage 0完全处理结束之前不会处理Stage 1。而Stage 0可能包含N个Task，这N个Task可以并行进行。如果其中N-1个Task都在10秒内完成，而另外一个Task却耗时1分钟，那该Stage的总时间至少为1分钟。换句话说，一个Stage所耗费的时间，主要由最慢的那个Task决定。</p>
<p>由于同一个Stage内的所有Task执行相同的计算，在排除不同计算节点计算能力差异的前提下，不同Task之间耗时的差异主要由该Task所处理的数据量决定。</p>
<p>Stage的数据来源主要分为如下两类</p>
<ul>
<li>从数据源直接读取。如读取HDFS，Kafka</li>
<li>读取上一个Stage的Shuffle数据</li>
</ul>
<h1 id="如何缓解-消除数据倾斜"><a href="#如何缓解-消除数据倾斜" class="headerlink" title="如何缓解/消除数据倾斜"></a>如何缓解/消除数据倾斜</h1><h2 id="避免数据源的数据倾斜-————-读Kafka"><a href="#避免数据源的数据倾斜-————-读Kafka" class="headerlink" title="避免数据源的数据倾斜 ———— 读Kafka"></a>避免数据源的数据倾斜 ———— 读Kafka</h2><p>以Spark Stream通过DirectStream方式读取Kafka数据为例。由于Kafka的每一个Partition对应Spark的一个Task（Partition），所以Kafka内相关Topic的各Partition之间数据是否平衡，直接决定Spark处理该数据时是否会产生数据倾斜。</p>
<p>如《<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/#Producer消息路由">Kafka设计解析（一）- Kafka背景及架构介绍</a>》一文所述，Kafka某一Topic内消息在不同Partition之间的分布，主要由Producer端所使用的Partition实现类决定。如果使用随机Partitioner，则每条消息会随机发送到一个Partition中，从而从概率上来讲，各Partition间的数据会达到平衡。此时源Stage（直接读取Kafka数据的Stage）不会产生数据倾斜。</p>
<p>但很多时候，业务场景可能会要求将具备同一特征的数据顺序消费，此时就需要将具有相同特征的数据放于同一个Partition中。一个典型的场景是，需要将同一个用户相关的PV信息置于同一个Partition中。此时，如果产生了数据倾斜，则需要通过其它方式处理。  </p>
<h2 id="避免数据源的数据倾斜-————-读文件"><a href="#避免数据源的数据倾斜-————-读文件" class="headerlink" title="避免数据源的数据倾斜 ———— 读文件"></a>避免数据源的数据倾斜 ———— 读文件</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>Spark以通过<code>textFile(path, minPartitions)</code>方法读取文件时，使用TextFileFormat。</p>
<p>对于不可切分的文件，每个文件对应一个Split从而对应一个Partition。此时各文件大小是否一致，很大程度上决定了是否存在数据源侧的数据倾斜。另外，对于不可切分的压缩文件，即使压缩后的文件大小一致，它所包含的实际数据量也可能差别很多，因为源文件数据重复度越高，压缩比越高。反过来，即使压缩文件大小接近，但由于压缩比可能差距很大，所需处理的数据量差距也可能很大。</p>
<p>此时可通过在数据生成端将不可切分文件存储为可切分文件，或者保证各文件包含数据量相同的方式避免数据倾斜。</p>
<p>对于可切分的文件，每个Split大小由如下算法决定。其中goalSize等于所有文件总大小除以minPartitions。而blockSize，如果是HDFS文件，由文件本身的block大小决定；如果是Linux本地文件，且使用本地模式，由<code>fs.local.block.size</code>决定。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize, <span class="keyword">long</span> blockSize)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>默认情况下各Split的大小不会太大，一般相当于一个Block大小（在Hadoop 2中，默认值为128MB），所以数据倾斜问题不明显。如果出现了严重的数据倾斜，可通过上述参数调整。</p>
<h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>现通过脚本生成一些文本文件，并通过如下代码进行简单的单词计数。为避免Shuffle，只计单词总个数，不须对单词进行分组计数。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">SparkConf sparkConf = <span class="keyword">new</span> SparkConf()</div><div class="line">    .setAppName(<span class="string">"ReadFileSkewDemo"</span>);</div><div class="line">JavaSparkContext javaSparkContext = <span class="keyword">new</span> JavaSparkContext(sparkConf);</div><div class="line"><span class="keyword">long</span> count = javaSparkContext.textFile(inputFile, minPartitions)</div><div class="line">    .flatMap((String line) -&gt; Arrays.asList(line.split(<span class="string">" "</span>)).iterator()).count();</div><div class="line">System.out.printf(<span class="string">"total words : %s"</span>, count);</div><div class="line">javaSparkContext.stop();</div></pre></td></tr></table></figure></p>
<p>总共生成如下11个csv文件，其中10个大小均为271.9MB，另外一个大小为8.5GB。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/uncompressedfiles.png" alt="uncompressed files"></p>
<p>之后将8.5GB大小的文件使用gzip压缩，压缩后大小仅为25.3MB。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/compressedfiles.png" alt="compressed files"></p>
<p>使用如上代码对未压缩文件夹进行单词计数操作。Split大小为 max(minSize, min(goalSize, blockSize) = max(1 B, min((271.9 <em> 10+8.5 </em> 1024) / 1 MB, 128 MB) = 128MB。无明显数据倾斜。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/splitable_unskewed.png" alt="splitable_unskewed"></p>
<p>使用同样代码对包含压缩文件的文件夹进行同样的单词计数操作。未压缩文件的Split大小仍然为128MB，而压缩文件（gzip压缩）由于不可切分，且大小仅为25.3MB，因此该文件作为一个单独的Split/Partition。虽然该文件相对较小，但是它由8.5GB文件压缩而来，包含数据量是其它未压缩文件的32倍，因此处理该Split/Partition/文件的Task耗时为4.4分钟，远高于其它Task的10秒。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/compressedfileskew.png" alt="compressed file skew"></p>
<p>由于上述gzip压缩文件大小为25.3MB，小于128MB的Split大小，不能证明gzip压缩文件不可切分。现将minPartitions从默认的1设置为229，从而目标Split大小为max(minSize, min(goalSize, blockSize) = max(1 B, min((271.9 * 10+25.3) / 229 MB, 128 MB) = 12 MB。如果gzip压缩文件可切分，则所有Split/Partition大小都不会远大于12。反之，如果仍然存在25.3MB的Partition，则说明gzip压缩文件确实不可切分，在生成不可切分文件时需要如上文所述保证各文件数量大大致相同。</p>
<p>如下图所示，gzip压缩文件对应的Split/Partition大小为25.3MB，其它Split大小均为12MB左右。而该Task耗时4.7分钟，远大于其它Task的4秒。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/unsplitable_skew.png" alt="compressed unsplitable file skew"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong><em> 适用场景 </em></strong><br>数据源侧存在不可切分文件，且文件内包含的数据量相差较大。</p>
<p><strong><em> 解决方案 </em></strong><br>尽量使用可切分的格式代替不可切分的格式，或者保证各文件实际包含数据量大致相同。</p>
<p><strong><em> 优势 </em></strong><br>可撤底消除数据源侧数据倾斜，效果显著。</p>
<p><strong><em> 劣势 </em></strong><br>数据源一般来源于外部系统，需要外部系统的支持。</p>
<h2 id="调整并行度分散同一个Task的不同Key"><a href="#调整并行度分散同一个Task的不同Key" class="headerlink" title="调整并行度分散同一个Task的不同Key"></a>调整并行度分散同一个Task的不同Key</h2><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>Spark在做Shuffle时，默认使用HashPartitioner（非Hash Shuffle）对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的Key对应的数据被分配到了同一个Task上，造成该Task所处理的数据远大于其它Task，从而造成数据倾斜。</p>
<p>如果调整Shuffle时的并行度，使得原本被分配到同一Task的不同Key发配到不同Task上处理，则可降低原Task所需处理的数据量，从而缓解数据倾斜问题造成的短板效应。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/changeparallelism.png" alt="spark change parallelism"></p>
<h3 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h3><p>现有一张测试表，名为student_external，内有10.5亿条数据，每条数据有一个唯一的id值。现从中取出id取值为9亿到10.5亿的共1.5亿条数据，并通过一些处理，使得id为9亿到9.4亿间的所有数据对12取模后余数为8（即在Shuffle并行度为12时该数据集全部被HashPartition分配到第8个Task），其它数据集对其id除以100取整，从而使得id大于9.4亿的数据在Shuffle时可被均匀分配到所有Task中，而id小于9.4亿的数据全部分配到同一个Task中。处理过程如下</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> <span class="keyword">test</span></div><div class="line"><span class="keyword">SELECT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> <span class="keyword">id</span> &lt; <span class="number">940000000</span> <span class="keyword">THEN</span> (<span class="number">9500000</span>  + (<span class="keyword">CAST</span> (<span class="keyword">RAND</span>() * <span class="number">8</span> <span class="keyword">AS</span> <span class="built_in">INTEGER</span>)) * <span class="number">12</span> )</div><div class="line">       <span class="keyword">ELSE</span> <span class="keyword">CAST</span>(<span class="keyword">id</span>/<span class="number">100</span> <span class="keyword">AS</span> <span class="built_in">INTEGER</span>)</div><div class="line">       <span class="keyword">END</span>,</div><div class="line">       <span class="keyword">name</span></div><div class="line"><span class="keyword">FROM</span> student_external</div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> <span class="keyword">BETWEEN</span> <span class="number">900000000</span> <span class="keyword">AND</span> <span class="number">1050000000</span>;</div></pre></td></tr></table></figure>
<p>通过上述处理，一份可能造成后续数据倾斜的测试数据即以准备好。接下来，使用Spark读取该测试数据，并通过<code>groupByKey(12)</code>对id分组处理，且Shuffle并行度为12。代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkDataSkew</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    SparkSession sparkSession = SparkSession.builder()</div><div class="line">      .appName(<span class="string">"SparkDataSkewTunning"</span>)</div><div class="line">      .config(<span class="string">"hive.metastore.uris"</span>, <span class="string">"thrift://hadoop1:9083"</span>)</div><div class="line">      .enableHiveSupport()</div><div class="line">      .getOrCreate();</div><div class="line"></div><div class="line">    Dataset&lt;Row&gt; dataframe = sparkSession.sql( <span class="string">"select * from test"</span>);</div><div class="line">    dataframe.toJavaRDD()</div><div class="line">      .mapToPair((Row row) -&gt; <span class="keyword">new</span> Tuple2&lt;Integer, String&gt;(row.getInt(<span class="number">0</span>),row.getString(<span class="number">1</span>)))</div><div class="line">      .groupByKey(<span class="number">12</span>)</div><div class="line">      .mapToPair((Tuple2&lt;Integer, Iterable&lt;String&gt;&gt; tuple) -&gt; &#123;</div><div class="line">        <span class="keyword">int</span> id = tuple._1();</div><div class="line">        AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</div><div class="line">        tuple._2().forEach((String name) -&gt; atomicInteger.incrementAndGet());</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(id, atomicInteger.get());</div><div class="line">      &#125;).count();</div><div class="line"></div><div class="line">      sparkSession.stop();</div><div class="line">      sparkSession.close();</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>本次实验所使用集群节点数为4，每个节点可被Yarn使用的CPU核数为16，内存为16GB。使用如下方式提交上述应用，将启动4个Executor，每个Executor可使用核数为12（该配置并非生产环境下的最优配置，仅用于本文实验），可用内存为12GB。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">spark-submit --queue ambari --num-executors 4 --executor-cores 12 --executor-memory 12g --class com.jasongj.spark.driver.SparkDataSkew --master yarn --deploy-mode client SparkExample-with-dependencies-1.0.jar</div></pre></td></tr></table></figure></p>
<p>GroupBy Stage的Task状态如下图所示，Task 8处理的记录数为4500万，远大于（9倍于）其它11个Task处理的500万记录。而Task 8所耗费的时间为38秒，远高于其它11个Task的平均时间（16秒）。整个Stage的时间也为38秒，该时间主要由最慢的Task 8决定。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/differentkeyskew12.png" alt="data skew"></p>
<p>在这种情况下，可以通过调整Shuffle并行度，使得原来被分配到同一个Task（即该例中的Task 8）的不同Key分配到不同Task，从而降低Task 8所需处理的数据量，缓解数据倾斜。</p>
<p>通过<code>groupByKey(48)</code>将Shuffle并行度调整为48，重新提交到Spark。新的Job的GroupBy Stage所有Task状态如下图所示。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/differentkeyskew48.png" alt="add parallelism"></p>
<p>从上图可知，记录数最多的Task 20处理的记录数约为1125万，相比于并行度为12时Task 8的4500万，降低了75%左右，而其耗时从原来Task 8的38秒降到了24秒。</p>
<p>在这种场景下，调整并行度，并不意味着一定要增加并行度，也可能是减小并行度。如果通过<code>groupByKey(11)</code>将Shuffle并行度调整为11，重新提交到Spark。新Job的GroupBy Stage的所有Task状态如下图所示。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/differentkeyskew11.png" alt="reduce parallelism"></p>
<p>从上图可见，处理记录数最多的Task 6所处理的记录数约为1045万，耗时为23秒。处理记录数最少的Task 1处理的记录数约为545万，耗时12秒。</p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><strong><em>适用场景</em></strong><br>大量不同的Key被分配到了相同的Task造成该Task数据量过大。</p>
<p><strong><em>解决方案</em></strong><br>调整并行度。一般是增大并行度，但有时如本例减小并行度也可达到效果。</p>
<p><strong><em>优势</em></strong><br>实现简单，可在需要Shuffle的操作算子上直接设置并行度或者使用<code>spark.default.parallelism</code>设置。如果是Spark SQL，还可通过<code>SET spark.sql.shuffle.partitions=[num_tasks]</code>设置并行度。可用最小的代价解决问题。一般如果出现数据倾斜，都可以通过这种方法先试验几次，如果问题未解决，再尝试其它方法。</p>
<p><strong><em>劣势</em></strong><br>适用场景少，只能将分配到同一Task的不同Key分散开，但对于同一Key倾斜严重的情况该方法并不适用。并且该方法一般只能缓解数据倾斜，没有彻底消除问题。从实践经验来看，其效果一般。</p>
<h2 id="自定义Partitioner"><a href="#自定义Partitioner" class="headerlink" title="自定义Partitioner"></a>自定义Partitioner</h2><h3 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h3><p>使用自定义的Partitioner（默认为HashPartitioner），将原本被分配到同一个Task的不同Key分配到不同Task。</p>
<h3 id="案例-2"><a href="#案例-2" class="headerlink" title="案例"></a>案例</h3><p>以上述数据集为例，继续将并发度设置为12，但是在<code>groupByKey</code>算子上，使用自定义的<code>Partitioner</code>（实现如下）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">.groupByKey(<span class="keyword">new</span> Partitioner() &#123;</div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numPartitions</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="number">12</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Object key)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> id = Integer.parseInt(key.toString());</div><div class="line">    <span class="keyword">if</span>(id &gt;= <span class="number">9500000</span> &amp;&amp; id &lt;= <span class="number">9500084</span> &amp;&amp; ((id - <span class="number">9500000</span>) % <span class="number">12</span>) == <span class="number">0</span>) &#123;</div><div class="line">      <span class="keyword">return</span> (id - <span class="number">9500000</span>) / <span class="number">12</span>;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> id % <span class="number">12</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;)</div></pre></td></tr></table></figure></p>
<p>由下图可见，使用自定义Partition后，耗时最长的Task 6处理约1000万条数据，用时15秒。并且各Task所处理的数据集大小相当。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/customizedpartition.png" alt="customizec partitioner"></p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p><strong><em>适用场景</em></strong><br>大量不同的Key被分配到了相同的Task造成该Task数据量过大。</p>
<p><strong><em>解决方案</em></strong><br>使用自定义的Partitioner实现类代替默认的HashPartitioner，尽量将所有不同的Key均匀分配到不同的Task中。</p>
<p><strong><em>优势</em></strong><br>不影响原有的并行度设计。如果改变并行度，后续Stage的并行度也会默认改变，可能会影响后续Stage。</p>
<p><strong><em>劣势</em></strong><br>适用场景有限，只能将不同Key分散开，对于同一Key对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的Partitioner，不够灵活。</p>
<h2 id="将Reduce-side-Join转变为Map-side-Join"><a href="#将Reduce-side-Join转变为Map-side-Join" class="headerlink" title="将Reduce side Join转变为Map side Join"></a>将Reduce side Join转变为Map side Join</h2><h3 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h3><p>通过Spark的Broadcast机制，将Reduce侧Join转化为Map侧Join，避免Shuffle从而完全消除Shuffle带来的数据倾斜。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/mapjoin.png" alt="spark map join"></p>
<h3 id="案例-3"><a href="#案例-3" class="headerlink" title="案例"></a>案例</h3><p>通过如下SQL创建一张具有倾斜Key且总记录数为1.5亿的大表test。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> <span class="keyword">test</span></div><div class="line"><span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">CASE</span> <span class="keyword">WHEN</span> <span class="keyword">id</span> &lt; <span class="number">980000000</span> <span class="keyword">THEN</span> (<span class="number">95000000</span>  + (<span class="keyword">CAST</span> (<span class="keyword">RAND</span>() * <span class="number">4</span> <span class="keyword">AS</span> <span class="built_in">INT</span>) + <span class="number">1</span>) * <span class="number">48</span> )</div><div class="line">       <span class="keyword">ELSE</span> <span class="keyword">CAST</span>(<span class="keyword">id</span>/<span class="number">10</span> <span class="keyword">AS</span> <span class="built_in">INT</span>) <span class="keyword">END</span> <span class="keyword">AS</span> <span class="keyword">STRING</span>),</div><div class="line">       <span class="keyword">name</span></div><div class="line"><span class="keyword">FROM</span> student_external</div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> <span class="keyword">BETWEEN</span> <span class="number">900000000</span> <span class="keyword">AND</span> <span class="number">1050000000</span>;</div></pre></td></tr></table></figure></p>
<p>使用如下SQL创建一张数据分布均匀且总记录数为50万的小表test_new。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> test_new</div><div class="line"><span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">CAST</span>(<span class="keyword">id</span>/<span class="number">10</span> <span class="keyword">AS</span> <span class="built_in">INT</span>) <span class="keyword">AS</span> <span class="keyword">STRING</span>),</div><div class="line">       <span class="keyword">name</span></div><div class="line"><span class="keyword">FROM</span> student_delta_external</div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> <span class="keyword">BETWEEN</span> <span class="number">950000000</span> <span class="keyword">AND</span> <span class="number">950500000</span>;</div></pre></td></tr></table></figure></p>
<p>直接通过Spark Thrift Server提交如下SQL将表test与表test_new进行Join并将Join结果存于表test_join中。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> test_join</div><div class="line"><span class="keyword">SELECT</span> test_new.id, test_new.name</div><div class="line"><span class="keyword">FROM</span> <span class="keyword">test</span></div><div class="line"><span class="keyword">JOIN</span> test_new</div><div class="line"><span class="keyword">ON</span> test.id = test_new.id;</div></pre></td></tr></table></figure></p>
<p>该SQL对应的DAG如下图所示。从该图可见，该执行过程总共分为三个Stage，前两个用于从Hive中读取数据，同时二者进行Shuffle，通过最后一个Stage进行Join并将结果写入表test_join中。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/reducejoindag.png" alt="reduce join DAG"></p>
<p>从下图可见，Join Stage各Task处理的数据倾斜严重，处理数据量最大的Task耗时7.1分钟，远高于其它无数据倾斜的Task约2秒的耗时。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/reducejoinlaststage.png" alt="reduce join DAG"></p>
<p>接下来，尝试通过Broadcast实现Map侧Join。实现Map侧Join的方法，并非直接通过<code>CACHE TABLE test_new</code>将小表test_new进行cache。现通过如下SQL进行Join。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CACHE</span> <span class="keyword">TABLE</span> test_new;</div><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> test_join</div><div class="line"><span class="keyword">SELECT</span> test_new.id, test_new.name</div><div class="line"><span class="keyword">FROM</span> <span class="keyword">test</span></div><div class="line"><span class="keyword">JOIN</span> test_new</div><div class="line"><span class="keyword">ON</span> test.id = test_new.id;</div></pre></td></tr></table></figure></p>
<p>通过如下DAG图可见，该操作仍分为三个Stage，且仍然有Shuffle存在，唯一不同的是，小表的读取不再直接扫描Hive表，而是扫描内存中缓存的表。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/reducejoincachedag.png" alt="reduce join DAG"></p>
<p>并且数据倾斜仍然存在。如下图所示，最慢的Task耗时为7.1分钟，远高于其它Task的约2秒。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/reducejoincachelaststage.png" alt="reduce join DAG"></p>
<p>正确的使用Broadcast实现Map侧Join的方式是，通过<code>SET spark.sql.autoBroadcastJoinThreshold=104857600;</code>将Broadcast的阈值设置得足够大。</p>
<p>再次通过如下SQL进行Join。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SET</span> spark.sql.autoBroadcastJoinThreshold=<span class="number">104857600</span>;</div><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> test_join</div><div class="line"><span class="keyword">SELECT</span> test_new.id, test_new.name</div><div class="line"><span class="keyword">FROM</span> <span class="keyword">test</span></div><div class="line"><span class="keyword">JOIN</span> test_new</div><div class="line"><span class="keyword">ON</span> test.id = test_new.id;</div></pre></td></tr></table></figure></p>
<p>通过如下DAG图可见，该方案只包含一个Stage。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/mapjoindag.png" alt="reduce join DAG"></p>
<p>并且从下图可见，各Task耗时相当，无明显数据倾斜现象。并且总耗时为1.5分钟，远低于Reduce侧Join的7.3分钟。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/mapjoinlaststage.png" alt="reduce join DAG"></p>
<h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><p><strong><em>适用场景</em></strong><br>参与Join的一边数据集足够小，可被加载进Driver并通过Broadcast方法广播到各个Executor中。</p>
<p><strong><em>解决方案</em></strong><br>在Java/Scala代码中将小数据集数据拉取到Driver，然后通过Broadcast方案将小数据集的数据广播到各Executor。或者在使用SQL前，将Broadcast的阈值调整得足够大，从而使用Broadcast生效。进而将Reduce侧Join替换为Map侧Join。</p>
<p><strong><em>优势</em></strong><br>避免了Shuffle，彻底消除了数据倾斜产生的条件，可极大提升性能。</p>
<p><strong><em>劣势</em></strong><br>要求参与Join的一侧数据集足够小，并且主要适用于Join的场景，不适合聚合的场景，适用条件有限。</p>
<h2 id="为skew的key增加随机前-后缀"><a href="#为skew的key增加随机前-后缀" class="headerlink" title="为skew的key增加随机前/后缀"></a>为skew的key增加随机前/后缀</h2><h3 id="原理-4"><a href="#原理-4" class="headerlink" title="原理"></a>原理</h3><p>为数据量特别大的Key增加随机前/后缀，使得原来Key相同的数据变为Key不相同的数据，从而使倾斜的数据集分散到不同的Task中，彻底解决数据倾斜问题。Join另一则的数据中，与倾斜Key对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜Key如何加前缀，都能与之正常Join。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/randomprefix.png" alt="spark random prefix"></p>
<h3 id="案例-4"><a href="#案例-4" class="headerlink" title="案例"></a>案例</h3><p>通过如下SQL，将id为9亿到9.08亿共800万条数据的id转为9500048或者9500096，其它数据的id除以100取整。从而该数据集中，id为9500048和9500096的数据各400万，其它id对应的数据记录数均为100条。这些数据存于名为test的表中。</p>
<p>对于另外一张小表test_new，取出50万条数据，并将id（递增且唯一）除以100取整，使得所有id都对应100条数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function">INSERT OVERWRITE TABLE test</span></div><div class="line">SELECT <span class="title">CAST</span><span class="params">(CASE WHEN id &lt; <span class="number">908000000</span> THEN (<span class="number">9500000</span>  + (CAST (RAND()</span> * 2 AS INT) + 1) * 48 )</div><div class="line">  ELSE <span class="title">CAST</span><span class="params">(id/<span class="number">100</span> AS INT)</span> END AS STRING),</div><div class="line">  name</div><div class="line">FROM student_external</div><div class="line">WHERE id BETWEEN 900000000 AND 1050000000;</div><div class="line"></div><div class="line"><span class="function">INSERT OVERWRITE TABLE test_new</span></div><div class="line">SELECT <span class="title">CAST</span><span class="params">(CAST(id/<span class="number">100</span> AS INT)</span> AS STRING),</div><div class="line">  name</div><div class="line">FROM student_delta_external</div><div class="line">WHERE id BETWEEN 950000000 AND 950500000;</div></pre></td></tr></table></figure>
<p>通过如下代码，读取test表对应的文件夹内的数据并转换为JavaPairRDD存于leftRDD中，同样读取test表对应的数据存于rightRDD中。通过RDD的join算子对leftRDD与rightRDD进行Join，并指定并行度为48。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkDataSkew</span></span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    SparkConf sparkConf = <span class="keyword">new</span> SparkConf();</div><div class="line">    sparkConf.setAppName(<span class="string">"DemoSparkDataFrameWithSkewedBigTableDirect"</span>);</div><div class="line">    sparkConf.set(<span class="string">"spark.default.parallelism"</span>, String.valueOf(parallelism));</div><div class="line">    JavaSparkContext javaSparkContext = <span class="keyword">new</span> JavaSparkContext(sparkConf);</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; leftRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test/"</span>)</div><div class="line">      .mapToPair((String row) -&gt; &#123;</div><div class="line">        String[] str = row.split(<span class="string">","</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; rightRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test_new/"</span>)</div><div class="line">      .mapToPair((String row) -&gt; &#123;</div><div class="line">        String[] str = row.split(<span class="string">","</span>);</div><div class="line">          <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">    leftRDD.join(rightRDD, parallelism)</div><div class="line">      .mapToPair((Tuple2&lt;String, Tuple2&lt;String, String&gt;&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;(tuple._1(), tuple._2()._2()))</div><div class="line">      .foreachPartition((Iterator&lt;Tuple2&lt;String, String&gt;&gt; iterator) -&gt; &#123;</div><div class="line">        AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</div><div class="line">          iterator.forEachRemaining((Tuple2&lt;String, String&gt; tuple) -&gt; atomicInteger.incrementAndGet());</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">    javaSparkContext.stop();</div><div class="line">    javaSparkContext.close();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从下图可看出，整个Join耗时1分54秒，其中Join Stage耗时1.7分钟。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/fewskewkeyjoinallstage.png" alt="few skewed key join"></p>
<p>通过分析Join Stage的所有Task可知，在其它Task所处理记录数为192.71万的同时Task 32的处理的记录数为992.72万，故它耗时为1.7分钟，远高于其它Task的约10秒。这与上文准备数据集时，将id为9500048为9500096对应的数据量设置非常大，其它id对应的数据集非常均匀相符合。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/fewskewkeyjoinlaststage.png" alt="few skewed key join"></p>
<p>现通过如下操作，实现倾斜Key的分散处理</p>
<ul>
<li>将leftRDD中倾斜的key（即9500048与9500096）对应的数据单独过滤出来，且加上1到24的随机前缀，并将前缀与原数据用逗号分隔（以方便之后去掉前缀）形成单独的leftSkewRDD</li>
<li>将rightRDD中倾斜key对应的数据抽取出来，并通过flatMap操作将该数据集中每条数据均转换为24条数据（每条分别加上1到24的随机前缀），形成单独的rightSkewRDD</li>
<li>将leftSkewRDD与rightSkewRDD进行Join，并将并行度设置为48，且在Join过程中将随机前缀去掉，得到倾斜数据集的Join结果skewedJoinRDD</li>
<li>将leftRDD中不包含倾斜Key的数据抽取出来作为单独的leftUnSkewRDD</li>
<li>对leftUnSkewRDD与原始的rightRDD进行Join，并行度也设置为48，得到Join结果unskewedJoinRDD</li>
<li>通过union算子将skewedJoinRDD与unskewedJoinRDD进行合并，从而得到完整的Join结果集</li>
</ul>
<p>具体实现代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkDataSkew</span></span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">      <span class="keyword">int</span> parallelism = <span class="number">48</span>;</div><div class="line">      SparkConf sparkConf = <span class="keyword">new</span> SparkConf();</div><div class="line">      sparkConf.setAppName(<span class="string">"SolveDataSkewWithRandomPrefix"</span>);</div><div class="line">      sparkConf.set(<span class="string">"spark.default.parallelism"</span>, parallelism + <span class="string">""</span>);</div><div class="line">      JavaSparkContext javaSparkContext = <span class="keyword">new</span> JavaSparkContext(sparkConf);</div><div class="line"></div><div class="line">      JavaPairRDD&lt;String, String&gt; leftRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test/"</span>)</div><div class="line">        .mapToPair((String row) -&gt; &#123;</div><div class="line">          String[] str = row.split(<span class="string">","</span>);</div><div class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">        &#125;);</div><div class="line"></div><div class="line">        JavaPairRDD&lt;String, String&gt; rightRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test_new/"</span>)</div><div class="line">          .mapToPair((String row) -&gt; &#123;</div><div class="line">            String[] str = row.split(<span class="string">","</span>);</div><div class="line">              <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">          &#125;);</div><div class="line"></div><div class="line">        String[] skewedKeyArray = <span class="keyword">new</span> String[]&#123;<span class="string">"9500048"</span>, <span class="string">"9500096"</span>&#125;;</div><div class="line">        Set&lt;String&gt; skewedKeySet = <span class="keyword">new</span> HashSet&lt;String&gt;();</div><div class="line">        List&lt;String&gt; addList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;=<span class="number">24</span>; i++) &#123;</div><div class="line">            addList.add(i + <span class="string">""</span>);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span>(String key : skewedKeyArray) &#123;</div><div class="line">            skewedKeySet.add(key);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        Broadcast&lt;Set&lt;String&gt;&gt; skewedKeys = javaSparkContext.broadcast(skewedKeySet);</div><div class="line">        Broadcast&lt;List&lt;String&gt;&gt; addListKeys = javaSparkContext.broadcast(addList);</div><div class="line"></div><div class="line">        JavaPairRDD&lt;String, String&gt; leftSkewRDD = leftRDD</div><div class="line">          .filter((Tuple2&lt;String, String&gt; tuple) -&gt; skewedKeys.value().contains(tuple._1()))</div><div class="line">          .mapToPair((Tuple2&lt;String, String&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;((<span class="keyword">new</span> Random().nextInt(<span class="number">24</span>) + <span class="number">1</span>) + <span class="string">","</span> + tuple._1(), tuple._2()));</div><div class="line"></div><div class="line">        JavaPairRDD&lt;String, String&gt; rightSkewRDD = rightRDD.filter((Tuple2&lt;String, String&gt; tuple) -&gt; skewedKeys.value().contains(tuple._1()))</div><div class="line">          .flatMapToPair((Tuple2&lt;String, String&gt; tuple) -&gt; addListKeys.value().stream()</div><div class="line">          .map((String i) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;( i + <span class="string">","</span> + tuple._1(), tuple._2()))</div><div class="line">          .collect(Collectors.toList())</div><div class="line">          .iterator()</div><div class="line">        );</div><div class="line"></div><div class="line">        JavaPairRDD&lt;String, String&gt; skewedJoinRDD = leftSkewRDD</div><div class="line">          .join(rightSkewRDD, parallelism)</div><div class="line">          .mapToPair((Tuple2&lt;String, Tuple2&lt;String, String&gt;&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;(tuple._1().split(<span class="string">","</span>)[<span class="number">1</span>], tuple._2()._2()));</div><div class="line"></div><div class="line">        JavaPairRDD&lt;String, String&gt; leftUnSkewRDD = leftRDD.filter((Tuple2&lt;String, String&gt; tuple) -&gt; !skewedKeys.value().contains(tuple._1()));</div><div class="line">        JavaPairRDD&lt;String, String&gt; unskewedJoinRDD = leftUnSkewRDD.join(rightRDD, parallelism).mapToPair((Tuple2&lt;String, Tuple2&lt;String, String&gt;&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;(tuple._1(), tuple._2()._2()));</div><div class="line"></div><div class="line">        skewedJoinRDD.union(unskewedJoinRDD).foreachPartition((Iterator&lt;Tuple2&lt;String, String&gt;&gt; iterator) -&gt; &#123;</div><div class="line">          AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</div><div class="line">          iterator.forEachRemaining((Tuple2&lt;String, String&gt; tuple) -&gt; atomicInteger.incrementAndGet());</div><div class="line">        &#125;);</div><div class="line"></div><div class="line">        javaSparkContext.stop();</div><div class="line">        javaSparkContext.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从下图可看出，整个Join耗时58秒，其中Join Stage耗时33秒。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/fewskewkeyrandomjoinallstage.png" alt="few skewed key join"></p>
<p>通过分析Join Stage的所有Task可知</p>
<ul>
<li>由于Join分倾斜数据集Join和非倾斜数据集Join，而各Join的并行度均为48，故总的并行度为96</li>
<li>由于提交任务时，设置的Executor个数为4，每个Executor的core数为12，故可用Core数为48，所以前48个Task同时启动（其Launch时间相同），后48个Task的启动时间各不相同（等待前面的Task结束才开始）</li>
<li>由于倾斜Key被加上随机前缀，原本相同的Key变为不同的Key，被分散到不同的Task处理，故在所有Task中，未发现所处理数据集明显高于其它Task的情况</li>
</ul>
<p><img src="http://www.jasongj.com/img/spark/spark1_skew/fewskewkeyjoinrandomlaststage.png" alt="few skewed key join"></p>
<p>实际上，由于倾斜Key与非倾斜Key的操作完全独立，可并行进行。而本实验受限于可用总核数为48，可同时运行的总Task数为48，故而该方案只是将总耗时减少一半（效率提升一倍）。如果资源充足，可并发执行Task数增多，该方案的优势将更为明显。在实际项目中，该方案往往可提升数倍至10倍的效率。</p>
<h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><p><strong><em>适用场景</em></strong><br>两张表都比较大，无法使用Map则Join。其中一个RDD有少数几个Key的数据量过大，另外一个RDD的Key分布较为均匀。</p>
<p><strong><em>解决方案</em></strong><br>将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD（相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join并去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。</p>
<p><strong><em>优势</em></strong><br>相对于Map则Join，更能适应大数据集的Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p>
<p><strong><em>劣势</em></strong><br>如果倾斜Key非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜Key与非倾斜Key分开处理，需要扫描数据集两遍，增加了开销。</p>
<h2 id="大表随机添加N种随机前缀，小表扩大N倍"><a href="#大表随机添加N种随机前缀，小表扩大N倍" class="headerlink" title="大表随机添加N种随机前缀，小表扩大N倍"></a>大表随机添加N种随机前缀，小表扩大N倍</h2><h3 id="原理-5"><a href="#原理-5" class="headerlink" title="原理"></a>原理</h3><p>如果出现数据倾斜的Key比较多，上一种方法将这些大量的倾斜Key分拆出来，意义不大。此时更适合直接对存在数据倾斜的数据集全部加上随机前缀，然后对另外一个不存在严重数据倾斜的数据集整体与随机前缀集作笛卡尔乘积（即将数据量扩大N倍）。<br><img src="http://www.jasongj.com/img/spark/spark1_skew/randomprefixandenlargesmalltable.png" alt="spark random prefix"></p>
<h3 id="案例-5"><a href="#案例-5" class="headerlink" title="案例"></a>案例</h3><p>这里给出示例代码，读者可参考上文中分拆出少数倾斜Key添加随机前缀的方法，自行测试。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkDataSkew</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    SparkConf sparkConf = <span class="keyword">new</span> SparkConf();</div><div class="line">    sparkConf.setAppName(<span class="string">"ResolveDataSkewWithNAndRandom"</span>);</div><div class="line">    sparkConf.set(<span class="string">"spark.default.parallelism"</span>, parallelism + <span class="string">""</span>);</div><div class="line">    JavaSparkContext javaSparkContext = <span class="keyword">new</span> JavaSparkContext(sparkConf);</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; leftRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test/"</span>)</div><div class="line">      .mapToPair((String row) -&gt; &#123;</div><div class="line">        String[] str = row.split(<span class="string">","</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; rightRDD = javaSparkContext.textFile(<span class="string">"hdfs://hadoop1:8020/apps/hive/warehouse/default/test_new/"</span>)</div><div class="line">      .mapToPair((String row) -&gt; &#123;</div><div class="line">        String[] str = row.split(<span class="string">","</span>);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, String&gt;(str[<span class="number">0</span>], str[<span class="number">1</span>]);</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    List&lt;String&gt; addList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;=<span class="number">48</span>; i++) &#123;</div><div class="line">      addList.add(i + <span class="string">""</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    Broadcast&lt;List&lt;String&gt;&gt; addListKeys = javaSparkContext.broadcast(addList);</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; leftRandomRDD = leftRDD.mapToPair((Tuple2&lt;String, String&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;(<span class="keyword">new</span> Random().nextInt(<span class="number">48</span>) + <span class="string">","</span> + tuple._1(), tuple._2()));</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; rightNewRDD = rightRDD</div><div class="line">      .flatMapToPair((Tuple2&lt;String, String&gt; tuple) -&gt; addListKeys.value().stream()</div><div class="line">      .map((String i) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;( i + <span class="string">","</span> + tuple._1(), tuple._2()))</div><div class="line">      .collect(Collectors.toList())</div><div class="line">      .iterator()</div><div class="line">    );</div><div class="line"></div><div class="line">    JavaPairRDD&lt;String, String&gt; joinRDD = leftRandomRDD</div><div class="line">      .join(rightNewRDD, parallelism)</div><div class="line">      .mapToPair((Tuple2&lt;String, Tuple2&lt;String, String&gt;&gt; tuple) -&gt; <span class="keyword">new</span> Tuple2&lt;String, String&gt;(tuple._1().split(<span class="string">","</span>)[<span class="number">1</span>], tuple._2()._2()));</div><div class="line"></div><div class="line">    joinRDD.foreachPartition((Iterator&lt;Tuple2&lt;String, String&gt;&gt; iterator) -&gt; &#123;</div><div class="line">      AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</div><div class="line">      iterator.forEachRemaining((Tuple2&lt;String, String&gt; tuple) -&gt; atomicInteger.incrementAndGet());</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    javaSparkContext.stop();</div><div class="line">    javaSparkContext.close();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h3><p><strong><em>适用场景</em></strong><br>一个数据集存在的倾斜Key比较多，另外一个数据集数据分布比较均匀。</p>
<p><strong><em>优势</em></strong><br>对大部分场景都适用，效果不错。</p>
<p><strong><em>劣势</em></strong><br>需要将一个数据集整体扩大N倍，会增加资源消耗。</p>
<h1 id="总结-6"><a href="#总结-6" class="headerlink" title="总结"></a>总结</h1><p>对于数据倾斜，并无一个统一的一劳永逸的方法。更多的时候，是结合数据特点（数据集大小，倾斜Key的多少等）综合使用上文所述的多种方法。</p>
]]></content>
    
    <summary type="html">
    
      本文结合实例详细阐明了Spark数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义Partitioner，使用Map侧Join代替Reduce侧Join，给倾斜Key加上随机前缀等。
    
    </summary>
    
      <category term="Spark" scheme="http://www.jasongj.com/categories/Spark/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Spark/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Spark/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Spark/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Spark" scheme="http://www.jasongj.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（五）Java I/O模型从BIO到NIO和Reactor模式</title>
    <link href="http://www.jasongj.com/java/nio_reactor/"/>
    <id>http://www.jasongj.com/java/nio_reactor/</id>
    <published>2016-08-22T22:55:29.000Z</published>
    <updated>2017-02-15T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/java/nio_reactor/">原文链接</a>　<a href="http://www.jasongj.com/java/nio_reactor/">http://www.jasongj.com/java/nio_reactor/</a></p>
</blockquote>
<h1 id="Java-I-O模型"><a href="#Java-I-O模型" class="headerlink" title="Java I/O模型"></a>Java I/O模型</h1><h2 id="同步-vs-异步"><a href="#同步-vs-异步" class="headerlink" title="同步 vs. 异步"></a>同步 vs. 异步</h2><p><strong><em>同步I/O</em></strong>　每个请求必须逐个地被处理，一个请求的处理会导致整个流程的暂时等待，这些事件无法并发地执行。用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行。</p>
<p><strong><em>异步I/O</em></strong>　多个请求可以并发地执行，一个请求或者任务的执行不会导致整个流程的暂时等待。用户线程发起I/O请求后仍然继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数。</p>
<h2 id="阻塞-vs-非阻塞"><a href="#阻塞-vs-非阻塞" class="headerlink" title="阻塞 vs. 非阻塞"></a>阻塞 vs. 非阻塞</h2><p><strong><em>阻塞</em></strong>　某个请求发出后，由于该请求操作需要的条件不满足，请求操作一直阻塞，不会返回，直到条件满足。</p>
<p><strong><em>非阻塞</em></strong>　请求发出后，若该请求需要的条件不满足，则立即返回一个标志信息告知条件不满足，而不会一直等待。一般需要通过循环判断请求条件是否满足来获取请求结果。</p>
<p>需要注意的是，阻塞并不等价于同步，而非阻塞并非等价于异步。事实上这两组概念描述的是I/O模型中的两个不同维度。</p>
<p>同步和异步着重点在于多个任务执行过程中，后发起的任务是否必须等先发起的任务完成之后再进行。而不管先发起的任务请求是阻塞等待完成，还是立即返回通过循环等待请求成功。</p>
<p>而阻塞和非阻塞重点在于请求的方法是否立即返回（或者说是否在条件不满足时被阻塞）。</p>
<h2 id="Unix下五种I-O模型"><a href="#Unix下五种I-O模型" class="headerlink" title="Unix下五种I/O模型"></a>Unix下五种I/O模型</h2><p>Unix 下共有五种 I/O 模型：</p>
<ul>
<li>阻塞 I/O</li>
<li>非阻塞 I/O</li>
<li>I/O 多路复用（select和poll）</li>
<li>信号驱动 I/O（SIGIO）</li>
<li>异步 I/O（Posix.1的aio_系列函数）</li>
</ul>
<h3 id="阻塞I-O"><a href="#阻塞I-O" class="headerlink" title="阻塞I/O"></a>阻塞I/O</h3><p>如上文所述，阻塞I/O下请求无法立即完成则保持阻塞。阻塞I/O分为如下两个阶段。</p>
<ul>
<li>阶段1：等待数据就绪。网络 I/O 的情况就是等待远端数据陆续抵达；磁盘I/O的情况就是等待磁盘数据从磁盘上读取到内核态内存中。</li>
<li>阶段2：数据拷贝。出于系统安全，用户态的程序没有权限直接读取内核态内存，因此内核负责把内核态内存中的数据拷贝一份到用户态内存中。</li>
</ul>
<h3 id="非阻塞I-O"><a href="#非阻塞I-O" class="headerlink" title="非阻塞I/O"></a>非阻塞I/O</h3><p>非阻塞I/O请求包含如下三个阶段</p>
<ul>
<li>socket设置为 NONBLOCK（非阻塞）就是告诉内核，当所请求的I/O操作无法完成时，不要将线程睡眠，而是返回一个错误码(EWOULDBLOCK) ，这样请求就不会阻塞。</li>
<li>I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。整个I/O 请求的过程中，虽然用户线程每次发起I/O请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的 CPU 的资源。</li>
<li>数据准备好了，从内核拷贝到用户空间。</li>
</ul>
<p>一般很少直接使用这种模型，而是在其他I/O模型中使用非阻塞I/O 这一特性。这种方式对单个I/O 请求意义不大，但给I/O多路复用提供了条件。</p>
<h3 id="I-O多路复用（异步阻塞-I-O）"><a href="#I-O多路复用（异步阻塞-I-O）" class="headerlink" title="I/O多路复用（异步阻塞 I/O）"></a>I/O多路复用（异步阻塞 I/O）</h3><p>I/O多路复用会用到select或者poll函数，这两个函数也会使线程阻塞，但是和阻塞I/O所不同的是，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。</p>
<p>从流程上来看，使用select函数进行I/O请求和同步阻塞模型没有太大的区别，甚至还多了添加监视Channel，以及调用select函数的额外操作，增加了额外工作。但是，使用 select以后最大的优势是用户可以在一个线程内同时处理多个Channel的I/O请求。用户可以注册多个Channel，然后不断地调用select读取被激活的Channel，即可达到在同一个线程内同时处理多个I/O请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p>
<p>调用select/poll该方法由一个用户态线程负责轮询多个Channel，直到某个阶段1的数据就绪，再通知实际的用户线程执行阶段2的拷贝。 通过一个专职的用户态线程执行非阻塞I/O轮询，模拟实现了阶段一的异步化。</p>
<h3 id="信号驱动I-O（SIGIO）"><a href="#信号驱动I-O（SIGIO）" class="headerlink" title="信号驱动I/O（SIGIO）"></a>信号驱动I/O（SIGIO）</h3><p>首先我们允许socket进行信号驱动I/O，并安装一个信号处理函数，线程继续运行并不阻塞。当数据准备好时，线程会收到一个SIGIO 信号，可以在信号处理函数中调用I/O操作函数处理数据。</p>
<h3 id="异步I-O"><a href="#异步I-O" class="headerlink" title="异步I/O"></a>异步I/O</h3><p>调用aio_read 函数，告诉内核描述字，缓冲区指针，缓冲区大小，文件偏移以及通知的方式，然后立即返回。当内核将数据拷贝到缓冲区后，再通知应用程序。所以异步I/O模式下，阶段1和阶段2全部由内核完成，完成不需要用户线程的参与。</p>
<h3 id="几种I-O模型对比"><a href="#几种I-O模型对比" class="headerlink" title="几种I/O模型对比"></a>几种I/O模型对比</h3><p>除异步I/O外，其它四种模型的阶段2基本相同，都是从内核态拷贝数据到用户态。区别在于阶段1不同。前四种都属于同步I/O。</p>
<h2 id="Java中四种I-O模型"><a href="#Java中四种I-O模型" class="headerlink" title="Java中四种I/O模型"></a>Java中四种I/O模型</h2><p>上一章所述Unix中的五种I/O模型，除信号驱动I/O外，Java对其它四种I/O模型都有所支持。其中Java最早提供的blocking I/O即是阻塞I/O，而NIO即是非阻塞I/O，同时通过NIO实现的Reactor模式即是I/O复用模型的实现，通过AIO实现的Proactor模式即是异步I/O模型的实现。</p>
<h1 id="从IO到NIO"><a href="#从IO到NIO" class="headerlink" title="从IO到NIO"></a>从IO到NIO</h1><h2 id="面向流-vs-面向缓冲"><a href="#面向流-vs-面向缓冲" class="headerlink" title="面向流 vs. 面向缓冲"></a>面向流 vs. 面向缓冲</h2><p>Java IO是面向流的，每次从流（InputStream/OutputStream）中读一个或多个字节，直到读取完所有字节，它们没有被缓存在任何地方。另外，它不能前后移动流中的数据，如需前后移动处理，需要先将其缓存至一个缓冲区。</p>
<p>Java NIO面向缓冲，数据会被读取到一个缓冲区，需要时可以在缓冲区中前后移动处理，这增加了处理过程的灵活性。但与此同时在处理缓冲区前需要检查该缓冲区中是否包含有所需要处理的数据，并需要确保更多数据读入缓冲区时，不会覆盖缓冲区内尚未处理的数据。</p>
<h2 id="阻塞-vs-非阻塞-1"><a href="#阻塞-vs-非阻塞-1" class="headerlink" title="阻塞 vs. 非阻塞"></a>阻塞 vs. 非阻塞</h2><p>Java IO的各种流是阻塞的。当某个线程调用read()或write()方法时，该线程被阻塞，直到有数据被读取到或者数据完全写入。阻塞期间该线程无法处理任何其它事情。</p>
<p>Java NIO为非阻塞模式。读写请求并不会阻塞当前线程，在数据可读/写前当前线程可以继续做其它事情，所以一个单独的线程可以管理多个输入和输出通道。</p>
<h2 id="选择器（Selector）"><a href="#选择器（Selector）" class="headerlink" title="选择器（Selector）"></a>选择器（Selector）</h2><p>Java NIO的选择器允许一个单独的线程同时监视多个通道，可以注册多个通道到同一个选择器上，然后使用一个单独的线程来“选择”已经就绪的通道。这种“选择”机制为一个单独线程管理多个通道提供了可能。</p>
<h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>Java NIO中提供的FileChannel拥有transferTo和transferFrom两个方法，可直接把FileChannel中的数据拷贝到另外一个Channel，或者直接把另外一个Channel中的数据拷贝到FileChannel。该接口常被用于高效的网络/文件的数据传输和大文件拷贝。在操作系统支持的情况下，通过该方法传输数据并不需要将源数据从内核态拷贝到用户态，再从用户态拷贝到目标通道的内核态，同时也避免了两次用户态和内核态间的上下文切换，也即使用了“零拷贝”，所以其性能一般高于Java IO中提供的方法。</p>
<p>使用FileChannel的零拷贝将本地文件内容传输到网络的示例代码如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">    SocketChannel socketChannel = SocketChannel.open();</div><div class="line">    InetSocketAddress address = <span class="keyword">new</span> InetSocketAddress(<span class="number">1234</span>);</div><div class="line">    socketChannel.connect(address);</div><div class="line"></div><div class="line">    RandomAccessFile file = <span class="keyword">new</span> RandomAccessFile(</div><div class="line">        NIOClient.class.getClassLoader().getResource(<span class="string">"test.txt"</span>).getFile(), <span class="string">"rw"</span>);</div><div class="line">    FileChannel channel = file.getChannel();</div><div class="line">    channel.transferTo(<span class="number">0</span>, channel.size(), socketChannel);</div><div class="line">    channel.close();</div><div class="line">    file.close();</div><div class="line">    socketChannel.close();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="阻塞I-O下的服务器实现"><a href="#阻塞I-O下的服务器实现" class="headerlink" title="阻塞I/O下的服务器实现"></a>阻塞I/O下的服务器实现</h1><h2 id="单线程逐个处理所有请求"><a href="#单线程逐个处理所有请求" class="headerlink" title="单线程逐个处理所有请求"></a>单线程逐个处理所有请求</h2><p>使用阻塞I/O的服务器，一般使用循环，逐个接受连接请求并读取数据，然后处理下一个请求。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IOServer</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(IOServer.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ServerSocket serverSocket = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      serverSocket = <span class="keyword">new</span> ServerSocket();</div><div class="line">      serverSocket.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">2345</span>));</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</div><div class="line">      LOGGER.error(<span class="string">"Listen failed"</span>, ex);</div><div class="line">      <span class="keyword">return</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">try</span>&#123;</div><div class="line">      <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</div><div class="line">        Socket socket = serverSocket.accept();</div><div class="line">        InputStream inputstream = socket.getInputStream();</div><div class="line">        LOGGER.info(<span class="string">"Received message &#123;&#125;"</span>, IOUtils.toString(inputstream));</div><div class="line">        IOUtils.closeQuietly(inputstream);</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span>(IOException ex) &#123;</div><div class="line">      IOUtils.closeQuietly(serverSocket);</div><div class="line">      LOGGER.error(<span class="string">"Read message failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="为每个请求创建一个线程"><a href="#为每个请求创建一个线程" class="headerlink" title="为每个请求创建一个线程"></a>为每个请求创建一个线程</h2><p>上例使用单线程逐个处理所有请求，同一时间只能处理一个请求，等待I/O的过程浪费大量CPU资源，同时无法充分使用多CPU的优势。下面是使用多线程对阻塞I/O模型的改进。一个连接建立成功后，创建一个单独的线程处理其I/O操作。<br><img src="http://www.jasongj.com/img/java/reactor/IO_multithread.png" alt="阻塞I/O 多线程"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IOServerMultiThread</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(IOServerMultiThread.class);</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">  ServerSocket serverSocket = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      serverSocket = <span class="keyword">new</span> ServerSocket();</div><div class="line">      serverSocket.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">2345</span>));</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</div><div class="line">      LOGGER.error(<span class="string">"Listen failed"</span>, ex);</div><div class="line">      <span class="keyword">return</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">try</span>&#123;</div><div class="line">      <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</div><div class="line">        Socket socket = serverSocket.accept();</div><div class="line">        <span class="keyword">new</span> Thread( () -&gt; &#123;</div><div class="line">          <span class="keyword">try</span>&#123;</div><div class="line">            InputStream inputstream = socket.getInputStream();</div><div class="line">            LOGGER.info(<span class="string">"Received message &#123;&#125;"</span>, IOUtils.toString(inputstream));</div><div class="line">            IOUtils.closeQuietly(inputstream);</div><div class="line">          &#125; <span class="keyword">catch</span> (IOException ex) &#123;</div><div class="line">            LOGGER.error(<span class="string">"Read message failed"</span>, ex);</div><div class="line">          &#125;</div><div class="line">        &#125;).start();</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span>(IOException ex) &#123;</div><div class="line">      IOUtils.closeQuietly(serverSocket);</div><div class="line">      LOGGER.error(<span class="string">"Accept connection failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="使用线程池处理请求"><a href="#使用线程池处理请求" class="headerlink" title="使用线程池处理请求"></a>使用线程池处理请求</h2><p>为了防止连接请求过多，导致服务器创建的线程数过多，造成过多线程上下文切换的开销。可以通过线程池来限制创建的线程数，如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IOServerThreadPool</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(IOServerThreadPool.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());</div><div class="line">    ServerSocket serverSocket = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      serverSocket = <span class="keyword">new</span> ServerSocket();</div><div class="line">      serverSocket.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">2345</span>));</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</div><div class="line">      LOGGER.error(<span class="string">"Listen failed"</span>, ex);</div><div class="line">      <span class="keyword">return</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">try</span>&#123;</div><div class="line">      <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</div><div class="line">        Socket socket = serverSocket.accept();</div><div class="line">        executorService.submit(() -&gt; &#123;</div><div class="line">          <span class="keyword">try</span>&#123;</div><div class="line">            InputStream inputstream = socket.getInputStream();</div><div class="line">            LOGGER.info(<span class="string">"Received message &#123;&#125;"</span>, IOUtils.toString(<span class="keyword">new</span> InputStreamReader(inputstream)));</div><div class="line">          &#125; <span class="keyword">catch</span> (IOException ex) &#123;</div><div class="line">            LOGGER.error(<span class="string">"Read message failed"</span>, ex);</div><div class="line">          &#125;</div><div class="line">        &#125;);</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">catch</span>(IOException ex) &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        serverSocket.close();</div><div class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">      &#125;</div><div class="line">      LOGGER.error(<span class="string">"Accept connection failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="Reactor模式"><a href="#Reactor模式" class="headerlink" title="Reactor模式"></a>Reactor模式</h1><h2 id="精典Reactor模式"><a href="#精典Reactor模式" class="headerlink" title="精典Reactor模式"></a>精典Reactor模式</h2><p>精典的Reactor模式示意图如下所示。<br><img src="http://www.jasongj.com/img/java/reactor/classic_reactor.png" alt="精典Reactor"></p>
<p>在Reactor模式中，包含如下角色</p>
<ul>
<li><strong><em>Reactor</em></strong> 将I/O事件发派给对应的Handler</li>
<li><strong><em>Acceptor</em></strong> 处理客户端连接请求</li>
<li><strong><em>Handlers</em></strong> 执行非阻塞读/写</li>
</ul>
<p>最简单的Reactor模式实现代码如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOServer</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(NIOServer.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Selector selector = Selector.open();</div><div class="line">    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class="line">    serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">    serverSocketChannel.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">1234</span>));</div><div class="line">    serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (selector.select() &gt; <span class="number">0</span>) &#123;</div><div class="line">      Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</div><div class="line">      Iterator&lt;SelectionKey&gt; iterator = keys.iterator();</div><div class="line">      <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">        SelectionKey key = iterator.next();</div><div class="line">        iterator.remove();</div><div class="line">        <span class="keyword">if</span> (key.isAcceptable()) &#123;</div><div class="line">          ServerSocketChannel acceptServerSocketChannel = (ServerSocketChannel) key.channel();</div><div class="line">          SocketChannel socketChannel = acceptServerSocketChannel.accept();</div><div class="line">          socketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">          LOGGER.info(<span class="string">"Accept request from &#123;&#125;"</span>, socketChannel.getRemoteAddress());</div><div class="line">          socketChannel.register(selector, SelectionKey.OP_READ);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isReadable()) &#123;</div><div class="line">          SocketChannel socketChannel = (SocketChannel) key.channel();</div><div class="line">          ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</div><div class="line">          <span class="keyword">int</span> count = socketChannel.read(buffer);</div><div class="line">          <span class="keyword">if</span> (count &lt;= <span class="number">0</span>) &#123;</div><div class="line">            socketChannel.close();</div><div class="line">            key.cancel();</div><div class="line">            LOGGER.info(<span class="string">"Received invalide data, close the connection"</span>);</div><div class="line">            <span class="keyword">continue</span>;</div><div class="line">          &#125;</div><div class="line">          LOGGER.info(<span class="string">"Received message &#123;&#125;"</span>, <span class="keyword">new</span> String(buffer.array()));</div><div class="line">        &#125;</div><div class="line">        keys.remove(key);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>为了方便阅读，上示代码将Reactor模式中的所有角色放在了一个类中。</p>
<p>从上示代码中可以看到，多个Channel可以注册到同一个Selector对象上，实现了一个线程同时监控多个请求状态（Channel）。同时注册时需要指定它所关注的事件，例如上示代码中<em>socketServerChannel</em>对象只注册了<em>OP_ACCEPT</em>事件，而<em>socketChannel</em>对象只注册了<em>OP_READ</em>事件。</p>
<p><code>selector.select()</code>是阻塞的，当有至少一个通道可用时该方法返回可用通道个数。同时该方法只捕获Channel注册时指定的所关注的事件。</p>
<h2 id="多工作线程Reactor模式"><a href="#多工作线程Reactor模式" class="headerlink" title="多工作线程Reactor模式"></a>多工作线程Reactor模式</h2><p>经典Reactor模式中，尽管一个线程可同时监控多个请求（Channel），但是所有读/写请求以及对新连接请求的处理都在同一个线程中处理，无法充分利用多CPU的优势，同时读/写操作也会阻塞对新连接请求的处理。因此可以引入多线程，并行处理多个读/写操作，如下图所示。<br><img src="http://www.jasongj.com/img/java/reactor/multithread_reactor.png" alt="多线程Reactor"></p>
<p>多线程Reactor模式示例代码如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOServer</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(NIOServer.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Selector selector = Selector.open();</div><div class="line">    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class="line">    serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">    serverSocketChannel.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">1234</span>));</div><div class="line">    serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">      <span class="keyword">if</span>(selector.selectNow() &lt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">continue</span>;</div><div class="line">      &#125;</div><div class="line">      Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</div><div class="line">      Iterator&lt;SelectionKey&gt; iterator = keys.iterator();</div><div class="line">      <span class="keyword">while</span>(iterator.hasNext()) &#123;</div><div class="line">        SelectionKey key = iterator.next();</div><div class="line">        iterator.remove();</div><div class="line">        <span class="keyword">if</span> (key.isAcceptable()) &#123;</div><div class="line">          ServerSocketChannel acceptServerSocketChannel = (ServerSocketChannel) key.channel();</div><div class="line">          SocketChannel socketChannel = acceptServerSocketChannel.accept();</div><div class="line">          socketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">          LOGGER.info(<span class="string">"Accept request from &#123;&#125;"</span>, socketChannel.getRemoteAddress());</div><div class="line">          SelectionKey readKey = socketChannel.register(selector, SelectionKey.OP_READ);</div><div class="line">          readKey.attach(<span class="keyword">new</span> Processor());</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isReadable()) &#123;</div><div class="line">          Processor processor = (Processor) key.attachment();</div><div class="line">          processor.process(key);</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上示代码中可以看到，注册完SocketChannel的<em>OP_READ</em>事件后，可以对相应的SelectionKey attach一个对象（本例中attach了一个Processor对象，该对象处理读请求），并且在获取到可读事件后，可以取出该对象。</p>
<p>注：attach对象及取出该对象是NIO提供的一种操作，但该操作并非Reactor模式的必要操作，本文使用它，只是为了方便演示NIO的接口。</p>
<p>具体的读请求处理在如下所示的Processor类中。该类中设置了一个静态的线程池处理所有请求。而<em>process</em>方法并不直接处理I/O请求，而是把该I/O操作提交给上述线程池去处理，这样就充分利用了多线程的优势，同时将对新连接的处理和读/写操作的处理放在了不同的线程中，读/写操作不再阻塞对新连接请求的处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Processor</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(Processor.class);</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ExecutorService service = Executors.newFixedThreadPool(<span class="number">16</span>);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(SelectionKey selectionKey)</span> </span>&#123;</div><div class="line">    service.submit(() -&gt; &#123;</div><div class="line">      ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</div><div class="line">      SocketChannel socketChannel = (SocketChannel) selectionKey.channel();</div><div class="line">      <span class="keyword">int</span> count = socketChannel.read(buffer);</div><div class="line">      <span class="keyword">if</span> (count &lt; <span class="number">0</span>) &#123;</div><div class="line">        socketChannel.close();</div><div class="line">        selectionKey.cancel();</div><div class="line">        LOGGER.info(<span class="string">"&#123;&#125;\t Read ended"</span>, socketChannel);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(count == <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">      &#125;</div><div class="line">      LOGGER.info(<span class="string">"&#123;&#125;\t Read message &#123;&#125;"</span>, socketChannel, <span class="keyword">new</span> String(buffer.array()));</div><div class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="多Reactor"><a href="#多Reactor" class="headerlink" title="多Reactor"></a>多Reactor</h2><p>Netty中使用的Reactor模式，引入了多Reactor，也即一个主Reactor负责监控所有的连接请求，多个子Reactor负责监控并处理读/写请求，减轻了主Reactor的压力，降低了主Reactor压力太大而造成的延迟。<br>并且每个子Reactor分别属于一个独立的线程，每个成功连接后的Channel的所有操作由同一个线程处理。这样保证了同一请求的所有状态和上下文在同一个线程中，避免了不必要的上下文切换，同时也方便了监控请求响应状态。</p>
<p>多Reactor模式示意图如下所示。<br><img src="http://www.jasongj.com/img/java/reactor/multi_reactor.png" alt="多Reactor"></p>
<p>多Reactor示例代码如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOServer</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(NIOServer.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Selector selector = Selector.open();</div><div class="line">    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</div><div class="line">    serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">    serverSocketChannel.bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">1234</span>));</div><div class="line">    serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</div><div class="line"></div><div class="line">    <span class="keyword">int</span> coreNum = Runtime.getRuntime().availableProcessors();</div><div class="line">    Processor[] processors = <span class="keyword">new</span> Processor[coreNum];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; processors.length; i++) &#123;</div><div class="line">      processors[i] = <span class="keyword">new</span> Processor();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> index = <span class="number">0</span>;</div><div class="line">    <span class="keyword">while</span> (selector.select() &gt; <span class="number">0</span>) &#123;</div><div class="line">      Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</div><div class="line">      <span class="keyword">for</span> (SelectionKey key : keys) &#123;</div><div class="line">        keys.remove(key);</div><div class="line">        <span class="keyword">if</span> (key.isAcceptable()) &#123;</div><div class="line">          ServerSocketChannel acceptServerSocketChannel = (ServerSocketChannel) key.channel();</div><div class="line">          SocketChannel socketChannel = acceptServerSocketChannel.accept();</div><div class="line">          socketChannel.configureBlocking(<span class="keyword">false</span>);</div><div class="line">          LOGGER.info(<span class="string">"Accept request from &#123;&#125;"</span>, socketChannel.getRemoteAddress());</div><div class="line">          Processor processor = processors[(<span class="keyword">int</span>) ((index++) % coreNum)];</div><div class="line">          processor.addChannel(socketChannel);</div><div class="line">          processor.wakeup();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如上代码所示，本文设置的子Reactor个数是当前机器可用核数的两倍（与Netty默认的子Reactor个数一致）。对于每个成功连接的SocketChannel，通过round robin的方式交给不同的子Reactor。</p>
<p>子Reactor对SocketChannel的处理如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Processor</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(Processor.class);</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ExecutorService service =</div><div class="line">      Executors.newFixedThreadPool(<span class="number">2</span> * Runtime.getRuntime().availableProcessors());</div><div class="line"></div><div class="line">  <span class="keyword">private</span> Selector selector;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Processor</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">this</span>.selector = SelectorProvider.provider().openSelector();</div><div class="line">    start();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addChannel</span><span class="params">(SocketChannel socketChannel)</span> <span class="keyword">throws</span> ClosedChannelException </span>&#123;</div><div class="line">    socketChannel.register(<span class="keyword">this</span>.selector, SelectionKey.OP_READ);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wakeup</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.selector.wakeup();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</div><div class="line">    service.submit(() -&gt; &#123;</div><div class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (selector.select(<span class="number">500</span>) &lt;= <span class="number">0</span>) &#123;</div><div class="line">          <span class="keyword">continue</span>;</div><div class="line">        &#125;</div><div class="line">        Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</div><div class="line">        Iterator&lt;SelectionKey&gt; iterator = keys.iterator();</div><div class="line">        <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">          SelectionKey key = iterator.next();</div><div class="line">          iterator.remove();</div><div class="line">          <span class="keyword">if</span> (key.isReadable()) &#123;</div><div class="line">            ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</div><div class="line">            SocketChannel socketChannel = (SocketChannel) key.channel();</div><div class="line">            <span class="keyword">int</span> count = socketChannel.read(buffer);</div><div class="line">            <span class="keyword">if</span> (count &lt; <span class="number">0</span>) &#123;</div><div class="line">              socketChannel.close();</div><div class="line">              key.cancel();</div><div class="line">              LOGGER.info(<span class="string">"&#123;&#125;\t Read ended"</span>, socketChannel);</div><div class="line">              <span class="keyword">continue</span>;</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (count == <span class="number">0</span>) &#123;</div><div class="line">              LOGGER.info(<span class="string">"&#123;&#125;\t Message size is 0"</span>, socketChannel);</div><div class="line">              <span class="keyword">continue</span>;</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              LOGGER.info(<span class="string">"&#123;&#125;\t Read message &#123;&#125;"</span>, socketChannel, <span class="keyword">new</span> String(buffer.array()));</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在Processor中，同样创建了一个静态的线程池，且线程池的大小为机器核数的两倍。每个Processor实例均包含一个Selector实例。同时每次获取Processor实例时均提交一个任务到该线程池，并且该任务正常情况下一直循环处理，不会停止。而提交给该Processor的SocketChannel通过在其Selector注册事件，加入到相应的任务中。由此实现了每个子Reactor包含一个Selector对象，并由一个独立的线程处理。</p>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Java中的四种I/O模型，同步阻塞，同步非阻塞，多路复用，异步阻塞。同时将NIO和BIO进行了对比，并详细分析了基于NIO的Reactor模式，包括经典单线程模型以及多线程模式和多Reactor模式。
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>UML(一) 类图详解</title>
    <link href="http://www.jasongj.com/uml/class_diagram/"/>
    <id>http://www.jasongj.com/uml/class_diagram/</id>
    <published>2016-08-07T22:55:29.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/uml/class_diagram/">原文链接</a>　<a href="http://www.jasongj.com/uml/class_diagram/">http://www.jasongj.com/uml/class_diagram/</a></p>
</blockquote>
<h1 id="UML类图"><a href="#UML类图" class="headerlink" title="UML类图"></a>UML类图</h1><h2 id="UML类图介绍"><a href="#UML类图介绍" class="headerlink" title="UML类图介绍"></a>UML类图介绍</h2><p>在UML 2.*的13种图形中，类图是使用频率最高的UML图之一。类图用于描述系统中所包含的类以及它们之间的相互关系，帮助开发人员理解系统，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。</p>
<h2 id="类的UML图示"><a href="#类的UML图示" class="headerlink" title="类的UML图示"></a>类的UML图示</h2><p>在UML类图中，类使用包含类名、属性和方法且带有分隔线的长方形来表示。如一个Employee类，它包含private属性age，protected属性name，public属性email，package属性gender，public方法work()。其UML类图表示如下图所示。<br><img src="http://www.jasongj.com/img/system_design/uml/class/employee.png" alt="Class in Class Diagram"></p>
<h3 id="属性及方法表示形式"><a href="#属性及方法表示形式" class="headerlink" title="属性及方法表示形式"></a>属性及方法表示形式</h3><p>UML规定类图中属性的表示方式为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">可见性 名称 : 类型 [=缺省值]</div></pre></td></tr></table></figure></p>
<p>方法表示形式为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">可见性 方法名 [参数名 : 参数类型] : 返回值类型</div></pre></td></tr></table></figure></p>
<p>方法的多个参数间用逗号隔开，无返回值时，其类型为<code>void</code></p>
<h3 id="属性及方法可见性"><a href="#属性及方法可见性" class="headerlink" title="属性及方法可见性"></a>属性及方法可见性</h3><ul>
<li><strong>public</strong> 用<code>+</code>表示</li>
<li><strong>private</strong> 用<code>-</code>表示</li>
<li><strong>protected</strong> 用<code>#</code>表示</li>
<li><strong>package</strong> 用<code>~</code>表示</li>
</ul>
<h3 id="接口的UML图示"><a href="#接口的UML图示" class="headerlink" title="接口的UML图示"></a>接口的UML图示</h3><p><img src="http://www.jasongj.com/img/system_design/uml/class/person.png" alt="Class in Class Diagram"></p>
<p>接口的表示形式与类类似，区别在于接口名须以尖括号包裹，同时接口无属性框，方法可见性只可能为<code>public</code>，这是由接口本身的特性决定的。</p>
<h1 id="类间关系"><a href="#类间关系" class="headerlink" title="类间关系"></a>类间关系</h1><h2 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h2><h3 id="依赖关系说明"><a href="#依赖关系说明" class="headerlink" title="依赖关系说明"></a>依赖关系说明</h3><p>依赖关系是一种偶然的、较弱的使用关系，特定事物的改变可能影响到使用该事情的其它事物，在需要表示一个事物使用另一个事物时使用依赖关系。</p>
<h3 id="依赖关系UML表示"><a href="#依赖关系UML表示" class="headerlink" title="依赖关系UML表示"></a>依赖关系UML表示</h3><p>UML中使用带箭头的虚线表示类间的依赖（Dependency）关系，箭头由依赖类指向被依赖类。下图表示Dirver类依赖于Car类<br><img src="http://www.jasongj.com/img/system_design/uml/class/dependency.png" alt="Class in Class Diagram"></p>
<h3 id="依赖关系的表现形式"><a href="#依赖关系的表现形式" class="headerlink" title="依赖关系的表现形式"></a>依赖关系的表现形式</h3><ul>
<li>B类的实例作为A类方法的参数</li>
<li>B类的实例作为A类方法的局部变量</li>
<li>A类调用B类的静态方法</li>
</ul>
<h2 id="关联关系"><a href="#关联关系" class="headerlink" title="关联关系"></a>关联关系</h2><p>关联（Association）关系是一种结构化关系，用于表示一类对象与另一类对象之间的联系。在Java中实现关联关系时，通常将一个类的对象作为另一个类的成员变量。</p>
<p>在UML类图中，用实线连接有关联关系的类，并可在关联线上标注角色名或关系名。</p>
<p>在UML中，关联关系包含如下四种形式</p>
<h3 id="双向关联"><a href="#双向关联" class="headerlink" title="双向关联"></a>双向关联</h3><p>默认情况下，关联是双向的。例如数据库管理员（DBA）管理数据库（DB），同时每个数据库都被某位管理员管理。因此，DBA和DB之间具有双向关联关系，如下图所示。</p>
<p><img src="http://www.jasongj.com/img/system_design/uml/class/dba_db.png" alt="Dual Association"></p>
<p>从上图可看出，双向关联的类的实例，互相持有对方的实例，并且可在关联线上注明二者的关系，必须同时注明两种关系（如上图中的manage和managed by）。</p>
<h3 id="单向关联"><a href="#单向关联" class="headerlink" title="单向关联"></a>单向关联</h3><p>单向关联用带箭头的实线表示，同时一方持有另一方的实例，并且由于是单向关联，如果在关联线上注明关系，则只可注明单向的关系，如下图所示。</p>
<p><img src="http://www.jasongj.com/img/system_design/uml/class/student_score.png" alt="One-way Association"></p>
<h3 id="自关联"><a href="#自关联" class="headerlink" title="自关联"></a>自关联</h3><p>自关联是指属性类型为该类本身。例如在链表中，每个节点持有下一个节点的实例，如下图所示。</p>
<p><img src="http://www.jasongj.com/img/system_design/uml/class/node.png" alt="Self Association"></p>
<h3 id="多重性关联"><a href="#多重性关联" class="headerlink" title="多重性关联"></a>多重性关联</h3><p>多重性（Multiplicity）关联关系，表示两个对象在数量上的对应关系。在UML类图中，对象间的多重性可在关联线上用一个数字或数字范围表示。常见的多重性表示方式如下表所示。</p>
<table>
<thead>
<tr>
<th>表示方式</th>
<th>多重性说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1..1</td>
<td>另一个类的一个对象只与该类的一个对象有关系</td>
</tr>
<tr>
<td>0..*</td>
<td>另一个类的一个对象只与该类的零个或多个对象有关系</td>
</tr>
<tr>
<td>1..*</td>
<td>另一个类的一个对象与该类的一个或多个对象有关系</td>
</tr>
<tr>
<td>0..1</td>
<td>另一个类的一个对象与该类的对象没关系或者只与该类的一个对象有关系</td>
</tr>
<tr>
<td>m..n</td>
<td>另一个类的一个对象与该类最少m，最多n个对象有关系</td>
</tr>
</tbody>
</table>
<p>例如一个网页可能没有可点击按钮，也可能有多个按钮，但是该页面中的一个按钮只属于该页面，其关联多重性如下图所示。<br><img src="http://www.jasongj.com/img/system_design/uml/class/page_button.png" alt="Multiplicity"></p>
<h2 id="聚合关系"><a href="#聚合关系" class="headerlink" title="聚合关系"></a>聚合关系</h2><p>聚合（Aggregation）关系表示整体与部分的关系。在聚合关系中，部分对象是整体对象的一部分，但是部分对象可以脱离整体对象独立存在，也即整体对象并不控制部分对象的生命周期。从代码实现上来讲，部分对象不由整体对象创建，一般通过整体类的带参构造方法或者Setter方法或其它业务方法传入到整体对象，并且有整体对象以外的对象持有部分对象的引用。</p>
<p>在UML类图中，聚合关系由带箭头的实线表示，并且实线的起点处以空心菱形表示，如下图所示。<br><img src="http://www.jasongj.com/img/system_design/uml/class/library_book.png" alt="Aggregation"></p>
<p>《<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六）代理模式 vs. 装饰模式</a>》一文中所述<a href="http://www.jasongj.com/design_pattern/proxy_decorator/#u88C5_u9970_u7C7B_u548C_u4F7F_u7528_u65B9_u5F0F">装饰模式</a>中，装饰类的对象与被装饰类的对象即为聚合关系。</p>
<h2 id="组合关系"><a href="#组合关系" class="headerlink" title="组合关系"></a>组合关系</h2><p>组合（Composition）关系也表示类之间整体和部分的关系，但是在组合关系中整体对象控制成员对象的生命周期，一旦整体对象不存在了，成员对象也即随之消亡。</p>
<p>从代码实现上看，一般在整体类的构造方法中直接实例化成员类，并且除整体类对象外，其它类的对象无法获取该对象的引用。</p>
<p>在UML类图中，组合关系的表示方式与聚合关系类似，区别在于实线以实心菱形表示。<br><img src="http://www.jasongj.com/img/system_design/uml/class/cat_leg.png" alt="Composition"></p>
<p>《<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六）代理模式 vs. 装饰模式</a>》一文中所述<a href="http://www.jasongj.com/design_pattern/proxy_decorator/#u4EE3_u7406_u7C7B_u548C_u4F7F_u7528_u65B9_u5F0F">代理模式</a>中，代理类的对象与被代理类的对象即为组合关系。</p>
<h2 id="泛化关系-继承关系"><a href="#泛化关系-继承关系" class="headerlink" title="泛化关系/继承关系"></a>泛化关系/继承关系</h2><p>泛化（Generalization）关系，用于描述父类与子类之间的关系，父类又称作超类或者其类，子类又称为派生类。注意，父类和子类都可为抽象类或者具体类。</p>
<p>在Java中，我们使用面向对象的三大特性之一——继承来实现泛化关系，具体来说会用到<code>extends</code>关键字。</p>
<p>在UML类图中，泛化关系用带空心三角形（指向父类）的实线表示。并且子类中不需要标明其从父类继承下来的属性和方法，只须注明其新增的属性和方法即可。<br><img src="http://www.jasongj.com/img/system_design/uml/class/employee_manager.png" alt="Generalization"></p>
<h2 id="实现关系"><a href="#实现关系" class="headerlink" title="实现关系"></a>实现关系</h2><p>很多面向对象编程语言（如Java）中都引入了接口的概念。接口与接口之间可以有类与类之间类似的继承和依赖关系。同时接口与类之间还存在一种实现（Realization）关系，在这种关系中，类实现了接口中声明的方法。</p>
<p>在UML类图中，类与接口间的实现关系用带空心三角形的虚线表示。同时类中也需要列出接口中所声明的所有方法（这一点与类间的继承关系表示不同）。<br><img src="http://www.jasongj.com/img/system_design/uml/class/truck_car.png" alt="Realization"></p>
<h1 id="UML类图十万个为什么"><a href="#UML类图十万个为什么" class="headerlink" title="UML类图十万个为什么"></a>UML类图十万个为什么</h1><p><strong><em>聚合关系与组合关系都表示整体与部分的关系，有何区别？</em></strong><br>聚合关系中，部分对象的生命周期独立于整体对象的生命周期，或者整体对象消亡后部分对象仍然可以独立存在，同时在代码中一般通过整体类的带参构造方法或Setter方法将部分类对象传入整体类的对象，UML中表示聚合关系的实线以空心菱形开始。<br>组合关系中，部分类对象的生命周期由整体对象控制，一旦整体对象消亡，部分类的对象随即消亡。代码中一般在整体类的构造方法内创建部分类的对象，UML中表示组合关系的实线以实心菱形开始。<br>同时在组合关系中，部分类的对象只属于某一个确定的整体类对象；而在聚合关系中，部分类对象可以属于一个或多个整体类对象。<br>如同《<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六）代理模式 vs. 装饰模式</a>》一文中所述<a href="http://www.jasongj.com/design_pattern/proxy_decorator/#u4EE3_u7406_u7C7B_u548C_u4F7F_u7528_u65B9_u5F0F">代理模式</a>中，代理类的对象与被代理类的对象即为组合关系。<a href="http://www.jasongj.com/design_pattern/proxy_decorator/#u88C5_u9970_u7C7B_u548C_u4F7F_u7528_u65B9_u5F0F">装饰模式</a>中，装饰类的对象与被装饰类的对象即为聚合关系。</p>
<p><strong><em>聚合关系、组合关系与关联关系有何区别和联系？</em></strong><br>聚合关系、组合关系和关联关系实质上是对象间的关系（继承和实现是类与类和类与接口间的关系）。从语意上讲，关联关系中两种对象间一般是平等的，而聚合和组合则代表整体和部分间的关系。而聚合与组合的区别主要体现在实现上和生命周期的管理上。</p>
<p><strong><em>依赖关系与关联关系的区别是？</em></strong><br>依赖关系是较弱的关系，一般表现为在局部变量中使用被依赖类的对象、以被依赖类的对象作为方法参数以及使用被依赖类的静态方法。而关联关系是相对较强的关系，一般表现为一个类包含一个类型为另外一个类的属性。</p>
]]></content>
    
    <summary type="html">
    
      在UML 2.*的13种图形中，类图是使用频率最高的UML图之一，它表示了类与类之间的关系，帮助开发人员理解系统。它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。本文详细介绍了类间的依赖关系，关联关系（聚合、组合等），实现关系以及继承关系的UML表示形式及其在代码中的实现方式。
    
    </summary>
    
      <category term="system design" scheme="http://www.jasongj.com/categories/system-design/"/>
    
      <category term="系统设计" scheme="http://www.jasongj.com/categories/system-design/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="system design" scheme="http://www.jasongj.com/tags/system-design/"/>
    
      <category term="系统设计" scheme="http://www.jasongj.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="架构设计" scheme="http://www.jasongj.com/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="UML" scheme="http://www.jasongj.com/tags/UML/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务（一）两阶段提交及JTA</title>
    <link href="http://www.jasongj.com/big_data/two_phase_commit/"/>
    <id>http://www.jasongj.com/big_data/two_phase_commit/</id>
    <published>2016-07-31T22:55:29.000Z</published>
    <updated>2017-02-18T11:34:21.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/big_data/two_phase_commit/">原文链接</a>　<a href="http://www.jasongj.com/big_data/two_phase_commit/">http://www.jasongj.com/big_data/two_phase_commit/</a></p>
</blockquote>
<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><h2 id="分布式事务简介"><a href="#分布式事务简介" class="headerlink" title="分布式事务简介"></a>分布式事务简介</h2><p>分布式事务是指会涉及到操作多个数据库（或者提供事务语义的系统，如JMS）的事务。其实就是将对同一数据库事务的概念扩大到了对多个数据库的事务。目的是为了保证分布式系统中事务操作的原子性。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）。</p>
<h2 id="分布式事务实现机制"><a href="#分布式事务实现机制" class="headerlink" title="分布式事务实现机制"></a>分布式事务实现机制</h2><p>如同作者在《<a href="http://www.jasongj.com/sql/mvcc/">SQL优化（六） MVCC PostgreSQL实现事务和多版本并发控制的精华</a>》一文中所讲，事务包含原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。</p>
<p>PostgreSQL针对ACID的实现技术如下表所示。</p>
<table>
<thead>
<tr>
<th>ACID</th>
<th>实现技术</th>
</tr>
</thead>
<tbody>
<tr>
<td>原子性（Atomicity）</td>
<td>MVCC</td>
</tr>
<tr>
<td>一致性（Consistency）</td>
<td>约束（主键、外键等）</td>
</tr>
<tr>
<td>隔离性</td>
<td>MVCC</td>
</tr>
<tr>
<td>持久性</td>
<td>WAL</td>
</tr>
</tbody>
</table>
<p>分布式事务的实现技术如下表所示。（以PostgreSQL作为事务参与方为例）</p>
<table>
<thead>
<tr>
<th>分布式ACID</th>
<th>实现技术</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>原子性（Atomicity）</strong></td>
<td><strong>MVCC + 两阶段提交</strong></td>
</tr>
<tr>
<td>一致性（Consistency）</td>
<td>约束（主键、外键等）</td>
</tr>
<tr>
<td>隔离性</td>
<td>MVCC</td>
</tr>
<tr>
<td>持久性</td>
<td>WAL</td>
</tr>
</tbody>
</table>
<p>从上表可以看到，一致性、隔离性和持久性靠的是各分布式事务参与方自己原有的机制，而两阶段提交主要保证了分布式事务的原子性。</p>
<h1 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h1><h2 id="分布式事务如何保证原子性"><a href="#分布式事务如何保证原子性" class="headerlink" title="分布式事务如何保证原子性"></a>分布式事务如何保证原子性</h2><p>在分布式系统中，各个节点（或者事务参与方）之间在物理上相互独立，通过网络进行协调。每个独立的节点（或组件）由于存在事务机制，可以保证其数据操作的ACID特性。但是，各节点之间由于相互独立，无法确切地知道其经节点中的事务执行情况，所以多节点之间很难保证ACID，尤其是原子性。</p>
<p>如果要实现分布式系统的原子性，则须保证所有节点的数据写操作，要不全部都执行（生效），要么全部都不执行（生效）。但是，一个节点在执行本地事务的时候无法知道其它机器的本地事务的执行结果，所以它就不知道本次事务到底应该commit还是 roolback。常规的解决办法是引入一个“协调者”的组件来统一调度所有分布式节点的执行。</p>
<h2 id="XA规范"><a href="#XA规范" class="headerlink" title="XA规范"></a>XA规范</h2><p>XA是由X/Open组织提出的分布式事务的规范。XA规范主要定义了（全局）事务管理器（Transaction Manager）和（局部）资源管理器（Resource Manager）之间的接口。XA接口是双向的系统接口，在事务管理器（Transaction Manager）以及一个或多个资源管理器（Resource Manager）之间形成通信桥梁。XA引入的事务管理器充当上文所述全局事务中的“协调者”角色。事务管理器控制着全局事务，管理事务生命周期，并协调资源。资源管理器负责控制和管理实际资源（如数据库或JMS队列）。目前，Oracle、Informix、DB2、Sybase和PostgreSQL等各主流数据库都提供了对XA的支持。</p>
<p>XA规范中，事务管理器主要通过以下的接口对资源管理器进行管理</p>
<ul>
<li>xa_open，xa_close：建立和关闭与资源管理器的连接。</li>
<li>xa_start，xa_end：开始和结束一个本地事务。</li>
<li>xa_prepare，xa_commit，xa_rollback：预提交、提交和回滚一个本地事务。</li>
<li>xa_recover：回滚一个已进行预提交的事务。</li>
</ul>
<h2 id="两阶段提交原理"><a href="#两阶段提交原理" class="headerlink" title="两阶段提交原理"></a>两阶段提交原理</h2><p>二阶段提交的算法思路可以概括为：协调者询问参与者是否准备好了提交，并根据所有参与者的反馈情况决定向所有参与者发送commit或者rollback指令（协调者向所有参与者发送相同的指令）。</p>
<p>所谓的两个阶段是指</p>
<ul>
<li><code>准备阶段</code> 又称投票阶段。在这一阶段，协调者询问所有参与者是否准备好提交，参与者如果已经准备好提交则回复<code>Prepared</code>，否则回复<code>Non-Prepared</code>。</li>
<li><code>提交阶段</code> 又称执行阶段。协调者如果在上一阶段收到所有参与者回复的<code>Prepared</code>，则在此阶段向所有参与者发送<code>commit</code>指令，所有参与者立即执行<code>commit</code>操作；否则协调者向所有参与者发送<code>rollback</code>指令，参与者立即执行<code>rollback</code>操作。</li>
</ul>
<p>两阶段提交中，协调者和参与方的交互过程如下图所示。<br><img src="http://www.jasongj.com/img/bigdata/two_phase_commit.png" alt="Two-phase commit"></p>
<h2 id="两阶段提交前提条件"><a href="#两阶段提交前提条件" class="headerlink" title="两阶段提交前提条件"></a>两阶段提交前提条件</h2><ul>
<li>网络通信是可信的。虽然网络并不可靠，但两阶段提交的主要目标并不是解决诸如拜占庭问题的网络问题。同时两阶段提交的主要网络通信危险期（In-doubt Time）在事务提交阶段，而该阶段非常短。</li>
<li>所有crash的节点最终都会恢复，不会一直处于crash状态。</li>
<li>每个分布式事务参与方都有WAL日志，并且该日志存于稳定的存储上。</li>
<li>各节点上的本地事务状态即使碰到机器crash都可从WAL日志上恢复。</li>
</ul>
<h2 id="两阶段提交容错方式"><a href="#两阶段提交容错方式" class="headerlink" title="两阶段提交容错方式"></a>两阶段提交容错方式</h2><p>两阶段提交中的异常主要分为如下三种情况</p>
<ol>
<li>协调者正常，参与方crash</li>
<li>协调者crash，参与者正常</li>
<li>协调者和参与方都crash</li>
</ol>
<p>对于第一种情况，若参与方在准备阶段crash，则协调者收不到<code>Prepared</code>回复，协调方不会发送<code>commit</code>命令，事务不会真正提交。若参与方在提交阶段提交，当它恢复后可以通过从其它参与方或者协调方获取事务是否应该提交，并作出相应的响应。</p>
<p>第二种情况，可以通过选出新的协调者解决。</p>
<p>第三种情况，是两阶段提交无法完美解决的情况。尤其是当协调者发送出<code>commit</code>命令后，唯一收到<code>commit</code>命令的参与者也crash，此时其它参与方不能从协调者和已经crash的参与者那儿了解事务提交状态。但如同上一节<a href="#u4E24_u9636_u6BB5_u63D0_u4EA4_u5047_u8BBE_u6761_u4EF6">两阶段提交前提条件</a>所述，两阶段提交的前提条件之一是所有crash的节点最终都会恢复，所以当收到<code>commit</code>的参与方恢复后，其它节点可从它那里获取事务状态并作出相应操作。</p>
<h1 id="JTA"><a href="#JTA" class="headerlink" title="JTA"></a>JTA</h1><h2 id="JTA介绍"><a href="#JTA介绍" class="headerlink" title="JTA介绍"></a>JTA介绍</h2><p>作为java平台上事务规范JTA（Java Transaction API）也定义了对XA事务的支持，实际上，JTA是基于XA架构上建模的。在JTA 中，事务管理器抽象为<code>javax.transaction.TransactionManager</code>接口，并通过底层事务服务（即Java Transaction Service）实现。像很多其他的Java规范一样，JTA仅仅定义了接口，具体的实现则是由供应商(如J2EE厂商)负责提供，目前JTA的实现主要有以下几种：</p>
<ul>
<li>J2EE容器所提供的JTA实现(如JBoss)。</li>
<li>独立的JTA实现：如JOTM（Java Open Transaction Manager），Atomikos。这些实现可以应用在那些不使用J2EE应用服务器的环境里用以提供分布事事务保证。</li>
</ul>
<h2 id="PostgreSQL两阶段提交接口"><a href="#PostgreSQL两阶段提交接口" class="headerlink" title="PostgreSQL两阶段提交接口"></a>PostgreSQL两阶段提交接口</h2><ul>
<li><code>PREPARE TRANSACTION transaction_id</code> PREPARE TRANSACTION 为当前事务的两阶段提交做准备。 在命令之后，事务就不再和当前会话关联了；它的状态完全保存在磁盘上， 它提交成功有非常高的可能性，即使是在请求提交之前数据库发生了崩溃也如此。这条命令必须在一个用BEGIN显式开始的事务块里面使用。</li>
<li><code>COMMIT PREPARED transaction_id</code> 提交已进入准备阶段的ID为<code>transaction_id</code>的事务</li>
<li><code>ROLLBACK PREPARED transaction_id</code> 回滚已进入准备阶段的ID为<code>transaction_id</code>的事务</li>
</ul>
<p>典型的使用方式如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">postgres=&gt; BEGIN;</div><div class="line">BEGIN</div><div class="line">postgres=&gt; CREATE TABLE demo(a TEXT, b INTEGER);    </div><div class="line">CREATE TABLE</div><div class="line">postgres=&gt; PREPARE TRANSACTION 'the first prepared transaction';</div><div class="line">PREPARE TRANSACTION</div><div class="line">postgres=&gt; SELECT * FROM pg_prepared_xacts;</div><div class="line"> transaction |              gid               |           prepared            | owner | database </div><div class="line">-------------+--------------------------------+-------------------------------+-------+----------</div><div class="line">       23970 | the first prepared transaction | 2016-08-01 20:44:55.816267+08 | casp  | postgres</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<p>从上面代码可看出，使用<code>PREPARE TRANSACTION transaction_id</code>语句后，PostgreSQL会在<code>pg_catalog.pg_prepared_xact</code>表中将该事务的<code>transaction_id</code>记于gid字段中，并将该事务的本地事务ID，即23970，存于<code>transaction</code>字段中，同时会记下该事务的创建时间及创建用户和数据库名。</p>
<p>继续执行如下命令<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">postgres=&gt; \q</div><div class="line">SELECT * FROM pg_prepared_xacts;</div><div class="line"> transaction |              gid               |           prepared            | owner | database </div><div class="line">-------------+--------------------------------+-------------------------------+-------+----------</div><div class="line">       23970 | the first prepared transaction | 2016-08-01 20:44:55.816267+08 | casp  | cqdb</div><div class="line">(1 row)</div><div class="line"></div><div class="line">cqdb=&gt; ROLLBACK PREPARED 'the first prepared transaction';            </div><div class="line">ROLLBACK PREPARED</div><div class="line">cqdb=&gt; SELECT * FROM pg_prepared_xacts;</div><div class="line"> transaction | gid | prepared | owner | database </div><div class="line">-------------+-----+----------+-------+----------</div><div class="line">(0 rows)</div></pre></td></tr></table></figure></p>
<p>即使退出当前session，<code>pg_catalog.pg_prepared_xact</code>表中关于已经进入准备阶段的事务信息依然存在，这与上文所述准备阶段后各节点会将事务信息存于磁盘中持久化相符。注：如果不使用<code>PREPARED TRANSACTION &#39;transaction_id&#39;</code>，则已BEGIN但还未COMMIT或ROLLBACK的事务会在session退出时自动ROLLBACK。</p>
<p>在ROLLBACK已进入准备阶段的事务时，必须指定其<code>transaction_id</code>。</p>
<h2 id="PostgreSQL两阶段提交注意事项"><a href="#PostgreSQL两阶段提交注意事项" class="headerlink" title="PostgreSQL两阶段提交注意事项"></a>PostgreSQL两阶段提交注意事项</h2><ul>
<li><code>PREPARE TRANSACTION transaction_id</code>命令后，事务状态完全保存在磁盘上。</li>
<li><code>PREPARE TRANSACTION transaction_id</code>命令后，事务就不再和当前会话关联，因此当前session可继续执行其它事务。</li>
<li><code>COMMIT PREPARED</code>和<code>ROLLBACK PREPARED</code>可在任何会话中执行，而并不要求在提交准备的会话中执行。</li>
<li>不允许对那些执行了涉及临时表或者是创建了带<code>WITH HOLD</code>游标的事务进行PREPARE。 这些特性和当前会话绑定得实在是太紧密了，因此在一个准备好的事务里没什么可用的。</li>
<li>如果事务用<code>SET</code>修改了运行时参数，这些效果在<code>PREPARE TRANSACTION</code>之后保留，并且不会被任何以后的<code>COMMIT PREPARED</code>或<code>ROLLBACK PREPARED</code>所影响，因为<code>SET</code>的生效范围是当前session。</li>
<li>从性能的角度来看，把一个事务长时间停在准备好的状态是不明智的，因为它会影响<code>VACUUM</code>回收存储的能力。</li>
<li>已准备好的事务会继续持有它们获得的锁，直到该事务被commit或者rollback。所以如果已进入准备阶段的事务一直不被处理，其它事务可能会因为获取不到锁而被block或者失败。</li>
<li>默认情况下，PostgreSQL并不开启两阶段提交，可以通过在<code>postgresql.conf</code>文件中设置<code>max_prepared_transactions</code>配置项开启PostgreSQL的两阶段提交。</li>
</ul>
<h1 id="JTA实现PostgreSQL两阶段提交"><a href="#JTA实现PostgreSQL两阶段提交" class="headerlink" title="JTA实现PostgreSQL两阶段提交"></a>JTA实现PostgreSQL两阶段提交</h1><p>本文使用Atomikos提供的JTA实现，利用PostgreSQL提供的两阶段提交特性，实现了分布式事务。本文中的分布式事务使用了2个不同机器上的PostgreSQL实例。</p>
<p>本例所示代码可从<a href="https://github.com/habren/atomikos-jta-tomcat" target="_blank" rel="external">作者Github</a>获取。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.jta.resource;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.sql.Connection;</div><div class="line"><span class="keyword">import</span> java.sql.SQLException;</div><div class="line"><span class="keyword">import</span> java.sql.Statement;</div><div class="line"></div><div class="line"><span class="keyword">import</span> javax.naming.Context;</div><div class="line"><span class="keyword">import</span> javax.naming.InitialContext;</div><div class="line"><span class="keyword">import</span> javax.naming.NamingException;</div><div class="line"><span class="keyword">import</span> javax.sql.DataSource;</div><div class="line"><span class="keyword">import</span> javax.transaction.NotSupportedException;</div><div class="line"><span class="keyword">import</span> javax.transaction.SystemException;</div><div class="line"><span class="keyword">import</span> javax.transaction.UserTransaction;</div><div class="line"><span class="keyword">import</span> javax.ws.rs.GET;</div><div class="line"><span class="keyword">import</span> javax.ws.rs.Path;</div><div class="line"><span class="keyword">import</span> javax.ws.rs.PathParam;</div><div class="line"><span class="keyword">import</span> javax.ws.rs.WebApplicationException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="meta">@Path</span>(<span class="string">"/jta"</span>)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JTAResource</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(JTAResource.class);</div><div class="line"></div><div class="line">  <span class="meta">@GET</span></div><div class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">test</span><span class="params">(@PathParam(value = <span class="string">"commit"</span>)</span> <span class="keyword">boolean</span> isCommit)</span></div><div class="line">      <span class="keyword">throws</span> NamingException, SQLException, NotSupportedException, SystemException &#123;</div><div class="line">    UserTransaction userTransaction = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      Context context = <span class="keyword">new</span> InitialContext();</div><div class="line">      userTransaction = (UserTransaction) context.lookup(<span class="string">"java:comp/UserTransaction"</span>);</div><div class="line">      userTransaction.setTransactionTimeout(<span class="number">600</span>);</div><div class="line">      </div><div class="line">      userTransaction.begin();</div><div class="line">      </div><div class="line">      DataSource dataSource1 = (DataSource) context.lookup(<span class="string">"java:comp/env/jdbc/1"</span>);</div><div class="line">      Connection xaConnection1 = dataSource1.getConnection();</div><div class="line">      </div><div class="line">      DataSource dataSource2 = (DataSource) context.lookup(<span class="string">"java:comp/env/jdbc/2"</span>);</div><div class="line">      Connection xaConnection2 = dataSource2.getConnection();</div><div class="line">      LOGGER.info(<span class="string">"Connection autocommit : &#123;&#125;"</span>, xaConnection1.getAutoCommit());</div><div class="line"></div><div class="line">      Statement st1 = xaConnection1.createStatement();</div><div class="line">      Statement st2 = xaConnection2.createStatement();</div><div class="line">      LOGGER.info(<span class="string">"Connection autocommit after created statement: &#123;&#125;"</span>, xaConnection1.getAutoCommit());</div><div class="line">      </div><div class="line"></div><div class="line">      st1.execute(<span class="string">"update casp.test set qtime=current_timestamp, value = 1"</span>);</div><div class="line">      st2.execute(<span class="string">"update casp.test set qtime=current_timestamp, value = 2"</span>);</div><div class="line">      LOGGER.info(<span class="string">"Autocommit after execution : "</span>, xaConnection1.getAutoCommit());</div><div class="line"></div><div class="line">      userTransaction.commit();</div><div class="line">      LOGGER.info(<span class="string">"Autocommit after commit: "</span>,  xaConnection1.getAutoCommit());</div><div class="line">      <span class="keyword">return</span> <span class="string">"commit"</span>;</div><div class="line"></div><div class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">      <span class="keyword">if</span> (userTransaction != <span class="keyword">null</span>) &#123;</div><div class="line">        userTransaction.rollback();</div><div class="line">      &#125;</div><div class="line">      LOGGER.info(ex.toString());</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> WebApplicationException(<span class="string">"failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上示代码中可以看到，虽然使用了Atomikos的JTA实现，但因为使用了面向接口编程特性，所以只出现了JTA相关的接口，而未显式使用Atomikos相关类。具体的Atomikos使用是在<code>WebContent/META-INFO/context.xml</code>中配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">Context</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">Transaction</span> <span class="attr">factory</span>=<span class="string">"com.atomikos.icatch.jta.UserTransactionFactory"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">Resource</span> <span class="attr">name</span>=<span class="string">"jdbc/1"</span></span></div><div class="line">    <span class="attr">auth</span>=<span class="string">"Container"</span></div><div class="line">    <span class="attr">type</span>=<span class="string">"com.atomikos.jdbc.AtomikosDataSourceBean"</span></div><div class="line">    <span class="attr">factory</span>=<span class="string">"com.jasongj.jta.util.EnhancedTomcatAtomikosBeanFactory"</span></div><div class="line">    <span class="attr">uniqueResourceName</span>=<span class="string">"DataSource_Resource1"</span></div><div class="line">    <span class="attr">minPoolSize</span>=<span class="string">"2"</span></div><div class="line">    <span class="attr">maxPoolSize</span>=<span class="string">"8"</span></div><div class="line">    <span class="attr">testQuery</span>=<span class="string">"SELECT 1"</span></div><div class="line">    <span class="attr">xaDataSourceClassName</span>=<span class="string">"org.postgresql.xa.PGXADataSource"</span></div><div class="line">    <span class="attr">xaProperties.databaseName</span>=<span class="string">"postgres"</span></div><div class="line">    <span class="attr">xaProperties.serverName</span>=<span class="string">"192.168.0.1"</span></div><div class="line">    <span class="attr">xaProperties.portNumber</span>=<span class="string">"5432"</span></div><div class="line">    <span class="attr">xaProperties.user</span>=<span class="string">"casp"</span></div><div class="line">    <span class="attr">xaProperties.password</span>=<span class="string">""</span>/&gt;</div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">Resource</span> <span class="attr">name</span>=<span class="string">"jdbc/2"</span></span></div><div class="line">    <span class="attr">auth</span>=<span class="string">"Container"</span></div><div class="line">    <span class="attr">type</span>=<span class="string">"com.atomikos.jdbc.AtomikosDataSourceBean"</span></div><div class="line">    <span class="attr">factory</span>=<span class="string">"com.jasongj.jta.util.EnhancedTomcatAtomikosBeanFactory"</span></div><div class="line">    <span class="attr">uniqueResourceName</span>=<span class="string">"DataSource_Resource2"</span></div><div class="line">    <span class="attr">minPoolSize</span>=<span class="string">"2"</span></div><div class="line">    <span class="attr">maxPoolSize</span>=<span class="string">"8"</span></div><div class="line">    <span class="attr">testQuery</span>=<span class="string">"SELECT 1"</span></div><div class="line">    <span class="attr">xaDataSourceClassName</span>=<span class="string">"org.postgresql.xa.PGXADataSource"</span></div><div class="line">    <span class="attr">xaProperties.databaseName</span>=<span class="string">"postgres"</span></div><div class="line">    <span class="attr">xaProperties.serverName</span>=<span class="string">"192.168.0.2"</span></div><div class="line">    <span class="attr">xaProperties.portNumber</span>=<span class="string">"5432"</span></div><div class="line">    <span class="attr">xaProperties.user</span>=<span class="string">"casp"</span></div><div class="line">    <span class="attr">xaProperties.password</span>=<span class="string">""</span>/&gt;  </div><div class="line"><span class="tag">&lt;/<span class="name">Context</span>&gt;</span></div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      分布式事务与本地事务一样，包含原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。两阶段提交是保证分布式事务中原子性的重要方法。本文重点介绍了两阶段提交的原理，PostgreSQL中两阶段提交接口，以及Java中两阶段提交接口规范JTA的使用方式。
    
    </summary>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式事务" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（四）线程间通信剖析</title>
    <link href="http://www.jasongj.com/java/thread_communication/"/>
    <id>http://www.jasongj.com/java/thread_communication/</id>
    <published>2016-06-22T22:55:29.000Z</published>
    <updated>2017-02-15T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/java/thread_communication/">原文链接</a>　<a href="http://www.jasongj.com/java/thread_communication/">http://www.jasongj.com/java/thread_communication/</a></p>
</blockquote>
<h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><h2 id="CountDownLatch适用场景"><a href="#CountDownLatch适用场景" class="headerlink" title="CountDownLatch适用场景"></a>CountDownLatch适用场景</h2><p>Java多线程编程中经常会碰到这样一种场景——某个线程需要等待一个或多个线程操作结束（或达到某种状态）才开始执行。比如开发一个并发测试工具时，主线程需要等到所有测试线程均执行完成再开始统计总共耗费的时间，此时可以通过CountDownLatch轻松实现。</p>
<h2 id="CountDownLatch实例"><a href="#CountDownLatch实例" class="headerlink" title="CountDownLatch实例"></a>CountDownLatch实例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountDownLatchDemo</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">int</span> totalThread = <span class="number">3</span>;</div><div class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">    CountDownLatch countDown = <span class="keyword">new</span> CountDownLatch(totalThread);</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; totalThread; i++) &#123;</div><div class="line">      <span class="keyword">final</span> String threadName = <span class="string">"Thread "</span> + i;</div><div class="line">      <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"started"</span>));</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">1000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        countDown.countDown();</div><div class="line">        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"ended"</span>));</div><div class="line">      &#125;).start();;</div><div class="line">    &#125;</div><div class="line">    countDown.await();</div><div class="line">    <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">    System.out.println(String.format(<span class="string">"Total time : %sms"</span>, (stop - start)));</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Sun Jun 19 20:34:31 CST 2016  Thread 1 started</div><div class="line">Sun Jun 19 20:34:31 CST 2016  Thread 0 started</div><div class="line">Sun Jun 19 20:34:31 CST 2016  Thread 2 started</div><div class="line">Sun Jun 19 20:34:32 CST 2016  Thread 2 ended</div><div class="line">Sun Jun 19 20:34:32 CST 2016  Thread 1 ended</div><div class="line">Sun Jun 19 20:34:32 CST 2016  Thread 0 ended</div><div class="line">Total time : 1072ms</div></pre></td></tr></table></figure></p>
<p>可以看到，主线程等待所有3个线程都执行结束后才开始执行。</p>
<h2 id="CountDownLatch主要接口分析"><a href="#CountDownLatch主要接口分析" class="headerlink" title="CountDownLatch主要接口分析"></a>CountDownLatch主要接口分析</h2><p>CountDownLatch工作原理相对简单，可以简单看成一个倒计数器，在构造方法中指定初始值，每次调用<em>countDown()</em>方法时将计数器减1，而<em>await()</em>会等待计数器变为0。CountDownLatch关键接口如下</p>
<ul>
<li><strong><em>countDown()</em></strong> 如果当前计数器的值大于1，则将其减1；若当前值为1，则将其置为0并唤醒所有通过await等待的线程；若当前值为0，则什么也不做直接返回。</li>
<li><strong><em>await()</em></strong> 等待计数器的值为0，若计数器的值为0则该方法返回；若等待期间该线程被中断，则抛出<strong>InterruptedException</strong>并清除该线程的中断状态。</li>
<li><strong><em>await(long timeout, TimeUnit unit)</em></strong> 在指定的时间内等待计数器的值为0，若在指定时间内计数器的值变为0，则该方法返回true；若指定时间内计数器的值仍未变为0，则返回false；若指定时间内计数器的值变为0之前当前线程被中断，则抛出<strong>InterruptedException</strong>并清除该线程的中断状态。</li>
<li><strong><em>getCount()</em></strong> 读取当前计数器的值，一般用于调试或者测试。</li>
</ul>
<h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><h2 id="CyclicBarrier适用场景"><a href="#CyclicBarrier适用场景" class="headerlink" title="CyclicBarrier适用场景"></a>CyclicBarrier适用场景</h2><p>在《<a href="http://www.jasongj.com/java/thread_safe">当我们说线程安全时，到底在说什么</a>》一文中讲过内存屏障，它能保证屏障之前的代码一定在屏障之后的代码之前被执行。CyclicBarrier可以译为循环屏障，也有类似的功能。CyclicBarrier可以在构造时指定需要在屏障前执行await的个数，所有对await的调用都会等待，直到调用await的次数达到预定指，所有等待都会立即被唤醒。</p>
<p>从使用场景上来说，CyclicBarrier是让多个线程互相等待某一事件的发生，然后同时被唤醒。而上文讲的CountDownLatch是让某一线程等待多个线程的状态，然后该线程被唤醒。</p>
<h2 id="CyclicBarrier实例"><a href="#CyclicBarrier实例" class="headerlink" title="CyclicBarrier实例"></a>CyclicBarrier实例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.CyclicBarrier;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CyclicBarrierDemo</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> totalThread = <span class="number">5</span>;</div><div class="line">    CyclicBarrier barrier = <span class="keyword">new</span> CyclicBarrier(totalThread);</div><div class="line">    </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; totalThread; i++) &#123;</div><div class="line">      String threadName = <span class="string">"Thread "</span> + i;</div><div class="line">      <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">" is waiting"</span>));</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          barrier.await();</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(String.format(<span class="string">"%s\t%s %s"</span>, <span class="keyword">new</span> Date(), threadName, <span class="string">"ended"</span>));</div><div class="line">      &#125;).start();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 1  is waiting</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 0  is waiting</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 3  is waiting</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 2  is waiting</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 4  is waiting</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 4 ended</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 0 ended</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 2 ended</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 1 ended</div><div class="line">Sun Jun 19 21:04:49 CST 2016  Thread 3 ended</div></pre></td></tr></table></figure></p>
<p>从执行结果可以看到，每个线程都不会在其它所有线程执行<em>await()</em>方法前继续执行，而等所有线程都执行<em>await()</em>方法后所有线程的等待都被唤醒从而继续执行。</p>
<h2 id="CyclicBarrier主要接口分析"><a href="#CyclicBarrier主要接口分析" class="headerlink" title="CyclicBarrier主要接口分析"></a>CyclicBarrier主要接口分析</h2><p>CyclicBarrier提供的关键方法如下</p>
<ul>
<li><strong><em>await()</em></strong> 等待其它参与方的到来（调用await()）。如果当前调用是最后一个调用，则唤醒所有其它的线程的等待并且如果在构造CyclicBarrier时指定了action，当前线程会去执行该action，然后该方法返回该线程调用await的次序（getParties()-1说明该线程是第一个调用await的，0说明该线程是最后一个执行await的），接着该线程继续执行await后的代码；如果该调用不是最后一个调用，则阻塞等待；如果等待过程中，当前线程被中断，则抛出<strong>InterruptedException</strong>；如果等待过程中，其它等待的线程被中断，或者其它线程等待超时，或者该barrier被reset，或者当前线程在执行barrier构造时注册的action时因为抛出异常而失败，则抛出<strong>BrokenBarrierException</strong>。</li>
<li><strong><em>await(long timeout, TimeUnit unit)</em></strong> 与<em>await()</em>唯一的不同点在于设置了等待超时时间，等待超时时会抛出<strong>TimeoutException</strong>。</li>
<li><strong><em>reset()</em></strong> 该方法会将该barrier重置为它的初始状态，并使得所有对该barrier的await调用抛出<strong>BrokenBarrierException</strong>。</li>
</ul>
<h1 id="Phaser"><a href="#Phaser" class="headerlink" title="Phaser"></a>Phaser</h1><h2 id="Phaser适用场景"><a href="#Phaser适用场景" class="headerlink" title="Phaser适用场景"></a>Phaser适用场景</h2><p>CountDownLatch和CyclicBarrier都是JDK 1.5引入的，而Phaser是JDK 1.7引入的。Phaser的功能与CountDownLatch和CyclicBarrier有部分重叠，同时也提供了更丰富的语义和更灵活的用法。</p>
<p>Phaser顾名思义，与阶段相关。Phaser比较适合这样一种场景，一种任务可以分为多个阶段，现希望多个线程去处理该批任务，对于每个阶段，多个线程可以并发进行，但是希望保证只有前面一个阶段的任务完成之后才能开始后面的任务。这种场景可以使用多个CyclicBarrier来实现，每个CyclicBarrier负责等待一个阶段的任务全部完成。但是使用CyclicBarrier的缺点在于，需要明确知道总共有多少个阶段，同时并行的任务数需要提前预定义好，且无法动态修改。而Phaser可同时解决这两个问题。</p>
<h2 id="Phaser实例"><a href="#Phaser实例" class="headerlink" title="Phaser实例"></a>Phaser实例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PhaserDemo</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">int</span> parties = <span class="number">3</span>;</div><div class="line">    <span class="keyword">int</span> phases = <span class="number">4</span>;</div><div class="line">    <span class="keyword">final</span> Phaser phaser = <span class="keyword">new</span> Phaser(parties) &#123;</div><div class="line">      <span class="meta">@Override</span>  </div><div class="line">      <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">onAdvance</span><span class="params">(<span class="keyword">int</span> phase, <span class="keyword">int</span> registeredParties)</span> </span>&#123;  </div><div class="line">          System.out.println(<span class="string">"====== Phase : "</span> + phase + <span class="string">" ======"</span>);  </div><div class="line">          <span class="keyword">return</span> registeredParties == <span class="number">0</span>;  </div><div class="line">      &#125;  </div><div class="line">    &#125;;</div><div class="line">    </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parties; i++) &#123;</div><div class="line">      <span class="keyword">int</span> threadId = i;</div><div class="line">      Thread thread = <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> phase = <span class="number">0</span>; phase &lt; phases; phase++) &#123;</div><div class="line">          System.out.println(String.format(<span class="string">"Thread %s, phase %s"</span>, threadId, phase));</div><div class="line">          phaser.arriveAndAwaitAdvance();</div><div class="line">        &#125;</div><div class="line">      &#125;);</div><div class="line">      thread.start();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Thread <span class="number">0</span>, phase <span class="number">0</span></div><div class="line">Thread <span class="number">1</span>, phase <span class="number">0</span></div><div class="line">Thread <span class="number">2</span>, phase <span class="number">0</span></div><div class="line">====== Phase : <span class="number">0</span> ======</div><div class="line">Thread <span class="number">2</span>, phase <span class="number">1</span></div><div class="line">Thread <span class="number">0</span>, phase <span class="number">1</span></div><div class="line">Thread <span class="number">1</span>, phase <span class="number">1</span></div><div class="line">====== Phase : <span class="number">1</span> ======</div><div class="line">Thread <span class="number">1</span>, phase <span class="number">2</span></div><div class="line">Thread <span class="number">2</span>, phase <span class="number">2</span></div><div class="line">Thread <span class="number">0</span>, phase <span class="number">2</span></div><div class="line">====== Phase : <span class="number">2</span> ======</div><div class="line">Thread <span class="number">0</span>, phase <span class="number">3</span></div><div class="line">Thread <span class="number">1</span>, phase <span class="number">3</span></div><div class="line">Thread <span class="number">2</span>, phase <span class="number">3</span></div><div class="line">====== Phase : <span class="number">3</span> ======</div></pre></td></tr></table></figure></p>
<p>从上面的结果可以看到，多个线程必须等到其它线程的同一阶段的任务全部完成才能进行到下一个阶段，并且每当完成某一阶段任务时，Phaser都会执行其<em>onAdvance</em>方法。</p>
<h2 id="Phaser主要接口分析"><a href="#Phaser主要接口分析" class="headerlink" title="Phaser主要接口分析"></a>Phaser主要接口分析</h2><p>Phaser主要接口如下</p>
<ul>
<li><strong><em>arriveAndAwaitAdvance()</em></strong> 当前线程当前阶段执行完毕，等待其它线程完成当前阶段。如果当前线程是该阶段最后一个未到达的，则该方法直接返回下一个阶段的序号（阶段序号从0开始），同时其它线程的该方法也返回下一个阶段的序号。</li>
<li><strong><em>arriveAndDeregister()</em></strong> 该方法立即返回下一阶段的序号，并且其它线程需要等待的个数减一，并且把当前线程从之后需要等待的成员中移除。如果该Phaser是另外一个Phaser的子Phaser（层次化Phaser会在后文中讲到），并且该操作导致当前Phaser的成员数为0，则该操作也会将当前Phaser从其父Phaser中移除。</li>
<li><strong><em>arrive()</em></strong> 该方法不作任何等待，直接返回下一阶段的序号。</li>
<li><strong><em>awaitAdvance(int phase)</em></strong> 该方法等待某一阶段执行完毕。如果当前阶段不等于指定的阶段或者该Phaser已经被终止，则立即返回。该阶段数一般由<em>arrive()</em>方法或者<em>arriveAndDeregister()</em>方法返回。返回下一阶段的序号，或者返回参数指定的值（如果该参数为负数），或者直接返回当前阶段序号（如果当前Phaser已经被终止）。</li>
<li><strong><em>awaitAdvanceInterruptibly(int phase)</em></strong> 效果与<em>awaitAdvance(int phase)</em>相当，唯一的不同在于若该线程在该方法等待时被中断，则该方法抛出<strong>InterruptedException</strong>。</li>
<li><strong><em>awaitAdvanceInterruptibly(int phase, long timeout, TimeUnit unit)</em></strong> 效果与<em>awaitAdvanceInterruptibly(int phase)</em>相当，区别在于如果超时则抛出<strong>TimeoutException</strong>。</li>
<li><strong><em>bulkRegister(int parties)</em></strong> 注册多个party。如果当前phaser已经被终止，则该方法无效，并返回负数。如果调用该方法时，<em>onAdvance</em>方法正在执行，则该方法等待其执行完毕。如果该Phaser有父Phaser则指定的party数大于0，且之前该Phaser的party数为0，那么该Phaser会被注册到其父Phaser中。</li>
<li><strong><em>forceTermination()</em></strong> 强制让该Phaser进入终止状态。已经注册的party数不受影响。如果该Phaser有子Phaser，则其所有的子Phaser均进入终止状态。如果该Phaser已经处于终止状态，该方法调用不造成任何影响。</li>
</ul>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文将介绍常用的线程间通信工具CountDownLatch、CyclicBarrier和Phaser的用法，并结合实例介绍它们各自的适用场景及相同点和不同点。
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（三）多线程开发关键技术</title>
    <link href="http://www.jasongj.com/java/multi_thread/"/>
    <id>http://www.jasongj.com/java/multi_thread/</id>
    <published>2016-06-19T22:55:29.000Z</published>
    <updated>2017-02-15T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/java/multi_thread/">原文链接</a>　<a href="http://www.jasongj.com/java/multi_thread/">http://www.jasongj.com/java/multi_thread/</a></p>
</blockquote>
<h1 id="sleep和wait到底什么区别"><a href="#sleep和wait到底什么区别" class="headerlink" title="sleep和wait到底什么区别"></a>sleep和wait到底什么区别</h1><p>其实这个问题应该这么问——sleep和wait有什么相同点。因为这两个方法除了都能让当前线程暂停执行完，几乎没有其它相同点。</p>
<p>wait方法是Object类的方法，这意味着所有的Java类都可以调用该方法。sleep方法是Thread类的静态方法。</p>
<p>wait是在当前线程持有wait对象锁的情况下，暂时放弃锁，并让出CPU资源，并积极等待其它线程调用同一对象的notify或者notifyAll方法。注意，即使只有一个线程在等待，并且有其它线程调用了notify或者notifyAll方法，等待的线程只是被激活，但是它必须得再次获得锁才能继续往下执行。换言之，即使notify被调用，但只要锁没有被释放，原等待线程因为未获得锁仍然无法继续执行。测试代码如下所示<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Wait</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Thread thread1 = <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      <span class="keyword">synchronized</span> (Wait.class) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread1 is running"</span>);</div><div class="line">          Wait.class.wait();</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread1 ended"</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">    thread1.start();</div><div class="line">    </div><div class="line">    Thread thread2 = <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      <span class="keyword">synchronized</span> (Wait.class) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread2 is running"</span>);</div><div class="line">          Wait.class.notify();</div><div class="line">          <span class="comment">// Don't use sleep method to avoid confusing</span></div><div class="line">          <span class="keyword">for</span>(<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">long</span> j = <span class="number">0</span>; j &lt; <span class="number">100000</span>; j++) &#123;&#125;</div><div class="line">          &#125;</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread2 release lock"</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      <span class="keyword">for</span>(<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">long</span> j = <span class="number">0</span>; j &lt; <span class="number">100000</span>; j++) &#123;&#125;</div><div class="line">      &#125;</div><div class="line">      System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread2 ended"</span>);</div><div class="line">    &#125;);</div><div class="line">    </div><div class="line">    <span class="comment">// Don't use sleep method to avoid confusing</span></div><div class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</div><div class="line">      <span class="keyword">for</span>(<span class="keyword">long</span> j = <span class="number">0</span>; j &lt; <span class="number">100000</span>; j++) &#123;&#125;</div><div class="line">    &#125;</div><div class="line">    thread2.start();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>执行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Tue Jun 14 22:51:11 CST 2016 Thread1 is running</div><div class="line">Tue Jun 14 22:51:23 CST 2016 Thread2 is running</div><div class="line">Tue Jun 14 22:51:36 CST 2016 Thread2 release lock</div><div class="line">Tue Jun 14 22:51:36 CST 2016 Thread1 ended</div><div class="line">Tue Jun 14 22:51:49 CST 2016 Thread2 ended</div></pre></td></tr></table></figure></p>
<p>从运行结果可以看出</p>
<ul>
<li>thread1执行wait后，暂停执行</li>
<li>thread2执行notify后，thread1并没有继续执行，因为此时thread2尚未释放锁，thread1因为得不到锁而不能继续执行</li>
<li>thread2执行完synchronized语句块后释放锁，thread1得到通知并获得锁，进而继续执行</li>
</ul>
<p><strong>注意</strong>：wait方法需要释放锁，前提条件是它已经持有锁。所以wait和notify（或者notifyAll）方法都必须被包裹在synchronized语句块中，并且synchronized后锁的对象应该与调用wait方法的对象一样。否则抛出<strong>IllegalMonitorStateException</strong></p>
<p>sleep方法告诉操作系统至少指定时间内不需为线程调度器为该线程分配执行时间片，并不释放锁（如果当前已经持有锁）。实际上，调用sleep方法时并不要求持有任何锁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sleep</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Thread thread1 = <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      <span class="keyword">synchronized</span> (Sleep.class) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread1 is running"</span>);</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread1 ended"</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">    thread1.start();</div><div class="line">    </div><div class="line">    Thread thread2 = <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      <span class="keyword">synchronized</span> (Sleep.class) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread2 is running"</span>);</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">" Thread2 ended"</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      <span class="keyword">for</span>(<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">long</span> j = <span class="number">0</span>; j &lt; <span class="number">100000</span>; j++) &#123;&#125;</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">    </div><div class="line">    <span class="comment">// Don't use sleep method to avoid confusing</span></div><div class="line">    <span class="keyword">for</span>(<span class="keyword">long</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</div><div class="line">      <span class="keyword">for</span>(<span class="keyword">long</span> j = <span class="number">0</span>; j &lt; <span class="number">100000</span>; j++) &#123;&#125;</div><div class="line">    &#125;</div><div class="line">    thread2.start();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Thu Jun 16 19:46:06 CST 2016 Thread1 is running</div><div class="line">Thu Jun 16 19:46:08 CST 2016 Thread1 ended</div><div class="line">Thu Jun 16 19:46:13 CST 2016 Thread2 is running</div><div class="line">Thu Jun 16 19:46:15 CST 2016 Thread2 ended</div></pre></td></tr></table></figure></p>
<p>由于thread 1和thread 2的run方法实现都在同步块中，无论哪个线程先拿到锁，执行sleep时并不释放锁，因此其它线程无法执行。直到前面的线程sleep结束并退出同步块（释放锁），另一个线程才得到锁并执行。</p>
<p>注意：sleep方法并不需要持有任何形式的锁，也就不需要包裹在synchronized中。  </p>
<p>本文所有示例均基于<code>Java HotSpot(TM) 64-Bit Server VM</code>  </p>
<p>调用sleep方法的线程，在jstack中显示的状态为<code>sleeping</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java.lang.Thread.State: TIMED_WAITING (sleeping)</div></pre></td></tr></table></figure></p>
<p>调用wait方法的线程，在jstack中显示的状态为<code>on object monitor</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java.lang.Thread.State: WAITING (on object monitor)</div></pre></td></tr></table></figure></p>
<h1 id="synchronized几种用法"><a href="#synchronized几种用法" class="headerlink" title="synchronized几种用法"></a>synchronized几种用法</h1><p>每个Java对象都可以用做一个实现同步的互斥锁，这些锁被称为内置锁。线程进入同步代码块或方法时自动获得内置锁，退出同步代码块或方法时自动释放该内置锁。进入同步代码块或者同步方法是获得内置锁的唯一途径。</p>
<h2 id="实例同步方法"><a href="#实例同步方法" class="headerlink" title="实例同步方法"></a>实例同步方法</h2><p>synchronized用于修饰实例方法（非静态方法）时，执行该方法需要获得的是该类实例对象的内置锁（同一个类的不同实例拥有不同的内置锁）。如果多个实例方法都被synchronized修饰，则当多个线程调用同一实例的不同同步方法（或者同一方法）时，需要竞争锁。但当调用的是不同实例的方法时，并不需要竞争锁。</p>
<h2 id="静态同步方法"><a href="#静态同步方法" class="headerlink" title="静态同步方法"></a>静态同步方法</h2><p>synchronized用于修饰静态方法时，执行该方法需要获得的是该类的class对象的内置锁（一个类只有唯一一个class对象）。调用同一个类的不同静态同步方法时会产生锁竞争。</p>
<h2 id="同步代码块"><a href="#同步代码块" class="headerlink" title="同步代码块"></a>同步代码块</h2><p>synchronized用于修饰代码块时，进入同步代码块需要获得synchronized关键字后面括号内的对象（可以是实例对象也可以是class对象）的内置锁。</p>
<h2 id="synchronized使用总结"><a href="#synchronized使用总结" class="headerlink" title="synchronized使用总结"></a>synchronized使用总结</h2><p>锁的使用是为了操作临界资源的正确性，而往往一个方法中并非所有的代码都操作临界资源。换句话说，方法中的代码往往并不都需要同步。此时建议不使用同步方法，而使用同步代码块，只对操作临界资源的代码，也即需要同步的代码加锁。这样做的好处是，当一个线程在执行同步代码块时，其它线程仍然可以执行该方法内同步代码块以外的部分，充分发挥多线程并发的优势，从而相较于同步整个方法而言提升性能。</p>
<p>释放Java内置锁的唯一方式是synchronized方法或者代码块执行结束。若某一线程在synchronized方法或代码块内发生死锁，则对应的内置锁无法释放，其它线程也无法获取该内置锁（即进入跟该内置锁相关的synchronized方法或者代码块）。</p>
<p>使用jstack dump线程栈时，可查看到相关线程通过synchronized获取到或等待的对象，但<code>Locked ownable synchronizers</code>仍然显示为<code>None</code>。下例中，线程<code>thead-test-b</code>已获取到类型为<code>java.lang.Double</code>的对象的内置锁（monitor），且该对象的内存地址为<code>0x000000076ab95cb8</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&quot;thread-test-b&quot; #11 prio=5 os_prio=31 tid=0x00007fab0190b800 nid=0x5903 runnable [0x0000700010249000]</div><div class="line">   java.lang.Thread.State: RUNNABLE</div><div class="line">        at com.jasongj.demo.TestJstack.lambda$1(TestJstack.java:27)</div><div class="line">        - locked &lt;0x000000076ab95cb8&gt; (a java.lang.Double)</div><div class="line">        at com.jasongj.demo.TestJstack$$Lambda$2/1406718218.run(Unknown Source)</div><div class="line">        at java.lang.Thread.run(Thread.java:745)</div><div class="line"></div><div class="line">   Locked ownable synchronizers:</div><div class="line">        - None</div></pre></td></tr></table></figure></p>
<h1 id="Java中的锁"><a href="#Java中的锁" class="headerlink" title="Java中的锁"></a>Java中的锁</h1><h2 id="重入锁"><a href="#重入锁" class="headerlink" title="重入锁"></a>重入锁</h2><p>Java中的重入锁（即ReentrantLock）与Java内置锁一样，是一种排它锁。使用synchronized的地方一定可以用ReentrantLock代替。</p>
<p>重入锁需要显示请求获取锁，并显示释放锁。为了避免获得锁后，没有释放锁，而造成其它线程无法获得锁而造成死锁，一般建议将释放锁操作放在finally块里，如下所示。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span>&#123;</div><div class="line">  renentrantLock.lock();</div><div class="line">  <span class="comment">// 用户操作</span></div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">  renentrantLock.unlock();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果重入锁已经被其它线程持有，则当前线程的lock操作会被阻塞。除了<strong><em>lock()</em></strong>方法之外，重入锁（或者说锁接口）还提供了其它获取锁的方法以实现不同的效果。</p>
<ul>
<li><strong><em>lockInterruptibly()</em></strong> 该方法尝试获取锁，若获取成功立即返回；若获取不成功则阻塞等待。与lock方法不同的是，在阻塞期间，如果当前线程被打断（interrupt）则该方法抛出<em>InterruptedException</em>。该方法提供了一种解除死锁的途径。</li>
<li><strong><em>tryLock()</em></strong> 该方法试图获取锁，若该锁当前可用，则该方法立即获得锁并立即返回true；若锁当前不可用，则立即返回false。该方法不会阻塞，并提供给用户对于成功获利锁与获取锁失败进行不同操作的可能性。</li>
<li><strong><em>tryLock(long time, TimeUnit unit)</em></strong> 该方法试图获得锁，若该锁当前可用，则立即获得锁并立即返回true。若锁当前不可用，则等待相应的时间（由该方法的两个参数决定）：1）若该时间内锁可用，则获得锁，并返回true；2）若等待期间当前线程被打断，则抛出<em>InterruptedException</em>；3）若等待时间结束仍未获得锁，则返回false。</li>
</ul>
<p>重入锁可定义为公平锁或非公平锁，默认实现为非公平锁。</p>
<ul>
<li>公平锁是指多个线程获取锁被阻塞的情况下，锁变为可用时，最新申请锁的线程获得锁。可通过在重入锁（RenentrantLock）的构造方法中传入true构建公平锁，如<em>Lock lock = new RenentrantLock(true)</em></li>
<li>非公平锁是指多个线程等待锁的情况下，锁变为可用状态时，哪个线程获得锁是随机的。synchonized相当于非公平锁。可通过在重入锁的构造方法中传入false或者使用无参构造方法构建非公平锁。</li>
</ul>
<p>使用jstack dump线程栈时，可查看到获取到或正在等待的锁对象，获取到该锁的线程会在<code>Locked ownable synchronizers</code>处显示该锁的对象类型及内存地址。在下例中，从<code>Locked ownable synchronizers</code>部分可看到，线程<code>thread-test-e</code>获取到公平重入锁，且该锁对象的内存地址为<code>0x000000076ae3d708</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&quot;thread-test-e&quot; #17 prio=5 os_prio=31 tid=0x00007fefaa0b6800 nid=0x6403 runnable [0x0000700002939000]</div><div class="line">   java.lang.Thread.State: RUNNABLE</div><div class="line">        at com.jasongj.demo.TestJstack.lambda$4(TestJstack.java:64)</div><div class="line">        at com.jasongj.demo.TestJstack$$Lambda$5/466002798.run(Unknown Source)</div><div class="line">        at java.lang.Thread.run(Thread.java:745)</div><div class="line"></div><div class="line">   Locked ownable synchronizers:</div><div class="line">        - &lt;0x000000076af86810&gt; (a java.util.concurrent.locks.ReentrantLock$FairSync)</div></pre></td></tr></table></figure></p>
<p>而线程<code>thread-test-f</code>由于未获取到锁，而处于<code>WAITING(parking)</code>状态，且它等待的锁正是上文线程<code>thread-test-e</code>获取的锁（内存地址<code>0x000000076af86810</code>）<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">"thread-test-f" #18 prio=5 os_prio=31 tid=0x00007fefaa9b2800 nid=0x6603 waiting on condition [0x0000700002a3c000]</div><div class="line">   java.lang.Thread.State: WAITING (parking)</div><div class="line">        at sun.misc.Unsafe.park(Native Method)</div><div class="line">        - parking to wait for  &lt;0x000000076af86810&gt; (a java.util.concurrent.locks.ReentrantLock$FairSync)</div><div class="line">        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)</div><div class="line">        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)</div><div class="line">        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)</div><div class="line">        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)</div><div class="line">        at java.util.concurrent.locks.ReentrantLock$FairSync.lock(ReentrantLock.java:224)</div><div class="line">        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285)</div><div class="line">        at com.jasongj.demo.TestJstack.lambda$5(TestJstack.java:69)</div><div class="line">        at com.jasongj.demo.TestJstack$$Lambda$6/33524623.run(Unknown Source)</div><div class="line">        at java.lang.Thread.run(Thread.java:745)</div><div class="line">   Locked ownable synchronizers:</div><div class="line">        - None</div></pre></td></tr></table></figure></p>
<h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>如上文《<a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a>》所述，锁可以保证原子性和可见性。而原子性更多是针对写操作而言。对于读多写少的场景，一个读操作无须阻塞其它读操作，只需要保证读和写或者写与写不同时发生即可。此时，如果使用重入锁（即排它锁），对性能影响较大。Java中的读写锁（ReadWriteLock）就是为这种读多写少的场景而创造的。</p>
<p>实际上，ReadWriteLock接口并非继承自Lock接口，ReentrantReadWriteLock也只实现了ReadWriteLock接口而未实现Lock接口。ReadLock和WriteLock，是ReentrantReadWriteLock类的静态内部类，它们实现了Lock接口。</p>
<p>一个<strong>ReentrantReadWriteLock</strong>实例包含一个<strong>ReentrantReadWriteLock.ReadLock</strong>实例和一个<strong>ReentrantReadWriteLock.WriteLock</strong>实例。通过<em>readLock()</em>和<em>writeLock()</em>方法可分别获得读锁实例和写锁实例，并通过Lock接口提供的获取锁方法获得对应的锁。</p>
<p>读写锁的锁定规则如下：</p>
<ul>
<li>获得读锁后，其它线程可获得读锁而不能获取写锁</li>
<li>获得写锁后，其它线程既不能获得读锁也不能获得写锁</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.Lock;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReadWriteLock;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantReadWriteLock;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReadWriteLockDemo</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ReadWriteLock readWriteLock = <span class="keyword">new</span> ReentrantReadWriteLock();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      readWriteLock.readLock().lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 started with read lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        readWriteLock.readLock().unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      readWriteLock.readLock().lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 started with read lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        readWriteLock.readLock().unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line"></div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      Lock lock = readWriteLock.writeLock();</div><div class="line">      lock.lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 3 started with write lock"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">2000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 3 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        lock.unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Sat Jun 18 21:33:46 CST 2016  Thread 1 started with read lock</div><div class="line">Sat Jun 18 21:33:46 CST 2016  Thread 2 started with read lock</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 2 ended</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 1 ended</div><div class="line">Sat Jun 18 21:33:48 CST 2016  Thread 3 started with write lock</div><div class="line">Sat Jun 18 21:33:50 CST 2016  Thread 3 ended</div></pre></td></tr></table></figure></p>
<p>从上面的执行结果可见，thread 1和thread 2都只需获得读锁，因此它们可以并行执行。而thread 3因为需要获取写锁，必须等到thread 1和thread 2释放锁后才能获得锁。</p>
<h1 id="条件锁"><a href="#条件锁" class="headerlink" title="条件锁"></a>条件锁</h1><p>条件锁只是一个帮助用户理解的概念，实际上并没有条件锁这种锁。对于每个重入锁，都可以通过<em>newCondition()</em>方法绑定若干个条件对象。</p>
<p>条件对象提供以下方法以实现不同的等待语义</p>
<ul>
<li><strong><em>await()</em></strong> 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出<strong>IllegalMonitorStateException</strong>。调用该方法外，当前线程会释放当前已经获得的锁（这一点与上文讲述的Java内置锁的wait方法一致），并且等待其它线程调用该条件对象的<em>signal()</em>或者<em>signalAll()</em>方法（这一点与Java内置锁wait后等待<em>notify()</em>或<em>notifyAll()</em>很像）。或者在等待期间，当前线程被打断，则<em>wait()</em>方法会抛出<strong>InterruptedException</strong>并清除当前线程的打断状态。</li>
<li><strong><em>await(long time, TimeUnit unit)</em></strong> 适用条件和行为与<em>await()</em>基本一致，唯一不同点在于，指定时间之内没有收到<em>signal()</em>或<em>signalALL()</em>信号或者线程中断时该方法会返回false;其它情况返回true。</li>
<li><strong><em>awaitNanos(long nanosTimeout)</em></strong> 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出<strong>IllegalMonitorStateException</strong>。<strong>nanosTimeout</strong>指定该方法等待信号的的最大时间（单位为纳秒）。若指定时间内收到<em>signal()</em>或<em>signalALL()</em>则返回<strong>nanosTimeout</strong>减去已经等待的时间；若指定时间内有其它线程中断该线程，则抛出<strong>InterruptedException</strong>并清除当前线程的打断状态；若指定时间内未收到通知，则返回0或负数。</li>
<li><strong><em>awaitUninterruptibly()</em></strong> 调用该方法的前提是，当前线程已经成功获得与该条件对象绑定的重入锁，否则调用该方法时会抛出<strong>IllegalMonitorStateException</strong>。调用该方法后，结束等待的唯一方法是其它线程调用该条件对象的<em>signal()</em>或<em>signalALL()</em>方法。等待过程中如果当前线程被中断，该方法仍然会继续等待，同时保留该线程的中断状态。</li>
<li><strong><em>awaitUntil(Date deadline)</em></strong> 适用条件与行为与<strong><em>awaitNanos(long nanosTimeout)</em></strong>完全一样，唯一不同点在于它不是等待指定时间，而是等待由参数指定的某一时刻。</li>
</ul>
<p>调用条件等待的注意事项</p>
<ul>
<li>调用上述任意条件等待方法的前提都是当前线程已经获得与该条件对象对应的重入锁。</li>
<li>调用条件等待后，当前线程让出CPU资源。</li>
<li>上述等待方法结束后，方法返回的前提是它能重新获得与该条件对象对应的重入锁。如果无法获得锁，仍然会继续等待。这也是<strong><em>awaitNanos(long nanosTimeout)</em></strong>可能会返回负值的原因。</li>
<li>一旦条件等待方法返回，则当前线程肯定已经获得了对应的重入锁。</li>
<li>重入锁可以创建若干个条件对象，<em>signal()</em>和<em>signalAll()</em>方法只能唤醒相同条件对象的等待。</li>
<li>一个重入锁上可以生成多个条件变量，不同线程可以等待不同的条件，从而实现更加细粒度的的线程间通信。</li>
</ul>
<p><em>signal()</em>与<em>signalAll()</em></p>
<ul>
<li><strong><em>signal()</em></strong> 若有一个或若干个线程在等待该条件变量，则该方法会唤醒其中的一个（具体哪一个，无法预测）。调用该方法的前提是当前线程持有该条件变量对应的锁，否则抛出<strong>IllegalMonitorStateException</strong>。</li>
<li><strong><em>signalALL()</em></strong> 若有一个或若干个线程在等待该条件变量，则该方法会唤醒所有等待。调用该方法的前提是当前线程持有该条件变量对应的锁，否则抛出<strong>IllegalMonitorStateException</strong>。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.test.thread;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Date;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.Condition;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.Lock;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConditionTest</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">    Lock lock = <span class="keyword">new</span> ReentrantLock();</div><div class="line">    Condition condition = lock.newCondition();</div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      lock.lock();</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 is waiting"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="keyword">long</span> waitTime = condition.awaitNanos(TimeUnit.SECONDS.toNanos(<span class="number">2</span>));</div><div class="line">          System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 remaining time "</span> + waitTime);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 1 is waken up"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        lock.unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line">    </div><div class="line">    <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">      lock.lock();</div><div class="line">      <span class="keyword">try</span>&#123;</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 is running"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          Thread.sleep(<span class="number">4000</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</div><div class="line">          ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        condition.signal();</div><div class="line">        System.out.println(<span class="keyword">new</span> Date() + <span class="string">"\tThread 2 ended"</span>);</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        lock.unlock();</div><div class="line">      &#125;</div><div class="line">    &#125;).start();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Sun Jun 19 15:59:09 CST 2016  Thread 1 is waiting</div><div class="line">Sun Jun 19 15:59:09 CST 2016  Thread 2 is running</div><div class="line">Sun Jun 19 15:59:13 CST 2016  Thread 2 ended</div><div class="line">Sun Jun 19 15:59:13 CST 2016  Thread 1 remaining time -2003467560</div><div class="line">Sun Jun 19 15:59:13 CST 2016  Thread 1 is waken up</div></pre></td></tr></table></figure></p>
<p>从执行结果可以看出，虽然thread 2一开始就调用了<em>signal()</em>方法去唤醒thread 1，但是因为thread 2在4秒钟后才释放锁，也即thread 1在4秒后才获得锁，所以thread 1的await方法在4秒钟后才返回，并且返回负值。</p>
<h1 id="信号量Semaphore"><a href="#信号量Semaphore" class="headerlink" title="信号量Semaphore"></a>信号量Semaphore</h1><p>信号量维护一个许可集，可通过<em>acquire()</em>获取许可（若无可用许可则阻塞），通过<em>release()</em>释放许可，从而可能唤醒一个阻塞等待许可的线程。</p>
<p>与互斥锁类似，信号量限制了同一时间访问临界资源的线程的个数，并且信号量也分公平信号量与非公平信号量。而不同的是，互斥锁保证同一时间只会有一个线程访问临界资源，而信号量可以允许同一时间多个线程访问特定资源。所以信号量并不能保证原子性。</p>
<p>信号量的一个典型使用场景是限制系统访问量。每个请求进来后，处理之前都通过acquire获取许可，若获取许可成功则处理该请求，若获取失败则等待处理或者直接不处理该请求。</p>
<p>信号量的使用方法</p>
<ul>
<li><strong><em>acquire(int permits)</em></strong> 申请<strong>permits</strong>（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前可用许可数少于permits指定的个数，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，则抛出<strong>InterruptedException</strong>。</li>
<li><strong><em>acquire()</em></strong> 等价于<em>acquire(1)</em>。</li>
<li><strong><em>acquireUninterruptibly(int permits)</em></strong> 申请<strong>permits</strong>（必须为非负数）个许可，若获取成功，则该方法返回并且当前可用许可数减permits；若当前许可数少于permits，则继续等待可用许可数大于等于permits；若等待过程中当前线程被中断，继续等待可用许可数大于等于permits，并且获取成功后设置线程中断状态。</li>
<li><strong><em>acquireUninterruptibly()</em></strong> 等价于<em>acquireUninterruptibly(1)</em>。</li>
<li><strong><em>drainPermits()</em></strong> 获取所有可用许可，并返回获取到的许可个数，该方法不阻塞。</li>
<li><strong><em>tryAcquire(int permits)</em></strong> 尝试获取permits个可用许可，如果当前许可个数大于等于permits，则返回true并且可用许可数减permits；否则返回false并且可用许可数不变。</li>
<li><strong><em>tryAcquire()</em></strong> 等价于<em>tryAcquire(1)</em>。</li>
<li><strong><em>tryAcquire(int permits, long timeout, TimeUnit unit)</em></strong> 尝试获取permits（必须为非负数）个许可，若在指定时间内获取成功则返回true并且可用许可数减permits；若指定时间内当前线程被中断，则抛出<strong>InterruptedException</strong>；若指定时间内可用许可数均小于permits，则返回false。</li>
<li><strong><em>tryAcquire(long timeout, TimeUnit unit)</em></strong> 等价于tryAcquire(1, long timeout, TimeUnit unit)*</li>
<li><strong><em>release(int permits)</em></strong> 释放permits个许可，该方法不阻塞并且某线程调用release方法前并不需要先调用acquire方法。</li>
<li><strong><em>release()</em></strong> 等价于<em>release(1)</em>。</li>
</ul>
<p>注意：与wait/notify和await/signal不同，acquire/release完全与锁无关，因此acquire等待过程中，可用许可满足要求时acquire可立即返回，而不用像锁的wait和条件变量的await那样重新获取锁才能返回。或者可以理解成，只要可用许可满足需求，就已经获得了锁。</p>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文将介绍Java多线程开发必不可少的锁和同步机制，同时介绍sleep和wait等常用的暂停线程执行的方法，并详述synchronized的几种使用方式，以及Java中的重入锁（ReentrantLock）和读写锁（ReadWriteLock），之后结合实例分析了重入锁条件变量（Condition）的使用技巧，最后介绍了信号量（Semaphore）的适用场景和使用技巧。
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（二）当我们说线程安全时，到底在说什么</title>
    <link href="http://www.jasongj.com/java/thread_safe/"/>
    <id>http://www.jasongj.com/java/thread_safe/</id>
    <published>2016-06-12T23:11:29.000Z</published>
    <updated>2017-02-15T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/java/thread_safe/">原文链接</a>　<a href="http://www.jasongj.com/java/thread_safe/">http://www.jasongj.com/java/thread_safe/</a></p>
</blockquote>
<h1 id="多线程编程中的三个核心概念"><a href="#多线程编程中的三个核心概念" class="headerlink" title="多线程编程中的三个核心概念"></a>多线程编程中的三个核心概念</h1><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。</p>
<p>关于原子性，一个非常经典的例子就是银行转账问题：比如A和B同时向C转账10万元。如果转账操作不具有原子性，A在向C转账时，读取了C的余额为20万，然后加上转账的10万，计算出此时应该有30万，但还未来及将30万写回C的账户，此时B的转账请求过来了，B发现C的余额为20万，然后将其加10万并写回。然后A的转账操作继续——将30万写回C的余额。这种情况下C的最终余额为30万，而非预期的40万。</p>
<h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。</p>
<p>CPU从主内存中读数据的效率相对来说不高，现在主流的计算机中，都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存（实际上写回主内存的时间不可预期）。此时其它线程（尤其是不在同一个CPU上执行的线程）访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。</p>
<p>这一点是操作系统或者说是硬件层面的机制，所以很多应用开发人员经常会忽略。</p>
<h2 id="顺序性"><a href="#顺序性" class="headerlink" title="顺序性"></a>顺序性</h2><p>顺序性指的是，程序执行的顺序按照代码的先后顺序执行。</p>
<p>以下面这段代码为例<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> started = <span class="keyword">false</span>; <span class="comment">// 语句1</span></div><div class="line"><span class="keyword">long</span> counter = <span class="number">0L</span>; <span class="comment">// 语句2</span></div><div class="line">counter = <span class="number">1</span>; <span class="comment">// 语句3</span></div><div class="line">started = <span class="keyword">true</span>; <span class="comment">// 语句4</span></div></pre></td></tr></table></figure></p>
<p>从代码顺序上看，上面四条语句应该依次执行，但实际上JVM真正在执行这段代码时，并不保证它们一定完全按照此顺序执行。</p>
<p>处理器为了提高程序整体的执行效率，可能会对代码进行优化，其中的一项优化方式就是调整代码顺序，按照更高效的顺序执行代码。</p>
<p>讲到这里，有人要着急了——什么，CPU不按照我的代码顺序执行代码，那怎么保证得到我们想要的效果呢？实际上，大家大可放心，CPU虽然并不保证完全按照代码顺序执行，但它会保证程序最终的执行结果和代码顺序执行时的结果一致。</p>
<h1 id="Java如何解决多线程并发问题"><a href="#Java如何解决多线程并发问题" class="headerlink" title="Java如何解决多线程并发问题"></a>Java如何解决多线程并发问题</h1><h2 id="Java如何保证原子性"><a href="#Java如何保证原子性" class="headerlink" title="Java如何保证原子性"></a>Java如何保证原子性</h2><h3 id="锁和同步"><a href="#锁和同步" class="headerlink" title="锁和同步"></a>锁和同步</h3><p>常用的保证Java操作原子性的工具是锁和同步方法（或者同步代码块）。使用锁，可以保证同一时间只有一个线程能拿到锁，也就保证了同一时间只有一个线程能执行申请锁和释放锁之间的代码。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span> <span class="params">()</span> </span>&#123;</div><div class="line">  lock.lock();</div><div class="line">  <span class="keyword">try</span>&#123;</div><div class="line">    <span class="keyword">int</span> j = i;</div><div class="line">    i = j + <span class="number">1</span>;</div><div class="line">  &#125; <span class="keyword">finally</span> &#123;</div><div class="line">    lock.unlock();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>与锁类似的是同步方法或者同步代码块。使用非静态同步方法时，锁住的是当前实例；使用静态同步方法时，锁住的是该类的Class对象；使用静态代码块时，锁住的是<code>synchronized</code>关键字后面括号内的对象。下面是同步代码块示例<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span> <span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">synchronized</span> (anyObject)&#123;</div><div class="line">    <span class="keyword">int</span> j = i;</div><div class="line">    i = j + <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。</p>
<h3 id="CAS（compare-and-swap）"><a href="#CAS（compare-and-swap）" class="headerlink" title="CAS（compare and swap）"></a>CAS（compare and swap）</h3><p>基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。AtomicInteger使用方法如下。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> b = <span class="number">0</span>; b &lt; numThreads; b++) &#123;</div><div class="line">  <span class="keyword">new</span> Thread(() -&gt; &#123;</div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> a = <span class="number">0</span>; a &lt; iteration; a++) &#123;</div><div class="line">      atomicInteger.incrementAndGet();</div><div class="line">    &#125;</div><div class="line">  &#125;).start();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Java如何保证可见性"><a href="#Java如何保证可见性" class="headerlink" title="Java如何保证可见性"></a>Java如何保证可见性</h2><p>Java提供了<code>volatile</code>关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。</p>
<h2 id="Java如何保证顺序性"><a href="#Java如何保证顺序性" class="headerlink" title="Java如何保证顺序性"></a>Java如何保证顺序性</h2><p>上文讲过编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。</p>
<p>Java中可通过<code>volatile</code>在一定程序上保证顺序性，另外还可以通过synchronized和锁来保证顺序性。</p>
<p>synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。</p>
<p>除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为happens-before原则隐式地保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。</p>
<h2 id="happens-before原则（先行发生原则）"><a href="#happens-before原则（先行发生原则）" class="headerlink" title="happens-before原则（先行发生原则）"></a>happens-before原则（先行发生原则）</h2><ul>
<li>传递规则：如果操作1在操作2前面，而操作2在操作3前面，则操作1肯定会在操作3前发生。该规则说明了happens-before原则具有传递性</li>
<li>锁定规则：一个unlock操作肯定会在后面对同一个锁的lock操作前发生。这个很好理解，锁只有被释放了才会被再次获取</li>
<li>volatile变量规则：对一个被volatile修饰的写操作先发生于后面对该变量的读操作</li>
<li>程序次序规则：一个线程内，按照代码顺序执行</li>
<li>线程启动规则：Thread对象的start()方法先发生于此线程的其它动作</li>
<li>线程终结原则：线程的终止检测后发生于线程中其它的所有操作</li>
<li>线程中断规则： 对线程interrupt()方法的调用先发生于对该中断异常的获取</li>
<li>对象终结规则：一个对象构造先于它的finalize发生</li>
</ul>
<h1 id="volatile适用场景"><a href="#volatile适用场景" class="headerlink" title="volatile适用场景"></a>volatile适用场景</h1><p>volatile适用于不需要保证原子性，但却需要保证可见性的场景。一种典型的使用场景是用它修饰用于停止线程的状态标记。如下所示<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> isRunning = <span class="keyword">false</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span> <span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">new</span> Thread( () -&gt; &#123;</div><div class="line">    <span class="keyword">while</span>(isRunning) &#123;</div><div class="line">      someOperation();</div><div class="line">    &#125;</div><div class="line">  &#125;).start();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span> <span class="params">()</span> </span>&#123;</div><div class="line">  isRunning = <span class="keyword">false</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在这种实现方式下，即使其它线程通过调用stop()方法将isRunning设置为false，循环也不一定会立即结束。可以通过volatile关键字，保证while循环及时得到isRunning最新的状态从而及时停止循环，结束线程。</p>
<h1 id="线程安全十万个为什么"><a href="#线程安全十万个为什么" class="headerlink" title="线程安全十万个为什么"></a>线程安全十万个为什么</h1><p>问：平时项目中使用锁和synchronized比较多，而很少使用volatile，难道就没有保证可见性？<br>答：锁和synchronized即可以保证原子性，也可以保证可见性。都是通过保证同一时间只有一个线程执行目标代码段来实现的。</p>
<p></p><p id="synchronized_visibility"><br>问：锁和synchronized为何能保证可见性？<br>答：根据<a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility" title="JDK 7的Java doc" target="_blank" rel="external nofollow">JDK 7的Java doc</a>中对<code>concurrent</code>包的说明，一个线程的写结果保证对另外线程的读操作可见，只要该写操作可以由<code>happen-before</code>原则推断出在读操作之前发生。<br></p><p></p>
<blockquote>
<p>The results of a write by one thread are guaranteed to be <strong>visible</strong> to a read by another thread only if the write operation happens-before the read operation. The synchronized and volatile constructs, as well as the Thread.start() and Thread.join() methods, can form happens-before relationships.</p>
</blockquote>
<p>问：既然锁和synchronized即可保证原子性也可保证可见性，为何还需要volatile？<br>答：synchronized和锁需要通过操作系统来仲裁谁获得锁，开销比较高，而volatile开销小很多。因此在只需要保证可见性的条件下，使用volatile的性能要比使用锁和synchronized高得多。</p>
<p>问：既然锁和synchronized可以保证原子性，为什么还需要AtomicInteger这种的类来保证原子操作？<br>答：锁和synchronized需要通过操作系统来仲裁谁获得锁，开销比较高，而AtomicInteger是通过CPU级的CAS操作来保证原子性，开销比较小。所以使用AtomicInteger的目的还是为了提高性能。</p>
<p>问：还有没有别的办法保证线程安全<br>答：有。尽可能避免引起非线程安全的条件——共享变量。如果能从设计上避免共享变量的使用，即可避免非线程安全的发生，也就无须通过锁或者synchronized以及volatile解决原子性、可见性和顺序性的问题。</p>
<p>问：synchronized即可修饰非静态方式，也可修饰静态方法，还可修饰代码块，有何区别<br>答：synchronized修饰非静态同步方法时，锁住的是当前实例；synchronized修饰静态同步方法时，锁住的是该类的Class对象；synchronized修饰静态代码块时，锁住的是<code>synchronized</code>关键字后面括号内的对象。</p>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      提到线程安全，可能大家的第一反应是要确保接口对共享变量的操作要具体原子性。实际上，在多线程编程中我们需要同时关注可见性、顺序性和原子性问题。本篇文章将从这三个问题出发，结合实例详解volatile如何保证可见性及一定程序上保证顺序性，同时例讲synchronized如何同时保证可见性和原子性，最后对比volatile和synchronized的适用场景。
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（六） MVCC PostgreSQL实现事务和多版本并发控制的精华</title>
    <link href="http://www.jasongj.com/sql/mvcc/"/>
    <id>http://www.jasongj.com/sql/mvcc/</id>
    <published>2016-06-05T23:09:04.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/sql/mvcc/">原文链接</a>　<a href="http://www.jasongj.com/sql/mvcc/">http://www.jasongj.com/sql/mvcc/</a></p>
</blockquote>
<h1 id="PostgreSQL针对ACID的实现机制"><a href="#PostgreSQL针对ACID的实现机制" class="headerlink" title="PostgreSQL针对ACID的实现机制"></a>PostgreSQL针对ACID的实现机制</h1><h2 id="数据库ACID"><a href="#数据库ACID" class="headerlink" title="数据库ACID"></a>数据库ACID</h2><p>数据库事务包含如下四个特性</p>
<ul>
<li><strong>原子性（Atomicity）</strong> 指一个事务要么全部执行，要么不执行。也即一个事务不可能只执行一半就停止（哪怕是因为意外也不行）。比如从取款机取钱，这个事务可以分成两个步骤：1)划卡；2)出钱。不可能划了卡，而钱却没出来。这两步必须同时完成，或者同时不完成。</li>
<li><strong>一致性（Consistency）</strong> 事务的运行不可改变数据库中数据的一致性，事务必须将数据库中的数据从一个正确的状态带到另一个正确的状态。事务在开始时，完全可以假定数据库中的数据是处于正确（一致）状态的，而不必作过多验证（从而提升效率），同时也必须保证事务结束时数据库数据处于正确（一致）状态。例如，完整性约束了a+b=10，一个事务改变了a，那么b也应该随之改变。</li>
<li><strong>隔离性（Isolation）</strong> 在并发数据操作时，不同的事务拥有各自的数据空间，其操作不会对对方产生干扰。隔离性允许事务行为独立或隔离于其它事务并发运行。</li>
<li>持久性（Durability）事务执行成功以后，该事务对数据库所作的更改是持久的保存在数据库之中，不会无缘无故的回滚。</li>
</ul>
<h2 id="ACID在PostgreSQL中的实现原理"><a href="#ACID在PostgreSQL中的实现原理" class="headerlink" title="ACID在PostgreSQL中的实现原理"></a>ACID在PostgreSQL中的实现原理</h2><p>事务的实现原理可以解读为RDBMS采取何种技术确保事务的ACID特性,PostgreSQL针对ACID的实现技术如下表所示。</p>
<table>
<thead>
<tr>
<th>ACID</th>
<th>实现技术</th>
</tr>
</thead>
<tbody>
<tr>
<td>原子性（Atomicity）</td>
<td>MVCC</td>
</tr>
<tr>
<td>一致性（Consistency）</td>
<td>约束（主键、外键等）</td>
</tr>
<tr>
<td>隔离性</td>
<td>MVCC</td>
</tr>
<tr>
<td>持久性</td>
<td>WAL</td>
</tr>
</tbody>
</table>
<p>从上表可以看到，PostgreSQL主要使用MVCC和WAL两项技术实现ACID特性。实际上，MVCC和WAL这两项技术都比较成熟，主流关系型数据库中都有相应的实现，但每个数据库中具体的实现方式往往存在较大的差异。本文将介绍PostgreSQL中的MVCC实现原理。</p>
<h1 id="PostgreSQL中的MVCC原理"><a href="#PostgreSQL中的MVCC原理" class="headerlink" title="PostgreSQL中的MVCC原理"></a>PostgreSQL中的MVCC原理</h1><h2 id="事务ID"><a href="#事务ID" class="headerlink" title="事务ID"></a>事务ID</h2><p>在PostgreSQL中，每个事务都有一个唯一的事务ID，被称为XID。注意：除了被BEGIN - COMMIT/ROLLBACK包裹的一组语句会被当作一个事务对待外，不显示指定BEGIN - COMMIT/ROLLBACK的单条语句也是一个事务。</p>
<p>数据库中的事务ID递增。可通过<code>txid_current()</code>函数获取当前事务的ID。</p>
<h2 id="隐藏多版本标记字段"><a href="#隐藏多版本标记字段" class="headerlink" title="隐藏多版本标记字段"></a>隐藏多版本标记字段</h2><p>PostgreSQL中，对于每一行数据（称为一个tuple），包含有4个隐藏字段。这四个字段是隐藏的，但可直接访问。</p>
<ul>
<li>xmin 在创建（insert）记录（tuple）时，记录此值为插入tuple的事务ID</li>
<li>xmax 默认值为0.在删除tuple时，记录此值</li>
<li>cmin和cmax 标识在同一个事务中多个语句命令的序列值，从0开始，用于同一个事务中实现版本可见性判断</li>
</ul>
<p>下面通过实验具体看看这些标记如何工作。在此之前，先创建测试表<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">test</span> </div><div class="line">(</div><div class="line">  <span class="keyword">id</span> <span class="built_in">INTEGER</span>,</div><div class="line">  <span class="keyword">value</span> <span class="built_in">TEXT</span></div><div class="line">);</div></pre></td></tr></table></figure></p>
<p>开启一个事务，查询当前事务ID（值为3277），并插入一条数据，xmin为3277，与当前事务ID相等。符合上文所述——插入tuple时记录xmin，记录未被删除时xmax为0<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">postgres=&gt; BEGIN;</div><div class="line">BEGIN</div><div class="line">postgres=&gt; SELECT TXID_CURRENT();</div><div class="line"> txid_current </div><div class="line">--------------</div><div class="line">         3277</div><div class="line">(1 row)</div><div class="line"></div><div class="line">postgres=&gt; INSERT INTO test VALUES(1, 'a');</div><div class="line">INSERT 0 1</div><div class="line">postgres=&gt; SELECT *, xmin, xmax, cmin, cmax FROM test;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line">----+-------+------+------+------+------</div><div class="line">  1 | a     | 3277 |    0 |    0 |    0</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<p>继续通过一条语句插入2条记录，xmin仍然为当前事务ID，即3277，xmax仍然为0，同时cmin和cmax为1，符合上文所述cmin/cmax在事务内随着所执行的语句递增。虽然此步骤插入了两条数据，但因为是在同一条语句中插入，故其cmin/cmax都为1，在上一条语句的基础上加一。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">VALUES</span>(<span class="number">2</span>, <span class="string">'b'</span>), (<span class="number">3</span>, <span class="string">'c'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">2</span></div><div class="line">postgres=&gt; <span class="keyword">SELECT</span> *, xmin, xmax, cmin, cmax <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line"><span class="comment">----+-------+------+------+------+------</span></div><div class="line">  1 | a     | 3277 |    0 |    0 |    0</div><div class="line">  2 | b     | 3277 |    0 |    1 |    1</div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">(3 rows)</div></pre></td></tr></table></figure></p>
<p>将id为1的记录的value字段更新为’d’，其xmin和xmax均未变，而cmin和cmax变为2，在上一条语句的基础之上增加一。此时提交事务。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">UPDATE test SET value = 'd' WHERE id = 1;</div><div class="line">UPDATE 1</div><div class="line">postgres=&gt; SELECT *, xmin, xmax, cmin, cmax FROM test;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line">----+-------+------+------+------+------</div><div class="line">  2 | b     | 3277 |    0 |    1 |    1</div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">  1 | d     | 3277 |    0 |    2 |    2</div><div class="line">(3 rows)</div><div class="line"></div><div class="line">postgres=&gt; COMMIT;</div><div class="line">COMMIT</div></pre></td></tr></table></figure></p>
<p>开启一个新事务，通过2条语句分别插入2条id为4和5的tuple。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">BEGIN</span>;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">postgres=&gt; <span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">VALUES</span> (<span class="number">4</span>, <span class="string">'x'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">1</span></div><div class="line">postgres=&gt; <span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">VALUES</span> (<span class="number">5</span>, <span class="string">'y'</span>); </div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">1</span></div><div class="line">postgres=&gt; <span class="keyword">SELECT</span> *, xmin, xmax, cmin, cmax <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line"><span class="comment">----+-------+------+------+------+------</span></div><div class="line">  2 | b     | 3277 |    0 |    1 |    1</div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">  1 | d     | 3277 |    0 |    2 |    2</div><div class="line">  4 | x     | 3278 |    0 |    0 |    0</div><div class="line">  5 | y     | 3278 |    0 |    1 |    1</div><div class="line">(5 rows)</div></pre></td></tr></table></figure></p>
<p>此时，将id为2的tuple的value更新为’e’，其对应的cmin/cmax被设置为2，且其xmin被设置为当前事务ID，即3278<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">UPDATE</span> <span class="keyword">test</span> <span class="keyword">SET</span> <span class="keyword">value</span> = <span class="string">'e'</span> <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">2</span>;</div><div class="line"><span class="keyword">UPDATE</span> <span class="number">1</span></div><div class="line">postgres=&gt; <span class="keyword">SELECT</span> *, xmin, xmax, cmin, cmax <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line"><span class="comment">----+-------+------+------+------+------</span></div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">  1 | d     | 3277 |    0 |    2 |    2</div><div class="line">  4 | x     | 3278 |    0 |    0 |    0</div><div class="line">  5 | y     | 3278 |    0 |    1 |    1</div><div class="line">  2 | e     | 3278 |    0 |    2 |    2</div></pre></td></tr></table></figure></p>
<p>在另外一个窗口中开启一个事务，可以发现id为2的tuple，xin仍然为3277，但其xmax被设置为3278，而cmin和cmax均为2。符合上文所述——若tuple被删除，则xmax被设置为删除tuple的事务的ID。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">BEGIN</span>;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">postgres=&gt; <span class="keyword">SELECT</span> *, xmin, xmax, cmin, cmax <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line"><span class="comment">----+-------+------+------+------+------</span></div><div class="line">  2 | b     | 3277 | 3278 |    2 |    2</div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">  1 | d     | 3277 |    0 |    2 |    2</div><div class="line">(3 rows)</div></pre></td></tr></table></figure></p>
<p>这里有几点要注意</p>
<ul>
<li>新旧窗口中id为2的tuple对应的value和xmin、xmax、cmin/cmax均不相同，实际上它们是该tuple的2个不同版本</li>
<li>在旧窗口中，更新之前，数据的顺序是2，3，1，4，5，更新后变为3，1，4，5，2。因为在PostgreSQL中更新实际上是将旧tuple标记为删除，并插入更新后的新数据，所以更新后id为2的tuple从原来最前面变成了最后面</li>
<li>在新窗口中，id为2的tuple仍然如旧窗口中更新之前一样，排在最前面。这是因为旧窗口中的事务未提交，更新对新窗口不可见，新窗口看到的仍然是旧版本的数据</li>
</ul>
<p>提交旧窗口中的事务后，新旧窗口中看到数据完全一致——id为2的tuple排在了最后，xmin变为3278，xmax为0，cmin/cmax为2。前文定义中，xmin是tuple创建时的事务ID，并没有提及更新的事务ID，但因为PostgreSQL的更新操作并非真正更新数据，而是将旧数据标记为删除，并插入新数据，所以“更新的事务ID”也就是“创建记录的事务ID”。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> <span class="keyword">SELECT</span> *, xmin, xmax, cmin, cmax <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line"> id | value | xmin | xmax | cmin | cmax </div><div class="line"><span class="comment">----+-------+------+------+------+------</span></div><div class="line">  3 | c     | 3277 |    0 |    1 |    1</div><div class="line">  1 | d     | 3277 |    0 |    2 |    2</div><div class="line">  4 | x     | 3278 |    0 |    0 |    0</div><div class="line">  5 | y     | 3278 |    0 |    1 |    1</div><div class="line">  2 | e     | 3278 |    0 |    2 |    2</div><div class="line">(5 rows)</div></pre></td></tr></table></figure></p>
<h2 id="MVCC保证原子性"><a href="#MVCC保证原子性" class="headerlink" title="MVCC保证原子性"></a>MVCC保证原子性</h2><p>原子性（Atomicity）指得是一个事务是一个不可分割的工作单位，事务中包括的所有操作要么都做，要么都不做。</p>
<p>对于插入操作，PostgreSQL会将当前事务ID存于xmin中。对于删除操作，其事务ID会存于xmax中。对于更新操作，PostgreSQL会将当前事务ID存于旧数据的xmax中，并存于新数据的xin中。换句话说，事务对增、删和改所操作的数据上都留有其事务ID，可以很方便的提交该批操作或者完全撤销操作，从而实现了事务的原子性。</p>
<h2 id="MVCC保证事物的隔离性"><a href="#MVCC保证事物的隔离性" class="headerlink" title="MVCC保证事物的隔离性"></a>MVCC保证事物的隔离性</h2><p>隔离性（Isolation）指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</p>
<p>标准SQL的事务隔离级别分为如下四个级别</p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>未提交读（read uncommitted）</td>
<td>可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>提交读（read committed）</td>
<td>不可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>可重复读（repeatable read）</td>
<td>不可能</td>
<td>不可能</td>
<td>可能</td>
</tr>
<tr>
<td>串行读（serializable）</td>
<td>不可能</td>
<td>不可能</td>
<td>不可能</td>
</tr>
</tbody>
</table>
<p>从上表中可以看出，从未提交读到串行读，要求越来越严格。</p>
<p>注意，SQL标准规定，具体数据库实现时，对于标准规定不允许发生的，绝不可发生；对于可能发生的，并不要求一定能发生。换句话说，具体数据库实现时，对应的隔离级别只可更严格，不可更宽松。</p>
<p>事实中，PostgreSQL实现了三种隔离级别——未提交读和提交读实际上都被实现为提交读。</p>
<p>下面将讨论提交读和可重复读的实现方式</p>
<h3 id="MVCC提交读"><a href="#MVCC提交读" class="headerlink" title="MVCC提交读"></a>MVCC提交读</h3><p>提交读只可读取其它已提交事务的结果。PostgreSQL中通过pg_clog来记录哪些事务已经被提交，哪些未被提交。具体实现方式将在下一篇文章《SQL优化（七） WAL PostgreSQL实现事务和高并发的重要技术》中讲述。</p>
<h3 id="MVCC可重复读"><a href="#MVCC可重复读" class="headerlink" title="MVCC可重复读"></a>MVCC可重复读</h3><p>相对于提交读，重复读要求在同一事务中，前后两次带条件查询所得到的结果集相同。实际中，PostgreSQL的实现更严格，不紧要求可重复读，还不允许出现幻读。它是通过只读取在当前事务开启之前已经提交的数据实现的。结合上文的四个隐藏系统字段来讲，PostgreSQL的可重复读是通过只读取xmin小于当前事务ID且已提交的事务的结果来实现的。</p>
<h1 id="PostgreSQL中的MVCC优势"><a href="#PostgreSQL中的MVCC优势" class="headerlink" title="PostgreSQL中的MVCC优势"></a>PostgreSQL中的MVCC优势</h1><ul>
<li>使用MVCC，读操作不会阻塞写，写操作也不会阻塞读，提高了并发访问下的性能</li>
<li>事务的回滚可立即完成，无论事务进行了多少操作</li>
<li>数据可以进行大量更新，不像MySQL和Innodb引擎和Oracle那样需要保证回滚段不会被耗尽</li>
</ul>
<h1 id="PostgreSQL中的MVCC缺点"><a href="#PostgreSQL中的MVCC缺点" class="headerlink" title="PostgreSQL中的MVCC缺点"></a>PostgreSQL中的MVCC缺点</h1><h2 id="事务ID个数有限制"><a href="#事务ID个数有限制" class="headerlink" title="事务ID个数有限制"></a>事务ID个数有限制</h2><p>事务ID由32位数保存，而事务ID递增，当事务ID用完时，会出现wraparound问题。</p>
<p>PostgreSQL通过VACUUM机制来解决该问题。对于事务ID，PostgreSQL有三个事务ID有特殊意义：</p>
<ul>
<li>0代表invalid事务号</li>
<li>1代表bootstrap事务号</li>
<li>2代表frozon事务。frozon transaction id比任何事务都要老</li>
</ul>
<p>可用的有效最小事务ID为3。VACUUM时将所有已提交的事务ID均设置为2，即frozon。之后所有的事务都比frozon事务新，因此VACUUM之前的所有已提交的数据都对之后的事务可见。PostgreSQL通过这种方式实现了事务ID的循环利用。</p>
<h2 id="大量过期数据占用磁盘并降低查询性能"><a href="#大量过期数据占用磁盘并降低查询性能" class="headerlink" title="大量过期数据占用磁盘并降低查询性能"></a>大量过期数据占用磁盘并降低查询性能</h2><p>由于上文提到的，PostgreSQL更新数据并非真正更改记录值，而是通过将旧数据标记为删除，再插入新的数据来实现。对于更新或删除频繁的表，会累积大量过期数据，占用大量磁盘，并且由于需要扫描更多数据，使得查询性能降低。</p>
<p>PostgreSQL解决该问题的方式也是VACUUM机制。从释放磁盘的角度，VACUUM分为两种</p>
<ul>
<li>VACUUM 该操作并不要求获得排它锁，因此它可以和其它的读写表操作并行进行。同时它只是简单的将dead tuple对应的磁盘空间标记为可用状态，新的数据可以重用这部分磁盘空间。但是这部分磁盘并不会被真正释放，也即不会被交还给操作系统，因此不能被系统中其它程序所使用，并且可能会产生磁盘碎片。</li>
<li>VACUUM FULL 需要获得排它锁，它通过“标记-复制”的方式将所有有效数据（非dead tuple）复制到新的磁盘文件中，并将原数据文件全部删除，并将未使用的磁盘空间还给操作系统，因此系统中其它进程可使用该空间，并且不会因此产生磁盘碎片。</li>
</ul>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a></li>
<li><a href="http://www.jasongj.com/sql/mvcc/">SQL优化（六） MVCC PostgreSQL实现事务和多版本并发控制的精华</a>
　　</li>
</ul>
]]></content>
    
    <summary type="html">
    
      数据库事务隔离性可通过锁机制或者MVCC实现，PostgreSQL默认使用MVCC。本文结合实例介绍了PostgreSQL的MVCC实现机制，并介绍了PostgreSQL如何通过MVCC保证事务的原子性和隔离性，最后介绍了PostgreSQL如何通过VACUUM机制克服MVCC带来的副作用。
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（十三） 别人再问你设计模式，叫他看这篇文章</title>
    <link href="http://www.jasongj.com/design_pattern/summary/"/>
    <id>http://www.jasongj.com/design_pattern/summary/</id>
    <published>2016-06-01T23:26:09.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/summary/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/summary/">http://www.jasongj.com/design_pattern/summary/</a></p>
</blockquote>
<h1 id="OOP三大基本特性"><a href="#OOP三大基本特性" class="headerlink" title="OOP三大基本特性"></a>OOP三大基本特性</h1><h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><p>封装，也就是把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类操作，对不可信的进行信息隐藏。</p>
<h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>继承是指这样一种能力，它可以使用现有的类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。</p>
<h2 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h2><p>多态指一个类实例的相同方法在不同情形有不同的表现形式。具体来说就是不同实现类对公共接口有不同的实现方式，但这些操作可以通过相同的方式（公共接口）予以调用。</p>
<h1 id="OOD七大原则"><a href="#OOD七大原则" class="headerlink" title="OOD七大原则"></a>OOD<strong><em>七</em></strong>大原则</h1><p>面向对象设计（OOD）有<strong><em>七</em></strong>大原则（是的，你没看错，是七大原则，不是六大原则），它们互相补充。</p>
<h2 id="开-闭原则"><a href="#开-闭原则" class="headerlink" title="开-闭原则"></a>开-闭原则</h2><p>Open-Close Principle（OCP），即开-闭原则。开，指的是对扩展开放，即要支持方便地扩展；闭，指的是对修改关闭，即要严格限制对已有内容的修改。开-闭原则是最抽象也是最重要的OOD原则。<a href="http://www.jasongj.com/design_pattern/simple_factory/">简单工厂模式</a>、<a href="http://www.jasongj.com/design_pattern/factory_method/">工厂方法模式</a>、<a href="http://www.jasongj.com/design_pattern/abstract_factory/">抽象工厂模式</a>中都提到了如何通过良好的设计遵循开-闭原则。</p>
<h2 id="里氏替换原则"><a href="#里氏替换原则" class="headerlink" title="里氏替换原则"></a>里氏替换原则</h2><p>Liskov Substitution Principle（LSP），即里氏替换原则。该原则规定“子类必须能够替换其父类，否则不应当设计为其子类”。换句话说，父类出现的地方，都应该能由其子类代替。所以，子类只能去扩展基类，而不是隐藏或者覆盖基类。</p>
<h2 id="依赖倒置原则"><a href="#依赖倒置原则" class="headerlink" title="依赖倒置原则"></a>依赖倒置原则</h2><p>Dependence Inversion Principle（DIP），依赖倒置原则。它讲的是“设计和实现要依赖于抽象而非具体”。一方面抽象化更符合人的思维习惯；另一方面，根据里氏替换原则，可以很容易将原来的抽象替换为扩展后的具体，这样可以很好的支持开-闭原则。</p>
<h2 id="接口隔离原则"><a href="#接口隔离原则" class="headerlink" title="接口隔离原则"></a>接口隔离原则</h2><p>Interface Segration Principle（ISP），接口隔离原则，“将大的接口打散成多个小的独立的接口”。由于Java类支持实现多个接口，可以很容易的让类具有多种接口的特征，同时每个类可以选择性地只实现目标接口。</p>
<h2 id="单一职责原则"><a href="#单一职责原则" class="headerlink" title="单一职责原则"></a>单一职责原则</h2><p>Single Responsibility Principle（SRP），单一职责原则。它讲的是，不要存在多于一个导致类变更的原因，是高内聚低耦合的一个体现。</p>
<h2 id="迪米特法则-最少知道原则"><a href="#迪米特法则-最少知道原则" class="headerlink" title="迪米特法则/最少知道原则"></a>迪米特法则/最少知道原则</h2><p>Law of Demeter or Least Knowledge Principle（LoD or LKP），迪米特法则或最少知道原则。它讲的是“一个对象就尽可能少的去了解其它对象”，从而实现松耦合。如果一个类的职责过多，由于多个职责耦合在了一起，任何一个职责的变更都可能引起其它职责的问题，严重影响了代码的可维护性和可重用性。</p>
<h2 id="合成-聚合复用原则"><a href="#合成-聚合复用原则" class="headerlink" title="合成/聚合复用原则"></a>合成/聚合复用原则</h2><p>Composite/Aggregate Reuse Principle（CARP / CRP），合成/聚合复用原则。如果新对象的某些功能在别的已经创建好的对象里面已经实现，那么应当尽量使用别的对象提供的功能，使之成为新对象的一部分，而不要再重新创建。新对象可通过向这些对象的委派达到复用已有功能的效果。简而言之，要尽量使用合成/聚合，而非使用继承。《<a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a>》中介绍的桥接模式即是对这一原则的典型应用。</p>
<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h2 id="什么是设计模式"><a href="#什么是设计模式" class="headerlink" title="什么是设计模式"></a>什么是设计模式</h2><p>可以用一句话概括设计模式———设计模式是一种利用OOP的封闭、继承和多态三大特性，同时在遵循单一职责原则、开闭原则、里氏替换原则、迪米特法则、依赖倒置原则、接口隔离原则及合成/聚合复用原则的前提下，被总结出来的经过反复实践并被多数人知晓且经过分类和设计的可重用的软件设计方式。</p>
<h2 id="设计模式十万个为什么"><a href="#设计模式十万个为什么" class="headerlink" title="设计模式十万个为什么"></a>设计模式十万个为什么</h2><h3 id="为什么要用设计模式"><a href="#为什么要用设计模式" class="headerlink" title="为什么要用设计模式"></a>为什么要用设计模式</h3><ul>
<li>设计模式是高级软件工程师和架构师面试基本必问的项目（先通过面试进入这个门槛我们再谈其它）</li>
<li>设计模式是经过大量实践检验的安全高效可复用的解决方案。不要重复发明轮子，而且大多数时候你发明的轮子还没有已有的好</li>
<li>设计模式是被主流工程师/架构师所广泛接受和使用的，你使用它，方便与别人沟通，也方便别人code review（这个够实在吧）</li>
<li>使用设计模式可以帮你快速解决80%的代码设计问题，从而让你更专注于业务本身</li>
<li>设计模式本身是对几大特性的利用和对几大设计原则的践行，代码量积累到一定程度，你会发现你已经或多或少的在使用某些设计模式了</li>
<li>架构师或者team leader教授初级工程师设计模式，可以很方便的以大家认可以方式提高初级工程师的代码设计水平，从而有利于提高团队工程实力</li>
</ul>
<h3 id="是不是一定要尽可能使用设计模式"><a href="#是不是一定要尽可能使用设计模式" class="headerlink" title="是不是一定要尽可能使用设计模式"></a>是不是一定要尽可能使用设计模式</h3><p>每个设计模式都有其适合范围，并解决特定问题。所以项目实践中应该针对特定使用场景选用合适的设计模式，如果某些场景下现在的设计模式都不能很完全的解决问题，那也不必拘泥于设计模式本身。实际上，学习和使用设计模式本身并不是目的，目的是通过学习和使用它，强化面向对象设计思路并用合适的方法解决工程问题。</p>
<h3 id="设计模式有时并非最优解"><a href="#设计模式有时并非最优解" class="headerlink" title="设计模式有时并非最优解"></a>设计模式有时并非最优解</h3><p>有些人认为，在某些特定场景下，设计模式并非最优方案，而自己的解决方案可能会更好。这个问题得分两个方面来讨论：一方面，如上文所述，所有设计模式都有其适用场景，“one size does not fit all”；另一方面，确实有可能自己设计的方案比设计模式更适合，但这并不影响你学习并使用设计模式，因为设计模式经过大量实战检验能在绝大多数情况下提供良好方案。</p>
<h3 id="设计模式太教条化"><a href="#设计模式太教条化" class="headerlink" title="设计模式太教条化"></a>设计模式太教条化</h3><p>设计模式虽然都有其相对固定的实现方式，但是它的精髓是利用OOP的三大特性，遵循OOD七大原则解决工程问题。所以学习设计模式的目的不是学习设计模式的固定实现方式本身，而是其思想。</p>
<h3 id="我有自己的一套思路，没必要引导团队成员学习设计模式"><a href="#我有自己的一套思路，没必要引导团队成员学习设计模式" class="headerlink" title="我有自己的一套思路，没必要引导团队成员学习设计模式"></a>我有自己的一套思路，没必要引导团队成员学习设计模式</h3><p>设计模式是被广泛接受和使用的，引导团队成员使用设计模式可以减少沟通成本，而更专注于业务本身。也许你有自己的一套思路，但是你怎么能保证团队成员一定认可你的思路，进而将你的思路贯彻实施呢？统一使用设计模式能让团队只使用20%的精力决解80%的问题。其它20%的问题，才是你需要花精力解决的。</p>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/summary/">Java设计模式（十三） 别人再问你设计模式，叫他看这篇文章</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文讲解了设计模式与OOP的三大特性及OOP七项原则间的关系，并讲解了使用设计模式的好处及为何需要使用设计模式。最后通过问答形式讲解了设计模式相关的常见问题
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（十二） 策略模式</title>
    <link href="http://www.jasongj.com/design_pattern/strategy/"/>
    <id>http://www.jasongj.com/design_pattern/strategy/</id>
    <published>2016-05-29T23:46:09.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/strategy/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/strategy/">http://www.jasongj.com/design_pattern/strategy/</a></p>
</blockquote>
<h1 id="策略模式介绍"><a href="#策略模式介绍" class="headerlink" title="策略模式介绍"></a>策略模式介绍</h1><h2 id="策略模式定义"><a href="#策略模式定义" class="headerlink" title="策略模式定义"></a>策略模式定义</h2><p>策略模式（Strategy Pattern），将各种算法封装到具体的类中，作为一个抽象策略类的子类，使得它们可以互换。客户端可以自行决定使用哪种算法。</p>
<h2 id="策略模式类图"><a href="#策略模式类图" class="headerlink" title="策略模式类图"></a>策略模式类图</h2><p>策略模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/strategy/Strategy.png" alt="Strategy Pattern Class Diagram"></p>
<h2 id="策略模式角色划分"><a href="#策略模式角色划分" class="headerlink" title="策略模式角色划分"></a>策略模式角色划分</h2><ul>
<li><strong><em>Strategy</em></strong> 策略接口或者（抽象策略类），定义策略执行接口</li>
<li><strong><em>ConcreteStrategy</em></strong> 具体策略类</li>
<li><strong><em>Context</em></strong> 上下文类，持有具体策略类的实例，并负责调用相关的算法</li>
</ul>
<h1 id="策略模式实例解析"><a href="#策略模式实例解析" class="headerlink" title="策略模式实例解析"></a>策略模式实例解析</h1><p>本文代码可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/StrategyPattern/src/main" target="_blank" rel="external">作者Github</a>下载</p>
<h2 id="典型策略模式实现"><a href="#典型策略模式实现" class="headerlink" title="典型策略模式实现"></a>典型策略模式实现</h2><p>策略接口，定义策略执行接口<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.strategy;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Strategy</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">strategy</span><span class="params">(String input)</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>具体策略类，实现策略接口，提供具体算法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.strategy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="meta">@com</span>.jasongj.annotation.Strategy(name=<span class="string">"StrategyA"</span>)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteStrategyA</span> <span class="keyword">implements</span> <span class="title">Strategy</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ConcreteStrategyB.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategy</span><span class="params">(String input)</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Strategy A for input : &#123;&#125;"</span>, input);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.strategy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="meta">@com</span>.jasongj.annotation.Strategy(name=<span class="string">"StrategyB"</span>)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteStrategyB</span> <span class="keyword">implements</span> <span class="title">Strategy</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ConcreteStrategyB.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">strategy</span><span class="params">(String input)</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Strategy B for input : &#123;&#125;"</span>, input);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Context类，持有具体策略类的实例，负责调用具体算法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.context;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.strategy.Strategy;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleContext</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> Strategy strategy;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SimpleContext</span><span class="params">(Strategy strategy)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.strategy = strategy;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">(String input)</span> </span>&#123;</div><div class="line">    strategy.strategy(input);</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>客户端可以实例化具体策略类，并传给Context类，通过Context统一调用具体算法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.context.SimpleContext;</div><div class="line"><span class="keyword">import</span> com.jasongj.strategy.ConcreteStrategyA;</div><div class="line"><span class="keyword">import</span> com.jasongj.strategy.Strategy;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Strategy strategy = <span class="keyword">new</span> ConcreteStrategyA();</div><div class="line">    SimpleContext context = <span class="keyword">new</span> SimpleContext(strategy);</div><div class="line">    context.action(<span class="string">"Hellow, world"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="使用Annotation和简单工厂模式增强策略模式"><a href="#使用Annotation和简单工厂模式增强策略模式" class="headerlink" title="使用Annotation和简单工厂模式增强策略模式"></a>使用Annotation和简单工厂模式增强策略模式</h2><p>上面的实现中，客户端需要显示决定具体使用何种策略，并且一旦需要换用其它策略，需要修改客户端的代码。解决这个问题，一个比较好的方式是使用简单工厂，使得客户端都不需要知道策略类的实例化过程，甚至都不需要具体哪种策略被使用。</p>
<p>如《<a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a>》所述，简单工厂的实现方式比较多，可以结合《<a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation">Java系列（一）Annotation（注解）</a>》中介绍的Annotation方法。</p>
<p>使用Annotation和简单工厂模式的Context类如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.context;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Collections;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"><span class="keyword">import</span> java.util.Set;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.ConfigurationException;</div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.XMLConfiguration;</div><div class="line"><span class="keyword">import</span> org.reflections.Reflections;</div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.strategy.Strategy;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleFactoryContext</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(SimpleFactoryContext.class);</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, Class&gt; allStrategies;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">    Reflections reflections = <span class="keyword">new</span> Reflections(<span class="string">"com.jasongj.strategy"</span>);</div><div class="line">    Set&lt;Class&lt;?&gt;&gt; annotatedClasses =</div><div class="line">        reflections.getTypesAnnotatedWith(com.jasongj.annotation.Strategy.class);</div><div class="line">    allStrategies = <span class="keyword">new</span> ConcurrentHashMap&lt;String, Class&gt;();</div><div class="line">    <span class="keyword">for</span> (Class&lt;?&gt; classObject : annotatedClasses) &#123;</div><div class="line">      com.jasongj.annotation.Strategy strategy = (com.jasongj.annotation.Strategy) classObject</div><div class="line">          .getAnnotation(com.jasongj.annotation.Strategy.class);</div><div class="line">      allStrategies.put(strategy.name(), classObject);</div><div class="line">    &#125;</div><div class="line">    allStrategies = Collections.unmodifiableMap(allStrategies);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> Strategy strategy;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SimpleFactoryContext</span><span class="params">()</span> </span>&#123;</div><div class="line">    String name = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      XMLConfiguration config = <span class="keyword">new</span> XMLConfiguration(<span class="string">"strategy.xml"</span>);</div><div class="line">      name = config.getString(<span class="string">"strategy.name"</span>);</div><div class="line">      LOG.info(<span class="string">"strategy name is &#123;&#125;"</span>, name);</div><div class="line">    &#125; <span class="keyword">catch</span> (ConfigurationException ex) &#123;</div><div class="line">      LOG.error(<span class="string">"Parsing xml configuration file failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (allStrategies.containsKey(name)) &#123;</div><div class="line">      LOG.info(<span class="string">"Created strategy name is &#123;&#125;"</span>, name);</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        strategy = (Strategy) allStrategies.get(name).newInstance();</div><div class="line">      &#125; <span class="keyword">catch</span> (InstantiationException | IllegalAccessException ex) &#123;</div><div class="line">        LOG.error(<span class="string">"Instantiate Strategy failed"</span>, ex);</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      LOG.error(<span class="string">"Specified Strategy name &#123;&#125; does not exist"</span>, name);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">(String input)</span> </span>&#123;</div><div class="line">    strategy.strategy(input);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面的实现可以看出，虽然并没有单独创建一个简单工厂类，但它已经融入了简单工厂模式的设计思想和实现方法。</p>
<p>客户端调用方式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.context.SimpleFactoryContext;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleFactoryClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    SimpleFactoryContext context = <span class="keyword">new</span> SimpleFactoryContext();</div><div class="line">    context.action(<span class="string">"Hellow, world"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面代码可以看出，引入简单工厂模式后，客户端不再需要直接实例化具体的策略类，也不需要判断应该使用何种策略，可以方便应对策略的切换。</p>
<h1 id="策略模式分析"><a href="#策略模式分析" class="headerlink" title="策略模式分析"></a>策略模式分析</h1><h2 id="策略模式优点"><a href="#策略模式优点" class="headerlink" title="策略模式优点"></a>策略模式优点</h2><ul>
<li>策略模式提供了对“开闭原则”的完美支持，用户可以在不修改原有系统的基础上选择算法（策略），并且可以灵活地增加新的算法（策略）。</li>
<li>策略模式通过Context类提供了管理具体策略类（算法族）的办法。</li>
<li>结合简单工厂模式和Annotation，策略模式可以方便的在不修改客户端代码的前提下切换算法（策略）。</li>
</ul>
<h2 id="策略模式缺点"><a href="#策略模式缺点" class="headerlink" title="策略模式缺点"></a>策略模式缺点</h2><ul>
<li>传统的策略模式实现方式中，客户端必须知道所有的具体策略类，并须自行显示决定使用哪一个策略类。但通过本文介绍的通过和Annotation和简单工厂模式结合，可以有效避免该问题</li>
<li>如果使用不当，策略模式可能创建很多具体策略类的实例，但可以通过使用上文《<a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a>》介绍的享元模式有效减少对象的数量。</li>
</ul>
<h1 id="策略模式已（未）遵循的OOP原则"><a href="#策略模式已（未）遵循的OOP原则" class="headerlink" title="策略模式已（未）遵循的OOP原则"></a>策略模式已（未）遵循的OOP原则</h1><h2 id="已遵循的OOP原则"><a href="#已遵循的OOP原则" class="headerlink" title="已遵循的OOP原则"></a>已遵循的OOP原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的OOP原则"><a href="#未遵循的OOP原则" class="headerlink" title="未遵循的OOP原则"></a>未遵循的OOP原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文结合实例详述了策略模式的实现方式，并介绍了如何结合简单工厂模式及Annotation优化策略模式。最后分析了策略模式的优缺点及已（未）遵循的OOP原则
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（十一） 享元模式</title>
    <link href="http://www.jasongj.com/design_pattern/flyweight/"/>
    <id>http://www.jasongj.com/design_pattern/flyweight/</id>
    <published>2016-05-22T23:34:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/flyweight/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/flyweight/">http://www.jasongj.com/design_pattern/flyweight/</a></p>
</blockquote>
<h1 id="享元模式介绍"><a href="#享元模式介绍" class="headerlink" title="享元模式介绍"></a>享元模式介绍</h1><h2 id="享元模式适用场景"><a href="#享元模式适用场景" class="headerlink" title="享元模式适用场景"></a>享元模式适用场景</h2><p>面向对象技术可以很好的解决一些灵活性或可扩展性问题，但在很多情况下需要在系统中增加类和对象的个数。当对象数量太多时，将导致对象创建及垃圾回收的代价过高，造成性能下降等问题。享元模式通过共享相同或者相似的细粒度对象解决了这一类问题。</p>
<h2 id="享元模式定义"><a href="#享元模式定义" class="headerlink" title="享元模式定义"></a>享元模式定义</h2><p>享元模式（Flyweight Pattern），又称轻量级模式（这也是其英文名为FlyWeight的原因），通过共享技术有效地实现了大量细粒度对象的复用。</p>
<h2 id="享元模式类图"><a href="#享元模式类图" class="headerlink" title="享元模式类图"></a>享元模式类图</h2><p>享元模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/flyweight/FlyWeight.png" alt="FlyWeight Pattern Class Diagram"></p>
<h2 id="享元模式角色划分"><a href="#享元模式角色划分" class="headerlink" title="享元模式角色划分"></a>享元模式角色划分</h2><ul>
<li><strong><em>FlyWeight</em></strong> 享元接口或者（抽象享元类），定义共享接口</li>
<li><strong><em>ConcreteFlyWeight</em></strong> 具体享元类，该类实例将实现共享</li>
<li><strong><em>UnSharedConcreteFlyWeight</em></strong> 非共享享元实现类</li>
<li><strong><em>FlyWeightFactory</em></strong> 享元工厂类，控制实例的创建和共享</li>
</ul>
<h2 id="内部状态-vs-外部状态"><a href="#内部状态-vs-外部状态" class="headerlink" title="内部状态 vs. 外部状态"></a>内部状态 vs. 外部状态</h2><ul>
<li><strong><em>内部状态</em></strong>是存储在享元对象内部，一般在构造时确定或通过setter设置，并且不会随环境改变而改变的状态，因此内部状态可以共享。</li>
<li><strong><em>外部状态</em></strong>是随环境改变而改变、不可以共享的状态。外部状态在需要使用时通过客户端传入享元对象。外部状态必须由客户端保存。</li>
</ul>
<h1 id="享元模式实例解析"><a href="#享元模式实例解析" class="headerlink" title="享元模式实例解析"></a>享元模式实例解析</h1><p>本文代码可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/FlyweightPattern/src/main" target="_blank" rel="external">作者Github</a>下载</p>
<p>享元接口，定义共享接口<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.flyweight;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">FlyWeight</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">action</span><span class="params">(String externalState)</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>具体享元类，实现享元接口。该类的对象将被复用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.flyweight;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteFlyWeight</span> <span class="keyword">implements</span> <span class="title">FlyWeight</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ConcreteFlyWeight.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> String name;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ConcreteFlyWeight</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.name = name;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">(String externalState)</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"name = &#123;&#125;, outerState = &#123;&#125;"</span>, <span class="keyword">this</span>.name, externalState);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>享元模式中，最关键的享元工厂。它将维护已创建的享元实例，并通过实例标记（一般用内部状态）去索引对应的实例。当目标对象未创建时，享元工厂负责创建实例并将其加入标记-对象映射。当目标对象已创建时，享元工厂直接返回已有实例，实现对象的复用。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.factory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.flyweight.ConcreteFlyWeight;</div><div class="line"><span class="keyword">import</span> com.jasongj.flyweight.FlyWeight;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlyWeightFactory</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(FlyWeightFactory.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> ConcurrentHashMap&lt;String, FlyWeight&gt; allFlyWeight = <span class="keyword">new</span> ConcurrentHashMap&lt;String, FlyWeight&gt;();</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FlyWeight <span class="title">getFlyWeight</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (allFlyWeight.get(name) == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">synchronized</span> (allFlyWeight) &#123;</div><div class="line">        <span class="keyword">if</span> (allFlyWeight.get(name) == <span class="keyword">null</span>) &#123;</div><div class="line">          LOG.info(<span class="string">"Instance of name = &#123;&#125; does not exist, creating it"</span>);</div><div class="line">          FlyWeight flyWeight = <span class="keyword">new</span> ConcreteFlyWeight(name);</div><div class="line">          LOG.info(<span class="string">"Instance of name = &#123;&#125; created"</span>);</div><div class="line">          allFlyWeight.put(name, flyWeight);</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> allFlyWeight.get(name);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面代码中可以看到，享元模式中对象的复用完全依靠享元工厂。同时本例中实现了对象创建的懒加载。并且为了保证线程安全及效率，本文使用了双重检查（Double Check）。</p>
<p>本例中，<code>name</code>可以认为是内部状态，在构造时确定。<code>externalState</code>属于外部状态，由客户端在调用时传入。</p>
<h1 id="享元模式分析"><a href="#享元模式分析" class="headerlink" title="享元模式分析"></a>享元模式分析</h1><h2 id="享元模式优点"><a href="#享元模式优点" class="headerlink" title="享元模式优点"></a>享元模式优点</h2><ul>
<li>享元模式的外部状态相对独立，使得对象可以在不同的环境中被复用（共享对象可以适应不同的外部环境）</li>
<li>享元模式可共享相同或相似的细粒度对象，从而减少了内存消耗，同时降低了对象创建与垃圾回收的开销</li>
</ul>
<h2 id="享元模式缺点"><a href="#享元模式缺点" class="headerlink" title="享元模式缺点"></a>享元模式缺点</h2><ul>
<li>外部状态由客户端保存，共享对象读取外部状态的开销可能比较大</li>
<li>享元模式要求将内部状态与外部状态分离，这使得程序的逻辑复杂化，同时也增加了状态维护成本</li>
</ul>
<h1 id="享元模式已（未）遵循的OOP原则"><a href="#享元模式已（未）遵循的OOP原则" class="headerlink" title="享元模式已（未）遵循的OOP原则"></a>享元模式已（未）遵循的OOP原则</h1><h2 id="已遵循的OOP原则"><a href="#已遵循的OOP原则" class="headerlink" title="已遵循的OOP原则"></a>已遵循的OOP原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的OOP原则"><a href="#未遵循的OOP原则" class="headerlink" title="未遵循的OOP原则"></a>未遵循的OOP原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了享元模式的适用场景，并结合实例详述了享元模式的实现方式。最后分析了享元模式的优缺点及已（未）遵循的OOP原则
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（十） 你真的用对单例模式了吗？</title>
    <link href="http://www.jasongj.com/design_pattern/singleton/"/>
    <id>http://www.jasongj.com/design_pattern/singleton/</id>
    <published>2016-05-15T23:34:46.000Z</published>
    <updated>2017-11-12T07:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/singleton/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/singleton/">http://www.jasongj.com/design_pattern/singleton/</a></p>
</blockquote>
<h1 id="为何需要单例模式"><a href="#为何需要单例模式" class="headerlink" title="为何需要单例模式"></a>为何需要单例模式</h1><p>对于系统中的某些类来说，只有一个实例很重要，例如，一个系统只能有一个窗口管理器或文件系统；一个系统只能有一个计时工具或ID（序号）生成器。</p>
<h1 id="单例模式设计要点"><a href="#单例模式设计要点" class="headerlink" title="单例模式设计要点"></a>单例模式设计要点</h1><ul>
<li>保证该类只有一个实例。将该类的构造方法定义为私有方法，这样其他处的代码就无法通过调用该类的构造方法来实例化该类的对象</li>
<li>提供一个该实例的访问点。一般由该类自己负责创建实例，并提供一个静态方法作为该实例的访问点</li>
</ul>
<h1 id="饿汉-vs-懒汉"><a href="#饿汉-vs-懒汉" class="headerlink" title="饿汉 vs. 懒汉"></a>饿汉 vs. 懒汉</h1><ul>
<li>饿汉 声明实例引用时即实例化</li>
<li>懒汉 静态方法第一次被调用前不实例化，也即懒加载。对于创建实例代价大，且不定会使用时，使用懒加载模式可以减少开销</li>
</ul>
<h1 id="实现单例模式的九种方法"><a href="#实现单例模式的九种方法" class="headerlink" title="实现单例模式的九种方法"></a>实现单例模式的九种方法</h1><h2 id="线程不安全的懒汉-多线程不可用"><a href="#线程不安全的懒汉-多线程不可用" class="headerlink" title="线程不安全的懒汉 - 多线程不可用"></a>线程不安全的懒汉 - 多线程不可用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton1;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton INSTANCE;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (INSTANCE == <span class="keyword">null</span>) &#123;</div><div class="line">      INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：达到了Lazy Loading的效果</li>
<li>缺点：只有在单线程下能保证只有一个实例，多线程下有创建多个实例的风险</li>
</ul>
<h2 id="同步方法下的懒汉-可用，不推荐"><a href="#同步方法下的懒汉-可用，不推荐" class="headerlink" title="同步方法下的懒汉 - 可用，不推荐"></a>同步方法下的懒汉 - 可用，不推荐</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton2;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton INSTANCE;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (INSTANCE == <span class="keyword">null</span>) &#123;</div><div class="line">      INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：线程安全，可确保正常使用下（不考虑通过反射调用私有构造方法）只有一个实例</li>
<li>缺点：每次获取实例都需要申请锁，开销大，效率低</li>
</ul>
<h2 id="同步代码块下的懒汉-不可用"><a href="#同步代码块下的懒汉-不可用" class="headerlink" title="同步代码块下的懒汉 - 不可用"></a>同步代码块下的懒汉 - 不可用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton3;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton INSTANCE;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (INSTANCE == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">synchronized</span> (Singleton.class) &#123;</div><div class="line">        INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：不需要在每次调用时加锁，效率比上一个高</li>
<li>缺点：虽然使用了<code>synchronized</code>，但本质上是线程不安全的。</li>
</ul>
<h2 id="双重检查（Double-Check）下的懒汉-推荐"><a href="#双重检查（Double-Check）下的懒汉-推荐" class="headerlink" title="双重检查（Double Check）下的懒汉 - 推荐"></a>双重检查（Double Check）下的懒汉 - 推荐</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton4;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> Singleton INSTANCE;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (INSTANCE == <span class="keyword">null</span>) &#123;</div><div class="line">      <span class="keyword">synchronized</span>(Singleton.class)&#123;</div><div class="line">        <span class="keyword">if</span>(INSTANCE == <span class="keyword">null</span>) &#123;</div><div class="line">          INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：使用了双重检查，避免了线程不安全，同时也避免了不必要的锁开销。</li>
<li>缺点：NA</li>
</ul>
<p>注：</p>
<ul>
<li>但是这里的<code>synchronized</code>已经保证了<code>INSTANCE</code>写操作对其它线程读操作的可见性。具体原理请参考《<a href="http://www.jasongj.com/java/thread_safe/#synchronized_visibility">Java进阶（二）当我们说线程安全时，到底在说什么</a>》</li>
<li>使用<code>volatile</code>关键字的目的不是保证可见性（<code>synchronized</code>已经保证了可见性），而是为了保证顺序性。具体来说，<code>INSTANCE = new Singleton()</code>不是原子操作，实际上被拆分为了三步：1) 分配内存；2) 初始化对象；3) 将INSTANCE指向分配的对象内存地址。 如果没有<code>volatile</code>，可能会发生指令重排，使得INSTANCE先指向内存地址，而对象尚未初始化，其它线程直接使用INSTANCE引用进行对象操作时出错。详细原理可参见《<a href="http://www.infoq.com/cn/articles/double-checked-locking-with-delay-initialization" target="_blank" title="双重检查锁定与延迟初始化" rel="external nofollow">双重检查锁定与延迟初始化</a>》</li>
</ul>
<h2 id="静态常量-饿汉-推荐"><a href="#静态常量-饿汉-推荐" class="headerlink" title="静态常量 饿汉 - 推荐"></a>静态常量 饿汉 - 推荐</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton6;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：实现简单，无线程同步问题</li>
<li>缺点：在类装载时完成实例化。若该实例一直未被使用，则会造成资源浪费</li>
</ul>
<h2 id="静态代码块-饿汉-可用"><a href="#静态代码块-饿汉-可用" class="headerlink" title="静态代码块 饿汉 可用"></a>静态代码块 饿汉 可用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton7;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Singleton INSTANCE;</div><div class="line">  </div><div class="line">  <span class="keyword">static</span>&#123;</div><div class="line">    INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：无线程同步问题</li>
<li>缺点：类装载时创建实例，无Lazy Loading。实例一直未被使用时，会浪费资源</li>
</ul>
<h2 id="静态内部类-推荐"><a href="#静态内部类-推荐" class="headerlink" title="静态内部类 推荐"></a>静态内部类 推荐</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton8;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> InnerClass.INSTANCE;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">InnerClass</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：无线程同步问题，实现了懒加载（Lazy Loading）。因为只有调用<code>getInstance</code>时才会装载内部类，才会创建实例。同时因为使用内部类时，先调用内部类的线程会获得类初始化锁，从而保证内部类的初始化（包括实例化它所引用的外部类对象）线程安全。即使内部类创建外部类的实例<code>Singleton INSTANCE = new Singleton()</code>发生指令重排也不会引起<a href="#双重检查（Double-Check）下的懒汉-推荐">双重检查（Double-Check）下的懒汉</a>模式中提到的问题，因此无须使用<code>volatile</code>关键字。</li>
<li>缺点：NA</li>
</ul>
<h2 id="枚举-强烈推荐"><a href="#枚举-强烈推荐" class="headerlink" title="枚举 强烈推荐"></a>枚举 强烈推荐</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.singleton9;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Singleton &#123;</div><div class="line"></div><div class="line">  INSTANCE;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">whatSoEverMethod</span><span class="params">()</span> </span>&#123; &#125;</div><div class="line"></div><div class="line">  <span class="comment">// 该方法非必须，只是为了保证与其它方案一样使用静态方法得到实例</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> INSTANCE;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>优点：枚举本身是线程安全的，且能防止通过反射和反序列化创建多实例。</li>
<li>缺点：使用的是枚举，而非类。
　　</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了为何需要单例模式，单例模式的设计要点，饿汉和懒汉的区别，并通过实例介绍了实现单例模式的八种实现方式及其优缺点。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（九） 桥接模式</title>
    <link href="http://www.jasongj.com/design_pattern/bridge/"/>
    <id>http://www.jasongj.com/design_pattern/bridge/</id>
    <published>2016-05-11T23:34:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/bridge/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/bridge/">http://www.jasongj.com/design_pattern/bridge/</a></p>
</blockquote>
<h1 id="桥接模式定义"><a href="#桥接模式定义" class="headerlink" title="桥接模式定义"></a>桥接模式定义</h1><p>桥接模式（Bridge Pattern），将抽象部分与它的实现部分分离，使它们都可以独立地变化。更容易理解的表述是：实现系统可从多种维度分类，桥接模式将各维度抽象出来，各维度独立变化，之后可通过聚合，将各维度组合起来，减少了各维度间的耦合。</p>
<h1 id="例讲桥接模式"><a href="#例讲桥接模式" class="headerlink" title="例讲桥接模式"></a>例讲桥接模式</h1><h2 id="不必要的继承导致类爆炸"><a href="#不必要的继承导致类爆炸" class="headerlink" title="不必要的继承导致类爆炸"></a>不必要的继承导致类爆炸</h2><p>汽车可按品牌分（本例中只考虑BMT，BenZ，Land Rover），也可按手动档、自动档、手自一体来分。如果对于每一种车都实现一个具体类，则一共要实现3*3=9个类。</p>
<p>使用继承方式的类图如下<br><img src="http://www.jasongj.com/img/designpattern/bridge/BridgeInherit.png" alt="Bridge pattern inherit class diagram"></p>
<p>从上图可以看到，对于每种组合都需要创建一个具体类，如果有N个维度，每个维度有M种变化，则需要$M^N$个具体类，类非常多，并且非常多的重复功能。</p>
<p>如果某一维度，如Transmission多一种可能，比如手自一体档（AMT），则需要增加3个类，BMWAMT，BenZAMT，LandRoverAMT。</p>
<h2 id="桥接模式类图"><a href="#桥接模式类图" class="headerlink" title="桥接模式类图"></a>桥接模式类图</h2><p>桥接模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/bridge/Bridge.png" alt="Bridge pattern class diagram"></p>
<p>从上图可知，当把每个维度拆分开来，只需要M*N个类，并且由于每个维度独立变化，基本不会出现重复代码。</p>
<p>此时如果增加手自一体档，只需要增加一个AMT类即可</p>
<h2 id="桥接模式实例解析"><a href="#桥接模式实例解析" class="headerlink" title="桥接模式实例解析"></a>桥接模式实例解析</h2><p>本文代码可从作者<a href="https://github.com/habren/JavaDesignPattern/tree/master/BridgePattern/src/main" target="_blank" rel="external">Github</a>下载</p>
<p>抽象车<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.brand;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.transmission.Transmission;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractCar</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> Transmission gear;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTransmission</span><span class="params">(Transmission gear)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.gear = gear;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>按品牌分，BMW牌车<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.brand;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BMWCar</span> <span class="keyword">extends</span> <span class="title">AbstractCar</span></span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(BMWCar.class);</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">    gear.gear();</div><div class="line">    LOG.info(<span class="string">"BMW is running"</span>);</div><div class="line">  &#125;;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>BenZCar<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.brand;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BenZCar</span> <span class="keyword">extends</span> <span class="title">AbstractCar</span></span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(BenZCar.class);</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">    gear.gear();</div><div class="line">    LOG.info(<span class="string">"BenZCar is running"</span>);</div><div class="line">  &#125;;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>LandRoverCar<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.brand;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LandRoverCar</span> <span class="keyword">extends</span> <span class="title">AbstractCar</span></span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(LandRoverCar.class);</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">    gear.gear();</div><div class="line">    LOG.info(<span class="string">"LandRoverCar is running"</span>);</div><div class="line">  &#125;;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>抽象变速器<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.transmission;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Transmission</span></span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">gear</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>手动档<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.transmission;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Manual</span> <span class="keyword">extends</span> <span class="title">Transmission</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(Manual.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">gear</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Manual transmission"</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>自动档<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.transmission;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Auto</span> <span class="keyword">extends</span> <span class="title">Transmission</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(Auto.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">gear</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Auto transmission"</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>有了变速器和品牌两个维度各自的实现后，可以通过聚合，实现不同品牌不同变速器的车，如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.brand.AbstractCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.brand.BMWCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.brand.BenZCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.transmission.Auto;</div><div class="line"><span class="keyword">import</span> com.jasongj.transmission.Manual;</div><div class="line"><span class="keyword">import</span> com.jasongj.transmission.Transmission;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BridgeClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Transmission auto = <span class="keyword">new</span> Auto();</div><div class="line">    AbstractCar bmw = <span class="keyword">new</span> BMWCar();</div><div class="line">    bmw.setTransmission(auto);</div><div class="line">    bmw.run();</div><div class="line">    </div><div class="line"></div><div class="line">    Transmission manual = <span class="keyword">new</span> Manual();</div><div class="line">    AbstractCar benz = <span class="keyword">new</span> BenZCar();</div><div class="line">    benz.setTransmission(manual);</div><div class="line">    benz.run();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="桥接模式与OOP原则"><a href="#桥接模式与OOP原则" class="headerlink" title="桥接模式与OOP原则"></a>桥接模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      当一种事物可在多种维度变化（如两个维度，每个维度三种可能）时，如果为每一种可能创建一个子类，则每增加一个维度上的可能需要增加多个类，这会造成类爆炸（3*3=9）。若使用桥接模式，使用类聚合，而非继承，将可缓解类爆炸，并增强可扩展性。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（八） 适配器模式</title>
    <link href="http://www.jasongj.com/design_pattern/adapter/"/>
    <id>http://www.jasongj.com/design_pattern/adapter/</id>
    <published>2016-05-08T23:04:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/adapter/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/adapter/">http://www.jasongj.com/design_pattern/adapter/</a></p>
</blockquote>
<h1 id="适配器模式介绍"><a href="#适配器模式介绍" class="headerlink" title="适配器模式介绍"></a>适配器模式介绍</h1><h2 id="适配器模式定义"><a href="#适配器模式定义" class="headerlink" title="适配器模式定义"></a>适配器模式定义</h2><p>适配器模式（Adapter Pattern），将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。</p>
<h2 id="适配器模式类图"><a href="#适配器模式类图" class="headerlink" title="适配器模式类图"></a>适配器模式类图</h2><p>适配器模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/adapter/Adapter.png" alt="Adapter pattern class diagram"></p>
<h2 id="适配器模式角色划分"><a href="#适配器模式角色划分" class="headerlink" title="适配器模式角色划分"></a>适配器模式角色划分</h2><ul>
<li>目标接口，如上图中的ITarget</li>
<li>具体目标实现，如ConcreteTarget</li>
<li>适配器，Adapter</li>
<li>待适配类，Adaptee</li>
</ul>
<h2 id="实例解析"><a href="#实例解析" class="headerlink" title="实例解析"></a>实例解析</h2><p>本文代码可从作者<a href="https://github.com/habren/JavaDesignPattern/tree/master/AdapterPattern/src/main" target="_blank" rel="external">Github</a>下载</p>
<p>目标接口<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.target;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ITarget</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">request</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>目标接口实现<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.target;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteTarget</span> <span class="keyword">implements</span> <span class="title">ITarget</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Logger LOG = LoggerFactory.getLogger(ConcreteTarget.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"ConcreteTarget.request()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>待适配类，其接口名为onRequest，而非目标接口request<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.adaptee;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.target.ConcreteTarget;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Adaptee</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Logger LOGGER = LoggerFactory.getLogger(ConcreteTarget.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onRequest</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOGGER.info(<span class="string">"Adaptee.onRequest()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>适配器类<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.target;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.adaptee.Adaptee;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Adapter</span> <span class="keyword">implements</span> <span class="title">ITarget</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Logger LOG = LoggerFactory.getLogger(Adapter.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> Adaptee adaptee = <span class="keyword">new</span> Adaptee();</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">request</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Adapter.request"</span>);</div><div class="line">    adaptee.onRequest();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面代码可看出，适配器类实际上是目标接口的类，因为持有待适配类的实例，所以可以在适配器类的目标接口被调用时，调用待适配对象的接口，而客户端并不需要知道二者接口的不同。通过这种方式，客户端可以使用统一的接口使用不同接口的类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.target.Adapter;</div><div class="line"><span class="keyword">import</span> com.jasongj.target.ConcreteTarget;</div><div class="line"><span class="keyword">import</span> com.jasongj.target.ITarget;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AdapterClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ITarget adapter = <span class="keyword">new</span> Adapter();</div><div class="line">    adapter.request();</div><div class="line"></div><div class="line">    ITarget target = <span class="keyword">new</span> ConcreteTarget();</div><div class="line">    target.request();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="适配器模式适用场景"><a href="#适配器模式适用场景" class="headerlink" title="适配器模式适用场景"></a>适配器模式适用场景</h1><ul>
<li>调用双方接口不一致且都不容易修改时，可以使用适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作</li>
<li>多个组件功能类似，但接口不统一且可能会经常切换时，可使用适配器模式，使得客户端可以以统一的接口使用它们</li>
</ul>
<h1 id="适配器模式优缺点"><a href="#适配器模式优缺点" class="headerlink" title="适配器模式优缺点"></a>适配器模式优缺点</h1><h2 id="适配器模式优点"><a href="#适配器模式优点" class="headerlink" title="适配器模式优点"></a>适配器模式优点</h2><ul>
<li>客户端可以以统一的方式使用ConcreteTarget和Adaptee</li>
<li>适配器负责适配过程，而不需要修改待适配类，其它直接依赖于待适配类的调用方不受适配过程的影响</li>
<li>可以为不同的目标接口实现不同的适配器，而不需要修改待适配类，符合开放-关闭原则</li>
</ul>
<h1 id="适配器模式与OOP原则"><a href="#适配器模式与OOP原则" class="headerlink" title="适配器模式与OOP原则"></a>适配器模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      适配器模式可将一个类的接口转换成调用方希望的另一个接口。这种需求往往发生在后期维护阶段，因此有观点认为适配器模式只是前期系统接口设计缺乏的一种弥补。从实际工程来看，并不完全这样，有时不同产商的功能类似但接口很难完全一样，而为了系统使用方式的一致性，也会用到适配器模式。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（七） Spring AOP  JDK动态代理 vs. Cglib</title>
    <link href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/"/>
    <id>http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/</id>
    <published>2016-05-02T12:42:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/</a></p>
</blockquote>
<h1 id="静态代理-VS-动态代理"><a href="#静态代理-VS-动态代理" class="headerlink" title="静态代理 VS. 动态代理"></a>静态代理 VS. 动态代理</h1><p>静态代理，是指程序运行前就已经存在了代理类的字节码文件，代理类和被代理类的关系在运行前就已经确定。</p>
<p>上一篇文章《<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a>》所讲的代理为静态代理。如上文所讲，一个静态代理类只代理一个具体类。如果需要对实现了同一接口的不同具体类作代理，静态代理需要为每一个具体类创建相应的代理类。</p>
<p>动态代理类的字节码是在程序运行期间动态生成，所以不存在代理类的字节码文件。代理类和被代理类的关系是在程序运行时确定的。</p>
<h1 id="JDK动态代理"><a href="#JDK动态代理" class="headerlink" title="JDK动态代理"></a>JDK动态代理</h1><p>JDK从1.3开始引入动态代理。可通过<code>java.lang.reflect.Proxy</code>类的静态方法<code>Proxy.newProxyInstance</code>动态创建代理类和实例。并且由它动态创建出来的代理类都是Proxy类的子类。</p>
<h2 id="定义代理行为"><a href="#定义代理行为" class="headerlink" title="定义代理行为"></a>定义代理行为</h2><p>代理类往往会在代理对象业务逻辑前后增加一些功能性的行为，如使用事务或者打印日志。本文把这些行为称之为<strong><em>代理行为</em></strong>。</p>
<p>使用JDK动态代理，需要创建一个实现<code>java.lang.reflect.InvocationHandler</code>接口的类，并在该类中定义代理行为。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.proxy.jdkproxy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Method;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubjectProxyHandler</span> <span class="keyword">implements</span> <span class="title">InvocationHandler</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(SubjectProxyHandler.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> Object target;</div><div class="line">  </div><div class="line">  <span class="meta">@SuppressWarnings</span>(<span class="string">"rawtypes"</span>)</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SubjectProxyHandler</span><span class="params">(Class clazz)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">this</span>.target = clazz.newInstance();</div><div class="line">    &#125; <span class="keyword">catch</span> (InstantiationException | IllegalAccessException ex) &#123;</div><div class="line">      LOG.error(<span class="string">"Create proxy for &#123;&#125; failed"</span>, clazz.getName());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">    preAction();</div><div class="line">    Object result = method.invoke(target, args);</div><div class="line">    postAction();</div><div class="line">    LOG.info(<span class="string">"Proxy class name &#123;&#125;"</span>, proxy.getClass().getName());</div><div class="line">    <span class="keyword">return</span> result;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">preAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectProxyHandler.preAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">postAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectProxyHandler.postAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从上述代码中可以看到，被代理对象的类对象作为参数传给了构造方法，原因如下</p>
<ul>
<li>如上文所述，动态代理可以代理多种类，而且具体代理哪种类并非台静态代理那样编译时确定，而是在运行时指定</li>
<li>之所以不传被代理类的实例而是传类对象，是为了与上文《<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a>》吻合——被代理对象不由客户端创建而由代理创建，客户端甚至都不需要知道被代理对象的存在。具体传被代理类的实例还是传类对象，并无严格规定</li>
<li>一些讲JDK动态代理的例子会专门使用一个public方法去接收该参数。但笔者个人认为最好不要在具体类中实现未出现在接口定义中的public方法</li>
</ul>
<p>注意，SubjectProxyHandler定义的是代理行为而非代理类本身。实际上代理类及其实例是在运行时通过反射动态创建出来的。</p>
<h2 id="JDK动态代理使用方式"><a href="#JDK动态代理使用方式" class="headerlink" title="JDK动态代理使用方式"></a>JDK动态代理使用方式</h2><p>代理行为定义好后，先实例化SubjectProxyHandler（在构造方法中指明被代理类），然后通过Proxy.newProxyInstance动态创建代理类的实例。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.proxy.jdkproxy.SubjectProxyHandler;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ConcreteSubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JDKDynamicProxyClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    InvocationHandler handler = <span class="keyword">new</span> SubjectProxyHandler(ConcreteSubject.class);</div><div class="line">    ISubject proxy =</div><div class="line">        (ISubject) Proxy.newProxyInstance(JDKDynamicProxyClient.class.getClassLoader(),</div><div class="line">            <span class="keyword">new</span> Class[] &#123;ISubject.class&#125;, handler);</div><div class="line">    proxy.action();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上述代码中也可以看到，Proxy.newProxyInstance的第二个参数是类对象数组，也就意味着被代理对象可以实现多个接口。</p>
<p>运行结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">SubjectProxyHandler.preAction()</div><div class="line">ConcreteSubject action()</div><div class="line">SubjectProxyHandler.postAction()</div><div class="line">Proxy class name com.sun.proxy.$Proxy18</div></pre></td></tr></table></figure></p>
<p>从上述结果可以看到，定义的代理行为顺利的加入到了执行逻辑中。同时，最后一行日志说明了代理类的类名是<code>com.sun.proxy.$Proxy18</code>，验证了上文的论点——SubjectProxyHandler定义的是代理行为而非代理类本身，代理类及其实例是在运行时通过反射动态创建出来的。</p>
<h2 id="生成的动态代理类"><a href="#生成的动态代理类" class="headerlink" title="生成的动态代理类"></a>生成的动态代理类</h2><p>Proxy.newProxyInstance是通过静态方法<code>ProxyGenerator.generateProxyClass</code>动态生成代理类的字节码的。为了观察创建出来的代理类的结构，本文手工调用该方法，得到了代理类的字节码，并将之输出到了class文件中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">byte</span>[] classFile = ProxyGenerator.generateProxyClass(<span class="string">"$Proxy18"</span>, ConcreteSubject.class.getInterfaces());</div></pre></td></tr></table></figure>
<p>使用反编译工具可以得到代理类的代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Method;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.UndeclaredThrowableException;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> $<span class="title">Proxy17</span> <span class="keyword">extends</span> <span class="title">Proxy</span> <span class="keyword">implements</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m1;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m2;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m0;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m3;</div><div class="line"></div><div class="line">  <span class="keyword">public</span> $Proxy17(InvocationHandler paramInvocationHandler) &#123;</div><div class="line">    <span class="keyword">super</span>(paramInvocationHandler);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object paramObject)</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">return</span> ((Boolean) <span class="keyword">this</span>.h.invoke(<span class="keyword">this</span>, m1, <span class="keyword">new</span> Object[] &#123;paramObject&#125;)).booleanValue();</div><div class="line">    &#125; <span class="keyword">catch</span> (Error | RuntimeException localError) &#123;</div><div class="line">      <span class="keyword">throw</span> localError;</div><div class="line">    &#125; <span class="keyword">catch</span> (Throwable localThrowable) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UndeclaredThrowableException(localThrowable);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">return</span> (String) <span class="keyword">this</span>.h.invoke(<span class="keyword">this</span>, m2, <span class="keyword">null</span>);</div><div class="line">    &#125; <span class="keyword">catch</span> (Error | RuntimeException localError) &#123;</div><div class="line">      <span class="keyword">throw</span> localError;</div><div class="line">    &#125; <span class="keyword">catch</span> (Throwable localThrowable) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UndeclaredThrowableException(localThrowable);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">return</span> ((Integer) <span class="keyword">this</span>.h.invoke(<span class="keyword">this</span>, m0, <span class="keyword">null</span>)).intValue();</div><div class="line">    &#125; <span class="keyword">catch</span> (Error | RuntimeException localError) &#123;</div><div class="line">      <span class="keyword">throw</span> localError;</div><div class="line">    &#125; <span class="keyword">catch</span> (Throwable localThrowable) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UndeclaredThrowableException(localThrowable);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="keyword">this</span>.h.invoke(<span class="keyword">this</span>, m3, <span class="keyword">null</span>);</div><div class="line">      <span class="keyword">return</span>;</div><div class="line">    &#125; <span class="keyword">catch</span> (Error | RuntimeException localError) &#123;</div><div class="line">      <span class="keyword">throw</span> localError;</div><div class="line">    &#125; <span class="keyword">catch</span> (Throwable localThrowable) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UndeclaredThrowableException(localThrowable);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      m1 = Class.forName(<span class="string">"java.lang.Object"</span>).getMethod(<span class="string">"equals"</span>,</div><div class="line">          <span class="keyword">new</span> Class[] &#123;Class.forName(<span class="string">"java.lang.Object"</span>)&#125;);</div><div class="line">      m2 = Class.forName(<span class="string">"java.lang.Object"</span>).getMethod(<span class="string">"toString"</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</div><div class="line">      m0 = Class.forName(<span class="string">"java.lang.Object"</span>).getMethod(<span class="string">"hashCode"</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</div><div class="line">      m3 = Class.forName(<span class="string">"com.jasongj.subject.ISubject"</span>).getMethod(<span class="string">"action"</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</div><div class="line">    &#125; <span class="keyword">catch</span> (NoSuchMethodException localNoSuchMethodException) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchMethodError(localNoSuchMethodException.getMessage());</div><div class="line">    &#125; <span class="keyword">catch</span> (ClassNotFoundException localClassNotFoundException) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NoClassDefFoundError(localClassNotFoundException.getMessage());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从该类的声明中可以看到，继承了Proxy类，并实现了ISubject接口。验证了上文中的论点——所有生成的动态代理类都是Proxy类的子类。同时也解释了为什么JDK动态代理只能代理实现了接口的类——Java不支持多继承，代理类已经继承了Proxy类，无法再继承其它类。</p>
<p>同时，代理类重写了hashCode，toString和equals这三个从Object继承下来的接口，通过InvocationHandler的invoke方法去实现。除此之外，该代理类还实现了ISubject接口的action方法，也是通过InvocationHandler的invoke方法去实现。这就解释了示例代码中代理行为是怎样被调用的。</p>
<p>前文提到，被代理类可以实现多个接口。从代理类代码中可以看到，代理类是通过InvocationHandler的invoke方法去实现代理接口的。所以当被代理对象实现了多个接口并且希望对不同接口实施不同的代理行为时，应该在SubjectProxyHandler类，也即代理行为定义类中，通过判断方法名，实现不同的代理行为。</p>
<h1 id="cglib"><a href="#cglib" class="headerlink" title="cglib"></a>cglib</h1><h2 id="cglib介绍"><a href="#cglib介绍" class="headerlink" title="cglib介绍"></a>cglib介绍</h2><p>cglib是一个强大的高性能代码生成库，它的底层是通过使用一个小而快的字节码处理框架ASM（Java字节码操控框架）来转换字节码并生成新的类。</p>
<h2 id="cglib方法拦截器"><a href="#cglib方法拦截器" class="headerlink" title="cglib方法拦截器"></a>cglib方法拦截器</h2><p>使用cglib实现动态代理，需要在MethodInterceptor实现类中定义代理行为。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.proxy.cglibproxy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.lang.reflect.Method;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.MethodInterceptor;</div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.MethodProxy;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubjectInterceptor</span> <span class="keyword">implements</span> <span class="title">MethodInterceptor</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(SubjectInterceptor.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Object obj, Method method, Object[] args, MethodProxy proxy)</span></span></div><div class="line">      <span class="keyword">throws</span> Throwable &#123;</div><div class="line">    preAction();</div><div class="line">    Object result = proxy.invokeSuper(obj, args);</div><div class="line">    postAction();</div><div class="line">    <span class="keyword">return</span> result;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">preAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectProxyHandler.preAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">postAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectProxyHandler.postAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>代理行为在intercept方法中定义，同时通过getInstance方法（该方法名可以自定义）获取动态代理的实例，并且可以通过向该方法传入类对象指定被代理对象的类型。</p>
<h2 id="cglib使用方式"><a href="#cglib使用方式" class="headerlink" title="cglib使用方式"></a>cglib使用方式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.proxy.cglibproxy.SubjectInterceptor;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ConcreteSubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.Enhancer;</div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.MethodInterceptor;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CgLibProxyClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    MethodInterceptor methodInterceptor = <span class="keyword">new</span> SubjectInterceptor();</div><div class="line">    Enhancer enhancer = <span class="keyword">new</span> Enhancer();</div><div class="line">    enhancer.setSuperclass(ConcreteSubject.class);</div><div class="line">    enhancer.setCallback(methodInterceptor);</div><div class="line">    ISubject subject = (ISubject)enhancer.create();</div><div class="line">    subject.action();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h1><p>分别使用JDK动态代理创建代理对象1亿次，并分别执行代理对象方法10亿次，代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.proxy.cglibproxy.SubjectInterceptor;</div><div class="line"><span class="keyword">import</span> com.jasongj.proxy.jdkproxy.SubjectProxyHandler;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ConcreteSubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.Enhancer;</div><div class="line"><span class="keyword">import</span> net.sf.cglib.proxy.MethodInterceptor;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DynamicProxyPerfClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(DynamicProxyPerfClient.class);</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> creation = <span class="number">100000000</span>;</div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> execution = <span class="number">1000000000</span>;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    testJDKDynamicCreation();</div><div class="line">    testJDKDynamicExecution();</div><div class="line">    testCglibCreation();</div><div class="line">    testCglibExecution();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testJDKDynamicCreation</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; creation; i++) &#123;</div><div class="line">      InvocationHandler handler = <span class="keyword">new</span> SubjectProxyHandler(ConcreteSubject.class);</div><div class="line">      Proxy.newProxyInstance(DynamicProxyPerfClient.class.getClassLoader(),</div><div class="line">          <span class="keyword">new</span> Class[] &#123;ISubject.class&#125;, handler);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">    LOG.info(<span class="string">"JDK creation time : &#123;&#125; ms"</span>, stop - start);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testJDKDynamicExecution</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">    InvocationHandler handler = <span class="keyword">new</span> SubjectProxyHandler(ConcreteSubject.class);</div><div class="line">    ISubject subject =</div><div class="line">        (ISubject) Proxy.newProxyInstance(DynamicProxyPerfClient.class.getClassLoader(),</div><div class="line">            <span class="keyword">new</span> Class[] &#123;ISubject.class&#125;, handler);</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; execution; i++) &#123;</div><div class="line">      subject.action();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">    LOG.info(<span class="string">"JDK execution time : &#123;&#125; ms"</span>, stop - start);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testCglibCreation</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; creation; i++) &#123;</div><div class="line">      MethodInterceptor methodInterceptor = <span class="keyword">new</span> SubjectInterceptor();</div><div class="line">      Enhancer enhancer = <span class="keyword">new</span> Enhancer();</div><div class="line">      enhancer.setSuperclass(ConcreteSubject.class);</div><div class="line">      enhancer.setCallback(methodInterceptor);</div><div class="line">      enhancer.create();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">    LOG.info(<span class="string">"cglib creation time : &#123;&#125; ms"</span>, stop - start);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testCglibExecution</span><span class="params">()</span> </span>&#123;</div><div class="line">    MethodInterceptor methodInterceptor = <span class="keyword">new</span> SubjectInterceptor();</div><div class="line">    Enhancer enhancer = <span class="keyword">new</span> Enhancer();</div><div class="line">    enhancer.setSuperclass(ConcreteSubject.class);</div><div class="line">    enhancer.setCallback(methodInterceptor);</div><div class="line">    ISubject subject = (ISubject) enhancer.create();</div><div class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; execution; i++) &#123;</div><div class="line">      subject.action();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> stop = System.currentTimeMillis();</div><div class="line">    LOG.info(<span class="string">"cglib execution time : &#123;&#125; ms"</span>, stop - start);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">JDK creation time : 9924 ms</div><div class="line">JDK execution time : 3472 ms</div><div class="line">cglib creation time : 16108 ms</div><div class="line">cglib execution time : 6309 ms</div></pre></td></tr></table></figure></p>
<p>该性能测试表明，JDK动态代理创建代理对象速度是cglib的约1.6倍，并且JDK创建出的代理对象执行速度是cglib代理对象执行速度的约1.8倍</p>
<h1 id="JDK动态代理与cglib对比"><a href="#JDK动态代理与cglib对比" class="headerlink" title="JDK动态代理与cglib对比"></a>JDK动态代理与cglib对比</h1><ul>
<li>字节码创建方式：JDK动态代理通过JVM实现代理类字节码的创建，cglib通过ASM创建字节码</li>
<li>对被代理对象的要求：JDK动态代理要求被代理对象实现接口，cglib要求被代理对象未被final修饰</li>
<li>代理对象创建速度：JDK动态代理创建代理对象速度比cglib快</li>
<li>代理对象执行速度：JDK动态代理代理对象执行速度比cglib快</li>
</ul>
<p>本文所有示例代理均可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/DynamicProxy" target="_blank" rel="external">作者Github</a>下载</p>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      Spring的AOP有JDK动态代理和cglib两种实现方式。JDK动态代理要求被代理对象实现接口；cglib通过动态继承实现，因此不能代理被final修饰的类；JDK动态代理生成代理对象速度比cglib快；cglib生成的代理对象比JDK动态代理生成的代理对象执行效率高。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（六） 代理模式 vs. 装饰模式</title>
    <link href="http://www.jasongj.com/design_pattern/proxy_decorator/"/>
    <id>http://www.jasongj.com/design_pattern/proxy_decorator/</id>
    <published>2016-04-29T12:42:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/proxy_decorator/">http://www.jasongj.com/design_pattern/proxy_decorator/</a></p>
</blockquote>
<h1 id="模式介绍"><a href="#模式介绍" class="headerlink" title="模式介绍"></a>模式介绍</h1><ul>
<li><strong>代理模式</strong>（Proxy Pattern），为其它对象提供一种代理以控制对这个对象的访问。</li>
<li><strong>装饰模式</strong>（Decorator Pattern），动态地给一个对象添加一些额外的职责。</li>
</ul>
<p>从语意上讲，代理模式的目标是控制对被代理对象的访问，而装饰模式是给原对象增加额外功能。</p>
<h1 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h1><p>代理模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/proxydecorator/ProxyPattern.png" alt="Proxy pattern class diagram"></p>
<p>装饰模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/proxydecorator/DecoratorPattern.png" alt="Decorator pattern class diagram"></p>
<p>从上图可以看到，代理模式和装饰模式的类图非常类似。下面结合具体的代码讲解两者的不同。</p>
<h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>本文所有代码均可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/ProxyAndDecoratorPattern/src/main" target="_blank" rel="external">作者Github</a>下载</p>
<h2 id="相同部分"><a href="#相同部分" class="headerlink" title="相同部分"></a>相同部分</h2><p>代理模式和装饰模式都包含ISubject和ConcreteSubject，并且这两种模式中这两个Component的实现没有任何区别。</p>
<p>ISubject代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.subject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">action</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>ConcreteSubject代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.subject;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteSubject</span> <span class="keyword">implements</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ConcreteSubject.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"ConcreteSubject action()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="代理类和使用方式"><a href="#代理类和使用方式" class="headerlink" title="代理类和使用方式"></a>代理类和使用方式</h2><p>代理类实现方式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.proxy;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"><span class="keyword">import</span> java.util.Random;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ConcreteSubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxySubject</span> <span class="keyword">implements</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(ProxySubject.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> ISubject subject;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ProxySubject</span><span class="params">()</span> </span>&#123;</div><div class="line">    subject = <span class="keyword">new</span> ConcreteSubject();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</div><div class="line">    preAction();</div><div class="line">    <span class="keyword">if</span>((<span class="keyword">new</span> Random()).nextBoolean())&#123;</div><div class="line">      subject.action();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      LOG.info(<span class="string">"Permission denied"</span>);</div><div class="line">    &#125;</div><div class="line">    postAction();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">preAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"ProxySubject.preAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">postAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"ProxySubject.postAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上述代码中可以看到，被代理对象由代理对象在编译时确定，并且代理对象可能限制对被代理对象的访问。</p>
<p>代理模式使用方式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.proxy.ProxySubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticProxyClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ISubject subject = <span class="keyword">new</span> ProxySubject();</div><div class="line">    subject.action();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上述代码中可以看到，调用方直接调用代理而不需要直接操作被代理对象甚至都不需要知道被代理对象的存在。同时，代理类可代理的具体被代理类是确定的，如本例中ProxySubject只可代理ConcreteSubject。</p>
<h2 id="装饰类和使用方式"><a href="#装饰类和使用方式" class="headerlink" title="装饰类和使用方式"></a>装饰类和使用方式</h2><p>装饰类实现方式如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.decorator;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubjectPreDecorator</span> <span class="keyword">implements</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(SubjectPreDecorator.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> ISubject subject;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SubjectPreDecorator</span><span class="params">(ISubject subject)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.subject = subject;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</div><div class="line">    preAction();</div><div class="line">    subject.action();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">preAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectPreDecorator.preAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.decorator;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SubjectPostDecorator</span> <span class="keyword">implements</span> <span class="title">ISubject</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(SubjectPostDecorator.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> ISubject subject;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">SubjectPostDecorator</span><span class="params">(ISubject subject)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.subject = subject;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span> </span>&#123;</div><div class="line">    subject.action();</div><div class="line">    postAction();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">postAction</span><span class="params">()</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"SubjectPostDecorator.preAction()"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>装饰模式使用方法如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.decorator.SubjectPostDecorator;</div><div class="line"><span class="keyword">import</span> com.jasongj.decorator.SubjectPreDecorator;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ConcreteSubject;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.ISubject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DecoratorClient</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ISubject subject = <span class="keyword">new</span> ConcreteSubject();</div><div class="line">    ISubject preDecorator = <span class="keyword">new</span> SubjectPreDecorator(subject);</div><div class="line">    ISubject postDecorator = <span class="keyword">new</span> SubjectPostDecorator(preDecorator);</div><div class="line">    postDecorator.action();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上述代码中可以看出，装饰类可装饰的类并不固定，并且被装饰对象是在使用时通过组合确定。如本例中SubjectPreDecorator装饰ConcreteSubject，而SubjectPostDecorator装饰SubjectPreDecorator。并且被装饰对象由调用方实例化后通过构造方法（或者setter）指定。</p>
<p>装饰模式的本质是<strong><em>动态组合</em></strong>。动态是手段，组合是目的。每个装饰类可以只负责添加一项额外功能，然后通过组合为被装饰类添加复杂功能。由于每个装饰类的职责比较简单单一，增加了这些装饰类的可重用性，同时也更符合单一职责原则。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>从语意上讲，代理模式是为控制对被代理对象的访问，而装饰模式是为了增加被装饰对象的功能</li>
<li>代理类所能代理的类完全由代理类确定，装饰类装饰的对象需要根据实际使用时客户端的组合来确定</li>
<li>被代理对象由代理对象创建，客户端甚至不需要知道被代理类的存在；被装饰对象由客户端创建并传给装饰对象</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      代理模式与装饰模式在代码组织结构上非常相近，以至于很多读者很难区分它们。本文将结合实例对比代理模式和装饰模式的适用场景，实现方式。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（五） 组合模式</title>
    <link href="http://www.jasongj.com/design_pattern/composite/"/>
    <id>http://www.jasongj.com/design_pattern/composite/</id>
    <published>2016-04-23T23:09:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/composite/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/composite/">http://www.jasongj.com/design_pattern/composite/</a></p>
</blockquote>
<h1 id="组合模式介绍"><a href="#组合模式介绍" class="headerlink" title="组合模式介绍"></a>组合模式介绍</h1><h2 id="组合模式定义"><a href="#组合模式定义" class="headerlink" title="组合模式定义"></a>组合模式定义</h2><p>组合模式（Composite Pattern）将对象组合成树形结构以表示“部分-整体”的层次结构。组合模式使得用户可以使用一致的方法操作单个对象和组合对象。</p>
<h2 id="组合模式类图"><a href="#组合模式类图" class="headerlink" title="组合模式类图"></a>组合模式类图</h2><p>组合模式类图如下<br><img src="http://www.jasongj.com/img/designpattern/composite/composite.png" alt="Composite pattern class diagram"></p>
<h2 id="组合模式角色划分"><a href="#组合模式角色划分" class="headerlink" title="组合模式角色划分"></a>组合模式角色划分</h2><ul>
<li>抽象组件，如上图中的Component</li>
<li>简单组件，如上图中的SimpleComponent</li>
<li>复合组件，如上图中的CompositeComponent</li>
</ul>
<h1 id="组合模式实例"><a href="#组合模式实例" class="headerlink" title="组合模式实例"></a>组合模式实例</h1><h2 id="实例介绍"><a href="#实例介绍" class="headerlink" title="实例介绍"></a>实例介绍</h2><p>对于一家大型公司，每当公司高层有重要事项需要通知到总部每个部门以及分公司的各个部门时，并不希望逐一通知，而只希望通过总部各部门及分公司，再由分公司通知其所有部门。这样，对于总公司而言，不需要关心通知的是总部的部门还是分公司。</p>
<h2 id="实例类图"><a href="#实例类图" class="headerlink" title="实例类图"></a>实例类图</h2><p>组合模式实例类图如下（点击可查看大图）<br><img src="http://www.jasongj.com/img/designpattern/composite/composite_example.png" alt="Composite pattern example class diagram"></p>
<h2 id="实例解析"><a href="#实例解析" class="headerlink" title="实例解析"></a>实例解析</h2><p>本例代码可从作者<a href="https://github.com/habren/JavaDesignPattern/tree/master/CompositePattern/src/main" target="_blank" rel="external">Github</a>下载</p>
<h2 id="抽象组件"><a href="#抽象组件" class="headerlink" title="抽象组件"></a>抽象组件</h2><p>抽象组件定义了组件的通知接口，并实现了增删子组件及获取所有子组件的方法。同时重写了<code>hashCode</code>和<code>equales</code>方法（至于原因，请读者自行思考。如有疑问，请在评论区留言）。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.organization;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Organization</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> List&lt;Organization&gt; childOrgs = <span class="keyword">new</span> ArrayList&lt;Organization&gt;();</div><div class="line"></div><div class="line">  <span class="keyword">private</span> String name;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Organization</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">    <span class="keyword">this</span>.name = name;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> name;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOrg</span><span class="params">(Organization org)</span> </span>&#123;</div><div class="line">    childOrgs.add(org);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeOrg</span><span class="params">(Organization org)</span> </span>&#123;</div><div class="line">    childOrgs.remove(org);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> List&lt;Organization&gt; <span class="title">getAllOrgs</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> childOrgs;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">inform</span><span class="params">(String info)</span></span>;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.name.hashCode();</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object org)</span></span>&#123;</div><div class="line">    <span class="keyword">if</span>(!(org <span class="keyword">instanceof</span> Organization)) &#123;</div><div class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.name.equals(((Organization) org).name);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="简单组件（部门）"><a href="#简单组件（部门）" class="headerlink" title="简单组件（部门）"></a>简单组件（部门）</h2><p>简单组件在通知方法中只负责对接收到消息作出响应。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.organization;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Department</span> <span class="keyword">extends</span> <span class="title">Organization</span></span>&#123;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Department</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">    <span class="keyword">super</span>(name);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Logger LOGGER = LoggerFactory.getLogger(Department.class);</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inform</span><span class="params">(String info)</span></span>&#123;</div><div class="line">    LOGGER.info(<span class="string">"&#123;&#125;-&#123;&#125;"</span>, info, getName());</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="复合组件（公司）"><a href="#复合组件（公司）" class="headerlink" title="复合组件（公司）"></a>复合组件（公司）</h3><p>复合组件在自身对消息作出响应后，还须通知其下所有子组件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.organization;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Company</span> <span class="keyword">extends</span> <span class="title">Organization</span></span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Logger LOGGER = LoggerFactory.getLogger(Company.class);</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Company</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">    <span class="keyword">super</span>(name);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inform</span><span class="params">(String info)</span></span>&#123;</div><div class="line">    LOGGER.info(<span class="string">"&#123;&#125;-&#123;&#125;"</span>, info, getName());</div><div class="line">    List&lt;Organization&gt; allOrgs = getAllOrgs();</div><div class="line">    allOrgs.forEach(org -&gt; org.inform(info+<span class="string">"-"</span>));</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="组合模式优缺点"><a href="#组合模式优缺点" class="headerlink" title="组合模式优缺点"></a>组合模式优缺点</h1><h2 id="组合模式优点"><a href="#组合模式优点" class="headerlink" title="组合模式优点"></a>组合模式优点</h2><ul>
<li>高层模块调用简单。组合模式中，用户不用关心到底是处理简单组件还是复合组件，可以按照统一的接口处理。不必判断组件类型，更不用为不同类型组件分开处理。</li>
<li>组合模式可以很容易的增加新的组件。若要增加一个简单组件或复合组件，只须找到它的父节点即可，非常容易扩展，符合“开放-关闭”原则。</li>
</ul>
<h2 id="组合模式缺点"><a href="#组合模式缺点" class="headerlink" title="组合模式缺点"></a>组合模式缺点</h2><ul>
<li>无法限制组合组件中的子组件类型。在需要检测组件类型时，不能依靠编译期的类型约束来实现，必须在运行期间动态检测。</li>
</ul>
<h1 id="组合模式与OOP原则"><a href="#组合模式与OOP原则" class="headerlink" title="组合模式与OOP原则"></a>组合模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则（复合类型不依赖于任何具体的组件而依赖于抽象组件）</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了组合模式的概念，UML类图，优缺点，实例讲解以及组合模式（未）遵循的OOP原则。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（四） 观察者模式</title>
    <link href="http://www.jasongj.com/design_pattern/observer/"/>
    <id>http://www.jasongj.com/design_pattern/observer/</id>
    <published>2016-04-13T12:13:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/observer/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/observer/">http://www.jasongj.com/design_pattern/observer/</a></p>
</blockquote>
<h1 id="观察者模式介绍"><a href="#观察者模式介绍" class="headerlink" title="观察者模式介绍"></a>观察者模式介绍</h1><h2 id="观察者模式定义"><a href="#观察者模式定义" class="headerlink" title="观察者模式定义"></a>观察者模式定义</h2><p>观察者模式又叫发布-订阅模式，它定义了一种一对多的依赖关系，多个观察者对象可同时监听某一主题对象，当该主题对象状态发生变化时，相应的所有观察者对象都可收到通知。</p>
<h2 id="观察者模式类图"><a href="#观察者模式类图" class="headerlink" title="观察者模式类图"></a>观察者模式类图</h2><p>观察者模式类图如下（点击可查看大图）<br><img src="http://www.jasongj.com/img/designpattern/observer/observer.png" alt="Observer pattern class diagram"></p>
<h2 id="观察者模式角色划分"><a href="#观察者模式角色划分" class="headerlink" title="观察者模式角色划分"></a>观察者模式角色划分</h2><ul>
<li>主题，抽象类或接口，如上面类图中的AbstractSubject</li>
<li>具体主题，如上面类图中的Subject1，Subject2</li>
<li>观察者，如上面类图中的IObserver</li>
<li>具体观察者，如上面类图中的Observer1，Observer2，Observer3</li>
</ul>
<h1 id="观察者模式实例"><a href="#观察者模式实例" class="headerlink" title="观察者模式实例"></a>观察者模式实例</h1><h2 id="实例介绍"><a href="#实例介绍" class="headerlink" title="实例介绍"></a>实例介绍</h2><p>猎头或者HR往往会有很多职位信息，求职者可以在猎头或者HR那里注册，当猎头或者HR有新的岗位信息时，即会通知这些注册过的求职者。这是一个典型的观察者模式使用场景。</p>
<h2 id="实例类图"><a href="#实例类图" class="headerlink" title="实例类图"></a>实例类图</h2><p>观察者模式实例类图如下（点击可查看大图）<br><img src="http://www.jasongj.com/img/designpattern/observer/observer_example.png" alt="Observer pattern example class diagram"></p>
<h2 id="实例解析"><a href="#实例解析" class="headerlink" title="实例解析"></a>实例解析</h2><p>本例代码可从作者<a href="https://github.com/habren/JavaDesignPattern/tree/master/ObserverPattern/src/main" target="_blank" rel="external">Github</a>下载</p>
<p>观察者接口（或抽象观察者，如本例中的ITalent）需要定义回调接口，如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.observer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ITalent</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">newJob</span><span class="params">(String job)</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>具体观察者（如本例中的JuniorEngineer，SeniorEngineer，Architect）在回调接口中实现其对事件的响应方法，如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.observer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Architect</span> <span class="keyword">implements</span> <span class="title">ITalent</span> </span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(Architect.class);</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">newJob</span><span class="params">(String job)</span> </span>&#123;</div><div class="line">    LOG.info(<span class="string">"Architect get new position &#123;&#125;"</span>, job);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>抽象主题类（如本例中的AbstractHR）定义通知观察者接口，并实现增加观察者和删除观察者方法（这两个方法可被子类共用，所以放在抽象类中实现），如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.subject;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.Collection;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.observer.ITalent;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractHR</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">protected</span> Collection&lt;ITalent&gt; allTalents = <span class="keyword">new</span> ArrayList&lt;ITalent&gt;();</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">publishJob</span><span class="params">(String job)</span></span>;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addTalent</span><span class="params">(ITalent talent)</span> </span>&#123;</div><div class="line">    allTalents.add(talent);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeTalent</span><span class="params">(ITalent talent)</span> </span>&#123;</div><div class="line">    allTalents.remove(talent);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>具体主题类（如本例中的HeadHunter）只需实现通知观察者接口，在该方法中通知所有注册的具体观察者。代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.subject;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeadHunter</span> <span class="keyword">extends</span> <span class="title">AbstractHR</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publishJob</span><span class="params">(String job)</span> </span>&#123;</div><div class="line">    allTalents.forEach(talent -&gt; talent.newJob(job));</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当主题类有更新（如本例中猎头有新的招聘岗位）时，调用其通知接口即可将其状态（岗位）通知给所有观察者（求职者）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.observer.Architect;</div><div class="line"><span class="keyword">import</span> com.jasongj.observer.ITalent;</div><div class="line"><span class="keyword">import</span> com.jasongj.observer.JuniorEngineer;</div><div class="line"><span class="keyword">import</span> com.jasongj.observer.SeniorEngineer;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.HeadHunter;</div><div class="line"><span class="keyword">import</span> com.jasongj.subject.AbstractHR;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client1</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    ITalent juniorEngineer = <span class="keyword">new</span> JuniorEngineer();</div><div class="line">    ITalent seniorEngineer = <span class="keyword">new</span> SeniorEngineer();</div><div class="line">    ITalent architect = <span class="keyword">new</span> Architect();</div><div class="line">    </div><div class="line">    AbstractHR subject = <span class="keyword">new</span> HeadHunter();</div><div class="line">    subject.addTalent(juniorEngineer);</div><div class="line">    subject.addTalent(seniorEngineer);</div><div class="line">    subject.addTalent(architect);</div><div class="line"></div><div class="line">    subject.publishJob(<span class="string">"Top 500 big data position"</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="观察者模式优缺点"><a href="#观察者模式优缺点" class="headerlink" title="观察者模式优缺点"></a>观察者模式优缺点</h1><h2 id="观察者模式优点"><a href="#观察者模式优点" class="headerlink" title="观察者模式优点"></a>观察者模式优点</h2><ul>
<li>抽象主题只依赖于抽象观察者</li>
<li>观察者模式支持广播通信</li>
<li>观察者模式使信息产生层和响应层分离</li>
</ul>
<h2 id="观察者模式缺点"><a href="#观察者模式缺点" class="headerlink" title="观察者模式缺点"></a>观察者模式缺点</h2><ul>
<li>如一个主题被大量观察者注册，则通知所有观察者会花费较高代价</li>
<li>如果某些观察者的响应方法被阻塞，整个通知过程即被阻塞，其它观察者不能及时被通知</li>
</ul>
<h1 id="观察者模式与OOP原则"><a href="#观察者模式与OOP原则" class="headerlink" title="观察者模式与OOP原则"></a>观察者模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则（主题类依赖于抽象观察者而非具体观察者）</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则</li>
<li>开闭原则</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>NA</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了观察者模式的概念，UML类图，优缺点，实例分析以及观察者模式（未）遵循的OOP原则。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（三） 抽象工厂模式</title>
    <link href="http://www.jasongj.com/design_pattern/abstract_factory/"/>
    <id>http://www.jasongj.com/design_pattern/abstract_factory/</id>
    <published>2016-04-09T12:39:46.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/abstract_factory/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/abstract_factory/">http://www.jasongj.com/design_pattern/abstract_factory/</a></p>
</blockquote>
<h1 id="抽象工厂模式解决的问题"><a href="#抽象工厂模式解决的问题" class="headerlink" title="抽象工厂模式解决的问题"></a>抽象工厂模式解决的问题</h1><p>上文《<a href="http://www.jasongj.com/design_pattern/factory_method/">工厂方法模式</a>》中提到，在工厂方法模式中一种工厂只能创建一种具体产品。而在抽象工厂模式中一种具体工厂可以创建多个种类的具体产品。</p>
<h1 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h1><h2 id="抽象工厂模式介绍"><a href="#抽象工厂模式介绍" class="headerlink" title="抽象工厂模式介绍"></a>抽象工厂模式介绍</h2><p>抽象工厂模式（Factory Method Pattern）中，抽象工厂提供一系列创建多个抽象产品的接口，而具体的工厂负责实现具体的产品实例。抽象工厂模式与工厂方法模式最大的区别在于抽象工厂中每个工厂可以创建多个种类的产品。</p>
<h2 id="抽象工厂模式类图"><a href="#抽象工厂模式类图" class="headerlink" title="抽象工厂模式类图"></a>抽象工厂模式类图</h2><p>抽象工厂模式类图如下 （点击可查看大图）<br><img src="http://www.jasongj.com/img/designpattern/abstractfactory/abstract_factory.png" alt="Factory Method Pattern Class Diagram"></p>
<h2 id="抽象工厂模式角色划分"><a href="#抽象工厂模式角色划分" class="headerlink" title="抽象工厂模式角色划分"></a>抽象工厂模式角色划分</h2><ul>
<li>抽象产品（或者产品接口），如上文类图中的IUserDao，IRoleDao，IProductDao</li>
<li>具体产品，如PostgreSQLProductDao</li>
<li>抽象工厂（或者工厂接口），如IFactory</li>
<li>具体工厂，如果MySQLFactory</li>
<li>产品族，如Oracle产品族，包含OracleUserDao，OracleRoleDao，OracleProductDao</li>
</ul>
<h2 id="抽象工厂模式使用方式"><a href="#抽象工厂模式使用方式" class="headerlink" title="抽象工厂模式使用方式"></a>抽象工厂模式使用方式</h2><p>与工厂方法模式类似，在创建具体产品时，客户端通过实例化具体的工厂类，并调用其创建目标产品的方法创建具体产品类的实例。根据依赖倒置原则，具体工厂类的实例由工厂接口引用，具体产品的实例由产品接口引用。具体调用代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.bean.Product;</div><div class="line"><span class="keyword">import</span> com.jasongj.bean.User;</div><div class="line"><span class="keyword">import</span> com.jasongj.dao.role.IRoleDao;</div><div class="line"><span class="keyword">import</span> com.jasongj.dao.user.IUserDao;</div><div class="line"><span class="keyword">import</span> com.jasongj.dao.user.product.IProductDao;</div><div class="line"><span class="keyword">import</span> com.jasongj.factory.IDaoFactory;</div><div class="line"><span class="keyword">import</span> com.jasongj.factory.MySQLDaoFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    IDaoFactory factory = <span class="keyword">new</span> MySQLDaoFactory();</div><div class="line"></div><div class="line">    IUserDao userDao = factory.createUserDao();</div><div class="line">    User user = <span class="keyword">new</span> User();</div><div class="line">    user.setUsername(<span class="string">"demo"</span>);</div><div class="line">    user.setPassword(<span class="string">"demo"</span>.toCharArray());</div><div class="line">    userDao.addUser(user);</div><div class="line"></div><div class="line">    IRoleDao roleDao = factory.createRoleDao();</div><div class="line">    roleDao.getRole(<span class="string">"admin"</span>);</div><div class="line"></div><div class="line">    IProductDao productDao = factory.createProductDao();</div><div class="line">    Product product = <span class="keyword">new</span> Product();</div><div class="line">    productDao.removeProduct(product);</div><div class="line"></div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="抽象工厂模式案例解析"><a href="#抽象工厂模式案例解析" class="headerlink" title="抽象工厂模式案例解析"></a>抽象工厂模式案例解析</h2><p>本文所述抽象工厂模式示例代码可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/AbstractFactoryPattern/src/main" target="_blank" rel="external">作者Github</a>下载</p>
<p>上例是J2EE开发中常用的DAO（Data Access Object），操作对象（如User和Role，对应于数据库中表的记录）需要对应的DAO类。</p>
<p>在实际项目开发中，经常会碰到要求使用其它类型的数据库，而不希望过多修改已有代码。因此，需要为每种DAO创建一个DAO接口（如IUserDao，IRoleDao和IProductDao），同时为不同数据库实现相应的具体类。</p>
<p>调用方依赖于DAO接口而非具体实现（依赖倒置原则），因此切换数据库时，调用方代码无需修改。</p>
<p>这些具体的DAO实现类往往不由调用方实例化，从而实现具体DAO的使用方与DAO的构建解耦。实际上，这些DAO类一般由对应的具体工厂类构建。调用方不依赖于具体工厂而是依赖于抽象工厂（依赖倒置原则，又是依赖倒置原则）。</p>
<p>每种具体工厂都能创建多种产品，由同一种工厂创建的产品属于同一产品族。例如PostgreSQLUserDao，PostgreSQLRoleDao和PostgreSQLProductDao都属于PostgreSQL这一产品族。</p>
<p>切换数据库即是切换产品族，只需要切换具体的工厂类。如上文示例代码中，客户端使用的MySQL，如果要换用Oracle，只需将MySQLDaoFactory换成OracleDaoFactory即可。</p>
<h2 id="抽象工厂模式优点"><a href="#抽象工厂模式优点" class="headerlink" title="抽象工厂模式优点"></a>抽象工厂模式优点</h2><ul>
<li>因为每个具体工厂类只负责创建产品，没有简单工厂中的逻辑判断，因此符合单一职责原则。</li>
<li>与简单工厂模式不同，抽象工厂并不使用静态工厂方法，可以形成基于继承的等级结构。</li>
<li>新增一个产品族（如上文类图中的MySQLUserDao，MySQLRoleDao，MySQLProductDao）时，只需要增加相应的具体产品和对应的具体工厂类即可。相比于简单工厂模式需要修改判断逻辑而言，抽象工厂模式更符合开-闭原则。</li>
</ul>
<h2 id="抽象工厂模式缺点"><a href="#抽象工厂模式缺点" class="headerlink" title="抽象工厂模式缺点"></a>抽象工厂模式缺点</h2><ul>
<li>新增产品种类（如上文类图中的UserDao，RoleDao，ProductDao）时，需要修改工厂接口（或者抽象工厂）及所有具体工厂，此时不符合开-闭原则。抽象工厂模式对于新的产品族符合开-闭原则而对于新的产品种类不符合开-闭原则，这一特性也被称为开-闭原则的倾斜性。</li>
</ul>
<h1 id="抽象工厂模式与OOP原则"><a href="#抽象工厂模式与OOP原则" class="headerlink" title="抽象工厂模式与OOP原则"></a>抽象工厂模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则（工厂构建产品的方法均返回产品接口而非具体产品，从而使客户端依赖于产品抽象而非具体）</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则（每个工厂只负责创建自己的具体产品族，没有简单工厂中的逻辑判断）</li>
<li>开闭原则（增加新的产品族，不像简单工厂那样需要修改已有的工厂，而只需增加相应的具体工厂类）</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>开闭原则（虽然对新增产品族符合开-闭原则，但对新增产品种类不符合开-闭原则）</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了抽象工厂模式的概念，UML类图，优缺点，实现方式以及（未）遵循的OOP原则。同时结合J2EE中常用的DAO实例详解了抽象工厂模式的实现。
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（二） 工厂方法模式</title>
    <link href="http://www.jasongj.com/design_pattern/factory_method/"/>
    <id>http://www.jasongj.com/design_pattern/factory_method/</id>
    <published>2016-04-02T00:00:01.000Z</published>
    <updated>2017-02-18T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/factory_method/">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/factory_method/">http://www.jasongj.com/design_pattern/factory_method/</a></p>
</blockquote>
<h1 id="工厂方法模式解决的问题"><a href="#工厂方法模式解决的问题" class="headerlink" title="工厂方法模式解决的问题"></a>工厂方法模式解决的问题</h1><p>上文《<a href="http://www.jasongj.com/design_pattern/simple_factory/">简单工厂模式不简单</a>》中提到，简单工厂模式有如下缺点，而工厂方法模式可以解决这些问题</p>
<ul>
<li>由于工厂类集中了所有实例的创建逻辑，这就直接导致一旦这个工厂出了问题，所有的客户端都会受到牵连。</li>
<li>由于简单工厂模式的产品是基于一个共同的抽象类或者接口，这样一来，产品的种类增加的时候，即有不同的产品接口或者抽象类的时候，工厂类就需要判断何时创建何种接口的产品，这就和创建何种种类的产品相互混淆在了一起，违背了单一职责原则，导致系统丧失灵活性和可维护性。</li>
<li>简单工厂模式违背了“开放-关闭原则”，因为当我们新增加一个产品的时候必须修改工厂类，相应的工厂类就需要重新编译一遍。</li>
<li>简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。</li>
</ul>
<h1 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h1><h2 id="工厂方法模式介绍"><a href="#工厂方法模式介绍" class="headerlink" title="工厂方法模式介绍"></a>工厂方法模式介绍</h2><p>工厂方法模式（Factory Method Pattern）又称为工厂模式，也叫多态工厂模式或者虚拟构造器模式。在工厂方法模式中，工厂父类定义创建产品对象的公共接口，具体的工厂子类负责创建具体的产品对象。每一个工厂子类负责创建一种具体产品。</p>
<h2 id="工厂方法模式类图"><a href="#工厂方法模式类图" class="headerlink" title="工厂方法模式类图"></a>工厂方法模式类图</h2><p>工厂模式类图如下 (点击可查看大图)<br><img src="http://www.jasongj.com/img/designpattern/factorymethod/factory_method.png" alt="Factory Method Pattern Class Diagram"></p>
<h2 id="工厂方法模式角色划分"><a href="#工厂方法模式角色划分" class="headerlink" title="工厂方法模式角色划分"></a>工厂方法模式角色划分</h2><ul>
<li>抽象产品（或者产品接口），如上图中IUserDao</li>
<li>具体产品，如上图中的MySQLUserDao，PostgreSQLUserDao和OracleUserDao</li>
<li>抽象工厂（或者工厂接口），如IFactory</li>
<li>具体工厂，如MySQLFactory，PostgreSQLFactory和OracleFactory</li>
</ul>
<h2 id="工厂方法模式使用方式"><a href="#工厂方法模式使用方式" class="headerlink" title="工厂方法模式使用方式"></a>工厂方法模式使用方式</h2><p>如简单工厂模式直接使用静态工厂方法创建产品对象不同，在工厂方法，客户端通过实例化具体的工厂类，并调用其创建实例接口创建具体产品类的实例。根据依赖倒置原则，具体工厂类的实例由工厂接口引用（客户端依赖于抽象工厂而非具体工厂），具体产品的实例由产品接口引用（客户端和工厂依赖于抽象产品而非具体产品）。具体调用代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.dao.IUserDao;</div><div class="line"><span class="keyword">import</span> com.jasongj.factory.IDaoFactory;</div><div class="line"><span class="keyword">import</span> com.jasongj.factory.MySQLDaoFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    IDaoFactory factory = <span class="keyword">new</span> MySQLDaoFactory();</div><div class="line">    IUserDao userDao = factory.createUserDao();</div><div class="line">    userDao.getUser(<span class="string">"admin"</span>);</div><div class="line"></div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="工厂方法模式示例代码"><a href="#工厂方法模式示例代码" class="headerlink" title="工厂方法模式示例代码"></a>工厂方法模式示例代码</h2><p>本文所述工厂方法模式示例代码可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/FactoryMethodPattern/src/main" target="_blank" rel="external">作者Github</a>下载</p>
<h2 id="工厂方法模式优点"><a href="#工厂方法模式优点" class="headerlink" title="工厂方法模式优点"></a>工厂方法模式优点</h2><ul>
<li>因为每个具体工厂类只负责创建产品，没有简单工厂中的逻辑判断，因此符合单一职责原则。</li>
<li>与简单工厂模式不同，工厂方法并不使用静态工厂方法，可以形成基于继承的等级结构。</li>
<li>新增一种产品时，只需要增加相应的具体产品类和相应的工厂子类即可，相比于简单工厂模式需要修改判断逻辑而言，工厂方法模式更符合开-闭原则。</li>
</ul>
<h2 id="工厂方法模式缺点"><a href="#工厂方法模式缺点" class="headerlink" title="工厂方法模式缺点"></a>工厂方法模式缺点</h2><ul>
<li>添加新产品时，除了增加新产品类外，还要提供与之对应的具体工厂类，系统类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。</li>
<li>虽然保证了工厂方法内的对修改关闭，但对于使用工厂方法的类，如果要换用另外一种产品，仍然需要修改实例化的具体工厂。</li>
<li>一个具体工厂只能创建一种具体产品</li>
</ul>
<h1 id="简单工厂模式与OOP原则"><a href="#简单工厂模式与OOP原则" class="headerlink" title="简单工厂模式与OOP原则"></a>简单工厂模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
<li>单一职责原则（每个工厂只负责创建自己的具体产品，没有简单工厂中的逻辑判断）</li>
<li>开闭原则（增加新的产品，不像简单工厂那样需要修改已有的工厂，而只需增加相应的具体工厂类）</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>开闭原则（虽然工厂对修改关闭了，但更换产品时，客户代码还是需要修改）</li>
</ul>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/summary/">Java设计模式（十三） 别人再问你设计模式，叫他看这篇文章</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了工厂方法模式的概念，优缺点，实现方式，UML类图，并介绍了工厂方法（未）遵循的OOP原则
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</title>
    <link href="http://www.jasongj.com/sql/cte/"/>
    <id>http://www.jasongj.com/sql/cte/</id>
    <published>2016-03-18T12:49:04.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/sql/cte/">原文链接</a>　<a href="http://www.jasongj.com/sql/cte/">http://www.jasongj.com/sql/cte/</a></p>
</blockquote>
<h1 id="CTE-or-WITH"><a href="#CTE-or-WITH" class="headerlink" title="CTE or WITH"></a>CTE or WITH</h1><p>WITH语句通常被称为通用表表达式（Common Table Expressions）或者CTEs。</p>
<p>WITH语句作为一个辅助语句依附于主语句，WITH语句和主语句都可以是<code>SELECT</code>，<code>INSERT</code>，<code>UPDATE</code>，<code>DELETE</code>中的任何一种语句。</p>
<h2 id="例讲CTE"><a href="#例讲CTE" class="headerlink" title="例讲CTE"></a>例讲CTE</h2><p>WITH语句最基本的功能是把复杂查询语句拆分成多个简单的部分，如下例所示<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">WITH regional_sales AS (</div><div class="line">  <span class="keyword">SELECT</span> region, <span class="keyword">SUM</span>(amount) <span class="keyword">AS</span> total_sales</div><div class="line">  <span class="keyword">FROM</span> orders</div><div class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> region</div><div class="line">), top_regions <span class="keyword">AS</span> (</div><div class="line">  <span class="keyword">SELECT</span> region</div><div class="line">  <span class="keyword">FROM</span> regional_sales</div><div class="line">  <span class="keyword">WHERE</span> total_sales &gt; (<span class="keyword">SELECT</span> <span class="keyword">SUM</span>(total_sales)/<span class="number">10</span> <span class="keyword">FROM</span> regional_sales</div><div class="line">)</div><div class="line"><span class="keyword">SELECT</span></div><div class="line">  region,</div><div class="line">  product,</div><div class="line">  <span class="keyword">SUM</span>(quantity) <span class="keyword">AS</span> product_units,</div><div class="line">  <span class="keyword">SUM</span>(amount) <span class="keyword">AS</span> product_sales</div><div class="line"><span class="keyword">FROM</span> orders</div><div class="line"><span class="keyword">WHERE</span> region <span class="keyword">IN</span> (<span class="keyword">SELECT</span> region <span class="keyword">FROM</span> top_regions)</div><div class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> region, product;</div></pre></td></tr></table></figure></p>
<p>该例中，定义了两个WITH辅助语句，regional_sales和top_regions。前者算出每个区域的总销售量，后者了查出所有销售量占所有地区总销售里10%以上的区域。主语句通过将这个CTEs及订单表关联，算出了顶级区域每件商品的销售量和销售额。</p>
<p>当然，本例也可以不使用CTEs而使用两层嵌套子查询来实现，但使用CTEs更简单，更清晰，可读性更强。</p>
<h2 id="在WITH中使用数据修改语句"><a href="#在WITH中使用数据修改语句" class="headerlink" title="在WITH中使用数据修改语句"></a>在WITH中使用数据修改语句</h2><p>文章开头处提到，WITH中可以不仅可以使用<code>SELECT</code>语句，同时还能使用<code>DELETE</code>，<code>UPDATE</code>，<code>INSERT</code>语句。因此，可以使用WITH，在一条SQL语句中进行不同的操作，如下例所示。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">WITH moved_rows AS (</div><div class="line">  <span class="keyword">DELETE</span> <span class="keyword">FROM</span> products</div><div class="line">  <span class="keyword">WHERE</span></div><div class="line">    <span class="string">"date"</span> &gt;= <span class="string">'2010-10-01'</span></div><div class="line">  <span class="keyword">AND</span> <span class="string">"date"</span> &lt; <span class="string">'2010-11-01'</span></div><div class="line">  <span class="keyword">RETURNING</span> *</div><div class="line">)</div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> products_log</div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> moved_rows;</div></pre></td></tr></table></figure></p>
<p>本例通过WITH中的DELETE语句从products表中删除了一个月的数据，并通过<code>RETURNING</code>子句将删除的数据集赋给moved_rows这一CTE，最后在主语句中通过INSERT将删除的商品插入products_log中。</p>
<p>如果WITH里面使用的不是SELECT语句，并且没有通过RETURNING子句返回结果集，则主查询中不可以引用该CTE，但主查询和WITH语句仍然可以继续执行。这种情况可以实现将多个不相关的语句放在一个SQL语句里，实现了在不显式使用事务的情况下保证WITH语句和主语句的事务性，如下例所示。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">WITH d AS (</div><div class="line">  <span class="keyword">DELETE</span> <span class="keyword">FROM</span> foo</div><div class="line">),</div><div class="line">u <span class="keyword">as</span> (</div><div class="line">  <span class="keyword">UPDATE</span> foo <span class="keyword">SET</span> a = <span class="number">1</span></div><div class="line">  <span class="keyword">WHERE</span> b = <span class="number">2</span></div><div class="line">)</div><div class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> bar;</div></pre></td></tr></table></figure></p>
<h2 id="WITH使用注意事项"><a href="#WITH使用注意事项" class="headerlink" title="WITH使用注意事项"></a>WITH使用注意事项</h2><ol>
<li>WITH中的数据修改语句会被执行一次，并且肯定会完全执行，无论主语句是否读取或者是否读取所有其输出。而WITH中的SELECT语句则只输出主语句中所需要记录数。</li>
<li>WITH中使用多个子句时，这些子句和主语句会并行执行，所以当存在多个修改子语句修改相同的记录时，它们的结果不可预测。</li>
<li>所有的子句所能“看”到的数据集是一样的，所以它们看不到其它语句对目标数据集的影响。这也缓解了多子句执行顺序的不可预测性造成的影响。</li>
<li>如果在一条SQL语句中，更新同一记录多次，只有其中一条会生效，并且很难预测哪一个会生效。</li>
<li>如果在一条SQL语句中，同时更新和删除某条记录，则只有更新会生效。</li>
<li>目前，任何一个被数据修改CTE的表，不允许使用条件规则，和ALSO规则以及INSTEAD规则。</li>
</ol>
<h1 id="WITH-RECURSIVE"><a href="#WITH-RECURSIVE" class="headerlink" title="WITH RECURSIVE"></a>WITH RECURSIVE</h1><p>WITH语句还可以通过增加<code>RECURSIVE</code>修饰符来引入它自己，从而实现递归</p>
<h2 id="WITH-RECURSIVE实例"><a href="#WITH-RECURSIVE实例" class="headerlink" title="WITH RECURSIVE实例"></a>WITH RECURSIVE实例</h2><p>WITH RECURSIVE一般用于处理逻辑上层次化或树状结构的数据，典型的使用场景是寻找直接及间接子结点。</p>
<p>定义下面这样的表，存储每个区域（省、市、区）的id，名字及上级区域的id<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> chinamap</div><div class="line">(</div><div class="line">  <span class="keyword">id</span> <span class="built_in">INTEGER</span>,</div><div class="line">  pid <span class="built_in">INTEGER</span>,</div><div class="line">  <span class="keyword">name</span> <span class="built_in">TEXT</span></div><div class="line">);</div></pre></td></tr></table></figure></p>
<p>需要查出某个省，比如湖北省，管辖的所有市及市辖地区，可以通过WITH RECURSIVE来实现，如下<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">WITH RECURSIVE result AS</div><div class="line">(</div><div class="line">  SELECCT</div><div class="line">    id,</div><div class="line">    name</div><div class="line">  FROM  chinamap</div><div class="line">  WHERE id = 11</div><div class="line">  UNION ALL</div><div class="line">  <span class="keyword">SELECT</span></div><div class="line">    origin.id,</div><div class="line">    result.name || <span class="string">' &gt; '</span> || origin.name</div><div class="line">  <span class="keyword">FROM</span> <span class="keyword">result</span></div><div class="line">  <span class="keyword">JOIN</span> chinamap origin</div><div class="line">  <span class="keyword">ON</span> origin.pid = result.id</div><div class="line">)</div><div class="line"><span class="keyword">SELECT</span></div><div class="line">  <span class="keyword">id</span>,</div><div class="line">  <span class="keyword">name</span></div><div class="line"><span class="keyword">FROM</span> <span class="keyword">result</span>;</div></pre></td></tr></table></figure></p>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"> id  |           name           </div><div class="line">-----+--------------------------</div><div class="line">  11 | 湖北省</div><div class="line"> 110 | 湖北省 &gt; 武汉市</div><div class="line"> 120 | 湖北省 &gt; 孝感市</div><div class="line"> 130 | 湖北省 &gt; 宜昌市</div><div class="line"> 140 | 湖北省 &gt; 随州市</div><div class="line"> 150 | 湖北省 &gt; 仙桃市</div><div class="line"> 160 | 湖北省 &gt; 荆门市</div><div class="line"> 170 | 湖北省 &gt; 枝江市</div><div class="line"> 180 | 湖北省 &gt; 神农架市</div><div class="line"> 111 | 湖北省 &gt; 武汉市 &gt; 武昌区</div><div class="line"> 112 | 湖北省 &gt; 武汉市 &gt; 下城区</div><div class="line"> 113 | 湖北省 &gt; 武汉市 &gt; 江岸区</div><div class="line"> 114 | 湖北省 &gt; 武汉市 &gt; 江汉区</div><div class="line"> 115 | 湖北省 &gt; 武汉市 &gt; 汉阳区</div><div class="line"> 116 | 湖北省 &gt; 武汉市 &gt; 洪山区</div><div class="line"> 117 | 湖北省 &gt; 武汉市 &gt; 青山区</div><div class="line">(16 rows)</div></pre></td></tr></table></figure></p>
<h2 id="WITH-RECURSIVE-执行过程"><a href="#WITH-RECURSIVE-执行过程" class="headerlink" title="WITH RECURSIVE 执行过程"></a>WITH RECURSIVE 执行过程</h2><p>从上面的例子可以看出，WITH RECURSIVE语句包含了两个部分</p>
<ul>
<li>non-recursive term（非递归部分），即上例中的union all前面部分</li>
<li>recursive term（递归部分），即上例中union all后面部分</li>
</ul>
<p>执行步骤如下</p>
<ol>
<li>执行non-recursive term。（如果使用的是union而非union all，则需对结果去重）其结果作为recursive term中对result的引用，同时将这部分结果放入临时的working table中</li>
<li>重复执行如下步骤，直到working table为空：用working table的内容替换递归的自引用，执行recursive term，（如果使用union而非union all，去除重复数据），并用该结果（如果使用union而非union all，则是去重后的结果）替换working table</li>
</ol>
<p>以上面的query为例，来看看具体过程<br>1.执行<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span></div><div class="line">  <span class="keyword">id</span>,</div><div class="line">  <span class="keyword">name</span></div><div class="line"><span class="keyword">FROM</span> chinamap</div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="number">11</span></div></pre></td></tr></table></figure></p>
<p>结果集和working table为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">11 | 湖北</div></pre></td></tr></table></figure></p>
<p>2.执行<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span></div><div class="line">  origin.id,</div><div class="line">  result.name || <span class="string">' &gt; '</span> || origin.name</div><div class="line"><span class="keyword">FROM</span> <span class="keyword">result</span></div><div class="line"><span class="keyword">JOIN</span> chinamap origin</div><div class="line"><span class="keyword">ON</span> origin.pid = result.id</div></pre></td></tr></table></figure></p>
<p>结果集和working table为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">110 | 湖北省 &gt; 武汉市</div><div class="line">120 | 湖北省 &gt; 孝感市</div><div class="line">130 | 湖北省 &gt; 宜昌市</div><div class="line">140 | 湖北省 &gt; 随州市</div><div class="line">150 | 湖北省 &gt; 仙桃市</div><div class="line">160 | 湖北省 &gt; 荆门市</div><div class="line">170 | 湖北省 &gt; 枝江市</div><div class="line">180 | 湖北省 &gt; 神农架市</div></pre></td></tr></table></figure></p>
<p>3.再次执行recursive query，结果集和working table为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">111 | 湖北省 &gt; 武汉市 &gt; 武昌区</div><div class="line">112 | 湖北省 &gt; 武汉市 &gt; 下城区</div><div class="line">113 | 湖北省 &gt; 武汉市 &gt; 江岸区</div><div class="line">114 | 湖北省 &gt; 武汉市 &gt; 江汉区</div><div class="line">115 | 湖北省 &gt; 武汉市 &gt; 汉阳区</div><div class="line">116 | 湖北省 &gt; 武汉市 &gt; 洪山区</div><div class="line">117 | 湖北省 &gt; 武汉市 &gt; 青山区</div></pre></td></tr></table></figure></p>
<p>4.继续执行recursive query，结果集和working table为空<br>5.结束递归，将前三个步骤的结果集合并，即得到最终的WITH RECURSIVE的结果集</p>
<p>严格来讲，这个过程实现上是一个迭代的过程而非递归，不过RECURSIVE这个关键词是SQL标准委员会定立的，所以PostgreSQL也延用了RECURSIVE这一关键词。 </p>
<h2 id="WITH-RECURSIVE-防止死循环"><a href="#WITH-RECURSIVE-防止死循环" class="headerlink" title="WITH RECURSIVE 防止死循环"></a>WITH RECURSIVE 防止死循环</h2><p>从上一节中可以看到，决定是否继续迭代的working table是否为空，如果它永不为空，则该CTE将陷入无限循环中。<br>对于本身并不会形成循环引用的数据集，无段作特别处理。而对于本身可能形成循环引用的数据集，则须通过SQL处理。</p>
<p>一种方式是使用UNION而非UNION ALL，从而每次recursive term的计算结果都会将已经存在的数据清除后再存入working table，使得working table最终会为空，从而结束迭代。</p>
<p>然而，这种方法并不总是有效的，因为有时可能需要这些重复数据。同时UNION只能去除那些所有字段都完全一样的记录，而很有可能特定字段集相同的记录即应该被删除。此时可以通过数组（单字段）或者ROW（多字段）记录已经访问过的记录，从而实现去重的目的。</p>
<h2 id="WITH-RECURSIVE-求最短路径"><a href="#WITH-RECURSIVE-求最短路径" class="headerlink" title="WITH RECURSIVE 求最短路径"></a>WITH RECURSIVE 求最短路径</h2><p>定义无向有环图如下图所示<br><img src="http://www.jasongj.com/img/sql/5cte/graph.png" alt="Non-directional cycle graph"></p>
<p>定义如下表并存入每条边的权重<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> graph</div><div class="line">(</div><div class="line">  <span class="keyword">id</span> <span class="built_in">char</span>,</div><div class="line">  neighbor <span class="built_in">char</span>,</div><div class="line">  <span class="keyword">value</span> <span class="built_in">integer</span></div><div class="line">);</div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> graph</div><div class="line"><span class="keyword">VALUES</span>(<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="number">3</span>),</div><div class="line">(<span class="string">'A'</span>, <span class="string">'C'</span>, <span class="number">5</span>),</div><div class="line">(<span class="string">'A'</span>, <span class="string">'D'</span>, <span class="number">4</span>),</div><div class="line">(<span class="string">'B'</span>, <span class="string">'E'</span>, <span class="number">8</span>),</div><div class="line">(<span class="string">'B'</span>, <span class="string">'C'</span>, <span class="number">4</span>),</div><div class="line">(<span class="string">'E'</span>, <span class="string">'C'</span>, <span class="number">7</span>),</div><div class="line">(<span class="string">'E'</span>,<span class="string">'F'</span>, <span class="number">10</span>),</div><div class="line">(<span class="string">'C'</span>, <span class="string">'D'</span>, <span class="number">3</span>),</div><div class="line">(<span class="string">'C'</span>, <span class="string">'F'</span>, <span class="number">6</span>),</div><div class="line">(<span class="string">'F'</span>,<span class="string">'D'</span>, <span class="number">5</span>);</div></pre></td></tr></table></figure></p>
<p>计算思路如下：</p>
<ul>
<li>因为是无向图，所以首先要将各条边的id和neighbor交换一次以方便后续计算。</li>
<li>利用WITH RECURSIVE算出所有可能的路径并计算其总权重。</li>
<li>因为该图有环，为避免无限循环，同时为了计算路径，将经过的结点存于数据中，当下一个结点已经在数据中时，说明该结点已被计算。</li>
<li>最终可算出所有可能的路径及其总权重</li>
</ul>
<p>实现如下<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"> WITH RECURSIVE edges AS (</div><div class="line">  <span class="keyword">SELECT</span> <span class="keyword">id</span>, neighbor, <span class="keyword">value</span> <span class="keyword">FROM</span> graph</div><div class="line">  <span class="keyword">UNION</span> ALL</div><div class="line">  <span class="keyword">SELECT</span> neighbor, <span class="keyword">id</span>, <span class="keyword">value</span> </div><div class="line">  <span class="keyword">FROM</span> graph</div><div class="line">), </div><div class="line">all_path (<span class="keyword">id</span>, neighbor, <span class="keyword">value</span>, <span class="keyword">path</span>, <span class="keyword">depth</span>, <span class="keyword">cycle</span>) <span class="keyword">AS</span> (</div><div class="line">  <span class="keyword">SELECT</span></div><div class="line">    <span class="keyword">id</span>, neighbor, <span class="keyword">value</span>, <span class="built_in">ARRAY</span>[<span class="keyword">id</span>], <span class="number">1</span>, <span class="string">'f'</span>::<span class="built_in">BOOLEAN</span></div><div class="line">  <span class="keyword">FROM</span> edges</div><div class="line">  <span class="keyword">WHERE</span> <span class="keyword">id</span> = <span class="string">'A'</span></div><div class="line">  <span class="keyword">UNION</span> ALL</div><div class="line">  <span class="keyword">SELECT</span></div><div class="line">    all_path.id,</div><div class="line">    edges.neighbor,</div><div class="line">    edges.value + all_path.value,</div><div class="line">    all_path.path || <span class="built_in">ARRAY</span>[edges.id],</div><div class="line">    <span class="keyword">depth</span> + <span class="number">1</span>,</div><div class="line">    edges.id = <span class="keyword">ANY</span>(all_path.path)</div><div class="line">  <span class="keyword">FROM</span> edges</div><div class="line">  <span class="keyword">JOIN</span> all_path</div><div class="line">  <span class="keyword">ON</span> all_path.neighbor = edges.id</div><div class="line">  <span class="keyword">AND</span> <span class="keyword">NOT</span> <span class="keyword">cycle</span></div><div class="line">), a_f <span class="keyword">AS</span> (</div><div class="line">  <span class="keyword">SELECT</span></div><div class="line">    <span class="keyword">rank</span>() <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">value</span>) <span class="keyword">AS</span> <span class="keyword">rank</span>,</div><div class="line">    <span class="keyword">path</span> || neighbor <span class="keyword">AS</span> <span class="keyword">path</span>,</div><div class="line">    <span class="keyword">value</span>,</div><div class="line">    <span class="keyword">depth</span></div><div class="line">  <span class="keyword">FROM</span> all_path</div><div class="line">  <span class="keyword">WHERE</span> neighbor = <span class="string">'F'</span></div><div class="line">)</div><div class="line"><span class="keyword">SELECT</span> <span class="keyword">path</span>, <span class="keyword">value</span>, <span class="keyword">depth</span></div><div class="line"><span class="keyword">FROM</span> a_f</div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">rank</span> = <span class="number">1</span>;</div></pre></td></tr></table></figure></p>
<h1 id="WITH-RECURSIVE-使用限制"><a href="#WITH-RECURSIVE-使用限制" class="headerlink" title="WITH RECURSIVE 使用限制"></a>WITH RECURSIVE 使用限制</h1><ul>
<li>如果在recursive term中使用LEFT JOIN，自引用必须在“左”边</li>
<li>如果在recursive term中使用RIGHT JOIN，自引用必须在“右”边</li>
<li>recursive term中不允许使用FULL JOIN</li>
<li>recursive term中不允许使用GROUP BY和HAVING</li>
<li>不允许在recursive term的WHERE语句的子查询中使用CTE的名字</li>
<li>不支持在recursive term中对CTE作aggregation</li>
<li>recursive term中不允许使用ORDER BY</li>
<li>LIMIT / OFFSET不允许在recursive term中使用</li>
<li>FOR UPDATE不可在recursive term中使用</li>
<li>recursive term中SELECT后面不允许出现引用CTE名字的子查询</li>
<li>同时使用多个CTE表达式时，不允许多表达式之间互相访问（支持单向访问）</li>
<li>在recursive term中不允许使用FOR UPDATE</li>
</ul>
<h1 id="CTE-优缺点"><a href="#CTE-优缺点" class="headerlink" title="CTE 优缺点"></a>CTE 优缺点</h1><ul>
<li>可以使用递归 WITH RECURSIVE，从而实现其它方式无法实现或者不容易实现的查询</li>
<li>当不需要将查询结果被其它独立查询共享时，它比视图更灵活也更轻量</li>
<li>CTE只会被计算一次，且可在主查询中多次使用</li>
<li>CTE可极大提高代码可读性及可维护性</li>
<li>CTE不支持将主查询中where后的限制条件push down到CTE中，而普通的子查询支持</li>
</ul>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a>
　　</li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文结合实例介绍了CTE（Common Table Expressions，通用表达式）的用法，优缺点，并详细阐述了递归CTE的执行步骤及使用方法。同时给出了使用WITH RECURSIVE计算图的最短路径方案。
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式（一） 简单工厂模式不简单</title>
    <link href="http://www.jasongj.com/design_pattern/simple_factory/"/>
    <id>http://www.jasongj.com/design_pattern/simple_factory/</id>
    <published>2016-03-08T12:49:04.000Z</published>
    <updated>2017-02-17T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/design_pattern/simple_factory">原文链接</a>　<a href="http://www.jasongj.com/design_pattern/simple_factory">http://www.jasongj.com/design_pattern/simple_factory</a></p>
</blockquote>
<h1 id="简单工厂模式使用案例"><a href="#简单工厂模式使用案例" class="headerlink" title="简单工厂模式使用案例"></a>简单工厂模式使用案例</h1><p>有一种抽象产品——汽车（Car），同时有多种具体的子类产品，如BenzCar，BMWCar，LandRoverCar。类图如下<br><img src="http://www.jasongj.com/img/designpattern/simplefactory/product.png" alt="Product class diagram"></p>
<p>作为司机，如果要开其中一种车，比如BenzCar，最直接的做法是直接创建BenzCar的实例，并执行其drive方法，如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.product.BenzCar;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Driver1</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    BenzCar car = <span class="keyword">new</span> BenzCar();</div><div class="line">    car.drive();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>此时如果要改为开Land Rover，则需要修改代码，创建Land Rover的实例并执行其drive方法。这也就意味着任何时候需要换一辆车开的时候，都必须修改客户端代码。</p>
<p>一种稍微好点的方法是，通过读取配置文件，获取需要开的车，然后创建相应的实例并由父类Car的引用指向它，利用多态执行不同车的drive方法。如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.ConfigurationException;</div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.XMLConfiguration;</div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.product.BMWCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.BenzCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.Car;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.LandRoverCar;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Driver2</span> </span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(Driver2.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ConfigurationException </span>&#123;</div><div class="line">    XMLConfiguration config = <span class="keyword">new</span> XMLConfiguration(<span class="string">"car.xml"</span>);</div><div class="line">    String name = config.getString(<span class="string">"driver2.name"</span>);</div><div class="line">    Car car;</div><div class="line"></div><div class="line">    <span class="keyword">switch</span> (name) &#123;</div><div class="line">    <span class="keyword">case</span> <span class="string">"Land Rover"</span>:</div><div class="line">      car = <span class="keyword">new</span> LandRoverCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">case</span> <span class="string">"BMW"</span>:</div><div class="line">      car = <span class="keyword">new</span> BMWCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">case</span> <span class="string">"Benz"</span>:</div><div class="line">      car = <span class="keyword">new</span> BenzCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">default</span>:</div><div class="line">      car = <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line">    LOG.info(<span class="string">"Created car name is &#123;&#125;"</span>, name);</div><div class="line">    car.drive();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>对于Car的使用方而言，只需要通过参数即可指定所需要Car的各类并得到其实例，同时无论使用哪种Car，都不需要修改后续对Car的操作。至此，简单工厂模式的原型已经形成。如果把上述的逻辑判断封装到一个专门的类的静态方法中，则实现了简单工厂模式。工厂代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.factory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.ConfigurationException;</div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.XMLConfiguration;</div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.product.BMWCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.BenzCar;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.Car;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.LandRoverCar;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarFactory1</span> </span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(CarFactory1.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Car <span class="title">newCar</span><span class="params">()</span> </span>&#123;</div><div class="line">    Car car = <span class="keyword">null</span>;</div><div class="line">    String name = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      XMLConfiguration config = <span class="keyword">new</span> XMLConfiguration(<span class="string">"car.xml"</span>);</div><div class="line">      name = config.getString(<span class="string">"factory1.name"</span>);</div><div class="line">    &#125; <span class="keyword">catch</span> (ConfigurationException ex) &#123;</div><div class="line">      LOG.error(<span class="string">"parse xml configuration file failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">switch</span> (name) &#123;</div><div class="line">    <span class="keyword">case</span> <span class="string">"Land Rover"</span>:</div><div class="line">      car = <span class="keyword">new</span> LandRoverCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">case</span> <span class="string">"BMW"</span>:</div><div class="line">      car = <span class="keyword">new</span> BMWCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">case</span> <span class="string">"Benz"</span>:</div><div class="line">      car = <span class="keyword">new</span> BenzCar();</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">default</span>:</div><div class="line">      car = <span class="keyword">null</span>;</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line">    LOG.info(<span class="string">"Created car name is &#123;&#125;"</span>, name);</div><div class="line">    <span class="keyword">return</span> car;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>调用方代码如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.factory.CarFactory1;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.Car;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Driver3</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Car car = CarFactory1.newCar();</div><div class="line">    car.drive();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>与Driver2相比，所有的判断逻辑都封装在工厂(CarFactory1)当中，Driver3不再需要关心Car的实例化，实现了对象的创建和使用的隔离。</p>
<p>当然，简单工厂模式并不要求一定要读配置文件来决定实例化哪个类，可以把参数作为工厂静态方法的参数传入。</p>
<h1 id="简单工厂模式进阶"><a href="#简单工厂模式进阶" class="headerlink" title="简单工厂模式进阶"></a>简单工厂模式进阶</h1><h2 id="使用反射实现扩展性"><a href="#使用反射实现扩展性" class="headerlink" title="使用反射实现扩展性"></a>使用反射实现扩展性</h2><p>从Driver2和CarFactory1的实现中可以看到，当有新的车加入时，需要更新Driver2和CarFactory1的代码也实现对新车的支持。这就违反了<code>开闭原则</code>（Open-Close Principle）。可以利用反射（Reflection）解决该问题。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.factory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.ConfigurationException;</div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.XMLConfiguration;</div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.product.Car;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarFactory2</span> </span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(CarFactory2.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Car <span class="title">newCar</span><span class="params">()</span> </span>&#123;</div><div class="line">    Car car = <span class="keyword">null</span>;</div><div class="line">    String name = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      XMLConfiguration config = <span class="keyword">new</span> XMLConfiguration(<span class="string">"car.xml"</span>);</div><div class="line">      name = config.getString(<span class="string">"factory2.class"</span>);</div><div class="line">    &#125; <span class="keyword">catch</span> (ConfigurationException ex) &#123;</div><div class="line">      LOG.error(<span class="string">"Parsing xml configuration file failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      car = (Car)Class.forName(name).newInstance();</div><div class="line">      LOG.info(<span class="string">"Created car class name is &#123;&#125;"</span>, name);</div><div class="line">    &#125; <span class="keyword">catch</span> (InstantiationException | IllegalAccessException | ClassNotFoundException e) &#123;</div><div class="line">      LOG.error(<span class="string">"Instantiate car &#123;&#125; failed"</span>, name);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> car;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面代码中可以看到，之后如果需要引入新的Car，只需要在配置文件中指定该Car的完整类名（包括package名），CarFactory2即可通过反射将其实例化。实现了对扩展的开放，同时保证了对修改的关闭。熟悉Spring的读者应该会想到Spring IoC的实现。</p>
<h2 id="注解让简单工厂模式不简单"><a href="#注解让简单工厂模式不简单" class="headerlink" title="注解让简单工厂模式不简单"></a>注解让简单工厂模式不简单</h2><p>上例中使用反射做到了对扩展开放，对修改关闭。但有些时候，使用类的全名不太方便，使用别名会更合适。例如Spring中每个Bean都会有个ID，引用Bean时也会通过ID去引用。像Apache Nifi这样的数据流工具，在流程上使用了职责链模式，而对于单个Processor的创建则使用了工厂，对于用户自定义的Processor并不需要通过代码去注册，而是使用注解（为了更方便理解下面这段代码，请先阅读笔者另外一篇文章<a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">《Java系列（一）Annotation（注解）》</a>）。</p>
<p>下面就继续在上文案例的基础上使用注解升级简单工厂模式。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.factory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.Collections;</div><div class="line"><span class="keyword">import</span> java.util.Map;</div><div class="line"><span class="keyword">import</span> java.util.Set;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.ConfigurationException;</div><div class="line"><span class="keyword">import</span> org.apache.commons.configuration.XMLConfiguration;</div><div class="line"><span class="keyword">import</span> org.reflections.Reflections;</div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.annotation.Vehicle;</div><div class="line"><span class="keyword">import</span> com.jasongj.product.Car;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarFactory3</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(CarFactory3.class);</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, Class&gt; allCars;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">    Reflections reflections = <span class="keyword">new</span> Reflections(<span class="string">"com.jasongj.product"</span>);</div><div class="line">    Set&lt;Class&lt;?&gt;&gt; annotatedClasses = reflections.getTypesAnnotatedWith(Vehicle.class);</div><div class="line">    allCars = <span class="keyword">new</span> ConcurrentHashMap&lt;String, Class&gt;();</div><div class="line">    <span class="keyword">for</span> (Class&lt;?&gt; classObject : annotatedClasses) &#123;</div><div class="line">      Vehicle vehicle = (Vehicle) classObject.getAnnotation(Vehicle.class);</div><div class="line">      allCars.put(vehicle.type(), classObject);</div><div class="line">    &#125;</div><div class="line">    allCars = Collections.unmodifiableMap(allCars);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Car <span class="title">newCar</span><span class="params">()</span> </span>&#123;</div><div class="line">    Car car = <span class="keyword">null</span>;</div><div class="line">    String type = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      XMLConfiguration config = <span class="keyword">new</span> XMLConfiguration(<span class="string">"car.xml"</span>);</div><div class="line">      type = config.getString(<span class="string">"factory3.type"</span>);</div><div class="line">      LOG.info(<span class="string">"car type is &#123;&#125;"</span>, type);</div><div class="line">    &#125; <span class="keyword">catch</span> (ConfigurationException ex) &#123;</div><div class="line">      LOG.error(<span class="string">"Parsing xml configuration file failed"</span>, ex);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (allCars.containsKey(type)) &#123;</div><div class="line">      LOG.info(<span class="string">"created car type is &#123;&#125;"</span>, type);</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        car = (Car) allCars.get(type).newInstance();</div><div class="line">      &#125; <span class="keyword">catch</span> (InstantiationException | IllegalAccessException ex) &#123;</div><div class="line">        LOG.error(<span class="string">"Instantiate car failed"</span>, ex);</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      LOG.error(<span class="string">"specified car type &#123;&#125; does not exist"</span>, type);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> car;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从上面代码中可以看到，该工厂会扫描所有被Vehicle注解的Car（每种Car都在注解中声明了自己的type，可作为该种Car的别名）然后建立起Car别名与具体Car的Class原映射。此时工厂的静态方法即可根据目标别名实例化对应的Car。</p>
<p>本文所有代码都可从<a href="https://github.com/habren/JavaDesignPattern/tree/master/SimpleFactoryPattern/src/main" target="_blank" rel="external">作者GitHub</a>下载.</p>
<h1 id="简单工厂模式详解"><a href="#简单工厂模式详解" class="headerlink" title="简单工厂模式详解"></a>简单工厂模式详解</h1><h2 id="简单工厂模式定义"><a href="#简单工厂模式定义" class="headerlink" title="简单工厂模式定义"></a>简单工厂模式定义</h2><p>简单工厂模式（Simple Factory Pattern）又叫静态工厂方法模式（Static FactoryMethod Pattern）。专门定义一个类（如上文中的CarFactory1、CarFactory2、CarFactory3）来负责创建其它类的实例，由它来决定实例化哪个具体类，从而避免了在客户端代码中显式指定，实现了解耦。该类由于可以创建同一抽象类（或接口）下的不同子类对象，就像一个工厂一样，因此被称为工厂类。</p>
<h2 id="简单工厂模式类图"><a href="#简单工厂模式类图" class="headerlink" title="简单工厂模式类图"></a>简单工厂模式类图</h2><p>简单工厂模式类图如下所示<br><img src="http://www.jasongj.com/img/designpattern/simplefactory/simple_factory.png" alt="Simple factory pettern class diagram"></p>
<h2 id="简单工厂模式角色划分"><a href="#简单工厂模式角色划分" class="headerlink" title="简单工厂模式角色划分"></a>简单工厂模式角色划分</h2><ul>
<li>工厂角色（如上文中的CarFactory1/2/3）：这是简单工厂模式的核心，由它负责创建所有的类的内部逻辑。当然工厂类必须能够被外界调用，创建所需要的产品对象。一般而言，工厂类提供一个静态方法，外部程序通过该方法创建所需对象。</li>
<li>抽象产品角色(如上文中的Car)：简单工厂模式所创建的是所有对象的父类。注意，这里的父类可以是接口也可以是抽象类，它负责描述所创建实例共有的公共接口。</li>
<li>具体产品角色（如上文中的BMWCar，BenzCar，LandRoverCar）：简单工厂所创建的具体实例对象，这些具体的产品往往都拥有共同的父类。</li>
</ul>
<h2 id="简单工厂模式优点"><a href="#简单工厂模式优点" class="headerlink" title="简单工厂模式优点"></a>简单工厂模式优点</h2><ul>
<li>工厂类是整个简单工厂模式的关键所在。它包含必要的判断逻辑，能够根据外界给定的信息（配置，或者参数），决定究竟应该创建哪个具体类的对象。用户在使用时可以直接根据工厂类去创建所需的实例，而无需了解这些对象是如何创建以及如何组织的。有利于整个软件体系结构的优化。</li>
<li>通过引入配置文件和反射，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性（如CarFactory2）。</li>
<li>客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量（如CarFactory3）。</li>
</ul>
<h2 id="简单工厂模式缺点"><a href="#简单工厂模式缺点" class="headerlink" title="简单工厂模式缺点"></a>简单工厂模式缺点</h2><ul>
<li>由于工厂类集中了所有实例的创建逻辑，这就直接导致一旦这个工厂出了问题，所有的客户端都会受到牵连。</li>
<li>由于简单工厂模式的产品是基于一个共同的抽象类或者接口，这样一来，产品的种类增加的时候，即有不同的产品接口或者抽象类的时候，工厂类就需要判断何时创建何种接口的产品，这就和创建何种种类的产品相互混淆在了一起，违背了单一职责原则，导致系统丧失灵活性和可维护性。</li>
<li>正如上文提到的，一般情况下（如CarFactory1），简单工厂模式违背了“开放-关闭原则”，因为当我们新增加一个产品的时候必须修改工厂类，相应的工厂类就需要重新编译一遍。但这一点可以利用反射（CarFactory3在本质上也是利用反射）在一定程度上解决（如CarFactory2）。</li>
<li>使用反射可以使简单工厂在一定条件下满足“开放-关闭原则”，但这仅限于产品类的构造及初始化相同的场景。对于各产品实例化或者初始化不同的场景，很难利用反射满足“开放-关闭”原则。</li>
<li>简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。这一点笔者持保留态度，因为继承不是目的，如果没有这样的需求，这一点完全不算缺点，例如JDBC的DriverManager。</li>
</ul>
<h1 id="简单工厂模式与OOP原则"><a href="#简单工厂模式与OOP原则" class="headerlink" title="简单工厂模式与OOP原则"></a>简单工厂模式与OOP原则</h1><h2 id="已遵循的原则"><a href="#已遵循的原则" class="headerlink" title="已遵循的原则"></a>已遵循的原则</h2><ul>
<li>依赖倒置原则</li>
<li>迪米特法则</li>
<li>里氏替换原则</li>
<li>接口隔离原则</li>
</ul>
<h2 id="未遵循的原则"><a href="#未遵循的原则" class="headerlink" title="未遵循的原则"></a>未遵循的原则</h2><ul>
<li>开闭原则（如上文所述，利用配置文件+反射或者注解可以避免这一点）</li>
<li>单一职责原则（工厂类即要负责逻辑判断又要负责实例创建）</li>
</ul>
<h1 id="简单工厂模式在JDK中的典型应用"><a href="#简单工厂模式在JDK中的典型应用" class="headerlink" title="简单工厂模式在JDK中的典型应用"></a>简单工厂模式在JDK中的典型应用</h1><p>简单工厂模式在JDK中最典型的应用要数JDBC了。可以把关系型数据库认为是一种抽象产品，各厂商提供的具体关系型数据库（MySQL，PostgreSQL，Oracle）则是具体产品。DriverManager是工厂类。应用程序通过JDBC接口使用关系型数据库时，并不需要关心具体使用的是哪种数据库，而直接使用DriverManager的静态方法去得到该数据库的Connection。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.client;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.sql.Connection;</div><div class="line"><span class="keyword">import</span> java.sql.DriverManager;</div><div class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</div><div class="line"><span class="keyword">import</span> java.sql.SQLException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.slf4j.Logger;</div><div class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JDBC</span> </span>&#123;</div><div class="line">  </div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(JDBC.class);</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Connection conn = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      Class.forName(<span class="string">"org.apache.hive.jdbc.HiveDriver"</span>);</div><div class="line">      conn = DriverManager.getConnection(<span class="string">"jdbc:hive2://127.0.0.1:10000/default"</span>);</div><div class="line">      PreparedStatement ps = conn.prepareStatement(<span class="string">"select count(*) from test.test"</span>);</div><div class="line">      ps.execute();</div><div class="line">    &#125; <span class="keyword">catch</span> (SQLException ex) &#123;</div><div class="line">      LOG.warn(<span class="string">"Execute query failed"</span>, ex);</div><div class="line">    &#125; <span class="keyword">catch</span>(ClassNotFoundException e) &#123;</div><div class="line">      LOG.warn(<span class="string">"Load Hive driver failed"</span>, e);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      <span class="keyword">if</span>(conn != <span class="keyword">null</span> )&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          conn.close();</div><div class="line">        &#125; <span class="keyword">catch</span> (SQLException e) &#123;</div><div class="line">          <span class="comment">// NO-OPT</span></div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="Java设计模式系列"><a href="#Java设计模式系列" class="headerlink" title="Java设计模式系列"></a>Java设计模式系列</h1><ul>
<li><a href="http://www.jasongj.com/design_pattern/simple_factory/">Java设计模式（一） 简单工厂模式不简单</a></li>
<li><a href="http://www.jasongj.com/design_pattern/factory_method/">Java设计模式（二） 工厂方法模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/abstract_factory/">Java设计模式（三） 抽象工厂模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/observer/">Java设计模式（四） 观察者模式 </a></li>
<li><a href="http://www.jasongj.com/design_pattern/composite/">Java设计模式（五） 组合模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/proxy_decorator/">Java设计模式（六） 代理模式 VS. 装饰模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/dynamic_proxy_cglib/">Java设计模式（七） Spring AOP JDK动态代理 vs. cglib</a></li>
<li><a href="http://www.jasongj.com/design_pattern/adapter/">Java设计模式（八） 适配器模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/bridge/">Java设计模式（九） 桥接模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/singleton/">Java设计模式（十） 你真的用对单例模式了吗？</a></li>
<li><a href="http://www.jasongj.com/design_pattern/flyweight/">Java设计模式（十一） 享元模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/strategy/">Java设计模式（十二） 策略模式</a></li>
<li><a href="http://www.jasongj.com/design_pattern/summary/">Java设计模式（十三） 别人再问你设计模式，叫他看这篇文章</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了简单工厂模式的概念，优缺点，实现方式，以及结合Annotation和反射的改良方案。同时介绍了简单工厂模式（未）遵循的OOP原则。最后给出了简单工厂模式在JDBC中的应用
    
    </summary>
    
      <category term="设计模式" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Design-Pattern/"/>
    
    
      <category term="Java" scheme="http://www.jasongj.com/tags/Java/"/>
    
      <category term="设计模式" scheme="http://www.jasongj.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="Design Pattern" scheme="http://www.jasongj.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>Java进阶（一）Annotation（注解）</title>
    <link href="http://www.jasongj.com/2016/01/17/Java1_%E6%B3%A8%E8%A7%A3Annotation/"/>
    <id>http://www.jasongj.com/2016/01/17/Java1_注解Annotation/</id>
    <published>2016-01-17T07:11:29.000Z</published>
    <updated>2017-02-15T12:31:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation">原文链接</a>　<a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation">http://www.jasongj.com/2016/01/17/Java1_注解Annotation</a></p>
</blockquote>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>Annotation是Java5开始引入的特性。它提供了一种安全的类似于注释和Java doc的机制。实事上，Annotation已经被广泛用于各种Java框架，如Spring，Jersey，JUnit，TestNG。注解相当于是一种嵌入在程序中的元数据，可以使用注解解析工具或编译器对其进行解析，也可以指定注解在编译期或运行期有效。这些元数据与程序业务逻辑无关，并且是供指定的工具或框架使用的。</p>
<h1 id="Meta-Annotation"><a href="#Meta-Annotation" class="headerlink" title="Meta Annotation"></a>Meta Annotation</h1><p>元注解的作用就是负责注解其他注解。Java5定义了4个标准的Meta Annotation类型，它们被用来提供对其它 Annotation类型作说明。</p>
<h2 id="Target"><a href="#Target" class="headerlink" title="@Target"></a>@Target</h2><p><code>@Target</code>说明了Annotation所修饰的对象范围：Annotation可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了<code>@Target</code>可更加明晰其修饰的目标。</p>
<p><code>@Target</code>作用：用于描述注解的使用范围，即被描述的注解可以用在什么地方</p>
<p><code>@Target</code>取值(ElementType)</p>
<ul>
<li><code>CONSTRUCTOR</code>：用于描述构造器</li>
<li><code>FIELD</code>：用于描述域</li>
<li><code>LOCAL_VARIABLE</code>：用于描述局部变量</li>
<li><code>METHOD</code>：用于描述方法</li>
<li><code>PACKAGE</code>：用于描述包</li>
<li><code>PARAMETER</code>：用于描述参数</li>
<li><code>TYPE</code>：用于描述类、接口(包括注解类型) 或enum声明</li>
</ul>
<h2 id="Retention"><a href="#Retention" class="headerlink" title="@Retention"></a>@Retention</h2><p><code>@Retention</code>定义了该Annotation的生命周期：某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中；编译在class文件中的Annotation可能会被虚拟机忽略，而另一些在class被装载时将被读取（请注意并不影响class的执行，因为Annotation与class在使用上是被分离的）。<code>@Retention</code>有唯一的value作为成员。</p>
<p><code>@Retention</code>作用：表示需要在什么级别保存该注释信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效）</p>
<p><code>@Retention</code>取值来自<code>java.lang.annotation.RetentionPolicy</code>的枚举类型值</p>
<ul>
<li>SOURCE:在源文件中有效（即源文件保留）</li>
<li>CLASS:在class文件中有效（即class保留）</li>
<li>RUNTIME:在运行时有效（即运行时保留）</li>
</ul>
<h2 id="Documented"><a href="#Documented" class="headerlink" title="@Documented"></a>@Documented</h2><p><code>@Documented</code>用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。<code>@Documented</code>是一个标记注解，没有成员。</p>
<h2 id="Inherited"><a href="#Inherited" class="headerlink" title="@Inherited"></a>@Inherited</h2><p><code>@Inherited</code> 是一个标记注解。如果一个使用了<code>@Inherited</code>修饰的annotation类型被用于一个class，则这个Annotation将被用于该class的子类。</p>
<h1 id="自定义Annotation"><a href="#自定义Annotation" class="headerlink" title="自定义Annotation"></a>自定义Annotation</h1><p>在实际项目中，经常会碰到下面这种场景，一个接口的实现类或者抽象类的子类很多，经常需要根据不同情况（比如根据配置文件）实例化并使用不同的子类。典型的例子是结合工厂使用职责链模式。</p>
<p>此时，可以为每个实现类加上特定的Annotation，并在Annotation中给该类取一个标识符，应用程序可通过该标识符来判断应该实例化哪个子类。</p>
<p>下面这个例子，定义了一个名为Component的Annotation，它包含一个名为identifier的成员变量。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj.annotation;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.lang.annotation.Documented;</div><div class="line"><span class="keyword">import</span> java.lang.annotation.RetentionPolicy;</div><div class="line"><span class="keyword">import</span> java.lang.annotation.Target;</div><div class="line"><span class="keyword">import</span> java.lang.annotation.ElementType;</div><div class="line"><span class="keyword">import</span> java.lang.annotation.Inherited;</div><div class="line"><span class="keyword">import</span> java.lang.annotation.Retention;</div><div class="line"></div><div class="line"><span class="meta">@Target</span>(ElementType.TYPE)</div><div class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</div><div class="line"><span class="meta">@Documented</span></div><div class="line"><span class="meta">@Inherited</span></div><div class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Component &#123;</div><div class="line">	<span class="function">String <span class="title">identifier</span> <span class="params">()</span> <span class="keyword">default</span> ""</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>对于上文所说的实现类加上<code>@Component</code><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.annotation.Component;</div><div class="line"></div><div class="line"><span class="meta">@Component</span>(identifier=<span class="string">"upper"</span>)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UpperCaseComponent</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">doWork</span><span class="params">(String input)</span> </span>&#123;</div><div class="line">		<span class="keyword">if</span>(input != <span class="keyword">null</span>) &#123;</div><div class="line">			<span class="keyword">return</span> input.toUpperCase();</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>应用程序中可以通过反射获取UpperCaseComponent对应的identifier<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.jasongj;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.jasongj.annotation.Component;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Class componentClass = Class.forName(<span class="string">"com.jasongj.UpperCaseComponent"</span>);</div><div class="line">            <span class="keyword">if</span>(componentClass.isAnnotationPresent(Component.class)) &#123;</div><div class="line">                Component component = (Component)componentClass.getAnnotation(Component.class);</div><div class="line">                String identifier = component.identifier();</div><div class="line">                System.out.println(String.format(<span class="string">"Identifier for "</span></div><div class="line">                    + <span class="string">"com.jasongj.UpperCaseComponent is ' %s '"</span>, identifier));</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                System.out.println(<span class="string">"com.jasongj.UpperCaseComponent is not annotated by"</span></div><div class="line">						+ <span class="string">" com.jasongj.annotation.Component"</span>);</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException ex) &#123;</div><div class="line">			ex.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>结果如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Identifier for com.jasongj.UpperCaseComponent is &apos; upper &apos;</div></pre></td></tr></table></figure></p>
<p>如果把<code>@Component</code>的<code>@Retention</code>设置为    <code>RetentionPolicy.SOURCE</code>或者<code>RetentionPolicy.CLASS</code>，则会得到如下结果，验证了上文中对<code>@Retention</code>的描述<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">com.jasongj.UpperCaseComponent is not annotated by com.jasongj.annotation.Component</div></pre></td></tr></table></figure></p>
<h1 id="Java内置Annotation"><a href="#Java内置Annotation" class="headerlink" title="Java内置Annotation"></a>Java内置Annotation</h1><p>Annotation的语法比较简单，除了@符号的使用外，他基本与Java固有的语法一致，JavaSE中内置三个标准Annotation，定义在<code>java.lang</code>中：</p>
<ol>
<li><code>@Override</code> 是一个标记型Annotation，说明了被标注的方法覆盖了父类的方法，起到了断言的作用。如果给一个非覆盖父类方法的方法添加该Annotation，编译器将报编译错误。它有两个典型的使用场景，一是在试图覆盖父类方法却写错了方法名时报错，二是删除已被子类覆盖（且用Annotation修饰）的父类方法时报错。</li>
<li><code>@Deprecated</code> 标记型Annotation，说明被修改的元素已被废弃并不推荐使用，编译器会在该元素上加一条横线以作提示。该修饰具有一定的“传递性”：如果我们通过继承的方式使用了这个弃用的元素，即使继承后的元素（类，成员或者方法）并未被标记为<code>@Deprecated</code>，编译器仍然会给出提示。</li>
<li><code>@SuppressWarnnings</code> 用于通知Java编译器关闭对特定类、方法、成员变量、变量初始化的警告。此种警告一般代表了可能的程序错误，例如当我们使用一个generic collection类而未提供它的类型时，编译器将提示“unchecked warning”的警告。通常当这种情况发生时，我们需要查找引起警告的代码，如果它真的表示错误，我们就需要纠正它。然而，有时我们无法避免这种警告，例如，我们使用必须和非generic的旧代码交互的generic collection类时，我们无法避免这个unchecked warning，此时可以在调用的方法前增加<code>@SuppressWarnnings</code>通知编译器关闭对此方法的警告。</li>
</ol>
<p><code>@SuppressWarnnings</code>不是标记型Annotation，它有一个类型为String[]的成员，这个成员的值为被禁止的警告名。常见的警告名为下。</p>
<ul>
<li><code>unchecked</code> 执行了未检查的转换时的警告。例如当使用集合时没有用泛型来指定集合的类型</li>
<li><code>finally</code> finally子句不能正常完成时的警告</li>
<li><code>fallthrough</code> 当switch程序块直接通往下一种情况而没有break时的警告</li>
<li><code>deprecation</code> 使用了弃用的类或者方法时的警告</li>
<li><code>seriel</code> 在可序列化的类上缺少serialVersionUID时的警告</li>
<li><code>path</code> 在类路径、源文件路径等中有不存在的路径时的警告</li>
<li><code>all</code> 对以上所有情况的警告</li>
</ul>
<h1 id="Annotation与Interface的异同"><a href="#Annotation与Interface的异同" class="headerlink" title="Annotation与Interface的异同"></a>Annotation与Interface的异同</h1><ul>
<li>Annotation类型使用关键字<code>@interface</code>而非<code>interface</code>。注意开头的<code>@</code>符号</li>
<li>Annotataion的方法定义是受限制的。其方法必须声明为无参数、无异常抛出的。这些方法同时也定义了Annotation的成员——方法名即为成员名，而方法返回类型即为成员类型。方法返回类型必须为Java基础类型、Class类型、枚举类型、Annotation类型或者相应的一维数组。方法后面可以使用default关键字和一个默认数值来声明成员的默认值，null不能作为成员默认值。成员一般不能是泛型，只有当其类型是Class时可以使用泛型，因为此方法能够用类型转换将各种类型转换为Class</li>
<li>Annotation和interface都可以定义常量、静态成员类型，也都可以被实现或者继承</li>
</ul>
<h1 id="Java进阶系列"><a href="#Java进阶系列" class="headerlink" title="Java进阶系列"></a>Java进阶系列</h1><ul>
<li><a href="http://www.jasongj.com/2016/01/17/Java1_注解Annotation/">Java进阶（一）Annotation（注解）</a></li>
<li><a href="http://www.jasongj.com/java/thread_safe">Java进阶（二）当我们说线程安全时，到底在说什么</a></li>
<li><a href="http://www.jasongj.com/java/multi_thread">Java进阶（三）多线程开发关键技术</a></li>
<li><a href="http://www.jasongj.com/java/thread_communication">Java进阶（四）线程间通信方式对比</a></li>
<li><a href="http://www.jasongj.com/java/nio_reactor/">Java进阶（五）NIO和Reactor模式进阶</a></li>
<li><a href="http://www.jasongj.com/java/concurrenthashmap/">Java进阶（六）从ConcurrentHashMap的演进看Java多线程核心技术</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Java Annotation的概念及Java提供的四种Meta Annotation的功能，并结合实例详解了自定义Annotation的方法和注意事项
    
    </summary>
    
      <category term="java" scheme="http://www.jasongj.com/categories/java/"/>
    
    
      <category term="java" scheme="http://www.jasongj.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</title>
    <link href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/"/>
    <id>http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/</id>
    <published>2015-12-30T23:01:27.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。（已授权<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-5" target="_blank" rel="external">InfoQ中文站发布</a>）<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark">原文链接</a>　<a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark">http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>　　本文主要介绍了如何利用Kafka自带的性能测试脚本及Kafka Manager测试Kafka的性能，以及如何使用Kafka Manager监控Kafka的工作状态，最后给出了Kafka的性能测试报告。</p>
<h1 id="性能测试及集群监控工具"><a href="#性能测试及集群监控工具" class="headerlink" title="性能测试及集群监控工具"></a>性能测试及集群监控工具</h1><p>　　Kafka提供了非常多有用的工具，如<a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a>中提到的运维类工具——Partition Reassign Tool，Preferred Replica Leader Election Tool，Replica Verification Tool，State Change Log Merge Tool。本文将介绍Kafka提供的性能测试工具，Metrics报告工具及Yahoo开源的Kafka Manager。</p>
<h2 id="Kafka性能测试脚本"><a href="#Kafka性能测试脚本" class="headerlink" title="Kafka性能测试脚本"></a>Kafka性能测试脚本</h2><ul>
<li><code>$KAFKA_HOME/bin/kafka-producer-perf-test.sh</code> 该脚本被设计用于测试Kafka Producer的性能，主要输出4项指标，总共发送消息量（以MB为单位），每秒发送消息量（MB/second），发送消息总数，每秒发送消息数（records/second）。除了将测试结果输出到标准输出外，该脚本还提供CSV Reporter，即将结果以CSV文件的形式存储，便于在其它分析工具中使用该测试结果</li>
<li><code>$KAFKA_HOME/bin/kafka-consumer-perf-test.sh</code> 该脚本用于测试Kafka Consumer的性能，测试指标与Producer性能测试脚本一样</li>
</ul>
<h2 id="Kafka-Metrics"><a href="#Kafka-Metrics" class="headerlink" title="Kafka Metrics"></a>Kafka Metrics</h2><p>　　Kafka使用<a href="http://metrics.dropwizard.io" target="_blank" rel="external">Yammer Metrics</a>来报告服务端和客户端的Metric信息。Yammer Metrics 3.1.0提供6种形式的Metrics收集——Meters，Gauges，Counters，Histograms，Timers，Health Checks。与此同时，Yammer Metrics将Metric的收集与报告（或者说发布）分离，可以根据需要自由组合。目前它支持的Reporter有Console Reporter，JMX Reporter，HTTP Reporter，CSV Reporter，SLF4J Reporter，Ganglia Reporter，Graphite Reporter。因此，Kafka也支持通过以上几种Reporter输出其Metrics信息。</p>
<h3 id="使用JConsole查看单服务器Metrics"><a href="#使用JConsole查看单服务器Metrics" class="headerlink" title="使用JConsole查看单服务器Metrics"></a>使用JConsole查看单服务器Metrics</h3><p>　　使用JConsole通过JMX，是在不安装其它工具（既然已经安装了Kafka，就肯定安装了Java，而JConsole是Java自带的工具）的情况下查看Kafka服务器Metrics的最简单最方便的方法之一。<br>　　首先必须通过为环境变量JMX_PORT设置有效值来启用Kafka的JMX Reporter。如<code>export JMX_PORT=19797</code>。然后即可使用JConsole通过上面设置的端口来访问某一台Kafka服务器来查看其Metrics信息，如下图所示。</p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/jconsole.png" alt="JConsole Kafka JMX"><br>　　使用JConsole的一个好处是不用安装额外的工具，缺点很明显，数据展示不够直观，数据组织形式不友好，更重要的是不能同时监控整个集群的Metrics。在上图中，在kafka.cluster-&gt;Partition-&gt;UnderReplicated-&gt;topic4下，只有2和5两个节点，这并非因为topic4只有这两个Partition的数据是处于复制状态的。事实上，topic4在该Broker上只有这2个Partition，其它Partition在其它Broker上，所以通过该服务器的JMX Reporter只看到了这两个Partition。</p>
<h3 id="通过Kafka-Manager查看整个集群的Metrics"><a href="#通过Kafka-Manager查看整个集群的Metrics" class="headerlink" title="通过Kafka Manager查看整个集群的Metrics"></a>通过Kafka Manager查看整个集群的Metrics</h3><p>　　<a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="external">Kafka Manager</a>是Yahoo开源的Kafka管理工具。它支持如下功能</p>
<ul>
<li>管理多个集群</li>
<li>方便查看集群状态</li>
<li>执行preferred replica election</li>
<li>批量为多个Topic生成并执行Partition分配方案</li>
<li>创建Topic</li>
<li>删除Topic（只支持0.8.2及以上版本，同时要求在Broker中将<code>delete.topic.enable</code>设置为true）</li>
<li>为已有Topic添加Partition</li>
<li>更新Topic配置</li>
<li>在Broker JMX Reporter开启的前提下，轮询Broker级别和Topic级别的Metrics</li>
<li>监控Consumer Group及其消费状态</li>
<li>支持添加和查看LogKafka</li>
</ul>
<p>　　安装好Kafka Manager后，添加Cluster非常方便，只需指明该Cluster所使用的Zookeeper列表并指明Kafka版本即可，如下图所示。</p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/addcluster.png" alt="Add Cluster"></p>
<p>　　这里要注意，此处添加Cluster是指添加一个已有的Kafka集群进入监控列表，而非通过Kafka Manager部署一个新的Kafka Cluster，这一点与Cloudera Manager不同。</p>
<h1 id="Kafka-Benchmark"><a href="#Kafka-Benchmark" class="headerlink" title="Kafka Benchmark"></a>Kafka Benchmark</h1><p>　　Kafka的一个核心特性是高吞吐率，因此本文的测试重点是Kafka的吞吐率。<br>　　本文的测试共使用6台安装Red Hat 6.6的虚拟机，3台作为Broker，另外3台作为Producer或者Consumer。每台虚拟机配置如下</p>
<ul>
<li>CPU：8 vCPU， Intel(R) Xeon(R) CPU E5-2680 v2 @ 2.80GHz，2 Sockets，4 Cores per socket，1 Thread per core</li>
<li>内存：16 GB</li>
<li>磁盘：500 GB</li>
</ul>
<p>　　开启Kafka JMX Reporter并使用19797端口，利用Kafka-Manager的JMX polling功能监控性能测试过程中的吞吐率。</p>
<p>　　本文主要测试如下四种场景，测试的指标主要是每秒多少兆字节数据，每秒多少条消息。</p>
<h2 id="Producer-Only"><a href="#Producer-Only" class="headerlink" title="Producer Only"></a>Producer Only</h2><p>　　这组测试不使用任何Consumer，只启动Broker和Producer。</p>
<h3 id="Producer-Number-VS-Throughput"><a href="#Producer-Number-VS-Throughput" class="headerlink" title="Producer Number VS. Throughput"></a>Producer Number VS. Throughput</h3><p>　　实验条件：3个Broker，1个Topic，6个Partition，无Replication，异步模式，消息Payload为100字节<br>　　测试项目：分别测试1，2，3个Producer时的吞吐量<br>　　测试目标：如<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a>所介绍，多个Producer可同时向同一个Topic发送数据，在Broker负载饱和前，理论上Producer数量越多，集群每秒收到的消息量越大，并且呈线性增涨。本实验主要验证该特性。同时作为性能测试，本实验还将监控测试过程中单个Broker的CPU和内存使用情况<br>　　测试结果：使用不同个数Producer时的总吞吐率如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/producerlinear.png" alt="Producer Number VS. Throughput"></p>
<p>　　由上图可看出，单个Producer每秒可成功发送约128万条Payload为100字节的消息，并且随着Producer个数的提升，每秒总共发送的消息量线性提升，符合之前的分析。</p>
<p>　　性能测试过程中，Broker的CPU和内存使用情况如下图所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/cpu_usage.png" alt="Broker CPU Usage"></p>
<p>　　由上图可知，在每秒接收约117万条消息（3个Producer总共每秒发送350万条消息，平均每个Broker每秒接收约117万条）的情况下，一个Broker的CPU使用量约为248%，内存使用量为601 MB。</p>
<h3 id="Message-Size-VS-Throughput"><a href="#Message-Size-VS-Throughput" class="headerlink" title="Message Size VS. Throughput"></a>Message Size VS. Throughput</h3><p>　　实验条件：3个Broker，1个Topic，6个Partition，无Replication，异步模式，3个Producer<br>　　测试项目：分别测试消息长度为10，20，40，60，80，100，150，200，400，800，1000，2000，5000，10000字节时的集群总吞吐量<br>　　测试结果：不同消息长度时的集群总吞吐率如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/messagesize.png" alt="Message Size VS. Throughput"></p>
<p>　　由上图可知，消息越长，每秒所能发送的消息数越少，而每秒所能发送的消息的量（MB）越大。另外，每条消息除了Payload外，还包含其它Metadata，所以每秒所发送的消息量比每秒发送的消息数乘以100字节大，而Payload越大，这些Metadata占比越小，同时发送时的批量发送的消息体积越大，越容易得到更高的每秒消息量（MB/s）。其它测试中使用的Payload为100字节，之所以使用这种短消息（相对短）只是为了测试相对比较差的情况下的Kafka吞吐率。</p>
<h3 id="Partition-Number-VS-Throughput"><a href="#Partition-Number-VS-Throughput" class="headerlink" title="Partition Number VS. Throughput"></a>Partition Number VS. Throughput</h3><p>　　实验条件：3个Broker，1个Topic，无Replication，异步模式，3个Producer，消息Payload为100字节<br>　　测试项目：分别测试1到9个Partition时的吞吐量<br>　　测试结果：不同Partition数量时的集群总吞吐率如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/partition_throughput.png" alt="Partition Number VS. Throughput"></p>
<p>　　由上图可知，当Partition数量小于Broker个数（3个）时，Partition数量越大，吞吐率越高，且呈线性提升。本文所有实验中，只启动3个Broker，而一个Partition只能存在于1个Broker上（不考虑Replication。即使有Replication，也只有其Leader接受读写请求），故当某个Topic只包含1个Partition时，实际只有1个Broker在为该Topic工作。如之前文章所讲，Kafka会将所有Partition均匀分布到所有Broker上，所以当只有2个Partition时，会有2个Broker为该Topic服务。3个Partition时同理会有3个Broker为该Topic服务。换言之，Partition数量小于等于3个时，越多的Partition代表越多的Broker为该Topic服务。如前几篇文章所述，不同Broker上的数据并行插入，这就解释了当Partition数量小于等于3个时，吞吐率随Partition数量的增加线性提升。<br>　　当Partition数量多于Broker个数时，总吞吐量并未有所提升，甚至还有所下降。可能的原因是，当Partition数量为4和5时，不同Broker上的Partition数量不同，而Producer会将数据均匀发送到各Partition上，这就造成各Broker的负载不同，不能最大化集群吞吐量。而上图中当Partition数量为Broker数量整数倍时吞吐量明显比其它情况高，也证实了这一点。</p>
<h3 id="Replica-Number-VS-Throughput"><a href="#Replica-Number-VS-Throughput" class="headerlink" title="Replica Number VS. Throughput"></a>Replica Number VS. Throughput</h3><p>　　实验条件：3个Broker，1个Topic，6个Partition，异步模式，3个Producer，消息Payload为100字节<br>　　测试项目：分别测试1到3个Replica时的吞吐率<br>　　测试结果：如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/replica_throughput.png" alt="Replica Number VS. Throughput"></p>
<p>　　由上图可知，随着Replica数量的增加，吞吐率随之下降。但吞吐率的下降并非线性下降，因为多个Follower的数据复制是并行进行的，而非串行进行。</p>
<p>　　</p>
<h2 id="Consumer-Only"><a href="#Consumer-Only" class="headerlink" title="Consumer Only"></a>Consumer Only</h2><p>　　实验条件：3个Broker，1个Topic，6个Partition，无Replication，异步模式，消息Payload为100字节<br>　　测试项目：分别测试1到3个Consumer时的集群总吞吐率<br>　　测试结果：在集群中已有大量消息的情况下，使用1到3个Consumer时的集群总吞吐量如下图所示</p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn5/consumer_throughput.png" alt="Consumer Number VS. Throughput"></p>
<p>　　由上图可知，单个Consumer每秒可消费306万条消息，该数量远大于单个Producer每秒可消费的消息数量，这保证了在合理的配置下，消息可被及时处理。并且随着Consumer数量的增加，集群总吞吐量线性增加。<br>　　根据<a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a>所述，多Consumer消费消息时以Partition为分配单位，当只有1个Consumer时，该Consumer需要同时从6个Partition拉取消息，该Consumer所在机器的I/O成为整个消费过程的瓶颈，而当Consumer个数增加至2个至3个时，多个Consumer同时从集群拉取消息，充分利用了集群的吞吐率。</p>
<h2 id="Producer-Consumer-pair"><a href="#Producer-Consumer-pair" class="headerlink" title="Producer Consumer pair"></a>Producer Consumer pair</h2><p>　　实验条件：3个Broker，1个Topic，6个Partition，无Replication，异步模式，消息Payload为100字节<br>　　测试项目：测试1个Producer和1个Consumer同时工作时Consumer所能消费到的消息量<br>　　测试结果：1,215,613 records/second</p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文详细阐述了Kafka的性能测试方法，并全面展示了Kafka各组件的性能测试报告。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（四） PostgreSQL存储过程</title>
    <link href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/"/>
    <id>http://www.jasongj.com/2015/12/27/SQL4_存储过程_Store Procedure/</id>
    <published>2015-12-27T06:59:45.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/12/27/SQL4_存储过程_Store Procedure">原文链接</a>　<a href="http://www.jasongj.com/2015/12/27/SQL4_存储过程_Store Procedure">http://www.jasongj.com/2015/12/27/SQL4_存储过程_Store Procedure/</a></p>
</blockquote>
<h1 id="存储过程简介"><a href="#存储过程简介" class="headerlink" title="存储过程简介"></a>存储过程简介</h1><h2 id="什么是存储过程"><a href="#什么是存储过程" class="headerlink" title="什么是存储过程"></a>什么是存储过程</h2><p>　　百度百科是这么描述存储过程的：存储过程（Stored Procedure）是在大型数据库系统中，一组为了完成特定功能的SQL语句集，存储在数据库中，首次编译后再次调用不需要再次编译，用户通过指定存储过程的名字并给出参数（如果有）来执行它。它是数据库中的一个重要对象，任何一个设计良好的数据库应用程序都应该用到存储过程。<br>　　<br>　　维基百科是这样定义的：A stored procedure (also termed proc, storp, sproc, StoPro, StoredProc, StoreProc, sp, or SP) is a subroutine available to applications that access a relational database management system (RDMS). Such procedures are stored in the database data dictionary。</p>
<p>　　PostgreSQL对存储过程的描述是：存储过程和用户自定义函数（UDF）是SQL和过程语句的集合，它存储于数据库服务器并能被SQL接口调用。</p>
<p>　　总结下来存储过程有如下特性：</p>
<ul>
<li>存储于数据库服务器</li>
<li>一次编译后可多次调用</li>
<li>设计良好的数据库应用程序很可能会用到它</li>
<li>由SQL和过程语句来定义</li>
<li>应用程序通过SQL接口来调用</li>
</ul>
<h2 id="使用存储过程的优势及劣势"><a href="#使用存储过程的优势及劣势" class="headerlink" title="使用存储过程的优势及劣势"></a>使用存储过程的优势及劣势</h2><p>　　首先看看使用存储过程的优势</p>
<ul>
<li>减少应用与数据库服务器的通信开销，从而提升整体性能。笔者在项目中使用的存储过程，少则几十行，多则几百行甚至上千行（假设一行10个字节，一千行即相当于10KB），如果不使用存储过程而直接通过应用程序将相应SQL请求发送到数据库服务器，会增大网络通信开销。相反，使用存储过程能降低该开销，从而提升整体性能。尤其在一些BI系统中，一个页面往往要使用多个存储过程，此时存储过程降低网络通信开销的优势非常明显</li>
<li>一次编译多次调用，提高性能。存储过程存于数据库服务器中，第一次被调用后即被编译，之后再调用时无需再次编译，直接执行，提高了性能</li>
<li>同一套业务逻辑可被不同应用程序共用，减少了应用程序的开发复杂度，同时也保证了不同应用程序使用的一致性</li>
<li>保护数据库元信息。如果应用程序直接使用SQL语句查询数据库，会将数据库表结构暴露给应用程序，而使用存储过程是应用程序并不知道数据库表结构</li>
<li>更细粒度的数据库权限管理。直接从表读取数据时，对应用程序只能实现表级别的权限管理，而使用存储过程是，可在存储过程中将应用程序无权访问的数据屏蔽</li>
<li>将业务实现与应用程序解耦。当业务需求更新时，只需更改存储过程的定义，而不需要更改应用程序</li>
<li>可以通过其它语言并可及其它系统交互。比如可以使用PL/Java与Kafka交互，将存储过程的参数Push到Kafka或者将从Kafka获取的数据作为存储过程的结果返回给调用方</li>
</ul>
<p>　　当然，使用存储过程也有它的劣势</p>
<ul>
<li>不便于调试。尤其在做性能调优时，以PostgreSQL为例，可使用EXPLAIN ANALYZE检查SQL查询计划，从而方便的进行性能调优。而使用存储过程时，EXPLAIN ANALYZE无法显示其内部查询计划</li>
<li>不便于移植到其它数据库。直接使用SQL时，SQL存于应用程序中，对大部分标准SQL而言，换用其它数据库并不影响应用程序的使用。而使用存储过程时，由于不同数据库的存储过程定义方式不同，支持的语言及语法不同，移植成本较高</li>
</ul>
<h1 id="存储过程在PostgreSQL中的使用"><a href="#存储过程在PostgreSQL中的使用" class="headerlink" title="存储过程在PostgreSQL中的使用"></a>存储过程在PostgreSQL中的使用</h1><h2 id="PostgreSQL支持的过程语言"><a href="#PostgreSQL支持的过程语言" class="headerlink" title="PostgreSQL支持的过程语言"></a>PostgreSQL支持的过程语言</h2><p>　　PostgreSQL官方支持PL/pgSQL，PL/Tcl，PL/Perl和PL/Python这几种过程语言。同时还支持一些第三方提供的过程语言，如PL/Java，PL/PHP，PL/Py，PL/R，PL/Ruby，PL/Scheme，PL/sh。</p>
<h2 id="基于SQL的存储过程定义"><a href="#基于SQL的存储过程定义" class="headerlink" title="基于SQL的存储过程定义"></a>基于SQL的存储过程定义</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> <span class="keyword">add</span>(a <span class="built_in">INTEGER</span>, b <span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="built_in">NUMERIC</span></div><div class="line"><span class="keyword">AS</span> $$</div><div class="line">	<span class="keyword">SELECT</span> a+b;</div><div class="line">$$ LANGUAGE SQL;</div></pre></td></tr></table></figure>
<p>　　调用方法<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> <span class="keyword">add</span>(<span class="number">1</span>,<span class="number">2</span>);</div><div class="line"> add</div><div class="line"><span class="comment">-----</span></div><div class="line">   3</div><div class="line">(1 row)</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">add</span>(<span class="number">1</span>,<span class="number">2</span>);</div><div class="line"> add</div><div class="line"><span class="comment">-----</span></div><div class="line">   3</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<p>　　上面这种方式参数列表只包含函数输入参数，不包含输出参数。下面这个例子将同时包含输入参数和输出参数<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> plus_and_minus</div><div class="line">(<span class="keyword">IN</span> a <span class="built_in">INTEGER</span>, <span class="keyword">IN</span> b <span class="built_in">NUMERIC</span>, <span class="keyword">OUT</span> c <span class="built_in">NUMERIC</span>, <span class="keyword">OUT</span> d <span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line">	<span class="keyword">SELECT</span> a+b, a-b;</div><div class="line">$$ LANGUAGE SQL;</div></pre></td></tr></table></figure></p>
<p>　调用方式<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> plus_and_minus(<span class="number">3</span>,<span class="number">2</span>);</div><div class="line"> add_and_minute</div><div class="line"><span class="comment">----------------</span></div><div class="line"> (5,1)</div><div class="line">(1 row)</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> plus_and_minus(<span class="number">3</span>,<span class="number">2</span>);</div><div class="line"> c | d</div><div class="line"><span class="comment">---+---</span></div><div class="line"> 5 | 1</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<p>　　该例中，IN代表输入参数，OUT代表输出参数。这个带输出参数的函数和之前的<code>add</code>函数并无本质区别。事实上，输出参数的最大价值在于它为函数提供了返回多个字段的途径。</p>
<p>　　在函数定义中，可以写多个SQL语句，不一定是SELECT语句，可以是其它任意合法的SQL。但最后一条SQL必须是SELECT语句，并且该SQL的结果将作为该函数的输出结果。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> plus_and_minus</div><div class="line">(<span class="keyword">IN</span> a <span class="built_in">INTEGER</span>, <span class="keyword">IN</span> b <span class="built_in">NUMERIC</span>, <span class="keyword">OUT</span> c <span class="built_in">NUMERIC</span>, <span class="keyword">OUT</span> d <span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line">	<span class="keyword">SELECT</span> a+b, a-b;</div><div class="line">	<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">VALUES</span>(<span class="string">'test1'</span>);</div><div class="line">	<span class="keyword">SELECT</span> a-b, a+b;</div><div class="line">$$ LANGUAGE SQL;</div></pre></td></tr></table></figure></p>
<p>　　其效果如下<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> plus_and_minus(<span class="number">5</span>,<span class="number">3</span>);</div><div class="line"> c | d</div><div class="line"><span class="comment">---+---</span></div><div class="line"> 2 | 8</div><div class="line">(1 row)</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">test</span>;</div><div class="line">   a</div><div class="line"><span class="comment">-------</span></div><div class="line"> test1</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<h2 id="基于PL-PgSQL的存储过程定义"><a href="#基于PL-PgSQL的存储过程定义" class="headerlink" title="基于PL/PgSQL的存储过程定义"></a>基于PL/PgSQL的存储过程定义</h2><p>　　PL/pgSQL是一个块结构语言。函数定义的所有文本都必须是一个块。一个块用下面的方法定义：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[ &lt;&lt;label&gt;&gt; ]</div><div class="line">[DECLARE</div><div class="line">	declarations]</div><div class="line">BEGIN</div><div class="line">	statements</div><div class="line">END [ label ];</div></pre></td></tr></table></figure></p>
<ul>
<li>中括号部分为可选部分</li>
<li>块中的每一个declaration和每一条statement都由一个分号终止</li>
<li>块支持嵌套，嵌套时子块的END后面必须跟一个分号，最外层的块END后可不跟分号</li>
<li>BEGIN后面不必也不能跟分号</li>
<li>END后跟的label名必须和块开始时的标签名一致</li>
<li>所有关键字都不区分大小写。标识符被隐含地转换成小写字符，除非被双引号包围</li>
<li>声明的变量在当前块及其子块中有效，子块开始前可声明并覆盖（只在子块内覆盖）外部块的同名变量</li>
<li>变量被子块中声明的变量覆盖时，子块可以通过外部块的label访问外部块的变量</li>
</ul>
<p>　　声明一个变量的语法如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">name [ CONSTANT ] type [ NOT NULL ] [ &#123; DEFAULT | := &#125; expression ];</div></pre></td></tr></table></figure></p>
<p>　　使用PL/PgSQL语言的函数定义如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> somefunc() <span class="keyword">RETURNS</span> <span class="built_in">integer</span> <span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">DECLARE</span></div><div class="line">	quantity <span class="built_in">integer</span> := <span class="number">30</span>;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="comment">-- Prints 30</span></div><div class="line">	<span class="keyword">RAISE</span> <span class="keyword">NOTICE</span> <span class="string">'Quantity here is %'</span>, quantity;</div><div class="line">	quantity := 50;</div><div class="line"></div><div class="line">	<span class="comment">-- Create a subblock</span></div><div class="line">    <span class="keyword">DECLARE</span></div><div class="line">    	quantity <span class="built_in">integer</span> := <span class="number">80</span>;</div><div class="line">    <span class="keyword">BEGIN</span></div><div class="line">    	<span class="comment">-- Prints 80</span></div><div class="line">    	<span class="keyword">RAISE</span> <span class="keyword">NOTICE</span> <span class="string">'Quantity here is %'</span>, quantity;</div><div class="line">    	<span class="comment">-- Prints 50</span></div><div class="line">    	RAISE NOTICE 'Outer quantity here is %', outerblock.quantity;</div><div class="line">    <span class="keyword">END</span>;</div><div class="line"></div><div class="line">    <span class="comment">-- Prints 50</span></div><div class="line">	RAISE NOTICE 'Quantity here is %', quantity;</div><div class="line">    RETURN quantity;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE plpgsql;</div></pre></td></tr></table></figure></p>
<h2 id="声明函数参数"><a href="#声明函数参数" class="headerlink" title="声明函数参数"></a>声明函数参数</h2><p>　　如果只指定输入参数类型，不指定参数名，则函数体里一般用$1，$n这样的标识符来使用参数。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> discount(<span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="built_in">NUMERIC</span></div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> $<span class="number">1</span> * <span class="number">0.8</span>;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div></pre></td></tr></table></figure></p>
<p>　　但该方法可读性不好，此时可以为$n参数声明别名，然后可以在函数体内通过别名指向该参数值。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> discount(<span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="built_in">NUMERIC</span></div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">DECLARE</span></div><div class="line">	total <span class="keyword">ALIAS</span> <span class="keyword">FOR</span> $<span class="number">1</span>;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> total * <span class="number">0.8</span>;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div></pre></td></tr></table></figure></p>
<p>　　笔者认为上述方法仍然不够直观，也不够完美。幸好PostgreSQL提供另外一种更为直接的方法来声明函数参数，即在声明参数类型时同时声明相应的参数名。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> discount(total <span class="built_in">NUMERIC</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="built_in">NUMERIC</span></div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> total * <span class="number">0.8</span>;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div></pre></td></tr></table></figure></p>
<h2 id="返回多行或多列"><a href="#返回多行或多列" class="headerlink" title="返回多行或多列"></a>返回多行或多列</h2><h3 id="使用自定义复合类型返回一行多列"><a href="#使用自定义复合类型返回一行多列" class="headerlink" title="使用自定义复合类型返回一行多列"></a>使用自定义复合类型返回一行多列</h3><p>　　PostgreSQL除了支持自带的类型外，还支持用户创建自定义类型。在这里可以自定义一个复合类型，并在函数中返回一个该复合类型的值，从而实现返回一行多列。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TYPE</span> compfoo <span class="keyword">AS</span> (col1 <span class="built_in">INTEGER</span>, col2 <span class="built_in">TEXT</span>);</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> getCompFoo</div><div class="line">(in_col1 <span class="built_in">INTEGER</span>, in_col2 <span class="built_in">TEXT</span>)</div><div class="line"><span class="keyword">RETURNS</span> compfoo</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">DECLARE</span> <span class="keyword">result</span> compfoo;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	result.col1 := in_col1 * <span class="number">2</span>;</div><div class="line">	result.col2 := in_col2 || '_result';</div><div class="line">	RETURN result;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> getCompFoo(<span class="number">1</span>,<span class="string">'1'</span>);</div><div class="line"> col1 |   col2</div><div class="line"><span class="comment">------+----------</span></div><div class="line">    2 | 1_result</div><div class="line">(1 row)</div></pre></td></tr></table></figure></p>
<h3 id="使用输出参数名返回一行多列"><a href="#使用输出参数名返回一行多列" class="headerlink" title="使用输出参数名返回一行多列"></a>使用输出参数名返回一行多列</h3><p>　　在声明函数时，除指定输入参数名及类型外，还可同时声明输出参数类型及参数名。此时函数可以输出一行多列。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> get2Col</div><div class="line">(<span class="keyword">IN</span> in_col1 <span class="built_in">INTEGER</span>,<span class="keyword">IN</span> in_col2 <span class="built_in">TEXT</span>,</div><div class="line"><span class="keyword">OUT</span> out_col1 <span class="built_in">INTEGER</span>, <span class="keyword">OUT</span> out_col2 <span class="built_in">TEXT</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	out_col1 := in_col1 * <span class="number">2</span>;</div><div class="line">	out_col2 := in_col2 || '_result';</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> get2Col(<span class="number">1</span>,<span class="string">'1'</span>);</div><div class="line"> out_col1 | out_col2 </div><div class="line"><span class="comment">----------+----------</span></div><div class="line">        2 | 1_result</div><div class="line">(1 row)</div></pre></td></tr></table></figure>
<h3 id="使用SETOF返回多行记录"><a href="#使用SETOF返回多行记录" class="headerlink" title="使用SETOF返回多行记录"></a>使用SETOF返回多行记录</h3><p>　　实际项目中，存储过程经常需要返回多行记录，可以通过SETOF实现。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TYPE</span> compfoo <span class="keyword">AS</span> (col1 <span class="built_in">INTEGER</span>, col2 <span class="built_in">TEXT</span>);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> getSet(<span class="keyword">rows</span> <span class="built_in">INTEGER</span>)</div><div class="line"><span class="keyword">RETURNS</span> SETOF compfoo</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> <span class="keyword">QUERY</span> <span class="keyword">SELECT</span> i * <span class="number">2</span>, i || <span class="string">'_text'</span> </div><div class="line">	<span class="keyword">FROM</span> generate_series(<span class="number">1</span>, <span class="keyword">rows</span>, <span class="number">1</span>) <span class="keyword">as</span> t(i);</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> col1, col2 <span class="keyword">FROM</span> getSet(<span class="number">2</span>);</div><div class="line"> col1 |  col2</div><div class="line"><span class="comment">------+--------</span></div><div class="line">    2 | 1_text</div><div class="line">    4 | 2_text</div><div class="line">(2 rows)</div></pre></td></tr></table></figure></p>
<p>　　本例返回的每一行记录是复合类型，该方法也可返回基本类型的结果集，即多行一列。</p>
<h3 id="使用RETURN-TABLE返回多行多列"><a href="#使用RETURN-TABLE返回多行多列" class="headerlink" title="使用RETURN TABLE返回多行多列"></a>使用RETURN TABLE返回多行多列</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> getTable(<span class="keyword">rows</span> <span class="built_in">INTEGER</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="keyword">TABLE</span>(col1 <span class="built_in">INTEGER</span>, col2 <span class="built_in">TEXT</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> <span class="keyword">QUERY</span> <span class="keyword">SELECT</span> i * <span class="number">2</span>, i || <span class="string">'_text'</span></div><div class="line">	<span class="keyword">FROM</span> generate_series(<span class="number">1</span>, <span class="keyword">rows</span>, <span class="number">1</span>) <span class="keyword">as</span> t(i);</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> col1, col2 <span class="keyword">FROM</span> getTable(<span class="number">2</span>);</div><div class="line"> col1 |  col2</div><div class="line"><span class="comment">------+--------</span></div><div class="line">    2 | 1_text</div><div class="line">    4 | 2_text</div><div class="line">(2 rows)</div></pre></td></tr></table></figure>
<p>　　此时从函数中读取字段就和从表或视图中取字段一样，可以看此种类型的函数看成是带参数的表或者视图。</p>
<h2 id="使用EXECUTE语句执行动态命令"><a href="#使用EXECUTE语句执行动态命令" class="headerlink" title="使用EXECUTE语句执行动态命令"></a>使用EXECUTE语句执行动态命令</h2><p>　　有时在PL/pgSQL函数中需要生成动态命令，这个命令将包括他们每次执行时使用不同的表或者字符。EXECUTE语句用法如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">EXECUTE</span> command-<span class="keyword">string</span> [ <span class="keyword">INTO</span> [<span class="keyword">STRICT</span>] target] [<span class="keyword">USING</span> expression [, ...]];</div></pre></td></tr></table></figure></p>
<p>　　此时PL/plSQL将不再缓存该命令的执行计划。相反，在该语句每次被执行的时候，命令都会编译一次。这也让该语句获得了对各种不同的字段甚至表进行操作的能力。<br>　　command-string包含了要执行的命令，它可以使用参数值，在命令中通过引用如$1，$2等来引用参数值。这些符号的值是指USING字句的值。这种方法对于在命令字符串中使用参数是最好的：它能避免运行时数值从文本来回转换，并且不容易产生SQL注入，而且它不需要引用或者转义。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> testExecute</div><div class="line"><span class="keyword">AS</span></div><div class="line"><span class="keyword">SELECT</span></div><div class="line">	i || <span class="string">''</span> <span class="keyword">AS</span> a,</div><div class="line">	i <span class="keyword">AS</span> b</div><div class="line"><span class="keyword">FROM</span></div><div class="line">	generate_series(<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>) <span class="keyword">AS</span> t(i);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> <span class="keyword">execute</span>(filter <span class="built_in">TEXT</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="keyword">TABLE</span> (a <span class="built_in">TEXT</span>, b <span class="built_in">INTEGER</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> <span class="keyword">QUERY</span> <span class="keyword">EXECUTE</span></div><div class="line">		<span class="string">'SELECT * FROM testExecute where a = $1'</span></div><div class="line">	<span class="keyword">USING</span> filter;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">execute</span>(<span class="string">'3'</span>);</div><div class="line"> a | b</div><div class="line"><span class="comment">---+---</span></div><div class="line"> 3 | 3</div><div class="line">(1 row)</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">execute</span>(<span class="string">'3'' or ''c''=''c'</span>);</div><div class="line"> a | b</div><div class="line"><span class="comment">---+---</span></div><div class="line">(0 rows)</div></pre></td></tr></table></figure></p>
<p>　　当然，也可以使用字符串拼接的方式在command-string中使用参数，但会有SQL注入的风险。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> testExecute</div><div class="line"><span class="keyword">AS</span></div><div class="line"><span class="keyword">SELECT</span></div><div class="line">	i || <span class="string">''</span> <span class="keyword">AS</span> a,</div><div class="line">	i <span class="keyword">AS</span> b</div><div class="line"><span class="keyword">FROM</span></div><div class="line">	generate_series(<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>) <span class="keyword">AS</span> t(i);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> <span class="keyword">execute</span>(filter <span class="built_in">TEXT</span>)</div><div class="line"><span class="keyword">RETURNS</span> <span class="keyword">TABLE</span> (a <span class="built_in">TEXT</span>, b <span class="built_in">INTEGER</span>)</div><div class="line"><span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">RETURN</span> <span class="keyword">QUERY</span> <span class="keyword">EXECUTE</span></div><div class="line">		<span class="string">'SELECT * FROM testExecute where b = '''</span></div><div class="line">		|| filter || <span class="string">''''</span>;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$ LANGUAGE PLPGSQL;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">execute</span>(<span class="number">3</span>);</div><div class="line"> a | b</div><div class="line"><span class="comment">---+---</span></div><div class="line"> 3 | 3</div><div class="line">(1 row)</div><div class="line"></div><div class="line"> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">execute</span>(<span class="string">'3'' or ''c''=''c'</span>);</div><div class="line"> a  | b</div><div class="line"><span class="comment">----+----</span></div><div class="line"> 1  |  1</div><div class="line"> 2  |  2</div><div class="line"> 3  |  3</div><div class="line"> 4  |  4</div><div class="line"> 5  |  5</div><div class="line"> 6  |  6</div><div class="line"> 7  |  7</div><div class="line"> 8  |  8</div><div class="line"> 9  |  9</div><div class="line"> 10 | 10</div><div class="line">(10 rows)</div></pre></td></tr></table></figure></p>
<p>　　从该例中可以看出使用字符串拼接的方式在command-string中使用参数会引入SQL注入攻击的风险，而使用USING的方式则能有效避免这一风险。</p>
<h2 id="PostgreSQL中的UDF与存储过程"><a href="#PostgreSQL中的UDF与存储过程" class="headerlink" title="PostgreSQL中的UDF与存储过程"></a>PostgreSQL中的UDF与存储过程</h2><p>　　本文中并未区分PostgreSQL中的UDF和存储过程。实际上PostgreSQL创建存储与创建UDF的方式一样，并没有专用于创建存储过程的语法，如CREATE PRECEDURE。在PostgreSQL官方文档中也暂未找到这二者的区别。倒是从一些资料中找对了它们的对比，如下表如示，仅供参考。<br><img src="http://www.jasongj.com/img/sql/SQL4/pg_udf_stored_precedure.png" alt="UDF VS. Stored Precedure"></p>
<h2 id="多态SQL函数"><a href="#多态SQL函数" class="headerlink" title="多态SQL函数"></a>多态SQL函数</h2><p>　　SQL函数可以声明为接受多态类型（anyelement和anyarray）的参数或返回多态类型的返回值。</p>
<ul>
<li><p>函数参数和返回值均为多态类型。其调用方式和调用其它类型的SQL函数完全相同，只是在传递字符串类型的参数时，需要显示转换到目标类型，否则将会被视为unknown类型。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">CREATE OR REPLACE FUNCTION get_array(anyelement, anyelement)</div><div class="line">RETURNS anyarray</div><div class="line">AS $$</div><div class="line">	SELECT ARRAY[$1, $2];</div><div class="line">$$ LANGUAGE SQL;</div><div class="line"></div><div class="line">SELECT get_array(1,2), get_array('a'::text,'b'::text);</div><div class="line"> get_array | get_array </div><div class="line">-----------+-----------</div><div class="line"> &#123;1,2&#125;     | &#123;a,b&#125;</div><div class="line">(1 row)</div></pre></td></tr></table></figure>
</li>
<li><p>函数参数为多态类型，而返回值为基本类型</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> is_greater(anyelement, anyelement)</div><div class="line"><span class="keyword">RETURNS</span> <span class="built_in">BOOLEAN</span></div><div class="line"><span class="keyword">AS</span> $$</div><div class="line">	<span class="keyword">SELECT</span> $<span class="number">1</span> &gt; $<span class="number">2</span>;</div><div class="line">$$ LANGUAGE SQL;</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> is_greater(<span class="number">7.0</span>, <span class="number">4.5</span>);</div><div class="line"> is_greater </div><div class="line"><span class="comment">------------</span></div><div class="line"> t</div><div class="line">(1 row)</div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> is_greater(<span class="number">2</span>, <span class="number">4</span>);    </div><div class="line"> is_greater </div><div class="line"><span class="comment">------------</span></div><div class="line"> f</div><div class="line">(1 row)</div></pre></td></tr></table></figure>
</li>
<li><p>输入输出参数均为多态类型。这种情况与第一种情况一样。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">CREATE OR REPLACE FUNCTION get_array</div><div class="line">(IN anyelement, IN anyelement, OUT anyelement, OUT anyarray)</div><div class="line">AS $$</div><div class="line">	SELECT $1, ARRAY[$1, $2];</div><div class="line">$$ LANGUAGE SQL;</div><div class="line"></div><div class="line">SELECT get_array(4,5), get_array('c'::text, 'd'::text);</div><div class="line">  get_array  |  get_array  </div><div class="line">-------------+-------------</div><div class="line"> (4,"&#123;4,5&#125;") | (c,"&#123;c,d&#125;")</div><div class="line">(1 row)</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="函数重载（Overwrite）"><a href="#函数重载（Overwrite）" class="headerlink" title="函数重载（Overwrite）"></a>函数重载（Overwrite）</h2><p>　　在PostgreSQL中，多个函数可共用同一个函数名，但它们的参数必须得不同。这一规则与面向对象语言（比如Java）中的函数重载类似。也正因如此，在PostgreSQL删除函数时，必须指定其参数列表，如：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">DROP</span> <span class="keyword">FUNCTION</span> get_array(anyelement, anyelement);</div></pre></td></tr></table></figure></p>
<p>　　另外，在实际项目中，经常会用到CREATE OR REPLACE FUNCTION去替换已有的函数实现。如果同名函数已存在，但输入参数列表不同，会创建同名的函数，也即重载。如果同名函数已存在，且输入输出参数列表均相同，则替换。如果已有的函数输入参数列表相同，但输出参数列表不同，则会报错，并提示需要先DROP已有的函数定义。</p>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a>
　　</li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了存储过程的概念，优势，并结合实例讲解了存储过程在PostgreSQL中的实现，注意事项
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（三） PostgreSQL Table Partitioning</title>
    <link href="http://www.jasongj.com/2015/12/13/SQL3_partition/"/>
    <id>http://www.jasongj.com/2015/12/13/SQL3_partition/</id>
    <published>2015-12-13T04:13:05.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">原文链接</a>　<a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">http://www.jasongj.com/2015/12/13/SQL3_partition/</a></p>
</blockquote>
<h1 id="典型使用场景"><a href="#典型使用场景" class="headerlink" title="典型使用场景"></a>典型使用场景</h1><p>　　随着使用时间的增加，数据库中的数据量也不断增加，因此数据库查询越来越慢。<br>　　加速数据库的方法很多，如添加特定的索引，将日志目录换到单独的磁盘分区，调整数据库引擎的参数等。这些方法都能将数据库的查询性能提高到一定程度。</p>
<p>　　对于许多应用数据库来说，许多数据是历史数据并且随着时间的推移它们的重要性逐渐降低。如果能找到一个办法将这些可能不太重要的数据隐藏，数据库查询速度将会大幅提高。可以通过<code>DELETE</code>来达到此目的，但同时这些数据就永远不可用了。<br>　　因此，需要一个高效的把历史数据从当前查询中隐藏起来并且不造成数据丢失的方法。本文即将介绍的数据库表分区即能达到此效果。</p>
<h1 id="数据库表分区介绍"><a href="#数据库表分区介绍" class="headerlink" title="数据库表分区介绍"></a>数据库表分区介绍</h1><p>　　数据库表分区把一个大的物理表分成若干个小的物理表，并使得这些小物理表在逻辑上可以被当成一张表来使用。<br><img src="http://www.jasongj.com/img/sql/SQL3/partition_arch.png" alt="Table partitioning architecture"></p>
<h2 id="数据库表分区术语介绍"><a href="#数据库表分区术语介绍" class="headerlink" title="数据库表分区术语介绍"></a>数据库表分区术语介绍</h2><ul>
<li><code>主表</code> / <code>父表</code> / <code>Master Table</code>　该表是创建子表的模板。它是一个正常的普通表，但正常情况下它并不储存任何数据。</li>
<li><code>子表</code> / <code>分区表</code> / <code>Child Table</code> / <code>Partition Table</code>　这些表继承并属于一个主表。子表中存储所有的数据。主表与分区表属于一对多的关系，也就是说，一个主表包含多个分区表，而一个分区表只从属于一个主表</li>
</ul>
<h2 id="数据库表分区的优势"><a href="#数据库表分区的优势" class="headerlink" title="数据库表分区的优势"></a>数据库表分区的优势</h2><ul>
<li>在特定场景下，查询性能极大提高，尤其是当大部分经常访问的数据记录在一个或少数几个分区表上时。表分区减小了索引的大小，并使得常访问的分区表的索引更容易保存于内存中。</li>
<li>当查询或者更新访问一个或少数几个分区表中的大部分数据时，可以通过顺序扫描该分区表而非使用大表索引来提高性能。</li>
<li>可通过添加或移除分区表来高效的批量增删数据。如可使用<code>ALTER TABLE NO INHERIT</code>可将特定分区从主逻辑表中移除（该表依然存在，并可单独使用，只是与主表不再有继承关系并无法再通过主表访问该分区表），或使用<code>DROP TABLE</code>直接将该分区表删除。这两种方式完全避免了使用<code>DELETE</code>时所需的<code>VACUUM</code>额外代价。</li>
<li>很少使用的数据可被迁移到便宜些的慢些的存储介质中</li>
</ul>
<p>　　以上优势只有当表非常大的时候才能体现出来。一般来说，当表的大小超过数据库服务器的物理内存时以上优势才能体现出来</p>
<h2 id="PostgreSQL表分区"><a href="#PostgreSQL表分区" class="headerlink" title="PostgreSQL表分区"></a>PostgreSQL表分区</h2><p>　　现在PostgreSQL支持通过表继承来实现表的分区。父表是普通表并且正常情况下并不存储任何数据，它的存在只是为了代表整个数据集。PostgreSQL可实现如下两种表分区</p>
<ul>
<li><strong><em>范围分区</em></strong>　每个分区表包含一个或多个字段组合的一部分，并且每个分区表的范围互不重叠。比如可近日期范围分区</li>
<li><strong><em>列表分区</em></strong>　分区表显示列出其所包含的key值</li>
</ul>
<h1 id="表分区在PostgreSQL上的实现"><a href="#表分区在PostgreSQL上的实现" class="headerlink" title="表分区在PostgreSQL上的实现"></a>表分区在PostgreSQL上的实现</h1><h2 id="在PostgreSQL中实现表分区的步骤"><a href="#在PostgreSQL中实现表分区的步骤" class="headerlink" title="在PostgreSQL中实现表分区的步骤"></a>在PostgreSQL中实现表分区的步骤</h2><ol>
<li><p>创建主表。不用为该表定义任何检查限制，除非需要将该限制应用到所有的分区表中。同样也无需为该表创建任何索引和唯一限制。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart</div><div class="line">(</div><div class="line">	date_key <span class="built_in">date</span>,</div><div class="line">	hour_key <span class="built_in">smallint</span>,</div><div class="line">	client_key <span class="built_in">integer</span>,</div><div class="line">	item_key <span class="built_in">integer</span>,</div><div class="line">	<span class="keyword">account</span> <span class="built_in">integer</span>,</div><div class="line">	expense <span class="built_in">numeric</span></div><div class="line">);</div></pre></td></tr></table></figure>
</li>
<li><p>创建多个分区表。每个分区表必须继承自主表，并且正常情况下都不要为这些分区表添加任何新的列。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart_2015_12_10 () inherits (almart);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart_2015_12_11 () inherits (almart);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart_2015_12_12 () inherits (almart);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart_2015_12_13 () inherits (almart);</div></pre></td></tr></table></figure>
</li>
<li><p>为分区表添加限制。这些限制决定了该表所能允许保存的数据集范围。这里必须保证各个分区表之间的限制不能有重叠。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2015_12_10</div><div class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> almart_2015_12_10_check_date_key</div><div class="line"><span class="keyword">CHECK</span> (date_Key = <span class="string">'2015-12-10'</span>::<span class="built_in">date</span>);</div><div class="line"></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2015_12_11</div><div class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> almart_2015_12_10_check_date_key</div><div class="line"><span class="keyword">CHECK</span> (date_Key = <span class="string">'2015-12-11'</span>::<span class="built_in">date</span>);</div><div class="line"></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2015_12_12</div><div class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> almart_2015_12_10_check_date_key</div><div class="line"><span class="keyword">CHECK</span> (date_Key = <span class="string">'2015-12-12'</span>::<span class="built_in">date</span>);</div><div class="line"></div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2015_12_13</div><div class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> almart_2015_12_10_check_date_key</div><div class="line"><span class="keyword">CHECK</span> (date_Key = <span class="string">'2015-12-13'</span>::<span class="built_in">date</span>);</div></pre></td></tr></table></figure>
</li>
<li><p>为每一个分区表，在主要的列上创建索引。该索引并不是严格必须创建的，但在大部分场景下，它都非常有用。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> almart_date_key_2015_12_10</div><div class="line"><span class="keyword">ON</span> almart_2015_12_10 (date_key);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> almart_date_key_2015_12_11</div><div class="line"><span class="keyword">ON</span> almart_2015_12_11 (date_key);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> almart_date_key_2015_12_12</div><div class="line"><span class="keyword">ON</span> almart_2015_12_12 (date_key);</div><div class="line"></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">INDEX</span> almart_date_key_2015_12_13</div><div class="line"><span class="keyword">ON</span> almart_2015_12_13 (date_key);</div></pre></td></tr></table></figure>
</li>
<li><p>定义一个trigger或者rule把对主表的数据插入操作重定向到对应的分区表。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--创建分区函数</span></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> almart_partition_trigger()</div><div class="line"><span class="keyword">RETURNS</span> <span class="keyword">TRIGGER</span> <span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">    <span class="keyword">IF</span> NEW.date_key = <span class="built_in">DATE</span> <span class="string">'2015-12-10'</span></div><div class="line">    <span class="keyword">THEN</span></div><div class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_10 <span class="keyword">VALUES</span> (NEW.*);</div><div class="line">    ELSIF NEW.date_key = DATE '2015-12-11'</div><div class="line">    THEN</div><div class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_11 <span class="keyword">VALUES</span> (NEW.*);</div><div class="line">    ELSIF NEW.date_key = DATE '2015-12-12'</div><div class="line">    THEN</div><div class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_12 <span class="keyword">VALUES</span> (NEW.*);</div><div class="line">    ELSIF NEW.date_key = DATE '2015-12-13'</div><div class="line">    THEN</div><div class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_13 <span class="keyword">VALUES</span> (NEW.*);</div><div class="line">    ELSIF NEW.date_key = DATE '2015-12-14'</div><div class="line">    THEN</div><div class="line">        <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_14 <span class="keyword">VALUES</span> (NEW.*);</div><div class="line">    <span class="keyword">END</span> <span class="keyword">IF</span>;</div><div class="line">    RETURN NULL;</div><div class="line"><span class="keyword">END</span>;</div><div class="line">$$</div><div class="line">LANGUAGE plpgsql;</div><div class="line"></div><div class="line"><span class="comment">--挂载分区Trigger</span></div><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> insert_almart_partition_trigger</div><div class="line"><span class="keyword">BEFORE</span> <span class="keyword">INSERT</span> <span class="keyword">ON</span> almart</div><div class="line"><span class="keyword">FOR</span> <span class="keyword">EACH</span> <span class="keyword">ROW</span> <span class="keyword">EXECUTE</span> <span class="keyword">PROCEDURE</span> almart_partition_trigger();</div></pre></td></tr></table></figure>
</li>
<li><p>确保postgresql.conf中的<a href="http://www.postgresql.org/docs/9.1/static/runtime-config-query.html#GUC-CONSTRAINT-EXCLUSION" target="_blank" rel="external">constraint_exclusion</a>配置项没有被disable。这一点非常重要，如果该参数项被disable，则基于分区表的查询性能无法得到优化，甚至比不使用分区表直接使用索引性能更低。</p>
</li>
</ol>
<h2 id="表分区如何加速查询优化"><a href="#表分区如何加速查询优化" class="headerlink" title="表分区如何加速查询优化"></a>表分区如何加速查询优化</h2><p>　　当<code>constraint_exclusion</code>为<code>on</code>或者<code>partition</code>时，查询计划器会根据分区表的检查限制将对主表的查询限制在符合检查限制条件的分区表上，直接避免了对不符合条件的分区表的扫描。<br>　　为了验证分区表的优势，这里创建一个与上文创建的almart结构一样的表almart_all，并为其date_key创建索引，向almart和almart_all中插入同样的9000万条数据（数据的时间跨度为2015-12-01到2015-12-30）。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> almart_all</div><div class="line">(</div><div class="line">	date_key <span class="built_in">date</span>,</div><div class="line">	hour_key <span class="built_in">smallint</span>,</div><div class="line">	client_key <span class="built_in">integer</span>,</div><div class="line">	item_key <span class="built_in">integer</span>,</div><div class="line">	<span class="keyword">account</span> <span class="built_in">integer</span>,</div><div class="line">	expense <span class="built_in">numeric</span></div><div class="line">);</div></pre></td></tr></table></figure></p>
<p>　　插入随机测试数据到almart_all<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span></div><div class="line">	almart_all</div><div class="line"><span class="keyword">select</span></div><div class="line">	(<span class="keyword">select</span></div><div class="line">		array_agg(i::<span class="built_in">date</span>)</div><div class="line">	<span class="keyword">from</span></div><div class="line">		generate_series(</div><div class="line">		<span class="string">'2015-12-01'</span>::<span class="built_in">date</span>,</div><div class="line">		<span class="string">'2015-12-30'</span>::<span class="built_in">date</span>,</div><div class="line">		<span class="string">'1 day'</span>::<span class="built_in">interval</span>) <span class="keyword">as</span> t(i)</div><div class="line">	)[<span class="keyword">floor</span>(random()*<span class="number">4</span>)+<span class="number">1</span>] <span class="keyword">as</span> date_key,</div><div class="line">	<span class="keyword">floor</span>(random()*<span class="number">24</span>) <span class="keyword">as</span> hour_key,</div><div class="line">	<span class="keyword">floor</span>(random()*<span class="number">1000000</span>)+<span class="number">1</span> <span class="keyword">as</span> client_key,</div><div class="line">	<span class="keyword">floor</span>(random()*<span class="number">100000</span>)+<span class="number">1</span> <span class="keyword">as</span> item_key,</div><div class="line">	<span class="keyword">floor</span>(random()*<span class="number">20</span>)+<span class="number">1</span> <span class="keyword">as</span> <span class="keyword">account</span>,</div><div class="line">	<span class="keyword">floor</span>(random()*<span class="number">10000</span>)+<span class="number">1</span> <span class="keyword">as</span> expense</div><div class="line"><span class="keyword">from</span></div><div class="line">	generate_series(<span class="number">1</span>,<span class="number">300000000</span>,<span class="number">1</span>);</div></pre></td></tr></table></figure></p>
<p>　　插入同样的测试数据到almart<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart_all;</div></pre></td></tr></table></figure></p>
<p>　　在almart和slmart_all上执行同样的query，查询2015-12-15日不同client_key的平均消费额。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line">\timing</div><div class="line"><span class="keyword">explain</span> <span class="keyword">analyze</span></div><div class="line"><span class="keyword">select</span></div><div class="line">	<span class="keyword">avg</span>(expense)</div><div class="line"><span class="keyword">from</span></div><div class="line">	(<span class="keyword">select</span></div><div class="line">		client_key,</div><div class="line">		<span class="keyword">sum</span>(expense) <span class="keyword">as</span> expense</div><div class="line">	<span class="keyword">from</span></div><div class="line">		almart</div><div class="line">	<span class="keyword">where</span></div><div class="line">		date_key = <span class="built_in">date</span> <span class="string">'2015-12-15'</span></div><div class="line">	<span class="keyword">group</span> <span class="keyword">by</span> <span class="number">1</span></div><div class="line">	)；</div><div class="line">                                         <span class="keyword">QUERY</span> PLAN</div><div class="line"><span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------</span></div><div class="line"> <span class="keyword">Aggregate</span>  (<span class="keyword">cost</span>=<span class="number">19449.05</span>.<span class="number">.19449</span><span class="number">.06</span> <span class="keyword">rows</span>=<span class="number">1</span> width=<span class="number">32</span>) (actual <span class="keyword">time</span>=<span class="number">9474.203</span>.<span class="number">.9474</span><span class="number">.203</span> <span class="keyword">rows</span>=<span class="number">1</span> loops=<span class="number">1</span>)</div><div class="line">   -&gt;  HashAggregate  (<span class="keyword">cost</span>=<span class="number">19196.10</span>.<span class="number">.19308</span><span class="number">.52</span> <span class="keyword">rows</span>=<span class="number">11242</span> width=<span class="number">36</span>) (actual <span class="keyword">time</span>=<span class="number">8632.592</span>.<span class="number">.9114</span><span class="number">.973</span> <span class="keyword">rows</span>=<span class="number">949825</span> loops=<span class="number">1</span>)</div><div class="line">         -&gt;  Append  (<span class="keyword">cost</span>=<span class="number">0.00</span>.<span class="number">.19139</span><span class="number">.89</span> <span class="keyword">rows</span>=<span class="number">11242</span> width=<span class="number">36</span>) (actual <span class="keyword">time</span>=<span class="number">4594.262</span>.<span class="number">.6091</span><span class="number">.630</span> <span class="keyword">rows</span>=<span class="number">2997704</span> loops=<span class="number">1</span>)</div><div class="line">               -&gt;  Seq <span class="keyword">Scan</span> <span class="keyword">on</span> almart  (<span class="keyword">cost</span>=<span class="number">0.00</span>.<span class="number">.0</span><span class="number">.00</span> <span class="keyword">rows</span>=<span class="number">1</span> width=<span class="number">9</span>) (actual <span class="keyword">time</span>=<span class="number">0.002</span>.<span class="number">.0</span><span class="number">.002</span> <span class="keyword">rows</span>=<span class="number">0</span> loops=<span class="number">1</span>)</div><div class="line">                     Filter: (date_key = <span class="string">'2015-12-15'</span>::<span class="built_in">date</span>)</div><div class="line">               -&gt;  <span class="keyword">Bitmap</span> <span class="keyword">Heap</span> <span class="keyword">Scan</span> <span class="keyword">on</span> almart_2015_12_15  (<span class="keyword">cost</span>=<span class="number">299.55</span>.<span class="number">.19139</span><span class="number">.89</span> <span class="keyword">rows</span>=<span class="number">11241</span> width=<span class="number">36</span>) (actual <span class="keyword">time</span>=<span class="number">4594.258</span>.<span class="number">.5842</span><span class="number">.708</span> <span class="keyword">rows</span>=<span class="number">2997704</span> loops=<span class="number">1</span>)</div><div class="line">                     Recheck Cond: (date_key = <span class="string">'2015-12-15'</span>::<span class="built_in">date</span>)</div><div class="line">                     -&gt;  <span class="keyword">Bitmap</span> <span class="keyword">Index</span> <span class="keyword">Scan</span> <span class="keyword">on</span> almart_date_key_2015_12_15  (<span class="keyword">cost</span>=<span class="number">0.00</span>.<span class="number">.296</span><span class="number">.74</span> <span class="keyword">rows</span>=<span class="number">11241</span> width=<span class="number">0</span>) (actual <span class="keyword">time</span>=<span class="number">4587.582</span>.<span class="number">.4587</span><span class="number">.582</span> <span class="keyword">rows</span>=<span class="number">2997704</span> loops=<span class="number">1</span>)</div><div class="line">                           <span class="keyword">Index</span> Cond: (date_key = <span class="string">'2015-12-15'</span>::<span class="built_in">date</span>)</div><div class="line"> Total runtime: <span class="number">9506.507</span> ms</div><div class="line">(<span class="number">10</span> <span class="keyword">rows</span>)</div><div class="line"></div><div class="line"><span class="keyword">Time</span>: <span class="number">9692.352</span> ms</div><div class="line"></div><div class="line"><span class="keyword">explain</span> <span class="keyword">analyze</span></div><div class="line"><span class="keyword">select</span></div><div class="line">	<span class="keyword">avg</span>(expense)</div><div class="line"><span class="keyword">from</span></div><div class="line">	(<span class="keyword">select</span></div><div class="line">		client_key,</div><div class="line">		<span class="keyword">sum</span>(expense) <span class="keyword">as</span> expense</div><div class="line">	<span class="keyword">from</span></div><div class="line">		almart_all</div><div class="line">	<span class="keyword">where</span></div><div class="line">		date_key = <span class="built_in">date</span> <span class="string">'2015-12-15'</span></div><div class="line">	<span class="keyword">group</span> <span class="keyword">by</span> <span class="number">1</span></div><div class="line">	) foo；</div><div class="line">                                         <span class="keyword">QUERY</span> PLAN</div><div class="line"><span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------</span></div><div class="line"> <span class="keyword">Aggregate</span>  (<span class="keyword">cost</span>=<span class="number">770294.11</span>.<span class="number">.770294</span><span class="number">.12</span> <span class="keyword">rows</span>=<span class="number">1</span> width=<span class="number">32</span>) (actual <span class="keyword">time</span>=<span class="number">62959.917</span>.<span class="number">.62959</span><span class="number">.917</span> <span class="keyword">rows</span>=<span class="number">1</span> loops=<span class="number">1</span>)</div><div class="line">   -&gt;  HashAggregate  (<span class="keyword">cost</span>=<span class="number">769549.54</span>.<span class="number">.769880</span><span class="number">.46</span> <span class="keyword">rows</span>=<span class="number">33092</span> width=<span class="number">9</span>) (actual <span class="keyword">time</span>=<span class="number">61694.564</span>.<span class="number">.62574</span><span class="number">.385</span> <span class="keyword">rows</span>=<span class="number">949825</span> loops=<span class="number">1</span>)</div><div class="line">         -&gt;  <span class="keyword">Bitmap</span> <span class="keyword">Heap</span> <span class="keyword">Scan</span> <span class="keyword">on</span> almart_all  (<span class="keyword">cost</span>=<span class="number">55704.56</span>.<span class="number">.754669</span><span class="number">.55</span> <span class="keyword">rows</span>=<span class="number">2975999</span> width=<span class="number">9</span>) (actual <span class="keyword">time</span>=<span class="number">919.941</span>.<span class="number">.56291</span><span class="number">.128</span> <span class="keyword">rows</span>=<span class="number">2997704</span> loops=<span class="number">1</span>)</div><div class="line">               Recheck Cond: (date_key = <span class="string">'2015-12-15'</span>::<span class="built_in">date</span>)</div><div class="line">               -&gt;  <span class="keyword">Bitmap</span> <span class="keyword">Index</span> <span class="keyword">Scan</span> <span class="keyword">on</span> almart_all_date_key_index  (<span class="keyword">cost</span>=<span class="number">0.00</span>.<span class="number">.54960</span><span class="number">.56</span> <span class="keyword">rows</span>=<span class="number">2975999</span> width=<span class="number">0</span>) (actual <span class="keyword">time</span>=<span class="number">677.741</span>.<span class="number">.677</span><span class="number">.741</span> <span class="keyword">rows</span>=<span class="number">2997704</span> loops=<span class="number">1</span>)</div><div class="line">                     <span class="keyword">Index</span> Cond: (date_key = <span class="string">'2015-12-15'</span>::<span class="built_in">date</span>)</div><div class="line"> Total runtime: <span class="number">62960.228</span> ms</div><div class="line">(<span class="number">7</span> <span class="keyword">rows</span>)</div><div class="line"></div><div class="line"><span class="keyword">Time</span>: <span class="number">62970.269</span> ms</div></pre></td></tr></table></figure></p>
<p>　　由上可见，使用分区表时，所需时间为9.5秒，而不使用分区表时，耗时63秒。<br>　　使用分区表，PostgreSQL跳过了除2015-12-15日分区表以外的分区表，只扫描2015-12-15的分区表。而不使用分区表只使用索引时，数据库要使用索引扫描整个数据库。另一方面，使用分区表时，每个表的索引是独立的，即每个分区表的索引都只针对一个小的分区表。而不使用分区表时，索引是建立在整个大表上的。数据量越大，索引的速度相对越慢。</p>
<h2 id="管理分区"><a href="#管理分区" class="headerlink" title="管理分区"></a>管理分区</h2><p>　　从上文分区表的创建过程可以看出，分区表必须在相关数据插入之前创建好。在生产环境中，很难保证所需的分区表都已经被提前创建好。同时为了不让分区表过多，影响数据库性能，不能创建过多无用的分区表。</p>
<h3 id="周期性创建分区表"><a href="#周期性创建分区表" class="headerlink" title="周期性创建分区表"></a>周期性创建分区表</h3><p>　　在生产环境中，经常需要周期性删除和创建一些分区表。一个经典的做法是使用定时任务。比如使用cronjob每天运行一次，将1年前的分区表删除，并创建第二天分区表（该表按天分区）。有时为了容错，会将之后一周的分区表全部创建出来。</p>
<h3 id="动态创建分区表"><a href="#动态创建分区表" class="headerlink" title="动态创建分区表"></a>动态创建分区表</h3><p>　　上述周期性创建分区表的方法在绝大部分情况下有效，但也只能在一定程度上容错。另外，上文所使用的分区函数，使用<code>IF</code>语句对date_key进行判断，需要为每一个分区表准备一个<code>IF</code>语句。<br>　　如插入<code>date_key</code>分别为<code>2015-12-10</code>到<code>2015-12-14</code>的5条记录，前面4条均可插入成功，因为相应的分区表已经存在，但最后一条数据因为相应的分区表不存在而插入失败。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart(date_key) <span class="keyword">VALUES</span> (<span class="string">'2015-12-10'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">0</span></div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart(date_key) <span class="keyword">VALUES</span> (<span class="string">'2015-12-11'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">0</span></div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart(date_key) <span class="keyword">VALUES</span> (<span class="string">'2015-12-12'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">0</span></div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart(date_key) <span class="keyword">VALUES</span> (<span class="string">'2015-12-13'</span>);</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">0</span></div><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart(date_key) <span class="keyword">VALUES</span> (<span class="string">'2015-12-14'</span>);</div><div class="line">ERROR:  relation "almart_2015_12_14" does not exist</div><div class="line">LINE 1: <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_14 <span class="keyword">VALUES</span> (NEW.*)</div><div class="line">                    ^</div><div class="line"><span class="keyword">QUERY</span>:  <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_14 <span class="keyword">VALUES</span> (NEW.*)</div><div class="line"><span class="keyword">CONTEXT</span>:  PL/pgSQL <span class="keyword">function</span> almart_partition_trigger() line <span class="number">17</span> <span class="keyword">at</span> <span class="keyword">SQL</span> <span class="keyword">statement</span></div><div class="line"></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart;</div><div class="line">  date_key  | hour_key | client_key | item_key | account | expense</div><div class="line"><span class="comment">------------+----------+------------+----------+---------+---------</span></div><div class="line"> 2015-12-10 |          |            |          |         |</div><div class="line"> 2015-12-11 |          |            |          |         |</div><div class="line"> 2015-12-12 |          |            |          |         |</div><div class="line"> 2015-12-13 |          |            |          |         |</div><div class="line">(4 rows)</div></pre></td></tr></table></figure></p>
<p>　　针对该问题，可使用动态SQL的方式进行数据路由，并通过获取将数据插入不存在的分区表产生的异常消息并动态创建分区表的方式保证分区表的可用性。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> <span class="keyword">REPLACE</span> <span class="keyword">FUNCTION</span> almart_partition_trigger()</div><div class="line"><span class="keyword">RETURNS</span> <span class="keyword">TRIGGER</span> <span class="keyword">AS</span> $$</div><div class="line"><span class="keyword">DECLARE</span> date_text <span class="built_in">TEXT</span>;</div><div class="line"><span class="keyword">DECLARE</span> insert_statement <span class="built_in">TEXT</span>;</div><div class="line"><span class="keyword">BEGIN</span></div><div class="line">	<span class="keyword">SELECT</span> to_char(NEW.date_key, <span class="string">'YYYY_MM_DD'</span>) <span class="keyword">INTO</span> date_text;</div><div class="line">	insert_statement := '<span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_<span class="string">'</span></div><div class="line">		|| date_text</div><div class="line">		||' <span class="keyword">VALUES</span> ($<span class="number">1.</span>*)<span class="string">';</span></div><div class="line">	EXECUTE insert_statement USING NEW;</div><div class="line">	RETURN NULL;</div><div class="line">	EXCEPTION</div><div class="line">	WHEN UNDEFINED_TABLE</div><div class="line">	THEN</div><div class="line">		EXECUTE</div><div class="line">			'<span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> almart_<span class="string">'</span></div><div class="line">			|| date_text</div><div class="line">			|| '(<span class="keyword">CHECK</span> (date_key = <span class="string">'''</span></div><div class="line">			|| date_text</div><div class="line">			|| ''')) INHERITS (almart)<span class="string">';</span></div><div class="line">		RAISE NOTICE '<span class="keyword">CREATE</span> NON-EXISTANT <span class="keyword">TABLE</span> almart_%<span class="string">', date_text;</span></div><div class="line">		EXECUTE</div><div class="line">			'<span class="keyword">CREATE</span> <span class="keyword">INDEX</span> almart_date_key_<span class="string">'</span></div><div class="line">			|| date_text</div><div class="line">			|| ' <span class="keyword">ON</span> almart_<span class="string">'</span></div><div class="line">			|| date_text</div><div class="line">			|| '(date_key)<span class="string">';</span></div><div class="line">		EXECUTE insert_statement USING NEW;</div><div class="line">    RETURN NULL;</div><div class="line">END;</div><div class="line">$$</div><div class="line">LANGUAGE plpgsql;</div></pre></td></tr></table></figure></p>
<p>　　使用该方法后，再次插入<code>date_key</code>为<code>2015-12-14</code>的记录时，对应的分区表不存在，但会被自动创建。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart <span class="keyword">VALUES</span>(<span class="string">'2015-12-13'</span>),(<span class="string">'2015-12-14'</span>),(<span class="string">'2015-12-15'</span>);</div><div class="line">NOTICE:  <span class="keyword">CREATE</span> NON-EXISTANT <span class="keyword">TABLE</span> almart_2015_12_14</div><div class="line"><span class="keyword">NOTICE</span>:  <span class="keyword">CREATE</span> NON-EXISTANT <span class="keyword">TABLE</span> almart_2015_12_15</div><div class="line"><span class="keyword">INSERT</span> <span class="number">0</span> <span class="number">0</span></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart;</div><div class="line">  date_key  | hour_key | client_key | item_key | account | expense</div><div class="line"><span class="comment">------------+----------+------------+----------+---------+---------</span></div><div class="line"> 2015-12-10 |          |            |          |         |</div><div class="line"> 2015-12-11 |          |            |          |         |</div><div class="line"> 2015-12-12 |          |            |          |         |</div><div class="line"> 2015-12-13 |          |            |          |         |</div><div class="line"> 2015-12-13 |          |            |          |         |</div><div class="line"> 2015-12-14 |          |            |          |         |</div><div class="line"> 2015-12-15 |          |            |          |         |</div><div class="line">(7 rows)</div></pre></td></tr></table></figure></p>
<h3 id="移除分区表"><a href="#移除分区表" class="headerlink" title="移除分区表"></a>移除分区表</h3><p>　　虽然如上文所述，分区表的使用可以跳过扫描不必要的分区表从而提高查询速度。但由于服务器磁盘的限制，不可能无限制存储所有数据，经常需要周期性删除过期数据，如删除5年前的数据。如果使用传统的<code>DELETE</code>，删除速度慢，并且由于<code>DELETE</code>只是将相应数据标记为删除状态，不会将数据从磁盘删除，需要使用<code>VACUUM</code>释放磁盘，从而引入额外负载。<br>　　而在使用分区表的条件下，可以通过直接<code>DROP</code>过期分区表的方式快速方便地移除过期数据。如<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> almart_2014_12_15;</div></pre></td></tr></table></figure></p>
<p>　　另外，无论使用<code>DELETE</code>还是<code>DROP</code>，都会将数据完全删除，即使有需要也无法再次使用。因此还有另外一种方式，即更改过期的分区表，解除其与主表的继承关系，如。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2015_12_15 <span class="keyword">NO</span> INHERIT almart;</div></pre></td></tr></table></figure></p>
<p>　　但该方法并未释放磁盘。此时可通过更改该分区表，使其属于其它<a href="http://www.postgresql.org/docs/9.4/static/manage-ag-tablespaces.html" target="_blank" rel="external">TABLESPACE</a>，同时将该TABLESPACE的目录设置为其它磁盘分区上的目录，从而释放主表所在的磁盘。同时，如果之后还需要再次使用该“过期”数据，只需更改该分区表，使其再次与主表形成继承关系。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLESPACE</span> cheap_table_space LOCATION <span class="string">'/data/cheap_disk'</span>;</div><div class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> almart_2014_12_15 <span class="keyword">SET</span> <span class="keyword">TABLESPACE</span> cheap_table_space;</div></pre></td></tr></table></figure></p>
<h2 id="PostgreSQL表分区的其它方式"><a href="#PostgreSQL表分区的其它方式" class="headerlink" title="PostgreSQL表分区的其它方式"></a>PostgreSQL表分区的其它方式</h2><p>　　除了使用Trigger外，可以使用Rule将对主表的插入请求重定向到对应的子表。如<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> RULE almart_rule_2015_12_31 <span class="keyword">AS</span></div><div class="line"><span class="keyword">ON</span> <span class="keyword">INSERT</span> <span class="keyword">TO</span> almart</div><div class="line"><span class="keyword">WHERE</span></div><div class="line">    date_key = <span class="built_in">DATE</span> <span class="string">'2015-12-31'</span></div><div class="line"><span class="keyword">DO</span> INSTEAD</div><div class="line">    <span class="keyword">INSERT</span> <span class="keyword">INTO</span> almart_2015_12_31 <span class="keyword">VALUES</span> (NEW.*);</div></pre></td></tr></table></figure></p>
<p>　　与Trigger相比，Rule会带来更大的额外开销，但每个请求只造成一次开销而非每条数据都引入一次开销，所以该方法对大批量的数据插入操作更具优势。然而，实际上在绝大部分场景下，Trigger比Rule的效率更高。</p>
<p>　　同时，<code>COPY</code>操作会忽略Rule，而可以正常触发Trigger。</p>
<p>　　另外，如果使用Rule方式，没有比较简单的方法处理没有被Rule覆盖到的插入操作。此时该数据会被插入到主表中而不会报错，从而无法有效利用表分区的优势。</p>
<p>　　除了使用表继承外，还可使用<code>UNION ALL</code>的方式达到表分区的效果。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> almart <span class="keyword">AS</span></div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart_2015_12_10</div><div class="line"><span class="keyword">UNION</span> ALL</div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart_2015_12_11</div><div class="line"><span class="keyword">UNION</span> ALL</div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart_2015_12_12</div><div class="line">...</div><div class="line"><span class="keyword">UNION</span> ALL</div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> almart_2015_12_30;</div></pre></td></tr></table></figure></p>
<p>　　当有新的分区表时，需要更新该View。实践中，与使用表继承相比，一般不推荐使用该方法。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>如果要充分使用分区表的查询优势，必须使用分区时的字段作为过滤条件</li>
<li>分区字段被用作过滤条件时，<code>WHERE</code>语句只能包含常量而不能使用参数化的表达式，因为这些表达式只有在运行时才能确定其值，而planner在真正执行query之前无法判定哪些分区表应该被使用</li>
<li>跳过不符合条件分区表是通过planner根据分区表的检查限制条件实现的，而非通过索引</li>
<li>必须将<code>constraint_exclusion</code>设置为<code>ON</code>或<code>Partition</code>，否则planner将无法正常跳过不符合条件的分区表，也即无法发挥表分区的优势</li>
<li>除了在查询上的优势，分区表的使用，也可提高删除旧数据的性能</li>
<li>为了充分利用分区表的优势，应该保证各分区表的检查限制条件互斥，但目前并无自动化的方式来保证这一点。因此使用代码造化创建或者修改分区表比手工操作更安全</li>
<li>在更新数据集时，如果使得partition key column(s)变化到需要使某些数据移动到其它分区，则该更新操作会因为检查限制的存在而失败。如果一定要处理这种情景，可以使用更新Trigger，但这会使得结构变得复杂。</li>
<li>大量的分区表会极大地增加查询计划时间。表分区在多达几百个分区表时能很好地发挥优势，但不要使用多达几千个分区表。</li>
</ul>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了数据库分区表的使用场景，优势，原理，及在PostgreSQL中的实现和注意事项。
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（四）- Kafka Consumer设计解析</title>
    <link href="http://www.jasongj.com/2015/08/09/KafkaColumn4/"/>
    <id>http://www.jasongj.com/2015/08/09/KafkaColumn4/</id>
    <published>2015-08-09T12:36:27.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。（已授权<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-4" target="_blank" rel="external">InfoQ中文站发布</a>）<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/08/09/KafkaColumn4">原文链接</a>　<a href="http://www.jasongj.com/2015/08/09/KafkaColumn4">http://www.jasongj.com/2015/08/09/KafkaColumn4</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>　　本文主要介绍了Kafka High Level Consumer，Consumer Group，Consumer Rebalance，Low Level Consumer实现的语义，以及适用场景。以及未来版本中对High Level Consumer的重新设计–使用Consumer Coordinator解决Split Brain和Herd等问题。</p>
<h1 id="High-Level-Consumer"><a href="#High-Level-Consumer" class="headerlink" title="High Level Consumer"></a>High Level Consumer</h1><p>　　很多时候，客户程序只是希望从Kafka读取数据，不太关心消息offset的处理。同时也希望提供一些语义，例如同一条消息只被某一个Consumer消费（单播）或被所有Consumer消费（广播）。因此，Kafka Hight Level Consumer提供了一个从Kafka消费数据的高层抽象，从而屏蔽掉其中的细节并提供丰富的语义。
　　</p>
<h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>　　High Level Consumer将从某个Partition读取的最后一条消息的offset存于Zookeeper中(<a href="https://archive.apache.org/dist/kafka/0.8.2.0/RELEASE_NOTES.html" target="_blank" rel="external">Kafka从0.8.2版本</a>开始同时支持将offset存于Zookeeper中与<a href="https://issues.apache.org/jira/browse/KAFKA-1012" target="_blank" rel="external">将offset存于专用的Kafka Topic中</a>)。这个offset基于客户程序提供给Kafka的名字来保存，这个名字被称为Consumer Group。Consumer Group是整个Kafka集群全局的，而非某个Topic的。每一个High Level Consumer实例都属于一个Consumer Group，若不指定则属于默认的Group。<br>　　Zookeeper中Consumer相关节点如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn4/KafkaColumn4-consumers.png" alt="Consumer Zookeeper Structure"><br>　　<br>　　很多传统的Message Queue都会在消息被消费完后将消息删除，一方面避免重复消费，另一方面可以保证Queue的长度比较短，提高效率。而如上文所述，Kafka并不删除已消费的消息，为了实现传统Message Queue消息只被消费一次的语义，Kafka保证每条消息在同一个Consumer Group里只会被某一个Consumer消费。与传统Message Queue不同的是，Kafka还允许不同Consumer Group同时消费同一条消息，这一特性可以为消息的多元化处理提供支持。<br><img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/consumer_group.png" alt="kafka consumer group"><br>　　<br>　　实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer在不同的Consumer Group即可。下图展示了Kafka在LinkedIn的一种简化部署模型。<br><img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/kafka_in_linkedin.png" alt="kafka sample deployment in linkedin"><br>　　<br>　　为了更清晰展示Kafka Consumer Group的特性，笔者进行了一项测试。创建一个Topic (名为topic1)，再创建一个属于group1的Consumer实例，并创建三个属于group2的Consumer实例，然后通过Producer向topic1发送Key分别为1，2，3的消息。结果发现属于group1的Consumer收到了所有的这三条消息，同时group2中的3个Consumer分别收到了Key为1，2，3的消息，如下图所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/consumer_group_test.png" alt="kafka consumer group"><br>　　注：上图中每个黑色区域代表一个Consumer实例，每个实例只创建一个MessageStream。实际上，本实验将Consumer应用程序打成jar包，并在4个不同的命令行终端中传入不同的参数运行。</p>
<h2 id="High-Level-Consumer-Rebalance"><a href="#High-Level-Consumer-Rebalance" class="headerlink" title="High Level Consumer Rebalance"></a>High Level Consumer Rebalance</h2><p>　　（本节所讲述Rebalance相关内容均基于Kafka High Level Consumer）<br>　　Kafka保证同一Consumer Group中只有一个Consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个Consumer实例只会消费某一个或多个特定Partition的数据，而某个Partition的数据只会被某一个特定的Consumer实例所消费。也就是说Kafka对消息的分配是以Partition为单位分配的，而非以每一条消息作为分配单元。这样设计的劣势是无法保证同一个Consumer Group里的Consumer均匀消费数据，优势是每个Consumer不用都跟大量的Broker通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个Partition里的数据是有序的，这种设计可以保证每个Partition里的数据可以被有序消费。<br>　　如果某Consumer Group中Consumer（每个Consumer只创建1个MessageStream）数量少于Partition数量，则至少有一个Consumer会消费多个Partition的数据，如果Consumer的数量与Partition数量相同，则正好一个Consumer消费一个Partition的数据。而如果Consumer的数量多于Partition的数量时，会有部分Consumer无法消费该Topic下任何一条消息。<br>　　如下例所示，如果topic1有0，1，2共三个Partition，当group1只有一个Consumer(名为consumer1)时，该 Consumer可消费这3个Partition的所有数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer1.png" alt="kafka rebalance 3 partition 1 consumer"><br>　　<br>　　增加一个Consumer(consumer2)后，其中一个Consumer（consumer1）可消费2个Partition的数据（Partition 0和Partition 1），另外一个Consumer(consumer2)可消费另外一个Partition（Partition 2）的数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2.png" alt="kafka rebalance 3 partitin 2 consumer"><br>　　<br>　　再增加一个Consumer(consumer3)后，每个Consumer可消费一个Partition的数据。consumer1消费partition0，consumer2消费partition1，consumer3消费partition2。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2_3.png" alt="kafka rebalance 3 partition 3 consumer"><br>　　<br>　　再增加一个Consumer（consumer4）后，其中3个Consumer可分别消费一个Partition的数据，另外一个Consumer（consumer4）不能消费topic1的任何数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2_3_4.png" alt="kafka rebalance 3 partition 4 consumer"><br>　　<br>　　此时关闭consumer1，其余3个Consumer可分别消费一个Partition的数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_2_3_4.png" alt="kafka rebalance 3 partition 3 consumer"><br>　　<br>　　接着关闭consumer2，consumer3可消费2个Partition，consumer4可消费1个Partition。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_3_4.png" alt="kafka rebalance 3 partition 2 consumer"><br>　　<br>　　再关闭consumer3，仅存的consumer4可同时消费topic1的3个Partition。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_4.png" alt="kafka rebalance 3 partition 1 consumer"></p>
<p>　　Consumer Rebalance的算法如下：</p>
<ul>
<li>将目标Topic下的所有Partirtion排序，存于$P_T$</li>
<li>对某Consumer Group下所有Consumer排序，存$于C_G$，第$i$个Consumer记为$C_i$</li>
<li>$N=size(P_T)/size(C_G)$，向上取整</li>
<li>解除$C_i$对原来分配的Partition的消费权（i从0开始）</li>
<li>将第$i*N$到$（i+1）*N-1$个Partition分配给$C_i$</li>
</ul>
<p>　　<br>　　目前，最新版（0.8.2.1）Kafka的Consumer Rebalance的控制策略是由每一个Consumer通过在Zookeeper上注册Watch完成的。每个Consumer被创建时会触发Consumer Group的Rebalance，具体启动流程如下：</p>
<ul>
<li>High Level Consumer启动时将其ID注册到其Consumer Group下，在Zookeeper上的路径为<code>/consumers/[consumer group]/ids/[consumer id]</code></li>
<li>在<code>/consumers/[consumer group]/ids</code>上注册Watch</li>
<li>在<code>/brokers/ids</code>上注册Watch</li>
<li>如果Consumer通过Topic Filter创建消息流，则它会同时在<code>/brokers/topics</code>上也创建Watch</li>
<li>强制自己在其Consumer Group内启动Rebalance流程</li>
</ul>
<p>　　在这种策略下，每一个Consumer或者Broker的增加或者减少都会触发Consumer Rebalance。因为每个Consumer只负责调整自己所消费的Partition，为了保证整个Consumer Group的一致性，当一个Consumer触发了Rebalance时，该Consumer Group内的其它所有其它Consumer也应该同时触发Rebalance。</p>
<p>　　该方式有如下缺陷：</p>
<ul>
<li><b>Herd effect</b><br>　　任何Broker或者Consumer的增减都会触发所有的Consumer的Rebalance</li>
<li><b>Split Brain</b><br>　　每个Consumer分别单独通过Zookeeper判断哪些Broker和Consumer 宕机了，那么不同Consumer<a href="http://zookeeper.apache.org/doc/r3.1.2/zookeeperProgrammers.html#ch_zkGuarantees" target="_blank" rel="external">在同一时刻从Zookeeper“看”到的View就可能不一样，这是由Zookeeper的特性决定的</a>，这就会造成不正确的Reblance尝试。</li>
<li><b>调整结果不可控</b><br>　　所有的Consumer都并不知道其它Consumer的Rebalance是否成功，这可能会导致Kafka<a href="https://issues.apache.org/jira/browse/KAFKA-242" target="_blank" rel="external">工作在一个不正确的状态</a>。</li>
</ul>
<p>　　根据Kafka社区wiki，Kafka作者正在考虑在还未发布的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design" target="_blank" rel="external">0.9.x版本中使用中心协调器(Coordinator)</a>。大体思想是为所有Consumer Group的子集选举出一个Broker作为Coordinator，由它Watch Zookeeper，从而判断是否有Partition或者Consumer的增减，然后生成Rebalance命令，并检查是否这些Rebalance在所有相关的Consumer中被执行成功，如果不成功则重试，若成功则认为此次Rebalance成功（这个过程跟Replication Controller非常类似）。具体方案将在后文中详细阐述。
　　</p>
<h1 id="Low-Level-Consumer"><a href="#Low-Level-Consumer" class="headerlink" title="Low Level Consumer"></a>Low Level Consumer</h1><p>　　使用Low Level Consumer (Simple Consumer)的主要原因是，用户希望比Consumer Group更好的控制数据的消费。比如：</p>
<ul>
<li>同一条消息读多次 </li>
<li>只读取某个Topic的部分Partition</li>
<li>管理事务，从而确保每条消息被处理一次，且仅被处理一次</li>
</ul>
<p>　　与Consumer Group相比，Low Level Consumer要求用户做大量的额外工作。</p>
<ul>
<li>必须在应用程序中跟踪offset，从而确定下一条应该消费哪条消息 </li>
<li>应用程序需要通过程序获知每个Partition的Leader是谁</li>
<li>必须处理Leader的变化</li>
</ul>
<p>　　使用Low Level Consumer的一般流程如下</p>
<ul>
<li>查找到一个“活着”的Broker，并且找出每个Partition的Leader</li>
<li>找出每个Partition的Follower</li>
<li>定义好请求，该请求应该能描述应用程序需要哪些数据</li>
<li>Fetch数据</li>
<li>识别Leader的变化，并对之作出必要的响应</li>
</ul>
<h1 id="Consumer重新设计"><a href="#Consumer重新设计" class="headerlink" title="Consumer重新设计"></a>Consumer重新设计</h1><p>　　根据社区社区wiki，Kafka在0.9.*版本中，重新设计Consumer可能是最重要的Feature之一。本节会根据社区wiki介绍Kafka 0.9.*中对Consumer可能的设计方向及思路。
　　</p>
<h2 id="设计方向"><a href="#设计方向" class="headerlink" title="设计方向"></a>设计方向</h2><p><strong><em>简化消费者客户端</em></strong><br>　　部分用户希望开发和使用non-java的客户端。现阶段使用non-java发SimpleConsumer比较方便，但想开发High Level Consumer并不容易。因为High Level Consumer需要实现一些复杂但必不可少的失败探测和Rebalance。如果能将消费者客户端更精简，使依赖最小化，将会极大的方便non-java用户实现自己的Consumer。<br>　　<br><strong><em>中心Coordinator</em></strong><br>　　如上文所述，当前版本的High Level Consumer存在Herd Effect和Split Brain的问题。如果将失败探测和Rebalance的逻辑放到一个高可用的中心Coordinator，那么这两个问题即可解决。同时还可大大减少Zookeeper的负载，有利于Kafka Broker的Scale Out。<br>　　<br><strong><em>允许手工管理offset</em></strong><br>　　一些系统希望以特定的时间间隔在自定义的数据库中管理Offset。这就要求Consumer能获取到每条消息的metadata，例如Topic，Partition，Offset，同时还需要在Consumer启动时得到每个Partition的Offset。实现这些，需要提供新的Consumer API。同时有个问题不得不考虑，即是否允许Consumer手工管理部分Topic的Offset，而让Kafka自动通过Zookeeper管理其它Topic的Offset。一个可能的选项是让每个Consumer只能选取1种Offset管理机制，这可极大的简化Consumer API的设计和实现。<br>　　<br><strong><em>Rebalance后触发用户指定的回调</em></strong><br>　　一些应用可能会在内存中为每个Partition维护一些状态，Rebalance时，它们可能需要将该状态持久化。因此该需求希望支持用户实现并指定一些可插拔的并在Rebalance时触发的回调。如果用户使用手动的Offset管理，那该需求可方便得由用户实现，而如果用户希望使用Kafka提供的自动Offset管理，则需要Kafka提供该回调机制。</p>
<p><strong><em>非阻塞式Consumer API</em></strong><br>　　该需求源于那些实现高层流处理操作，如filter by， group by， join等，的系统。现阶段的阻塞式Consumer几乎不可能实现Join操作。</p>
<p>##如何通过中心Coordinator实现Rebalance<br>　　成功Rebalance的结果是，被订阅的所有Topic的每一个Partition将会被Consumer Group内的一个（有且仅有一个）Consumer拥有。每一个Broker将被选举为某些Consumer Group的Coordinator。某个Cosnumer Group的Coordinator负责在该Consumer Group的成员变化或者所订阅的Topic的Partititon变化时协调Rebalance操作。</p>
<p><strong><em>Consumer</em></strong><br>　　1) Consumer启动时，先向Broker列表中的任意一个Broker发送ConsumerMetadataRequest，并通过ConsumerMetadataResponse获取它所在Group的Coordinator信息。ConsumerMetadataRequest和ConsumerMetadataResponse的结构如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">ConsumerMetadataRequest</div><div class="line">&#123;</div><div class="line">  GroupId                =&gt; String</div><div class="line">&#125;</div><div class="line"></div><div class="line">ConsumerMetadataResponse</div><div class="line">&#123;</div><div class="line">  ErrorCode              =&gt; int16</div><div class="line">  Coordinator            =&gt; Broker</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　2）Consumer连接到Coordinator并发送HeartbeatRequest，如果返回的HeartbeatResponse没有任何错误码，Consumer继续fetch数据。若其中包含IllegalGeneration错误码，即说明Coordinator已经发起了Rebalance操作，此时Consumer停止fetch数据，commit offset，并发送JoinGroupRequest给它的Coordinator，并在JoinGroupResponse中获得它应该拥有的所有Partition列表和它所属的Group的新的Generation ID。此时Rebalance完成，Consumer开始fetch数据。相应Request和Response结构如下</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">HeartbeatRequest</div><div class="line">&#123;</div><div class="line">  GroupId                =&gt; String</div><div class="line">  GroupGenerationId      =&gt; int32</div><div class="line">  ConsumerId             =&gt; String</div><div class="line">&#125;</div><div class="line"></div><div class="line">HeartbeatResponse</div><div class="line">&#123;</div><div class="line">  ErrorCode              =&gt; int16</div><div class="line">&#125;</div><div class="line"></div><div class="line">JoinGroupRequest</div><div class="line">&#123;</div><div class="line">  GroupId                     =&gt; String</div><div class="line">  SessionTimeout              =&gt; int32</div><div class="line">  Topics                      =&gt; [String]</div><div class="line">  ConsumerId                  =&gt; String</div><div class="line">  PartitionAssignmentStrategy =&gt; String</div><div class="line">&#125;</div><div class="line"></div><div class="line">JoinGroupResponse</div><div class="line">&#123;</div><div class="line">  ErrorCode              =&gt; int16</div><div class="line">  GroupGenerationId      =&gt; int32</div><div class="line">  ConsumerId             =&gt; String</div><div class="line">  PartitionsToOwn        =&gt; [TopicName [Partition]]</div><div class="line">&#125;</div><div class="line">TopicName =&gt; String</div><div class="line">Partition =&gt; int32</div></pre></td></tr></table></figure>
<p><strong><em>Consumer状态机</em></strong><br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn4/consumer_state_diagram.png" alt="Consumer状态图"><br>　　Down：Consumer停止工作<br>　　Start up &amp; discover coordinator：Consumer检测其所在Group的Coordinator。一旦它检测到Coordinator，即向其发送JoinGroupRequest。<br>　　Part of a group：该状态下，Consumer已经是该Group的成员，并周期性发送HeartbeatRequest。如HeartbeatResponse包含IllegalGeneration错误码，则转换到Stopped Consumption状态。若连接丢失，HeartbeatResponse包含NotCoordinatorForGroup错误码，则转换到Rediscover coordinator状态。<br>　　Rediscover coordinator：该状态下，Consumer不停止消费而是尝试通过发送ConsumerMetadataRequest来探测新的Coordinator，并且等待直到获得无错误码的响应。<br>　　Stopped consumption：该状态下，Consumer停止消费并提交offset，直到它再次加入Group。<br>　　<br>　　<br>　　<br><strong><em>故障检测机制</em></strong><br>　　Consumer成功加入Group后，Consumer和相应的Coordinator同时开始故障探测程序。Consumer向Coordinator发起周期性的Heartbeat（HeartbeatRequest）并等待响应，该周期为 session.timeout.ms/heartbeat.frequency。若Consumer在session.timeout.ms内未收到HeartbeatResponse，或者发现相应的Socket channel断开，它即认为Coordinator已宕机并启动Coordinator探测程序。若Coordinator在session.timeout.ms内没有收到一次HeartbeatRequest，则它将该Consumer标记为宕机状态并为其所在Group触发一次Rebalance操作。<br>　　Coordinator Failover过程中，Consumer可能会在新的Coordinator完成Failover过程之前或之后发现新的Coordinator并向其发送HeatbeatRequest。对于后者，新的Cooodinator可能拒绝该请求，致使该Consumer重新探测Coordinator并发起新的连接请求。如果该Consumer向新的Coordinator发送连接请求太晚，新的Coordinator可能已经在此之前将其标记为宕机状态而将之视为新加入的Consumer并触发一次Rebalance操作。</p>
<p><strong><em>Coordinator</em></strong><br>　　1）稳定状态下，Coordinator通过上述故障探测机制跟踪其所管理的每个Group下的每个Consumer的健康状态。<br>　　2）刚启动时或选举完成后，Coordinator从Zookeeper读取它所管理的Group列表及这些Group的成员列表。如果没有获取到Group成员信息，它不会做任何事情直到某个Group中有成员注册进来。<br>　　3）在Coordinator完成加载其管理的Group列表及其相应的成员信息之前，它将为HeartbeatRequest，OffsetCommitRequest和JoinGroupRequests返回CoordinatorStartupNotComplete错误码。此时，Consumer会重新发送请求。<br>　　4）Coordinator会跟踪被其所管理的任何Consumer Group注册的Topic的Partition的变化，并为该变化触发Rebalance操作。创建新的Topic也可能触发Rebalance，因为Consumer可以在Topic被创建之前就已经订阅它了。<br>　　Coordinator发起Rebalance操作流程如下所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/coordinator.png" alt="kafka coordinator rebalance"></p>
<p><strong><em>Coordinator状态机</em></strong><br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn4/coordinator_state_diagram.png" alt="Coordinator状态图"><br>　　Down：Coordinator不再担任之前负责的Consumer Group的Coordinator<br>　　Catch up：该状态下，Coordinator竞选成功，但还未能做好服务相应请求的准备。<br>　　Ready：该状态下，新竞选出来的Coordinator已经完成从Zookeeper中加载它所负责管理的所有Group的metadata，并可开始接收相应的请求。<br>　　Prepare for rebalance：该状态下，Coordinator在所有HeartbeatResponse中返回IllegalGeneration错误码，并等待所有Consumer向其发送JoinGroupRequest后转到Rebalancing状态。<br>　　Rebalancing：该状态下，Coordinator已经收到了JoinGroupRequest请求，并增加其Group Generation ID，分配Consumer ID，分配Partition。Rebalance成功后，它会等待接收包含新的Consumer Generation ID的HeartbeatRequest，并转至Ready状态。</p>
<p><strong><em>Coordinator Failover</em></strong><br>　　如前文所述，Rebalance操作需要经历如下几个阶段<br>　　1）Topic/Partition的改变或者新Consumer的加入或者已有Consumer停止，触发Coordinator注册在Zookeeper上的watch，Coordinator收到通知准备发起Rebalance操作。<br>　　2）Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码发起Rebalance操作。<br>　　3）Consumer发送JoinGroupRequest<br>　　4）Coordinator在Zookeeper中增加Group的Generation ID并将新的Partition分配情况写入Zookeeper<br>　　5）Coordinator发送JoinGroupResponse<br>　　<br>　　在这个过程中的每个阶段，Coordinator都可能出现故障。下面给出Rebalance不同阶段中Coordinator的Failover处理方式。<br>　　1）如果Coordinator的故障发生在第一阶段，即它收到Notification并未来得及作出响应，则新的Coordinator将从Zookeeper读取Group的metadata，包含这些Group订阅的Topic列表和之前的Partition分配。如果某个Group所订阅的Topic数或者某个Topic的Partition数与之前的Partition分配不一致，亦或者某个Group连接到新的Coordinator的Consumer数与之前Partition分配中的不一致，新的Coordinator会发起Rebalance操作。<br>　　2）如果失败发生在阶段2，它可能对部分而非全部Consumer发出带错误码的HeartbeatResponse。与第上面第一种情况一样，新的Coordinator会检测到Rebalance的必要性并发起一次Rebalance操作。如果Rebalance是由Consumer的失败所触发并且Cosnumer在Coordinator的Failover完成前恢复，新的Coordinator不会为此发起新的Rebalance操作。<br>　　3）如果Failure发生在阶段3，新的Coordinator可能只收到部分而非全部Consumer的JoinGroupRequest。Failover完成后，它可能收到部分Consumer的HeartRequest及另外部分Consumer的JoinGroupRequest。与第1种情况类似，它将发起新一轮的Rebalance操作。<br>　　4）如果Failure发生在阶段4，即它将新的Group Generation ID和Group成员信息写入Zookeeper后。新的Generation ID和Group成员信息以一个原子操作一次性写入Zookeeper。Failover完成后，Consumer会发送HeartbeatRequest给新的Coordinator，并包含旧的Generation ID。此时新的Coordinator通过在HeartbeatResponse中返回IllegalGeneration错误码发起新的一轮Rebalance。这也解释了为什么每次HeartbeatRequest中都需要包含Generation ID和Consumer ID。<br>　　5）如果Failure发生在阶段5，旧的Coordinator可能只向Group中的部分Consumer发送了JoinGroupResponse。收到JoinGroupResponse的Consumer在下次向已经失效的Coordinator发送HeartbeatRequest或者提交Offset时会检测到它已经失败。此时，它将检测新的Coordinator并向其发送带有新的Generation ID 的HeartbeatRequest。而未收到JoinGroupResponse的Consumer将检测新的Coordinator并向其发送JoinGroupRequest，这将促使新的Coordinator发起新一轮的Rebalance。</p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文主要介绍了Kafka High Level Consumer，Consumer Group，Consumer Rebalance，Low Level Consumer实现的语义，以及适用场景。以及未来版本中对High Level Consumer的重新设计--使用Consumer Coordinator解决Split Brain和Herd等问题。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（三）- Kafka High Availability （下）</title>
    <link href="http://www.jasongj.com/2015/06/08/KafkaColumn3/"/>
    <id>http://www.jasongj.com/2015/06/08/KafkaColumn3/</id>
    <published>2015-06-08T07:43:29.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。（已授权<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-3" target="_blank" rel="external">InfoQ中文站发布</a>）<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/06/08/KafkaColumn3">原文链接</a>　<a href="http://www.jasongj.com/2015/06/08/KafkaColumn3">http://www.jasongj.com/2015/06/08/KafkaColumn3</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>　　本文在上篇文章基础上，更加深入讲解了Kafka的HA机制，主要阐述了HA相关各种场景，如Broker failover，Controller failover，Topic创建/删除，Broker启动，Follower从Leader fetch数据等详细处理过程。同时介绍了Kafka提供的与Replication相关的工具，如重新分配Partition等。</p>
<h1 id="Broker-Failover过程"><a href="#Broker-Failover过程" class="headerlink" title="Broker Failover过程"></a>Broker Failover过程</h1><h2 id="Controller对Broker-failure的处理过程"><a href="#Controller对Broker-failure的处理过程" class="headerlink" title="Controller对Broker failure的处理过程"></a>Controller对Broker failure的处理过程</h2><ol>
<li>Controller在Zookeeper的<code>/brokers/ids</code>节点上注册Watch。一旦有Broker宕机（本文用宕机代表任何让Kafka认为其Broker die的情景，包括但不限于机器断电，网络不可用，GC导致的Stop The World，进程crash等），其在Zookeeper对应的Znode会自动被删除，Zookeeper会fire Controller注册的Watch，Controller即可获取最新的幸存的Broker列表。</li>
<li>Controller决定set_p，该集合包含了宕机的所有Broker上的所有Partition。</li>
<li>对set_p中的每一个Partition：<br>　　3.1 从<code>/brokers/topics/[topic]/partitions/[partition]/state</code>读取该Partition当前的ISR。<br>　　3.2 决定该Partition的新Leader。如果当前ISR中有至少一个Replica还幸存，则选择其中一个作为新Leader，新的ISR则包含当前ISR中所有幸存的Replica。否则选择该Partition中任意一个幸存的Replica作为新的Leader以及ISR（该场景下可能会有潜在的数据丢失）。如果该Partition的所有Replica都宕机了，则将新的Leader设置为-1。<br>　　3.3 将新的Leader，ISR和新的<code>leader_epoch</code>及<code>controller_epoch</code>写入<code>/brokers/topics/[topic]/partitions/[partition]/state</code>。注意，该操作只有Controller版本在3.1至3.3的过程中无变化时才会执行，否则跳转到3.1。</li>
<li>直接通过RPC向set_p相关的Broker发送LeaderAndISRRequest命令。Controller可以在一个RPC操作中发送多个命令从而提高效率。<br>　　Broker failover顺序图如下所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/kafka_broker_failover.png" alt="broker failover sequence diagram "></li>
</ol>
<p>　　LeaderAndIsrRequest结构如下<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/LeaderAndIsrRequest.png" alt="LeaderAndIsrRequest"></p>
<p>　　LeaderAndIsrResponse结构如下<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/LeaderAndIsrResponse.png" alt="LeaderAndIsrResponse"></p>
<h2 id="创建-删除Topic"><a href="#创建-删除Topic" class="headerlink" title="创建/删除Topic"></a>创建/删除Topic</h2><ol>
<li>Controller在Zookeeper的<code>/brokers/topics</code>节点上注册Watch，一旦某个Topic被创建或删除，则Controller会通过Watch得到新创建/删除的Topic的Partition/Replica分配。</li>
<li>对于删除Topic操作，Topic工具会将该Topic名字存于<code>/admin/delete_topics</code>。若<code>delete.topic.enable</code>为true，则Controller注册在<code>/admin/delete_topics</code>上的Watch被fire，Controller通过回调向对应的Broker发送StopReplicaRequest；若为false则Controller不会在<code>/admin/delete_topics</code>上注册Watch，也就不会对该事件作出反应，此时Topic操作只被记录而不会被执行。</li>
<li>对于创建Topic操作，Controller从<code>/brokers/ids</code>读取当前所有可用的Broker列表，对于set_p中的每一个Partition：<br>　　3.1 从分配给该Partition的所有Replica（称为AR）中任选一个可用的Broker作为新的Leader，并将AR设置为新的ISR（因为该Topic是新创建的，所以AR中所有的Replica都没有数据，可认为它们都是同步的，也即都在ISR中，任意一个Replica都可作为Leader）<br>　　3.2 将新的Leader和ISR写入<code>/brokers/topics/[topic]/partitions/[partition]</code></li>
<li>直接通过RPC向相关的Broker发送LeaderAndISRRequest。<br>　　创建Topic顺序图如下所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/kafka_create_topic.png" alt="create topic sequence diagram"></li>
</ol>
<h2 id="Broker响应请求流程"><a href="#Broker响应请求流程" class="headerlink" title="Broker响应请求流程"></a>Broker响应请求流程</h2><p>　　Broker通过<code>kafka.network.SocketServer</code>及相关模块接受各种请求并作出响应。整个网络通信模块基于Java NIO开发，并采用Reactor模式，其中包含1个Acceptor负责接受客户请求，N个Processor负责读写数据，M个Handler处理业务逻辑。<br>　　Acceptor的主要职责是监听并接受客户端（请求发起方，包括但不限于Producer，Consumer，Controller，Admin Tool）的连接请求，并建立和客户端的数据传输通道，然后为该客户端指定一个Processor，至此它对该客户端该次请求的任务就结束了，它可以去响应下一个客户端的连接请求了。其核心代码如下。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/Acceptor_run.png" alt="Kafka SocketServer Acceptor_run"><br>　　<br>　　Processor主要负责从客户端读取数据并将响应返回给客户端，它本身并不处理具体的业务逻辑，并且其内部维护了一个队列来保存分配给它的所有SocketChannel。Processor的run方法会循环从队列中取出新的SocketChannel并将其<code>SelectionKey.OP_READ</code>注册到selector上，然后循环处理已就绪的读（请求）和写（响应）。Processor读取完数据后，将其封装成Request对象并将其交给RequestChannel。<br>　　RequestChannel是Processor和KafkaRequestHandler交换数据的地方，它包含一个队列requestQueue用来存放Processor加入的Request，KafkaRequestHandler会从里面取出Request来处理；同时它还包含一个respondQueue，用来存放KafkaRequestHandler处理完Request后返还给客户端的Response。<br>　　Processor会通过processNewResponses方法依次将requestChannel中responseQueue保存的Response取出，并将对应的<code>SelectionKey.OP_WRITE</code>事件注册到selector上。当selector的select方法返回时，对检测到的可写通道，调用write方法将Response返回给客户端。<br>　　KafkaRequestHandler循环从RequestChannel中取Request并交给<code>kafka.server.KafkaApis</code>处理具体的业务逻辑。</p>
<h2 id="LeaderAndIsrRequest响应过程"><a href="#LeaderAndIsrRequest响应过程" class="headerlink" title="LeaderAndIsrRequest响应过程"></a>LeaderAndIsrRequest响应过程</h2><p>　　对于收到的LeaderAndIsrRequest，Broker主要通过ReplicaManager的becomeLeaderOrFollower处理，流程如下：</p>
<ol>
<li>若请求中controllerEpoch小于当前最新的controllerEpoch，则直接返回ErrorMapping.StaleControllerEpochCode。</li>
<li>对于请求中partitionStateInfos中的每一个元素，即（(topic, partitionId), partitionStateInfo)：<br>　　2.1 若partitionStateInfo中的leader epoch大于当前ReplicManager中存储的(topic, partitionId)对应的partition的leader epoch，则：<br>　　　　2.1.1 若当前brokerid（或者说replica id）在partitionStateInfo中，则将该partition及partitionStateInfo存入一个名为partitionState的HashMap中<br>　　　　2.1.2否则说明该Broker不在该Partition分配的Replica list中，将该信息记录于log中<br>　　2.2否则将相应的Error code（ErrorMapping.StaleLeaderEpochCode）存入Response中</li>
<li>筛选出partitionState中Leader与当前Broker ID相等的所有记录存入partitionsTobeLeader中，其它记录存入partitionsToBeFollower中。</li>
<li>若partitionsTobeLeader不为空，则对其执行makeLeaders方。</li>
<li>若partitionsToBeFollower不为空，则对其执行makeFollowers方法。</li>
<li>若highwatermak线程还未启动，则将其启动，并将hwThreadInitialized设为true。</li>
<li>关闭所有Idle状态的Fetcher。</li>
</ol>
<p>　　LeaderAndIsrRequest处理过程如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/LeaderAndIsrRequest_Flow_Chart.png" alt="LeaderAndIsrRequest Flow Chart"></p>
<h2 id="Broker启动过程"><a href="#Broker启动过程" class="headerlink" title="Broker启动过程"></a>Broker启动过程</h2><p>　　Broker启动后首先根据其ID在Zookeeper的<code>/brokers/ids</code>zonde下创建临时子节点（<a href="http://zookeeper.apache.org/doc/trunk/zookeeperOver.html#Nodes+and+ephemeral+nodes" target="_blank" rel="external">Ephemeral node</a>），创建成功后Controller的ReplicaStateMachine注册其上的Broker Change Watch会被fire，从而通过回调KafkaController.onBrokerStartup方法完成以下步骤：</p>
<ol>
<li>向所有新启动的Broker发送UpdateMetadataRequest，其定义如下。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/UpdateMetadataRequest.png" alt="UpdateMetadataRequest"></li>
<li>将新启动的Broker上的所有Replica设置为OnlineReplica状态，同时这些Broker会为这些Partition启动high watermark线程。</li>
<li>通过partitionStateMachine触发OnlinePartitionStateChange。</li>
</ol>
<h2 id="Controller-Failover"><a href="#Controller-Failover" class="headerlink" title="Controller Failover"></a>Controller Failover</h2><p>Controller也需要Failover。每个Broker都会在Controller Path (<code>/controller</code>)上注册一个Watch。当前Controller失败时，对应的Controller Path会自动消失（因为它是Ephemeral Node），此时该Watch被fire，所有“活”着的Broker都会去竞选成为新的Controller（创建新的Controller Path），但是只会有一个竞选成功（这点由Zookeeper保证）。竞选成功者即为新的Leader，竞选失败者则重新在新的Controller Path上注册Watch。因为<a href="http://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html#ch_zkWatches" target="_blank" rel="external">Zookeeper的Watch是一次性的，被fire一次之后即失效</a>，所以需要重新注册。</p>
<p>Broker成功竞选为新Controller后会触发KafkaController.onControllerFailover方法，并在该方法中完成如下操作：</p>
<ol>
<li>读取并增加Controller Epoch。</li>
<li>在ReassignedPartitions Path(<code>/admin/reassign_partitions</code>)上注册Watch。</li>
<li>在PreferredReplicaElection Path(<code>/admin/preferred_replica_election</code>)上注册Watch。</li>
<li>通过partitionStateMachine在Broker Topics Patch(<code>/brokers/topics</code>)上注册Watch。</li>
<li>若<code>delete.topic.enable</code>设置为true（默认值是false），则partitionStateMachine在Delete Topic Patch(<code>/admin/delete_topics</code>)上注册Watch。</li>
<li>通过replicaStateMachine在Broker Ids Patch(<code>/brokers/ids</code>)上注册Watch。</li>
<li>初始化ControllerContext对象，设置当前所有Topic，“活”着的Broker列表，所有Partition的Leader及ISR等。</li>
<li>启动replicaStateMachine和partitionStateMachine。</li>
<li>将brokerState状态设置为RunningAsController。</li>
<li>将每个Partition的Leadership信息发送给所有“活”着的Broker。</li>
<li>若<code>auto.leader.rebalance.enable</code>配置为true（默认值是true），则启动partition-rebalance线程。</li>
<li>若<code>delete.topic.enable</code>设置为true且Delete Topic Patch(<code>/admin/delete_topics</code>)中有值，则删除相应的Topic。</li>
</ol>
<h2 id="Partition重新分配"><a href="#Partition重新分配" class="headerlink" title="Partition重新分配"></a>Partition重新分配</h2><p>　　管理工具发出重新分配Partition请求后，会将相应信息写到<code>/admin/reassign_partitions</code>上，而该操作会触发ReassignedPartitionsIsrChangeListener，从而通过执行回调函数KafkaController.onPartitionReassignment来完成以下操作：</p>
<ol>
<li>将Zookeeper中的AR（Current Assigned Replicas）更新为OAR（Original list of replicas for partition） + RAR（Reassigned replicas）。</li>
<li>强制更新Zookeeper中的leader epoch，向AR中的每个Replica发送LeaderAndIsrRequest。</li>
<li>将RAR - OAR中的Replica设置为NewReplica状态。</li>
<li>等待直到RAR中所有的Replica都与其Leader同步。</li>
<li>将RAR中所有的Replica都设置为OnlineReplica状态。</li>
<li>将Cache中的AR设置为RAR。</li>
<li>若Leader不在RAR中，则从RAR中重新选举出一个新的Leader并发送LeaderAndIsrRequest。若新的Leader不是从RAR中选举而出，则还要增加Zookeeper中的leader epoch。</li>
<li>将OAR - RAR中的所有Replica设置为OfflineReplica状态，该过程包含两部分。第一，将Zookeeper上ISR中的OAR - RAR移除并向Leader发送LeaderAndIsrRequest从而通知这些Replica已经从ISR中移除；第二，向OAR - RAR中的Replica发送StopReplicaRequest从而停止不再分配给该Partition的Replica。</li>
<li>将OAR - RAR中的所有Replica设置为NonExistentReplica状态从而将其从磁盘上删除。</li>
<li>将Zookeeper中的AR设置为RAR。</li>
<li>删除<code>/admin/reassign_partition</code>。<br>　　<br><strong><em>注意</em></strong>：最后一步才将Zookeeper中的AR更新，因为这是唯一一个持久存储AR的地方，如果Controller在这一步之前crash，新的Controller仍然能够继续完成该过程。<br>　　以下是Partition重新分配的案例，OAR = ｛1，2，3｝，RAR = ｛4，5，6｝，Partition重新分配过程中Zookeeper中的AR和Leader/ISR路径如下</li>
</ol>
<table>
<thead>
<tr>
<th>AR</th>
<th>leader/isr</th>
<th>Step</th>
</tr>
</thead>
<tbody>
<tr>
<td>{1,2,3}</td>
<td>1/{1,2,3}</td>
<td>(initial state)</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>1/{1,2,3}</td>
<td>(step 2)</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>1/{1,2,3,4,5,6}</td>
<td>(step 4)</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>4/{1,2,3,4,5,6}</td>
<td>(step 7)</td>
</tr>
<tr>
<td>{1,2,3,4,5,6}</td>
<td>4/{4,5,6}</td>
<td>(step 8)</td>
</tr>
<tr>
<td>{4,5,6}</td>
<td>4/{4,5,6}</td>
<td>(step 10)</td>
</tr>
</tbody>
</table>
<h2 id="Follower从Leader-Fetch数据"><a href="#Follower从Leader-Fetch数据" class="headerlink" title="Follower从Leader Fetch数据"></a>Follower从Leader Fetch数据</h2><p>　　Follower通过向Leader发送FetchRequest获取消息，FetchRequest结构如下<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/FetchRequest.png" alt="FetchRequest"><br>　　从FetchRequest的结构可以看出，每个Fetch请求都要指定最大等待时间和最小获取字节数，以及由TopicAndPartition和PartitionFetchInfo构成的Map。实际上，Follower从Leader数据和Consumer从Broker Fetch数据，都是通过FetchRequest请求完成，所以在FetchRequest结构中，其中一个字段是clientID，并且其默认值是ConsumerConfig.DefaultClientId。<br>　　<br>　　Leader收到Fetch请求后，Kafka通过KafkaApis.handleFetchRequest响应该请求，响应过程如下：</p>
<ol>
<li>replicaManager根据请求读出数据存入dataRead中。</li>
<li>如果该请求来自Follower则更新其相应的LEO（log end offset）以及相应Partition的High Watermark</li>
<li>根据dataRead算出可读消息长度（单位为字节）并存入bytesReadable中。</li>
<li>满足下面4个条件中的1个，则立即将相应的数据返回</li>
</ol>
<ul>
<li>Fetch请求不希望等待，即fetchRequest.macWait &lt;= 0</li>
<li>Fetch请求不要求一定能取到消息，即fetchRequest.numPartitions &lt;= 0，也即requestInfo为空</li>
<li>有足够的数据可供返回，即bytesReadable &gt;= fetchRequest.minBytes</li>
<li>读取数据时发生异常</li>
</ul>
<ol>
<li>若不满足以上4个条件，FetchRequest将不会立即返回，并将该请求封装成DelayedFetch。检查该DeplayedFetch是否满足，若满足则返回请求，否则将该请求加入Watch列表</li>
</ol>
<p>　　Leader通过以FetchResponse的形式将消息返回给Follower，FetchResponse结构如下<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/FetchResponse.png" alt="FetchResponse"></p>
<p>#Replication工具</p>
<h2 id="Topic-Tool"><a href="#Topic-Tool" class="headerlink" title="Topic Tool"></a>Topic Tool</h2><p>　　<code>$KAFKA_HOME/bin/kafka-topics.sh</code>，该工具可用于创建、删除、修改、查看某个Topic，也可用于列出所有Topic。另外，该工具还可修改以下配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">unclean.leader.election.enable</div><div class="line">delete.retention.ms</div><div class="line">segment.jitter.ms</div><div class="line">retention.ms</div><div class="line">flush.ms</div><div class="line">segment.bytes</div><div class="line">flush.messages</div><div class="line">segment.ms</div><div class="line">retention.bytes</div><div class="line">cleanup.policy</div><div class="line">segment.index.bytes</div><div class="line">min.cleanable.dirty.ratio</div><div class="line">max.message.bytes</div><div class="line">file.delete.delay.ms</div><div class="line">min.insync.replicas</div><div class="line">index.interval.bytes</div></pre></td></tr></table></figure></p>
<h2 id="Replica-Verification-Tool"><a href="#Replica-Verification-Tool" class="headerlink" title="Replica Verification Tool"></a>Replica Verification Tool</h2><p>　　<code>$KAFKA_HOME/bin/kafka-replica-verification.sh</code>，该工具用来验证所指定的一个或多个Topic下每个Partition对应的所有Replica是否都同步。可通过<code>topic-white-list</code>这一参数指定所需要验证的所有Topic，支持正则表达式。
　　</p>
<h2 id="Preferred-Replica-Leader-Election-Tool"><a href="#Preferred-Replica-Leader-Election-Tool" class="headerlink" title="Preferred Replica Leader Election Tool"></a>Preferred Replica Leader Election Tool</h2><p><strong><em>用途</em></strong><br>　　有了Replication机制后，每个Partition可能有多个备份。某个Partition的Replica列表叫作AR（Assigned Replicas），AR中的第一个Replica即为“Preferred Replica”。创建一个新的Topic或者给已有Topic增加Partition时，Kafka保证Preferred Replica被均匀分布到集群中的所有Broker上。理想情况下，Preferred Replica会被选为Leader。以上两点保证了所有Partition的Leader被均匀分布到了集群当中，这一点非常重要，因为所有的读写操作都由Leader完成，若Leader分布过于集中，会造成集群负载不均衡。但是，随着集群的运行，该平衡可能会因为Broker的宕机而被打破，该工具就是用来帮助恢复Leader分配的平衡。<br>　　事实上，每个Topic从失败中恢复过来后，它默认会被设置为Follower角色，除非某个Partition的Replica全部宕机，而当前Broker是该Partition的AR中第一个恢复回来的Replica。因此，某个Partition的Leader（Preferred Replica）宕机并恢复后，它很可能不再是该Partition的Leader，但仍然是Preferred Replica。<br>　　<br><strong><em>原理</em></strong></p>
<ol>
<li>在Zookeeper上创建<code>/admin/preferred_replica_election</code>节点，并存入需要调整Preferred Replica的Partition信息。</li>
<li>Controller一直Watch该节点，一旦该节点被创建，Controller会收到通知，并获取该内容。</li>
<li>Controller读取Preferred Replica，如果发现该Replica当前并非是Leader并且它在该Partition的ISR中，Controller向该Replica发送LeaderAndIsrRequest，使该Replica成为Leader。如果该Replica当前并非是Leader，且不在ISR中，Controller为了保证没有数据丢失，并不会将其设置为Leader。
　</li>
</ol>
<p><strong><em>用法</em></strong><br>　　<code>$KAFKA_HOME/bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181</code></p>
<p>　　在包含8个Broker的Kafka集群上，创建1个名为topic1，replication-factor为3，Partition数为8的Topic，使用<code>$KAFKA_HOME/bin/kafka-topics.sh --describe --topic topic1 --zookeeper localhost:2181</code>命令查看其Partition/Replica分布。</p>
<p>　　查询结果如下图所示，从图中可以看到，Kafka将所有Replica均匀分布到了整个集群，并且Leader也均匀分布。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/preferred_topic_test_1.png" alt="preferred_topic_test_1"></p>
<p>　　手动停止部分Broker，topic1的Partition/Replica分布如下图所示。从图中可以看到，由于Broker 1/2/4都被停止，Partition 0的Leader由原来的1变为3，Partition 1的Leader由原来的2变为5，Partition 2的Leader由原来的3变为6，Partition 3的Leader由原来的4变为7。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/preferred_topic_test_2.png" alt="preferred_topic_test_2">　　<br>　　<br>　　再重新启动ID为1的Broker，topic1的Partition/Replica分布如下。可以看到，虽然Broker 1已经启动（Partition 0和Partition5的ISR中有1），但是1并不是任何一个Parititon的Leader，而Broker 5/6/7都是2个Partition的Leader，即Leader的分布不均衡——一个Broker最多是2个Partition的Leader，而最少是0个Partition的Leader。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/preferred_topic_test_3.png" alt="preferred_topic_test_3"><br>　　<br>　　运行该工具后，topic1的Partition/Replica分布如下图所示。由图可见，除了Partition 1和Partition 3由于Broker 2和Broker 4还未启动，所以其Leader不是其Preferred Repliac外，其它所有Partition的Leader都是其Preferred Replica。同时，与运行该工具前相比，Leader的分配更均匀——一个Broker最多是2个Parittion的Leader，最少是1个Partition的Leader。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/preferred_topic_test_4.png" alt="preferred_topic_test_4"><br>　　<br>　　启动Broker 2和Broker 4，Leader分布与上一步相比并未变化，如下图所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/preferred_topic_test_5.png" alt="preferred_topic_test_5"></p>
<p>　　再次运行该工具，所有Partition的Leader都由其Preferred Replica承担，Leader分布更均匀——每个Broker承担1个Partition的Leader角色。<br>　　<br>　　除了手动运行该工具使Leader分配均匀外，Kafka还提供了自动平衡Leader分配的功能，该功能可通过将<code>auto.leader.rebalance.enable</code>设置为true开启，它将周期性检查Leader分配是否平衡，若不平衡度超过一定阈值则自动由Controller尝试将各Partition的Leader设置为其Preferred Replica。检查周期由<code>leader.imbalance.check.interval.seconds</code>指定，不平衡度阈值由<code>leader.imbalance.per.broker.percentage</code>指定。
　　</p>
<h2 id="Kafka-Reassign-Partitions-Tool"><a href="#Kafka-Reassign-Partitions-Tool" class="headerlink" title="Kafka Reassign Partitions Tool"></a>Kafka Reassign Partitions Tool</h2><p><strong><em>用途</em></strong><br>　　该工具的设计目标与Preferred Replica Leader Election Tool有些类似，都旨在促进Kafka集群的负载均衡。不同的是，Preferred Replica Leader Election只能在Partition的AR范围内调整其Leader，使Leader分布均匀，而该工具还可以调整Partition的AR。<br>　　Follower需要从Leader Fetch数据以保持与Leader同步，所以仅仅保持Leader分布的平衡对整个集群的负载均衡来说是不够的。另外，生产环境下，随着负载的增大，可能需要给Kafka集群扩容。向Kafka集群中增加Broker非常简单方便，但是对于已有的Topic，并不会自动将其Partition迁移到新加入的Broker上，此时可用该工具达到此目的。某些场景下，实际负载可能远小于最初预期负载，此时可用该工具将分布在整个集群上的Partition重装分配到某些机器上，然后可以停止不需要的Broker从而实现节约资源的目的。<br>　　需要说明的是，该工具不仅可以调整Partition的AR位置，还可调整其AR数量，即改变该Topic的replication factor。<br>　　<br><strong><em>原理</em></strong><br>　　该工具只负责将所需信息存入Zookeeper中相应节点，然后退出，不负责相关的具体操作，所有调整都由Controller完成。</p>
<ol>
<li>在Zookeeper上创建<code>/admin/reassign_partitions</code>节点，并存入目标Partition列表及其对应的目标AR列表。</li>
<li>Controller注册在<code>/admin/reassign_partitions</code>上的Watch被fire，Controller获取该列表。</li>
<li>对列表中的所有Partition，Controller会做如下操作：</li>
</ol>
<ul>
<li>启动<code>RAR - AR</code>中的Replica，即新分配的Replica。（RAR = Reassigned Replicas， AR = Assigned Replicas）</li>
<li>等待新的Replica与Leader同步</li>
<li>如果Leader不在RAR中，从RAR中选出新的Leader</li>
<li>停止并删除<code>AR - RAR</code>中的Replica，即不再需要的Replica</li>
<li>删除<code>/admin/reassign_partitions</code>节点</li>
</ul>
<p><strong><em>用法</em></strong><br>　　该工具有三种使用模式</p>
<ul>
<li>generate模式，给定需要重新分配的Topic，自动生成reassign plan（并不执行） </li>
<li>execute模式，根据指定的reassign plan重新分配Partition</li>
<li>verify模式，验证重新分配Partition是否成功</li>
</ul>
<p>　　下面这个例子将使用该工具将Topic的所有Partition重新分配到Broker 4/5/6/7上，步骤如下：</p>
<ol>
<li>使用generate模式，生成reassign plan。指定需要重新分配的Topic （{“topics”:[{“topic”:”topic1”}],”version”:1}），并存入<code>/tmp/topics-to-move.json</code>文件中，然后执行<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$KAFKA_HOME</span>/bin/kafka-reassign-partitions.sh </div><div class="line">	--zookeeper localhost:2181 </div><div class="line">	--topics-to-move-json-file /tmp/topics-to-move.json  </div><div class="line">	--broker-list <span class="string">"4,5,6,7"</span> --generate</div></pre></td></tr></table></figure>
</li>
</ol>
<p>　　结果如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/reassign_1.png" alt="reassign_1"><br>　　<br>2.　使用execute模式，执行reassign plan<br>　　将上一步生成的reassignment plan存入<code>/tmp/reassign-plan.json</code>文件中，并执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">   <span class="variable">$KAFKA_HOME</span>/bin/kafka-reassign-partitions.sh </div><div class="line">--zookeeper localhost:2181     </div><div class="line">--reassignment-json-file /tmp/reassign-plan.json --execute</div></pre></td></tr></table></figure></p>
<p><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/reassign_2.png" alt="reassign_2"></p>
<p>　　此时，Zookeeper上<code>/admin/reassign_partitions</code>节点被创建，且其值与<code>/tmp/reassign-plan.json</code>文件的内容一致。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/reassign_3.png" alt="reassign_3"></p>
<p>3.　使用verify模式，验证reassign是否完成。执行verify命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$KAFKA_HOME</span>/bin/kafka-reassign-partitions.sh </div><div class="line">--zookeeper localhost:2181 --verify</div><div class="line">--reassignment-json-file /tmp/reassign-plan.json</div></pre></td></tr></table></figure></p>
<p>　　结果如下所示，从图中可看出topic1的所有Partititon都重新分配成功。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/reassign_4.png" alt="reassign_4"></p>
<p>　　接下来用Topic Tool再次验证。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic topic1</div></pre></td></tr></table></figure></p>
<p>　　结果如下图所示，从图中可看出topic1的所有Partition都被重新分配到Broker 4/5/6/7，且每个Partition的AR与reassign plan一致。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn3/reassign_5.png" alt="reassign_5"></p>
<p>　　需要说明的是，在使用execute之前，并不一定要使用generate模式自动生成reassign plan，使用generate模式只是为了方便。事实上，某些场景下，generate模式生成的reassign plan并不一定能满足需求，此时用户可以自己设置reassign plan。
　　</p>
<h2 id="State-Change-Log-Merge-Tool"><a href="#State-Change-Log-Merge-Tool" class="headerlink" title="State Change Log Merge Tool"></a>State Change Log Merge Tool</h2><p><strong><em>用途</em></strong><br>　　该工具旨在从整个集群的Broker上收集状态改变日志，并生成一个集中的格式化的日志以帮助诊断状态改变相关的故障。每个Broker都会将其收到的状态改变相关的的指令存于名为<code>state-change.log</code>的日志文件中。某些情况下，Partition的Leader Election可能会出现问题，此时我们需要对整个集群的状态改变有个全局的了解从而诊断故障并解决问题。该工具将集群中相关的<code>state-change.log</code>日志按时间顺序合并，同时支持用户输入时间范围和目标Topic及Partition作为过滤条件，最终将格式化的结果输出。<br>　　<br><strong><em>用法</em></strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bin/kafka-run-class.sh kafka.tools.StateChangeLogMerger</div><div class="line">--logs /opt/kafka_2.11-0.8.2.1/logs/state-change.log</div><div class="line">--topic topic1 --partitions 0,1,2,3,4,5,6,7</div></pre></td></tr></table></figure></p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文在上篇文章 基础上，更加深入讲解了Kafka的HA机制，主要阐述了HA相关各种场景，如Broker failover，Controller failover，Topic创建/删除，Broker启动，Follower从Leader fetch数据等详细处理过程。同时介绍了Kafka提供的与Replication相关的工具，如重新分配Partition等。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（二）- Kafka High Availability （上）</title>
    <link href="http://www.jasongj.com/2015/04/24/KafkaColumn2/"/>
    <id>http://www.jasongj.com/2015/04/24/KafkaColumn2/</id>
    <published>2015-04-24T14:21:18.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。（已授权<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-2" target="_blank" rel="external">InfoQ中文站发布</a>）<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/04/24/KafkaColumn2">原文链接</a>　<a href="http://www.jasongj.com/2015/04/24/KafkaColumn2">http://www.jasongj.com/2015/04/24/KafkaColumn2</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>　　Kafka在0.8以前的版本中，并不提供High Availablity机制，一旦一个或多个Broker宕机，则宕机期间其上所有Partition都无法继续提供服务。若该Broker永远不能再恢复，亦或磁盘故障，则其上数据将丢失。而Kafka的设计目标之一即是提供数据持久化，同时对于分布式系统来说，尤其当集群规模上升到一定程度后，一台或者多台机器宕机的可能性大大提高，对于Failover机制的需求非常高。因此，Kafka从0.8开始提供High Availability机制。本文从Data Replication和Leader Election两方面介绍了Kafka的HA机制。</p>
<h1 id="Kafka为何需要High-Available"><a href="#Kafka为何需要High-Available" class="headerlink" title="Kafka为何需要High Available"></a>Kafka为何需要High Available</h1><h2 id="为何需要Replication"><a href="#为何需要Replication" class="headerlink" title="为何需要Replication"></a>为何需要Replication</h2><p>　　在Kafka在0.8以前的版本中，是没有Replication的，一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，这与Kafka数据持久性及Delivery Guarantee的设计目标相悖。同时Producer都不能再将数据存于这些Partition中。</p>
<ul>
<li>如果Producer使用同步模式则Producer会在尝试重新发送<code>message.send.max.retries</code>（默认值为3）次后抛出Exception，用户可以选择停止发送后续数据也可选择继续选择发送。而前者会造成数据的阻塞，后者会造成本应发往该Broker的数据的丢失。</li>
<li>如果Producer使用异步模式，则Producer会尝试重新发送<code>message.send.max.retries</code>（默认值为3）次后记录该异常并继续发送后续数据，这会造成数据丢失并且用户只能通过日志发现该问题。</li>
</ul>
<p>　　由此可见，在没有Replication的情况下，一旦某机器宕机或者某个Broker停止工作则会造成整个系统的可用性降低。随着集群规模的增加，整个集群中出现该类异常的几率大大增加，因此对于生产系统而言Replication机制的引入非常重要。
　　</p>
<h2 id="为何需要Leader-Election"><a href="#为何需要Leader-Election" class="headerlink" title="为何需要Leader Election"></a>为何需要Leader Election</h2><p>　　（本文所述Leader Election主要指Replica之间的Leader Election）<br>　　引入Replication之后，同一个Partition可能会有多个Replica，而这时需要在这些Replica中选出一个Leader，Producer和Consumer只与这个Leader交互，其它Replica作为Follower从Leader中复制数据。<br>　　因为需要保证同一个Partition的多个Replica之间的数据一致性（其中一个宕机后其它Replica必须要能继续服务并且即不能造成数据重复也不能造成数据丢失）。如果没有一个Leader，所有Replica都可同时读/写数据，那就需要保证多个Replica之间互相（N×N条通路）同步数据，数据的一致性和有序性非常难保证，大大增加了Replication实现的复杂性，同时也增加了出现异常的几率。而引入Leader后，只有Leader负责数据读写，Follower只向Leader顺序Fetch数据（N条通路），系统更加简单且高效。
　　
　　</p>
<h1 id="Kafka-HA设计解析"><a href="#Kafka-HA设计解析" class="headerlink" title="Kafka HA设计解析"></a>Kafka HA设计解析</h1><h2 id="如何将所有Replica均匀分布到整个集群"><a href="#如何将所有Replica均匀分布到整个集群" class="headerlink" title="如何将所有Replica均匀分布到整个集群"></a>如何将所有Replica均匀分布到整个集群</h2><p>　　为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。实际上，如果所有的Replica都在同一个Broker上，那一旦该Broker宕机，该Partition的所有Replica都无法工作，也就达不到HA的效果。同时，如果某个Broker宕机了，需要保证它上面的负载可以被均匀的分配到其它幸存的所有Broker上。<br>　　Kafka分配Replica的算法如下：</p>
<ol>
<li>将所有Broker（假设共n个Broker）和待分配的Partition排序</li>
<li>将第i个Partition分配到第（i mod n）个Broker上</li>
<li>将第i个Partition的第j个Replica分配到第（(i + j) mod n）个Broker上</li>
</ol>
<h2 id="Data-Replication"><a href="#Data-Replication" class="headerlink" title="Data Replication"></a>Data Replication</h2><p>　　Kafka的Data Replication需要解决如下问题：</p>
<ul>
<li>怎样Propagate消息</li>
<li>在向Producer发送ACK前需要保证有多少个Replica已经收到该消息 </li>
<li>怎样处理某个Replica不工作的情况</li>
<li>怎样处理Failed Replica恢复回来的情况</li>
</ul>
<h3 id="Propagate消息"><a href="#Propagate消息" class="headerlink" title="Propagate消息"></a>Propagate消息</h3><p>　　Producer在发布消息到某个Partition时，先通过Zookeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。<br>    为了提高性能，每个Follower在接收到数据后就立马向Leader发送ACK，而非等到数据写入Log中。因此，对于已经commit的消息，Kafka只能保证它被存于多个Replica的内存中，而不能保证它们被持久化到磁盘中，也就不能完全保证异常发生后该条消息一定能被Consumer消费。但考虑到这种场景非常少见，可以认为这种方式在性能和数据持久化上做了一个比较好的平衡。在将来的版本中，Kafka会考虑提供更高的持久性。<br>    Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。<br>    Kafka Replication的数据流如下图所示<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/Replication.png" alt="Kafka Replication Data Flow">    </p>
<h3 id="ACK前需要保证有多少个备份"><a href="#ACK前需要保证有多少个备份" class="headerlink" title="ACK前需要保证有多少个备份"></a>ACK前需要保证有多少个备份</h3><p>　　和大部分分布式系统一样，Kafka处理失败需要明确定义一个Broker是否“活着”。对于Kafka而言，Kafka存活包含两个条件，一是它必须维护与Zookeeper的session(这个通过Zookeeper的Heartbeat机制来实现)。二是Follower必须能够及时将Leader的消息复制过来，不能“落后太多”。<br>　　Leader会跟踪与其保持同步的Replica列表，该列表称为ISR（即in-sync Replica）。如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除。这里所描述的“落后太多”指Follower复制的消息落后于Leader后的条数超过预定值（该值可在$KAFKA_HOME/config/server.properties中通过<code>replica.lag.max.messages</code>配置，其默认值是4000）或者Follower超过一定时间（该值可在$KAFKA_HOME/config/server.properties中通过<code>replica.lag.time.max.ms</code>来配置，其默认值是10000）未向Leader发送fetch请求。。<br>　　Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下如果Follower都复制完都落后于Leader，而如果Leader突然宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了Follower与Leader的差距。<br>　　需要说明的是，Kafka只解决fail/recover，不处理“Byzantine”（“拜占庭”）问题。一条消息只有被ISR里的所有Follower都从Leader复制过去才会被认为已提交。这样就避免了部分数据被写进了Leader，还没来得及被任何Follower复制就宕机了，而造成数据丢失（Consumer无法消费这些数据）。而对于Producer而言，它可以选择是否等待消息commit，这可以通过<code>request.required.acks</code>来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。
　　</p>
<h3 id="Leader-Election算法"><a href="#Leader-Election算法" class="headerlink" title="Leader Election算法"></a>Leader Election算法</h3><p>　　上文说明了Kafka是如何做Replication的，另外一个很重要的问题是当Leader宕机了，怎样在Follower中选举出新的Leader。因为Follower可能落后许多或者crash了，所以必须确保选择“最新”的Follower作为新的Leader。一个基本的原则就是，如果Leader不在了，新的Leader必须拥有原来的Leader commit过的所有消息。这就需要作一个折衷，如果Leader在标明一条消息被commit前等待更多的Follower确认，那在它宕机之后就有更多的Follower可以作为新的Leader，但这也会造成吞吐率的下降。<br>　　一种非常常用的Leader Election的方式是“Majority Vote”（“少数服从多数”），但Kafka并未采用这种方式。这种模式下，如果我们有2f+1个Replica（包含Leader和Follower），那在commit之前必须保证有f+1个Replica复制完消息，为了保证正确选出新的Leader，fail的Replica不能超过f个。因为在剩下的任意f+1个Replica里，至少有一个Replica包含有最新的所有消息。这种方式有个很大的优势，系统的latency只取决于最快的几个Broker，而非最慢那个。Majority Vote也有一些劣势，为了保证Leader Election的正常进行，它所能容忍的fail的follower个数比较少。如果要容忍1个follower挂掉，必须要有3个以上的Replica，如果要容忍2个Follower挂掉，必须要有5个以上的Replica。也就是说，在生产环境下为了保证较高的容错程度，必须要有大量的Replica，而大量的Replica又会在大数据量下导致性能的急剧下降。这就是这种算法更多用在<a href="http://zookeeper.apache.org/" target="_blank" rel="external">Zookeeper</a>这种共享集群配置的系统中而很少在需要存储大量数据的系统中使用的原因。例如HDFS的HA Feature是基于<a href="http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1" target="_blank" rel="external">majority-vote-based journal</a>，但是它的数据存储并没有使用这种方式。<br>　　实际上，Leader Election算法非常多，比如Zookeeper的<a href="http://web.stanford.edu/class/cs347/reading/zab.pdf" target="_blank" rel="external">Zab</a>, <a href="https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf" target="_blank" rel="external">Raft</a>和<a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf" target="_blank" rel="external">Viewstamped Replication</a>。而Kafka所使用的Leader Election算法更像微软的<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=66814" target="_blank" rel="external">PacificA</a>算法。<br>　　Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。在大多数使用场景中，这种模式是非常有利的。事实上，为了容忍f个Replica的失败，Majority Vote和ISR在commit前需要等待的Replica数量是一样的，但是ISR需要的总的Replica的个数几乎是Majority Vote的一半。<br>　　虽然Majority Vote与ISR相比有不需等待最慢的Broker这一优势，但是Kafka作者认为Kafka可以通过Producer选择是否被commit阻塞来改善这一问题，并且节省下来的Replica和磁盘使得ISR模式仍然值得。
　　</p>
<h3 id="如何处理所有Replica都不工作"><a href="#如何处理所有Replica都不工作" class="headerlink" title="如何处理所有Replica都不工作"></a>如何处理所有Replica都不工作</h3><p>　　上文提到，在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>等待ISR中的任一个Replica“活”过来，并且选它作为Leader</li>
<li>选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader</li>
</ul>
<p>　　这就需要在可用性和一致性当中作出一个简单的折衷。如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。
　　</p>
<h3 id="如何选举Leader"><a href="#如何选举Leader" class="headerlink" title="如何选举Leader"></a>如何选举Leader</h3><p>　　最简单最直观的方案是，所有Follower都在Zookeeper上设置一个Watch，一旦Leader宕机，其对应的ephemeral znode会自动删除，此时所有Follower都尝试创建该节点，而创建成功者（Zookeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。<br>　　但是该方法会有3个问题：
　　</p>
<ul>
<li>split-brain 这是由Zookeeper的特性引起的，虽然Zookeeper能保证所有Watch按顺序触发，但并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致</li>
<li>herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</li>
<li>Zookeeper负载过重 每个Replica都要为此在Zookeeper上注册一个Watch，当集群规模增加到几千个Partition时Zookeeper负载会过重。</li>
</ul>
<p>　　Kafka 0.8.*的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。</p>
<h2 id="HA相关Zookeeper结构"><a href="#HA相关Zookeeper结构" class="headerlink" title="HA相关Zookeeper结构"></a>HA相关Zookeeper结构</h2><p>　　（本节所示Zookeeper结构中，实线框代表路径名是固定的，而虚线框代表路径名与业务相关）<br>　　<strong>admin</strong> （该目录下znode只有在有相关操作时才会存在，操作结束时会将其删除）<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/kafka_zookeeper_admin.png" alt="Kafka Zookeeper Admin Structure"></p>
<p>　　<code>/admin/preferred_replica_election</code>数据结构<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">   Schema:</div><div class="line">&#123;</div><div class="line">      "fields":[</div><div class="line">         &#123;</div><div class="line">            "name":"version",</div><div class="line">            "type":"int",</div><div class="line">            "doc":"version id"</div><div class="line">         &#125;,</div><div class="line">         &#123;</div><div class="line">            "name":"partitions",</div><div class="line">            "type":&#123;</div><div class="line">               "type":"array",</div><div class="line">               "items":&#123;</div><div class="line">                  "fields":[</div><div class="line">                     &#123;</div><div class="line">                        "name":"topic",</div><div class="line">                        "type":"string",</div><div class="line">                        "doc":"topic of the partition for which preferred replica election should be triggered"</div><div class="line">                     &#125;,</div><div class="line">                     &#123;</div><div class="line">                        "name":"partition",</div><div class="line">                        "type":"int",</div><div class="line">                        "doc":"the partition for which preferred replica election should be triggered"</div><div class="line">                     &#125;</div><div class="line">                  ],</div><div class="line">               &#125;</div><div class="line">               "doc":"an array of partitions for which preferred replica election should be triggered"</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      ]</div><div class="line">   &#125;</div><div class="line">    </div><div class="line">   Example:     </div><div class="line">   &#123;</div><div class="line">     "version": 1,</div><div class="line">     "partitions":</div><div class="line">        [</div><div class="line">           &#123;</div><div class="line">               "topic": "topic1",</div><div class="line">               "partition": 8         </div><div class="line">           &#125;,</div><div class="line">           &#123;</div><div class="line">               "topic": "topic2",</div><div class="line">               "partition": 16        </div><div class="line">           &#125;</div><div class="line">        ]            </div><div class="line">   &#125;</div></pre></td></tr></table></figure></p>
<p>　　<code>/admin/reassign_partitions</code>用于将一些Partition分配到不同的broker集合上。对于每个待重新分配的Partition，Kafka会在该znode上存储其所有的Replica和相应的Broker id。该znode由管理进程创建并且一旦重新分配成功它将会被自动移除。其数据结构如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">   Schema:</div><div class="line">&#123;</div><div class="line">      "fields":[</div><div class="line">         &#123;</div><div class="line">            "name":"version",</div><div class="line">            "type":"int",</div><div class="line">            "doc":"version id"</div><div class="line">         &#125;,</div><div class="line">         &#123;</div><div class="line">            "name":"partitions",</div><div class="line">            "type":&#123;</div><div class="line">               "type":"array",</div><div class="line">               "items":&#123;</div><div class="line">                  "fields":[</div><div class="line">                     &#123;</div><div class="line">                        "name":"topic",</div><div class="line">                        "type":"string",</div><div class="line">                        "doc":"topic of the partition to be reassigned"</div><div class="line">                     &#125;,</div><div class="line">                     &#123;</div><div class="line">                        "name":"partition",</div><div class="line">                        "type":"int",</div><div class="line">                        "doc":"the partition to be reassigned"</div><div class="line">                     &#125;,</div><div class="line">                     &#123;</div><div class="line">                        "name":"replicas",</div><div class="line">                        "type":"array",</div><div class="line">                        "items":"int",</div><div class="line">                        "doc":"a list of replica ids"</div><div class="line">                     &#125;</div><div class="line">                  ],</div><div class="line">               &#125;</div><div class="line">               "doc":"an array of partitions to be reassigned to new replicas"</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      ]</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   Example:</div><div class="line">   &#123;</div><div class="line">     "version": 1,</div><div class="line">     "partitions":</div><div class="line">        [</div><div class="line">           &#123;</div><div class="line">               "topic": "topic3",</div><div class="line">               "partition": 1,</div><div class="line">               "replicas": [1, 2, 3]</div><div class="line">           &#125;</div><div class="line">        ]            </div><div class="line">   &#125;</div></pre></td></tr></table></figure></p>
<p>　　<code>/admin/delete_topics</code>数据结构<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">Schema:</div><div class="line">&#123; "fields":</div><div class="line">    [ &#123;"name": "version", "type": "int", "doc": "version id"&#125;,</div><div class="line">      &#123;"name": "topics",</div><div class="line">       "type": &#123; "type": "array", "items": "string", "doc": "an array of topics to be deleted"&#125;</div><div class="line">      &#125; ]</div><div class="line">&#125;</div><div class="line"> </div><div class="line">Example:</div><div class="line">&#123;</div><div class="line">  "version": 1,</div><div class="line">  "topics": ["topic4", "topic5"]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　<strong>brokers</strong><br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/kafka_zookeeper_brokers.png" alt="Kafka Zookeeper brokers structure"></p>
<p>　　broker（即<code>/brokers/ids/[brokerId]</code>）存储“活着”的Broker信息。数据结构如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Schema:</div><div class="line">&#123; "fields":</div><div class="line">    [ &#123;"name": "version", "type": "int", "doc": "version id"&#125;,</div><div class="line">      &#123;"name": "host", "type": "string", "doc": "ip address or host name of the broker"&#125;,</div><div class="line">      &#123;"name": "port", "type": "int", "doc": "port of the broker"&#125;,</div><div class="line">      &#123;"name": "jmx_port", "type": "int", "doc": "port for jmx"&#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line"> </div><div class="line">Example:</div><div class="line">&#123;</div><div class="line">    "jmx_port":-1,</div><div class="line">    "host":"node1",</div><div class="line">    "version":1,</div><div class="line">    "port":9092</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　topic注册信息（<code>/brokers/topics/[topic]</code>），存储该Topic的所有Partition的所有Replica所在的Broker id，第一个Replica即为Preferred Replica，对一个给定的Partition，它在同一个Broker上最多只有一个Replica,因此Broker id可作为Replica id。数据结构如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">Schema:</div><div class="line">&#123; "fields" :</div><div class="line">    [ &#123;"name": "version", "type": "int", "doc": "version id"&#125;,</div><div class="line">      &#123;"name": "partitions",</div><div class="line">       "type": &#123;"type": "map",</div><div class="line">                "values": &#123;"type": "array", "items": "int", "doc": "a list of replica ids"&#125;,</div><div class="line">                "doc": "a map from partition id to replica list"&#125;,</div><div class="line">      &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">Example:</div><div class="line">&#123;</div><div class="line">    "version":1,</div><div class="line">    "partitions":</div><div class="line">        &#123;"12":[6],</div><div class="line">        "8":[2],</div><div class="line">        "4":[6],</div><div class="line">        "11":[5],</div><div class="line">        "9":[3],</div><div class="line">        "5":[7],</div><div class="line">        "10":[4],</div><div class="line">        "6":[8],</div><div class="line">        "1":[3],</div><div class="line">        "0":[2],</div><div class="line">        "2":[4],</div><div class="line">        "7":[1],</div><div class="line">        "3":[5]&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　partition state（<code>/brokers/topics/[topic]/partitions/[partitionId]/state</code>） 结构如下<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Schema:</div><div class="line">&#123; "fields":</div><div class="line">    [ &#123;"name": "version", "type": "int", "doc": "version id"&#125;,</div><div class="line">      &#123;"name": "isr",</div><div class="line">       "type": &#123;"type": "array",</div><div class="line">                "items": "int",</div><div class="line">                "doc": "an array of the id of replicas in isr"&#125;</div><div class="line">      &#125;,</div><div class="line">      &#123;"name": "leader", "type": "int", "doc": "id of the leader replica"&#125;,</div><div class="line">      &#123;"name": "controller_epoch", "type": "int", "doc": "epoch of the controller that last updated the leader and isr info"&#125;,</div><div class="line">      &#123;"name": "leader_epoch", "type": "int", "doc": "epoch of the leader"&#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line"> </div><div class="line">Example:</div><div class="line">&#123;</div><div class="line">    "controller_epoch":29,</div><div class="line">    "leader":2,</div><div class="line">    "version":1,</div><div class="line">    "leader_epoch":48,</div><div class="line">    "isr":[2]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　<strong>controller</strong><br>　　<code>/controller -&gt; int (broker id of the controller)</code>存储当前controller的信息<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Schema:</div><div class="line">&#123; "fields":</div><div class="line">    [ &#123;"name": "version", "type": "int", "doc": "version id"&#125;,</div><div class="line">      &#123;"name": "brokerid", "type": "int", "doc": "broker id of the controller"&#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">Example:</div><div class="line">&#123;</div><div class="line">    "version":1,</div><div class="line">　　"brokerid":8</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　<code>/controller_epoch -&gt; int (epoch)</code>直接以整数形式存储controller epoch，而非像其它znode一样以JSON字符串形式存储。
　　
　　</p>
<h2 id="broker-failover过程简介"><a href="#broker-failover过程简介" class="headerlink" title="broker failover过程简介"></a>broker failover过程简介</h2><ol>
<li>Controller在Zookeeper注册Watch，一旦有Broker宕机（这是用宕机代表任何让系统认为其die的情景，包括但不限于机器断电，网络不可用，GC导致的Stop The World，进程crash等），其在Zookeeper对应的znode会自动被删除，Zookeeper会fire Controller注册的watch，Controller读取最新的幸存的Broker</li>
<li>Controller决定set_p，该集合包含了宕机的所有Broker上的所有Partition</li>
<li>对set_p中的每一个Partition<br>　　3.1 从<code>/brokers/topics/[topic]/partitions/[partition]/state</code>读取该Partition当前的ISR<br>　　3.2 决定该Partition的新Leader。如果当前ISR中有至少一个Replica还幸存，则选择其中一个作为新Leader，新的ISR则包含当前ISR中所有幸存的Replica。否则选择该Partition中任意一个幸存的Replica作为新的Leader以及ISR（该场景下可能会有潜在的数据丢失）。如果该Partition的所有Replica都宕机了，则将新的Leader设置为-1。<br>　　　3.3 将新的Leader，ISR和新的<code>leader_epoch</code>及<code>controller_epoch</code>写入<code>/brokers/topics/[topic]/partitions/[partition]/state</code>。注意，该操作只有其version在3.1至3.3的过程中无变化时才会执行，否则跳转到3.1</li>
<li>直接通过RPC向set_p相关的Broker发送LeaderAndISRRequest命令。Controller可以在一个RPC操作中发送多个命令从而提高效率。<br>　　Broker failover顺序图如下所示。<br><img src="http://www.jasongj.com/img/kafka/KafkaColumn2/kafka_broker_failover.png" alt="broker failover sequence diagram "></li>
</ol>
<h1 id="下篇预告"><a href="#下篇预告" class="headerlink" title="下篇预告"></a>下篇预告</h1><p>　　下篇文章将详细介绍Kafka HA相关的异常情况处理，例如，怎样处理Broker failover，Follower如何从Leader fetch消息，如何重新分配Replica，如何处理Controller failure等。</p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      Kafka从0.8版本开始提供High Availability机制，从而提高了系统可用性及数据持久性。本文从Data Replication和Leader Election两方面介绍了Kafka的HA机制。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（一） 从一个R语言案例学线性回归</title>
    <link href="http://www.jasongj.com/2015/03/27/ml1_linear_regression/"/>
    <id>http://www.jasongj.com/2015/03/27/ml1_linear_regression/</id>
    <published>2015-03-26T19:41:18.000Z</published>
    <updated>2017-04-02T12:53:27.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/03/27/ml1_linear_regression">原文链接</a>　<a href="http://www.jasongj.com/2015/03/27/ml1_linear_regression">http://www.jasongj.com/2015/03/27/ml1_linear_regression</a></p>
</blockquote>
<p><strong><em>写在前面的话</em></strong> 　　按照正常的顺序，本文应该先讲一些线性回归的基本概念，比如什么叫线性回归，线性回规的常用解法等。但既然本文名为《从一个R语言案例学会线性回归》，那就更重视如何使用R语言去解决线性回归问题，因此本文会先讲案例。</p>
<h1 id="线性回归简介"><a href="#线性回归简介" class="headerlink" title="线性回归简介"></a>线性回归简介</h1><p>　　如下图所示，如果把自变量（也叫independent variable）和因变量（也叫dependent variable）画在二维坐标上，则每条记录对应一个点。线性回规最常见的应用场景则是用一条直线去拟和已知的点，并对给定的x值预测其y值。而我们要做的就是找出一条合适的曲线，也就是找出合适的斜率及纵截矩。<br><img src="http://www.jasongj.com/img/ml/linearregression/one_variable_lr.png" alt="一维线性回规"></p>
<h2 id="SSE-amp-RMSE"><a href="#SSE-amp-RMSE" class="headerlink" title="SSE  &amp; RMSE"></a>SSE  &amp; RMSE</h2><p>　　上图中的SSE指sum of squared error，也即预测值与实际值之差的平方和，可由此判断该模型的误差。但使用SSE表征模型的误差有些弊端，比如它依赖于点的个数，且不好定其单位。所以我们有另外一个值去称量模型的误差。RMSE（Root-Mean-Square Error）。$$RMSE=\sqrt{\frac{SSE}{N}}$$<br>　　由N将其标准化，并且其单位与变量单位相同。
　　</p>
<h2 id="R-2"><a href="#R-2" class="headerlink" title="$R^2$"></a>$R^2$</h2><p>　　在选择用于预测的直线时，我们可以使用已知记录的y值的平均值作为直线，如上图红线所示，这条线我们称之为baseline model。SST(total sum of squares)指是的baseline的SSE。用SSE表征模型好坏也有不便之处，比如给定$SSE=10$，我们并不知道这个模型是好还是好，因此我们引入另一个变量，$R^2$，定义如下：$$R^2 = 1 - \frac{SSE}{SST}$$<br>　　$R^2$用来表明我们所选的模型在baseline model的基础之上提升了多少（对于任意给定数据集，我们都可以用baseline作为模型，而事实上，我们总希望我们最后选出的模型在baseline基础之上有所提升），并且这个值的范围是[0,1]。$R^2=0$意味着它并未在baseline model的基础之上有所提升，而$R^2=1$（此时$SSE=0$）意味着一个一个非常完美的模型。
　　</p>
<h2 id="Adjusted-R-2"><a href="#Adjusted-R-2" class="headerlink" title="Adjusted $R^2$"></a>Adjusted $R^2$</h2><p>　　在多元回归模型中，选用的Feature越多，我们所能得到的$R^2$越大。所以$R^2$不能用于帮助我们在Feature特别多时，选择合适的Feature用于建模。因此又有了Adjusted $R^2$，它会补偿由Feature增多/减少而引起的$R^2$的增加/减少，从而可通过它选择出真正适合用于建模的Feature。</p>
<h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>　　许多研究表明，全球平均气温在过去几十年中有所升高，以此引起的海平面上升和极端天气频现将会影响无数人。本文所讲案例就试图研究全球平均气温与一些其它因素的关系。<br>　　读者可<a href="https://courses.edx.org/c4x/MITx/15.071x_2/asset/climate_change.csv" target="_blank" rel="external">由此下载</a>本文所使用的数据<a href="https://courses.edx.org/c4x/MITx/15.071x_2/asset/climate_change.csv" target="_blank" rel="external">climate_change.csv</a>。<br>　　<a href="https://courses.edx.org/c4x/MITx/15.071x_2/asset/climate_change.csv" target="_blank" rel="external">https://courses.edx.org/c4x/MITx/15.071x_2/asset/climate_change.csv</a><br>　　此数据集包含了从1983年5月到2008年12月的数据。<br>　　本例我们以1983年5月到2006年12月的数据作为训练数据集，以之后的数据作为测试数据集。</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>　　首先加载数据</p>
<pre><code>temp &lt;- read.csv(&quot;climate_change.csv&quot;)
</code></pre><p>　　数据解释</p>
<ul>
<li>Year 年份 M</li>
<li>Month 月份 T</li>
<li>emp 当前周期内的全球平均气温与一个参考值之差 </li>
<li>$CO_2$，$N_2O$，$CH_4$，$CFC.11$，$CFC.12$：这几个气体的大气浓度 Aerosols</li>
</ul>
<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>　　线性回归模型保留两部分。</p>
<ul>
<li>选择目标Feature。我们数据中，有多个Feature，但并非所有的Feature都对预测有帮助，或者并非所有的Feature都需要一起工作来做预测，因此我们需要筛选出最小的最能预测出接近事实的Feature组合。</li>
<li>确定Feature系数（coefficient）。Feature选出来后，我们要确定每个Feature对预测结果所占的权重，这个权重即为coefficient</li>
</ul>
<h3 id="前向选择"><a href="#前向选择" class="headerlink" title="前向选择"></a>前向选择</h3><ol>
<li>以每个Feature为模型，分别算出其Adjusted $R^2$，最后取使得Adjusted $R^2$最大的Feature作为第一轮的Feature，并记下这个最大Adjusted $R^2$</li>
<li>在其它未被使用的Feature中选一个出来，与上轮作组合，并分别算出使其Adjusted $R^2$。若所有组合的Adjusted $R^2$都比上一轮小，则结束，以上一轮Feature组合作为最组的model。否则选出使得Adjusted $R^2$最大的Feature与上一轮的Feature结合，作为本轮Feature，并记下这个最大Adjusted $R^2$。</li>
<li>循环步骤2直到结束</li>
</ol>
<h3 id="后向选择"><a href="#后向选择" class="headerlink" title="后向选择"></a>后向选择</h3><ol>
<li>首先把所有Feature作为第一个模型，并算出其Adjusted $R^2$。</li>
<li>在上一轮的Feature组合中，分别去掉每个Feature，并算出其Adjusted $R^2$，如果去掉任意一个Feature都不能使得Adjusted $R^2$比上一轮大，则结束，取上一轮的Feature组合为最终的model。否则取使得Adjusted $R^2$最大的组合作为本轮的结果，并记下对应的Adjusted $R^2$。</li>
<li>循环步骤2直到结束</li>
</ol>
<h2 id="结合实例选择模型"><a href="#结合实例选择模型" class="headerlink" title="结合实例选择模型"></a>结合实例选择模型</h2><p><strong><em>初始选择所有Feature</em></strong><br>　　选择所有Feature作为第一个model1，并使用summary函数算出其Adjusted $R^2$为0.7371。<br>$$model1 &lt;- lm(Temp ~ MEI + CO_2 + CH_4 + N_2O + CFC.11 + CFC.12 + TSI + Aerosols, temp)$$</p>
<p>summary(model1)<br><img src="http://www.jasongj.com/img/ml/linearregression/model1.png" alt="adjusted r"></p>
<p><strong><em>逐一去掉Feature</em></strong><br>　　在model1中去掉任一个Feature，并记下相应的Adjusted $R^2$如下</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Adjusted $R^2$</th>
</tr>
</thead>
<tbody>
<tr>
<td>CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.6373</td>
</tr>
<tr>
<td>MEI + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.7331</td>
</tr>
<tr>
<td>MEI + CO2 + N2O + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.738</td>
</tr>
<tr>
<td>MEI + CO2 + CH4 + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.7339</td>
</tr>
<tr>
<td>MEI + CO2 + CH4 + N2O + CFC.12 + TSI + Aerosols</td>
<td>0.7163</td>
</tr>
<tr>
<td>MEI + CO2 + CH4 + N2O + CFC.11 + TSI + Aerosols</td>
<td>0.7172</td>
</tr>
<tr>
<td>MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + Aerosols</td>
<td>0.697</td>
</tr>
<tr>
<td>MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI</td>
<td>0.6883</td>
</tr>
</tbody>
</table>
<p>　　本轮得到<br>$$Temp \sim MEI + CO_2 + N_2O + CFC.11 + CFC.12 + TSI + Aerosols$$</p>
<p>　　从model2中任意去掉1个Feature，并记下相应的Adjusted $R^2$如下</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Adjusted $R^2$</th>
</tr>
</thead>
<tbody>
<tr>
<td>CO2 + N2O + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.6377</td>
</tr>
<tr>
<td>MEI + N2O + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.7339</td>
</tr>
<tr>
<td>MEI + CO2 + CFC.11 + CFC.12 + TSI + Aerosols</td>
<td>0.7346</td>
</tr>
<tr>
<td>MEI + CO2 + N2O + CFC.12 + TSI + Aerosols</td>
<td>0.7171</td>
</tr>
<tr>
<td>MEI + CO2 + N2O + CFC.11 + TSI + Aerosols</td>
<td>0.7166</td>
</tr>
<tr>
<td>MEI + CO2 + N2O + CFC.11 + CFC.12 + Aerosols</td>
<td>0.698</td>
</tr>
<tr>
<td>MEI + CO2 + N2O + CFC.11 + CFC.12 + TSI</td>
<td>0.6891</td>
</tr>
</tbody>
</table>
<p>   任一组合的Adjusted $R^2$都比上一轮小，因此选择上一轮的Feature组合作为最终的模型，也即<br>$$Temp \sim MEI + CO_2 + N_2O + CFC.11 + CFC.12 + TSI + Aerosols$$</p>
<p>   由<code>summary(model2)</code>可算出每个Feature的coefficient如下 。<br><img src="http://www.jasongj.com/img/ml/linearregression/model2.png" alt="Feature coefficient"></p>
<h1 id="线性回归介绍"><a href="#线性回归介绍" class="headerlink" title="线性回归介绍"></a>线性回归介绍</h1><p>　　<br>　　在线性回归中，数据使用线性预测函数来建模，并且未知的模型参数也是通过数据来估计。这些模型被叫做线性模型。最常用的线性回归建模是给定X值的y的条件均值是X的仿射函数。<br>　　线性回归是回归分析中第一种经过严格研究并在实际应用中广泛使用的类型。这是因为线性依赖于其未知参数的模型比非线性依赖于其位置参数的模型更容易拟合，而且产生的估计的统计特性也更容易确定。<br>　　上面这段定义来自于<a href="http://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8" target="_blank" rel="external">维基百科</a>。<br>　　<br>　　线性回归假设特征和结果满足线性关系。我们用$X_1,X_2..X_n$ 去描述Feature里面的分量，比如$x_1$=房间的面积，$x_2$=房间的朝向，等等，我们可以做出一个估计函数：  $$h(x)=h_θ(x)=θ_0+θ_1x_1+θ_2x_2$$</p>
<p>　　θ在这儿称为参数(coefficient)，在这的意思是调整Feature中每个分量的影响力，就是到底是房屋的面积更重要还是房屋的地段更重要。如果我们令$x_0 = 1$，就可以用向量的方式来表示了：　　$$h_θ(x)=θ^TX$$<br>　　<br>　　我们的程序也需要一个机制去评估我们θ是否比较好，所以说需要对我们做出的h函数进行评估，一般这个函数称为损失函数（loss function）或者错误函数(error function)，也有叫代价函数（cost function）的。在本文中，我们称这个函数为J函数。<br>　　在这里，我们可以认为J函数如下：　　$$J(0)=\frac{1}{2m}\sum_{i=1}^m(h_0x^{(i)}-y^{(i)})^2$$<br>　　<br>　　这个错误估计函数是去对$x(i)$的估计值与真实值$y(i)$差的平方和作为错误估计函数，前面乘上的$1/2m$是为了在求导的时候，这个系数就不见了。至于为何选择平方和作为错误估计函数，就得从概率分布的角度来解释了。<br>　　如何调整$θ$以使得$J(θ)$取得最小值有很多方法，本文会重点介绍梯度下降法和正规方程法。
　　</p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>　　在选定线性回归模型后，只需要确定参数$θ$，就可以将模型用来预测。然而$θ$需要使得$J(θ)$最小。因此问题归结为求极小值问题。<br>　　梯度下降法流程如下：</p>
<p>　　1. 首先对$θ$赋值，这个值可以是随机的，也可以让$θ$为一个全零向量。<br>　　2. 改变$θ$的值，使得$J(θ)$按梯度下降的方向进行调整。</p>
<p>　　梯度方向由$J(θ)$对$θ$的偏导数确定，由于求的是极小值，因此梯度方向是偏导数的反方向。更新公式为为： $$0_j = 0_j - α\frac{1}{m}\sum^m_{i=1}(h_θ(x^{(i)})-y^{(i)})x_j^{i}$$<br>　　<br>　　这种方法需要对全部的训练数据求得误差后再对$θ$进行更新。（$α$为学习速度）
　　</p>
<h1 id="正规方程（Normal-Equation）"><a href="#正规方程（Normal-Equation）" class="headerlink" title="正规方程（Normal Equation）"></a>正规方程（Normal Equation）</h1><p>　　$Xθ=y$<br>=&gt;<br>　　$X^TXθ=X^Ty$<br>=&gt;<br>　　$θ = (X^TX)^{-1}X^Ty$<br>　　利用以上公式可直接算出$θ$<br>　　<br>　　看到这里，读者可能注意到了，正规方程法，不需要像梯度下降那样迭代多次，更关键的是从编程的角度更直接，那为什么不直接用正规，还要保留梯度下降呢？想必学过线性代数的朋友一眼能看出来，正规方程需要求$(X^TX)$的逆，这就要求$(X^TX)$是可逆的。同时，如果Feature数比较多，比如共有100个Feature，那么$(X^TX)$的维度会非常高，求其逆会非常耗时。</p>
]]></content>
    
    <summary type="html">
    
      本文简要介绍了线性回归的原理，适用场景，并结合实例讲解如何使用R语言解决线性回归问题
    
    </summary>
    
      <category term="machine learning" scheme="http://www.jasongj.com/categories/machine-learning/"/>
    
      <category term="机器学习" scheme="http://www.jasongj.com/categories/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://www.jasongj.com/categories/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AI/"/>
    
    
      <category term="machine learning" scheme="http://www.jasongj.com/tags/machine-learning/"/>
    
      <category term="机器学习" scheme="http://www.jasongj.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://www.jasongj.com/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（二） 快速计算Distinct Count</title>
    <link href="http://www.jasongj.com/2015/03/15/count_distinct/"/>
    <id>http://www.jasongj.com/2015/03/15/count_distinct/</id>
    <published>2015-03-15T08:00:00.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/03/15/count_distinct/">原文链接</a>　<a href="http://www.jasongj.com/2015/03/15/count_distinct">http://www.jasongj.com/2015/03/15/count_distinct/</a></p>
</blockquote>
<h1 id="UV-vs-PV"><a href="#UV-vs-PV" class="headerlink" title="UV vs. PV"></a>UV vs. PV</h1><p>　　在互联网中，经常需要计算UV和PV。所谓PV即Page View，网页被打开多少次（YouTube等视频网站非常重视视频的点击率，即被播放多少次，也即PV）。而UV即Unique Visitor（微信朋友圈或者微信公众号中的文章则统计有多少人看过该文章，也即UV。虽然微信上显示是指明该值是PV，但经笔者测试，实为UV）。这两个概念非常重要，比如淘宝卖家在做活动时，他往往需要统计宝贝被看了多少次，有多少个不同的人看过该活动介绍。至于如何在互联网上唯一标识一个自然人，也是一个难点，目前还没有一个非常准确的方法，常用的方法是用户名加cookie，这里不作深究。</p>
<h1 id="count-distinct-vs-count-group-by"><a href="#count-distinct-vs-count-group-by" class="headerlink" title="count distinct vs. count group by"></a>count distinct vs. count group by</h1><p>　　很多情景下，尤其对于文本类型的字段，直接使用count distinct的查询效率是非常低的，而先做group by更count往往能提升查询效率。但实验表明，对于不同的字段，count distinct与count group by的性能并不一样，而且其效率也与目标数据集的数据重复度相关。</p>
<p>　　本节通过几组实验说明了不同场景下不同query的不同效率，同时分析性能差异的原因。 （本文所有实验皆基于PostgreSQL 9.3.5平台）<br>分别使用count distinct 和 count group by对 bigint, macaddr, text三种类型的字段做查询。<br>    首先创建如下结构的表</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>Type</th>
<th>Modifiers</th>
</tr>
</thead>
<tbody>
<tr>
<td>mac_bigint</td>
<td>bigint</td>
<td></td>
</tr>
<tr>
<td>mac_macaddr</td>
<td>macaddr</td>
<td></td>
</tr>
<tr>
<td>mac_text</td>
<td>text</td>
</tr>
</tbody>
</table>
<p>　　并插入1000万条记录，并保证mac_bigint为mac_macaddr去掉冒号后的16进制转换而成的10进制bigint，而mac_text为mac_macaddr的文本形式，从而保证在这三个字段上查询的结果，并且复杂度相同。</p>
<p>　　count distinct SQL如下<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> </div><div class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> mac_macaddr) </div><div class="line"><span class="keyword">from</span> </div><div class="line">    testmac</div></pre></td></tr></table></figure></p>
<p>　　count group by SQL如下<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span></div><div class="line">    <span class="keyword">count</span>(*)</div><div class="line"><span class="keyword">from</span></div><div class="line">    (<span class="keyword">select</span></div><div class="line">        mac_macaddr</div><div class="line">    <span class="keyword">from</span></div><div class="line">        testmac</div><div class="line">    <span class="keyword">group</span> <span class="keyword">by</span></div><div class="line">        <span class="number">1</span>) foo</div></pre></td></tr></table></figure></p>
<p>　　对于不同记录数较大的情景（1000万条记录中，有300多万条不同记录），查询时间（单位毫秒）如下表所示。</p>
<table>
<thead>
<tr>
<th>query/字段类型</th>
<th>macaddr</th>
<th>bigint</th>
<th>text</th>
</tr>
</thead>
<tbody>
<tr>
<td>count distinct</td>
<td>24668.023</td>
<td>13890.051</td>
<td>149048.911</td>
</tr>
<tr>
<td>count group by</td>
<td>32152.808</td>
<td>25929.555</td>
<td>159212.700</td>
</tr>
</tbody>
</table>
<p>　　对于不同记录数较小的情景（1000万条记录中，只有1万条不同记录），查询时间（单位毫秒）如下表所示。</p>
<table>
<thead>
<tr>
<th>query/字段类型</th>
<th>macaddr</th>
<th>bigint</th>
<th>text</th>
</tr>
</thead>
<tbody>
<tr>
<td>count distinct</td>
<td>20006.681</td>
<td>9984.763</td>
<td>225208.133</td>
</tr>
<tr>
<td>count group by</td>
<td>2529.420</td>
<td>2554.720</td>
<td>3701.869</td>
</tr>
</tbody>
</table>
<p>　　从上面两组实验可看出，在不同记录数较小时，count group by性能普遍高于count distinct，尤其对于text类型表现的更明显。而对于不同记录数较大的场景，count group by性能反而低于直接count distinct。为什么会造成这种差异呢，我们以macaddr类型为例来对比不同结果集下count group by的query plan。<br>　　当结果集较小时，planner会使用HashAggregation。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">explain analyze select count(*) from (select mac_macaddr from testmac_small group by 1) foo;</div><div class="line">                                        QUERY PLAN</div><div class="line"> Aggregate  (cost=668465.04..668465.05 rows=1 width=0) (actual time=9166.486..9166.486 rows=1 loops=1)</div><div class="line">   -&gt;  HashAggregate  (cost=668296.74..668371.54 rows=7480 width=6) (actual time=9161.796..9164.393 rows=10001 loops=1)</div><div class="line">         -&gt;  Seq Scan on testmac_small  (cost=0.00..572898.79 rows=38159179 width=6) (actual time=323.338..5091.112 rows=10000000 l</div><div class="line">oops=1)</div></pre></td></tr></table></figure></p>
<p>　　而当结果集较大时，无法通过在内存中维护Hash表的方式使用HashAggregation，planner会使用GroupAggregation，并会用到排序，而且因为目标数据集太大，无法在内存中使用Quick Sort，而要在外存中使用Merge Sort，而这就极大的增加了I/O开销。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">explain analyze select count(*) from (select mac_macaddr from testmac group by 1) foo;</div><div class="line">                                        QUERY PLAN</div><div class="line"> Aggregate  (cost=1881542.62..1881542.63 rows=1 width=0) (actual time=34288.232..34288.232 rows=1 loops=1)</div><div class="line">   -&gt;  Group  (cost=1794262.09..1844329.41 rows=2977057 width=6) (actual time=25291.372..33481.228 rows=3671797 loops=1)</div><div class="line">         -&gt;  Sort  (cost=1794262.09..1819295.75 rows=10013464 width=6) (actual time=25291.366..29907.351 rows=10000000 loops=1)</div><div class="line">               Sort Key: testmac.mac_macaddr</div><div class="line">               Sort Method: external merge  Disk: 156440kB</div><div class="line">               -&gt;  Seq Scan on testmac  (cost=0.00..219206.64 rows=10013464 width=6) (actual time=0.082..4312.053 rows=10000000 loo</div><div class="line">ps=1)</div></pre></td></tr></table></figure></p>
<h1 id="dinstinct-count高效近似算法"><a href="#dinstinct-count高效近似算法" class="headerlink" title="dinstinct count高效近似算法"></a>dinstinct count高效近似算法</h1><p>　　由于distinct count的需求非常普遍（如互联网中计算UV），而该计算的代价又相比较高，很难适应实时性要求较高的场景，如流计算，因此有很多相关研究试图解决该问题。比较著名的算法有<a href="http://en.wikipedia.org/wiki/Adaptive_sampling" target="_blank" rel="external">daptive sampling Algorithm</a>，<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4812493&amp;tag=1" target="_blank" rel="external">Distinct Counting with a Self-Learning Bitmap</a>，<a href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf" target="_blank" rel="external">HyperLogLog</a>，<a href="http://algo.inria.fr/flajolet/Publications/DuFl03-LNCS.pdf" target="_blank" rel="external">LogLog</a>，<a href="http://www.mathcs.emory.edu/~cheung/papers/StreamDB/Probab/1985-Flajolet-Probabilistic-counting.pdf" target="_blank" rel="external">Probabilistic Counting Algorithms</a>。这些算法都不能精确计算distinct count，都是在保证误差较小的情况下高效计算出结果。本文分别就这几种算法做了两组实验。</p>
<ul>
<li>数据集100万条，每条记录均不相同，几种算法耗时及内存使用如下。</li>
</ul>
<table>
<thead>
<tr>
<th>algorithm</th>
<th>result</th>
<th>error</th>
<th>time(ms)</th>
<th>memory (B)</th>
</tr>
</thead>
<tbody>
<tr>
<td>count(distinct)</td>
<td>1000000</td>
<td>0%</td>
<td>14026</td>
<td>？</td>
</tr>
<tr>
<td>Adaptive Sampling</td>
<td>1008128</td>
<td>0.8%</td>
<td>8653</td>
<td>57627</td>
</tr>
<tr>
<td>Self-learning Bitmap</td>
<td>991651</td>
<td>0.9%</td>
<td>1151</td>
<td>65571</td>
</tr>
<tr>
<td>Bloom filter</td>
<td>788052</td>
<td>22%</td>
<td>2400</td>
<td>1198164</td>
</tr>
<tr>
<td>Probalilistic Counting</td>
<td>1139925</td>
<td>14%</td>
<td>3613</td>
<td>95</td>
</tr>
<tr>
<td>PCSA</td>
<td>841735</td>
<td>16%</td>
<td>842</td>
<td>495</td>
</tr>
</tbody>
</table>
<ul>
<li>数据集100万条，只有100条不同记录，几种近似算法耗时及内存使用如下。</li>
</ul>
<table>
<thead>
<tr>
<th>algorithm</th>
<th>result</th>
<th>error</th>
<th>time(ms)</th>
<th>memory (B)</th>
</tr>
</thead>
<tbody>
<tr>
<td>count(distinct)</td>
<td>100</td>
<td>0%</td>
<td>75306</td>
<td>？</td>
</tr>
<tr>
<td>Adaptive Sampling</td>
<td>100</td>
<td>0%</td>
<td>1491</td>
<td>57627</td>
</tr>
<tr>
<td>Self-learning Bitmap</td>
<td>101</td>
<td>1%</td>
<td>1031</td>
<td>65571</td>
</tr>
<tr>
<td>Bloom filter</td>
<td>100</td>
<td>0%</td>
<td>1675</td>
<td>1198164</td>
</tr>
<tr>
<td>Probalilistic Counting</td>
<td>95</td>
<td>5%</td>
<td>3613</td>
<td>95</td>
</tr>
<tr>
<td>PCSA</td>
<td>98</td>
<td>2%</td>
<td>852</td>
<td>495</td>
</tr>
</tbody>
</table>
<p>　　<br>　　从上面两组实验可看出，大部分的近似算法工作得都很好，其速度都比简单的count distinct要快很多，而且它们对内存的使用并不多而结果去非常好，尤其是Adaptive Sampling和Self-learning Bitmap，误差一般不超过1%，性能却比简单的count distinct高十几倍乃至几十倍。
　　</p>
<h1 id="distinct-count结果合并"><a href="#distinct-count结果合并" class="headerlink" title="distinct count结果合并"></a>distinct count结果合并</h1><p>　　如上几种近似算法可以极大提高distinct count的效率，但对于data warehouse来说，数据量非常大，可能存储了几年的数据，为了提高查询速度，对于sum及avg这些aggregation一般会创建一些aggregation table。比如如果要算过去三年的总营业额，那可以创建一张daily/monthly aggregation table，基于daily/monthly表去计算三年的营业额。但对于distinct count，即使创建了daily/monthly aggregation table，也没办法通过其计算三年的数值。这里有种新的数据类型hll，这是一种<a href="http://research.neustar.biz/2012/10/25/sketch-of-the-day-hyperloglog-cornerstone-of-a-big-data-infrastructure/" target="_blank" rel="external">HyperLogLog</a>数据结构。一个1280字节的hll能计算几百亿的不同数值并且保证只有很小的误差。<br>　　首先创建一张表(fact)，结构如下</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>Type</th>
<th>Modifiers</th>
</tr>
</thead>
<tbody>
<tr>
<td>day</td>
<td>date</td>
<td></td>
</tr>
<tr>
<td>user_id</td>
<td>integer</td>
<td></td>
</tr>
<tr>
<td>sales</td>
<td>numeric</td>
</tr>
</tbody>
</table>
<p>　　插入三年的数据，并保证总共有10万个不同的user_id，总数据量为1亿条（一天10万条左右）。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">insert</span> <span class="keyword">into</span> fact</div><div class="line"><span class="keyword">select</span></div><div class="line">    <span class="keyword">current_date</span> - (random()*<span class="number">1095</span>)::<span class="built_in">integer</span> * <span class="string">'1 day'</span>::<span class="built_in">interval</span>,</div><div class="line">    (random()*<span class="number">100000</span>)::<span class="built_in">integer</span> + <span class="number">1</span>,</div><div class="line">    random() * <span class="number">10000</span> + <span class="number">500</span></div><div class="line"><span class="keyword">from</span></div><div class="line">    generate_series(<span class="number">1</span>, <span class="number">100000000</span>, <span class="number">1</span>);</div></pre></td></tr></table></figure></p>
<p>　　直接从fact表中查询不同用户的总数，耗时115143.217 ms。<br>    利用hll，创建daily_unique_user_hll表，将每天的不同用户信息存于hll类型的字段中。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> daily_unique_user_hll </div><div class="line"><span class="keyword">as</span> <span class="keyword">select</span></div><div class="line">    <span class="keyword">day</span>, </div><div class="line">    hll_add_agg(hll_hash_integer(user_id))</div><div class="line"><span class="keyword">from</span> </div><div class="line">    fact</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="number">1</span>;</div></pre></td></tr></table></figure></p>
<p>　　通过上面的daily aggregation table可计算任意日期范围内的unique user count。如计算整个三年的不同用户数，耗时17.485 ms，查询结果为101044，误差为(101044-100000)/100000=1.044%。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">explain analyze select hll_cardinality(hll_union_agg(hll_add_agg)) from daily_unique_user_hll;</div><div class="line">                                   QUERY PLAN</div><div class="line"> Aggregate  (cost=196.70..196.72 rows=1 width=32) (actual time=16.772..16.772 rows=1 loops=1)</div><div class="line">   -&gt;  Seq Scan on daily_unique_user_hll  (cost=0.00..193.96 rows=1096 width=32) (actual time=0.298..3.251 rows=</div><div class="line">1096 loops=1)</div><div class="line"> Planning time: 0.081 ms</div><div class="line"> Execution time: 16.851 ms</div><div class="line"> Time: 17.485 ms</div></pre></td></tr></table></figure></p>
<p>　　而如果直接使用count distinct基于fact表计算该值，则耗时长达 127807.105 ms。<br>　　<br>　　从上面的实验中可以看到，hll类型实现了distinct count的合并，并可以通过hll存储各个部分数据集上的distinct count值，并可通过合并这些hll值来快速计算整个数据集上的distinct count值，耗时只有直接使用count distinct在原始数据上计算的1/7308，并且误差非常小，1%左右。
　　</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>　　如果必须要计算精确的distinct count，可以针对不同的情况使用count distinct或者count group by来实现较好的效率，同时对于数据的存储类型，能使用macaddr/intger/bigint的，尽量不要使用text。<br>　　<br>　　另外不必要精确计算，只需要保证误差在可接受的范围之内，或者计算效率更重要时，可以采用本文所介绍的<a href="http://en.wikipedia.org/wiki/Adaptive_sampling" target="_blank" rel="external">daptive sampling Algorithm</a>，<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4812493&amp;tag=1" target="_blank" rel="external">Distinct Counting with a Self-Learning Bitmap</a>，<a href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf" target="_blank" rel="external">HyperLogLog</a>，<a href="http://algo.inria.fr/flajolet/Publications/DuFl03-LNCS.pdf" target="_blank" rel="external">LogLog</a>，<a href="http://www.mathcs.emory.edu/~cheung/papers/StreamDB/Probab/1985-Flajolet-Probabilistic-counting.pdf" target="_blank" rel="external">Probabilistic Counting Algorithms</a>等近似算法。另外，对于data warehouse这种存储数据量随着时间不断超增加且最终数据总量非常巨大的应用场景，可以使用hll这种支持合并dintinct count结果的数据类型，并周期性的（比如daily/weekly/monthly）计算部分数据的distinct值，然后通过合并部分结果的方式得到总结果的方式来快速响应查询请求。</p>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了distinct count的SQL优化方法，以及常用的高效近似算法及其在PostgreSQL上的实现。
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Kafka设计解析（一）- Kafka背景及架构介绍</title>
    <link href="http://www.jasongj.com/2015/03/10/KafkaColumn1/"/>
    <id>http://www.jasongj.com/2015/03/10/KafkaColumn1/</id>
    <published>2015-03-10T06:00:00.000Z</published>
    <updated>2017-03-29T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处。（已授权<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-1" target="_blank" rel="external">InfoQ中文站发布</a>）<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1">原文链接</a>　<a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">http://www.jasongj.com/2015/03/10/KafkaColumn1</a></p>
</blockquote>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>　　Kafka是由LinkedIn开发并开源的分布式消息系统，因其分布式及高吞吐率而被广泛使用，现已与Cloudera Hadoop，Apache Storm，Apache Spark集成。本文介绍了Kafka的创建背景，设计目标，使用消息系统的优势以及目前流行的消息系统对比。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。</p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><h2 id="Kafka创建背景"><a href="#Kafka创建背景" class="headerlink" title="Kafka创建背景"></a>Kafka创建背景</h2><p>　　Kafka是一个消息系统，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被<a href="https://cwiki.apache.org/confluence/display/KAFKA/Powered+By" target="_blank" rel="external">多家不同类型的公司</a> 作为多种类型的数据管道和消息系统使用。<br>　　活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。<br>　　近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。
　　</p>
<h2 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h2><p>　　Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：</p>
<ul>
<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输</li>
<li>同时支持离线数据处理和实时数据处理</li>
<li>Scale out：支持在线水平扩展</li>
</ul>
<h2 id="为何使用消息系统"><a href="#为何使用消息系统" class="headerlink" title="为何使用消息系统"></a>为何使用消息系统</h2><ul>
<li><p><strong>解耦</strong><br>　　在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
</li>
<li><p><strong>冗余</strong><br>　　有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</p>
</li>
<li><p><strong>扩展性</strong><br>　　因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</p>
</li>
<li><p><strong>灵活性 &amp; 峰值处理能力</strong><br>　　在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
</li>
<li><p><strong>可恢复性</strong><br>　　系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>
</li>
<li><p><strong>顺序保证</strong><br>　　在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。</p>
</li>
<li><p><strong>缓冲</strong><br>　　在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。</p>
</li>
<li><p><strong>异步通信</strong><br>　　很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
</li>
</ul>
<h2 id="常用Message-Queue对比"><a href="#常用Message-Queue对比" class="headerlink" title="常用Message Queue对比"></a>常用Message Queue对比</h2><ul>
<li><p><strong>RabbitMQ</strong><br>　　RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</p>
</li>
<li><p><strong>Redis</strong><br>　　Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p>
</li>
<li><p><strong>ZeroMQ</strong><br>　　ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。</p>
</li>
<li><p><strong>ActiveMQ</strong><br>　　ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。</p>
</li>
<li><p><strong>Kafka/Jafka</strong><br>　　Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p>
</li>
</ul>
<h1 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h1><h2 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h2><ul>
<li><strong>Broker</strong><br>　　Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>
<li><strong>Topic</strong><br>　　每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</li>
<li><strong>Partition</strong><br>　　Parition是物理上的概念，每个Topic包含一个或多个Partition.</li>
<li><strong>Producer</strong><br>　　负责发布消息到Kafka broker</li>
<li><strong>Consumer</strong><br>　　消息消费者，向Kafka broker读取消息的客户端。</li>
<li><strong>Consumer Group</strong><br>　　每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</li>
</ul>
<h2 id="Kafka拓扑结构"><a href="#Kafka拓扑结构" class="headerlink" title="Kafka拓扑结构"></a>Kafka拓扑结构</h2><p><img src="http://www.jasongj.com/img/kafka/KafkaColumn1/KafkaArchitecture.png" alt="kafka architecture 架构"><br>　　如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个<a href="http://zookeeper.apache.org/" target="_blank" rel="external">Zookeeper</a>集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。
　　</p>
<h2 id="Topic-amp-Partition"><a href="#Topic-amp-Partition" class="headerlink" title="Topic &amp; Partition"></a>Topic &amp; Partition</h2><p>　　Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹（本文所用集群共8个节点，此处topic1和topic2 replication-factor均为1），如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/topic-partition.png" alt="kafka topic partition"><br>　　<br>　　每个日志文件都是一个<code>log entry</code>序列，每个<code>log entry</code>包含一个4字节整型数值（值为N+5），1个字节的”magic value”，4个字节的CRC校验码，其后跟N个字节的消息体。每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：<br>　　message length    ：   4 bytes (value: 1+4+n)<br>　　“magic” value     ：   1 byte<br>　　crc               ：   4 bytes<br>　　payload           ：   n bytes<br>　　这个<code>log entry</code>并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以“.kafka”为后缀。另外会有一个索引文件，它标明了每个segment下包含的<code>log entry</code>的offset范围，如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/partition_segment.png" alt="kafka partition event index"><br>　　<br>　　因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/partition.png" alt="kafka 顺序写磁盘"><br>　　<br>　　对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。一是基于时间，二是基于Partition文件大小。例如可以通过配置<code>$KAFKA_HOME/config/server.properties</code>，让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></div><div class="line">log.retention.hours=168</div><div class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></div><div class="line">log.segment.bytes=1073741824</div><div class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according to the retention policies</span></div><div class="line">log.retention.check.interval.ms=300000</div><div class="line"><span class="comment"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction.</span></div><div class="line">log.cleaner.enable=<span class="literal">false</span></div></pre></td></tr></table></figure></p>
<p>　　这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由Consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。
　　</p>
<h2 id="Producer消息路由"><a href="#Producer消息路由" class="headerlink" title="Producer消息路由"></a>Producer消息路由</h2><p>　　Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。可以在<code>$KAFKA_HOME/config/server.properties</code>中通过配置项<code>num.partitions</code>来指定新建Topic的默认Partition数量，也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。<br>　　<br>　　在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。Paritition机制可以通过指定Producer的<code>paritition. class</code>这一参数来指定，该class必须实现<code>kafka.producer.Partitioner</code>接口。本例中如果key可以被解析为整数则将对应的整数与Partition总数取余，该消息会被发送到该数对应的Partition。（每个Parition都会有个序号,序号从0开始）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> kafka.producer.Partitioner;</div><div class="line"><span class="keyword">import</span> kafka.utils.VerifiableProperties;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JasonPartitioner</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JasonPartitioner</span><span class="params">(VerifiableProperties verifiableProperties)</span> </span>&#123;&#125;</div><div class="line">    </div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Object key, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">int</span> partitionNum = Integer.parseInt((String) key);</div><div class="line">            <span class="keyword">return</span> Math.abs(Integer.parseInt((String) key) % numPartitions);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            <span class="keyword">return</span> Math.abs(key.hashCode() % numPartitions);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　如果将上例中的类作为<code>partition.class</code>，并通过如下代码发送20条消息（key分别为0，1，2，3）至topic3（包含4个Partition）。<br>　　<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>&#123;</div><div class="line">　　<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</div><div class="line">　　      List messageList = <span class="keyword">new</span> ArrayList&lt;KeyedMessage&lt;String, String&gt;&gt;();</div><div class="line">　　      <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; j++）&#123;</div><div class="line">　　          messageList.add(<span class="keyword">new</span> KeyedMessage&lt;String, String&gt;(<span class="string">"topic2"</span>, String.valueOf(j), String.format(<span class="string">"The %d message for key %d"</span>, i,  j));</div><div class="line">　　      &#125;</div><div class="line">　　      producer.send(messageList);</div><div class="line">    &#125;</div><div class="line">　　producer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　则key相同的消息会被发送并存储到同一个partition里，而且key的序号正好和Partition序号相同。（Partition序号从0开始，本例中的key也从0开始）。下图所示是通过Java程序调用Consumer后打印出的消息列表。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/partition_key.png" alt="kafka consumer rebalance">
　　</p>
<h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>　　（本节所有描述都是基于Consumer hight level API而非low level API）。<br>　　使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/consumer_group.png" alt="kafka consumer group"><br>　　这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。<br>　　实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。下图是Kafka在Linkedin的一种简化部署示意图。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/kafka_in_linkedin.png" alt="kafka sample deployment in linkedin"><br>　　<br>　　下面这个例子更清晰地展示了Kafka Consumer Group的特性。首先创建一个Topic (名为topic1，包含3个Partition)，然后创建一个属于group1的Consumer实例，并创建三个属于group2的Consumer实例，最后通过Producer向topic1发送key分别为1，2，3的消息。结果发现属于group1的Consumer收到了所有的这三条消息，同时group2中的3个Consumer分别收到了key为1，2，3的消息。如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaColumn1/consumer_group_test.png" alt="kafka consumer group">
　　</p>
<h2 id="Push-vs-Pull"><a href="#Push-vs-Pull" class="headerlink" title="Push vs. Pull　　"></a>Push vs. Pull　　</h2><p>　　作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的<a href="https://github.com/facebookarchive/scribe" target="_blank" rel="external">Scribe</a>和Cloudera的<a href="http://flume.apache.org/" target="_blank" rel="external">Flume</a>，采用push模式。事实上，push模式和pull模式各有优劣。<br>　　push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。<br>　　对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。
　　</p>
<h2 id="Kafka-delivery-guarantee"><a href="#Kafka-delivery-guarantee" class="headerlink" title="Kafka delivery guarantee"></a>Kafka delivery guarantee</h2><p>　　有这么几种可能的delivery guarantee：</p>
<ul>
<li><code>At most once</code> 消息可能会丢，但绝不会重复传输</li>
<li><code>At least one</code> 消息绝不会丢，但可能会重复传输</li>
<li><code>Exactly once</code> 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。<br>　　<br>　　当Producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果Producer发送数据给broker后，遇到网络问题而造成通信中断，那Producer就无法判断该条消息是否已经commit。虽然Kafka无法确定网络故障期间发生了什么，但是Producer可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了<code>Exactly once</code>。截止到目前(Kafka 0.8.2版本，2015-03-04)，这一Feature还并未实现，有希望在Kafka未来的版本中实现。（所以目前默认情况下一条消息从Producer到broker是确保了<code>At least once</code>，可通过设置Producer异步发送实现<code>At most once</code>）。<br>　　接下来讨论的是消息从broker到Consumer的delivery guarantee语义。（仅针对Kafka consumer high level API）。Consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中保存该Consumer在该Partition中读取的消息的offset。该Consumer下一次再读该Partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将Consumer设置为autocommit，即Consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了<code>Exactly once</code>。但实际使用中应用程序并非在Consumer读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</li>
<li>读完消息先commit再处理消息。这种模式下，如果Consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于<code>At most once</code></li>
<li>读完消息先处理再commit。这种模式下，如果在处理完消息之后commit之前Consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了。这就对应于<code>At least once</code>。在很多使用场景下，消息都有一个主键，所以消息的处理往往具有幂等性，即多次处理这一条消息跟只处理一次是等效的，那就可以认为是<code>Exactly once</code>。（笔者认为这种说法比较牵强，毕竟它不是Kafka本身提供的机制，主键本身也并不能完全保证操作的幂等性。而且实际上我们说delivery guarantee 语义是讨论被处理多少次，而非处理结果怎样，因为处理方式多种多样，我们不应该把处理过程的特性——如是否幂等性，当成Kafka本身的Feature）</li>
<li>如果一定要做到<code>Exactly once</code>，就需要协调offset和实际操作的输出。经典的做法是引入两阶段提交。如果能让offset和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，Consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现<code>Exactly once</code>。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）<br>　　总之，Kafka默认保证<code>At least once</code>，并且允许通过设置Producer异步提交来实现<code>At most once</code>。而<code>Exactly once</code>要求与外部存储系统协作，幸运的是Kafka提供的offset可以非常直接非常容易得使用这种方式。</li>
</ul>
<p>　　</p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a>
　　
　　
　　</li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Kafka的创建背景，设计目标，使用消息系统的优势以及目前流行的消息系统对比。并介绍了Kafka的架构，Producer消息路由，Consumer Group以及由其实现的不同消息分发方式，Topic &amp; Partition，最后介绍了Kafka Consumer为何使用pull模式以及Kafka提供的三种delivery guarantee。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</title>
    <link href="http://www.jasongj.com/2015/03/07/Join1/"/>
    <id>http://www.jasongj.com/2015/03/07/Join1/</id>
    <published>2015-03-07T13:00:00.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/03/07/Join1/">原文链接</a>　<a href="http://www.jasongj.com/2015/03/07/Join1">http://www.jasongj.com/2015/03/07/Join1/</a></p>
</blockquote>
<h1 id="Nested-Loop，Hash-Join，Merge-Join介绍"><a href="#Nested-Loop，Hash-Join，Merge-Join介绍" class="headerlink" title="Nested Loop，Hash Join，Merge Join介绍"></a>Nested Loop，Hash Join，Merge Join介绍</h1><ul>
<li><p>Nested Loop:<br>对于被连接的数据子集较小的情况，Nested Loop是个较好的选择。Nested Loop就是扫描一个表（外表），每读到一条记录，就根据Join字段上的索引去另一张表（内表）里面查找，若Join字段上没有索引查询优化器一般就不会选择 Nested Loop。在Nested Loop中，内表（一般是带索引的大表）被外表（也叫“驱动表”，一般为小表——不紧相对其它表为小表，而且记录数的绝对值也较小，不要求有索引）驱动，外表返回的每一行都要在内表中检索找到与它匹配的行，因此整个查询返回的结果集不能太大（大于1 万不适合）。</p>
</li>
<li><p>Hash Join:<br>Hash Join是做大数据集连接时的常用方式，优化器使用两个表中较小（相对较小）的表利用Join Key在内存中建立散列表，然后扫描较大的表并探测散列表，找出与Hash表匹配的行。<br>这种方式适用于较小的表完全可以放于内存中的情况，这样总成本就是访问两个表的成本之和。但是在表很大的情况下并不能完全放入内存，这时优化器会将它分割成若干不同的分区，不能放入内存的部分就把该分区写入磁盘的临时段，此时要求有较大的临时段从而尽量提高I/O 的性能。它能够很好的工作于没有索引的大表和并行查询的环境中，并提供最好的性能。大多数人都说它是Join的重型升降机。Hash Join只能应用于等值连接(如WHERE A.COL3 = B.COL4)，这是由Hash的特点决定的。</p>
</li>
<li><p>Merge Join:<br>通常情况下Hash Join的效果都比排序合并连接要好，然而如果两表已经被排过序，在执行排序合并连接时不需要再排序了，这时Merge Join的性能会优于Hash Join。Merge join的操作通常分三步：<br>　　1. 对连接的每个表做table access full;<br>　　2. 对table access full的结果进行排序。<br>　　3. 进行merge join对排序结果进行合并。<br>在全表扫描比索引范围扫描再进行表访问更可取的情况下，Merge Join会比Nested Loop性能更佳。当表特别小或特别巨大的时候，实行全表访问可能会比索引范围扫描更有效。Merge Join的性能开销几乎都在前两步。Merge Join可适于于非等值Join（&gt;，&lt;，&gt;=，&lt;=，但是不包含!=，也即&lt;&gt;）</p>
</li>
</ul>
<h1 id="Nested-Loop，Hash-JOin，Merge-Join对比"><a href="#Nested-Loop，Hash-JOin，Merge-Join对比" class="headerlink" title="Nested Loop，Hash JOin，Merge Join对比"></a>Nested Loop，Hash JOin，Merge Join对比</h1><table>
<thead>
<tr>
<th>类别</th>
<th>Nested Loop</th>
<th>Hash Join</th>
<th>Merge Join</th>
</tr>
</thead>
<tbody>
<tr>
<td>使用条件</td>
<td>任何条件</td>
<td>等值连接（=）</td>
<td>等值或非等值连接(&gt;，&lt;，=，&gt;=，&lt;=)，‘&lt;&gt;’除外</td>
</tr>
<tr>
<td>相关资源</td>
<td>CPU、磁盘I/O</td>
<td>内存、临时空间</td>
<td>内存、临时空间</td>
</tr>
<tr>
<td>特点</td>
<td>当有高选择性索引或进行限制性搜索时效率比较高，能够快速返回第一次的搜索结果。</td>
<td>当缺乏索引或者索引条件模糊时，Hash Join比Nested Loop有效。通常比Merge Join快。在数据仓库环境下，如果表的纪录数多，效率高。</td>
<td>当缺乏索引或者索引条件模糊时，Merge Join比Nested Loop有效。非等值连接时，Merge Join比Hash Join更有效</td>
</tr>
<tr>
<td>缺点</td>
<td>当索引丢失或者查询条件限制不够时，效率很低；当表的纪录数多时，效率低。</td>
<td>为建立哈希表，需要大量内存。第一次的结果返回较慢。</td>
<td>所有的表都需要排序。它为最优化的吞吐量而设计，并且在结果没有全部找到前不返回数据。</td>
</tr>
</tbody>
</table>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>本文所做实验均基于PostgreSQL 9.3.5平台</p>
<h2 id="小于万条记录小表与大表Join"><a href="#小于万条记录小表与大表Join" class="headerlink" title="小于万条记录小表与大表Join"></a>小于万条记录小表与大表Join</h2><p>一张记录数1万以下的小表nbar.mse_test_test，一张大表165万条记录的大表nbar.nbar_test，大表上建有索引</p>
<h3 id="Query-1-等值Join"><a href="#Query-1-等值Join" class="headerlink" title="Query 1:等值Join"></a><strong>Query 1:</strong>等值Join</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> </div><div class="line">	<span class="keyword">count</span>(*)</div><div class="line"><span class="keyword">from</span> </div><div class="line">	mse_test_test, </div><div class="line">	nbar_test </div><div class="line"><span class="keyword">where</span> </div><div class="line">	mse_test_test.client_key = nbar_test.client_key;</div></pre></td></tr></table></figure>
<h4 id="Query-1-Test-1：-查询优化器自动选择Nested-Loop，耗时784-845-ms"><a href="#Query-1-Test-1：-查询优化器自动选择Nested-Loop，耗时784-845-ms" class="headerlink" title="Query 1 Test 1： 查询优化器自动选择Nested Loop，耗时784.845 ms"></a><strong>Query 1 Test 1：</strong> 查询优化器自动选择Nested Loop，耗时784.845 ms</h4><p><img src="http://www.jasongj.com/img/sql/Join/Nest_Nest_Explain.png" alt="Nested loop"></p>
<p>　　如下图所示，执行器将小表mse_test_test作为外表（驱动表），对于其中的每条记录，通过大表（nbar_test）上的索引匹配相应记录。</p>
<p> <img src="http://www.jasongj.com/img/sql/Join/Nest_Nest.png" alt="Nested loop"></p>
<h4 id="Query-1-Test-2：强制使用Hash-Join，耗时1731-836ms"><a href="#Query-1-Test-2：强制使用Hash-Join，耗时1731-836ms" class="headerlink" title="Query 1 Test 2：强制使用Hash Join，耗时1731.836ms"></a><strong>Query 1 Test 2：</strong>强制使用Hash Join，耗时1731.836ms</h4><p><img src="http://www.jasongj.com/img/sql/Join/Nest_Hash_Explain.png" alt="Nested loop join"></p>
<p>　　如下图所示，执行器选择一张表将其映射成散列表，再遍历另外一张表并从散列表中匹配相应记录。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Hash.png" alt="Hash join"></p>
<h4 id="Query-1-Test-3：强制使用Merge-Join，耗时4956-768-ms"><a href="#Query-1-Test-3：强制使用Merge-Join，耗时4956-768-ms" class="headerlink" title="Query 1 Test 3：强制使用Merge Join，耗时4956.768 ms"></a><strong>Query 1 Test 3：</strong>强制使用Merge Join，耗时4956.768 ms</h4><p><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge_Explain.png" alt="Merge join plan"> </p>
<p>　　如下图所示，执行器先分别对mse_test_test和nbar_test按client_key排序。其中mse_test_test使用快速排序，而nbar_test使用external merge排序，之后对二者进行Merge Join。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge.png" alt="Merge join"></p>
<h4 id="Query-1-总结-1-："><a href="#Query-1-总结-1-：" class="headerlink" title="Query 1 总结 1 ："></a><strong>Query 1 总结 1 ：</strong></h4><p>通过对比<code>Query 1 Test 1</code>，<code>Query 1 Test 2</code>，<code>Query 1 Test 3</code>可以看出Nested Loop适用于结果集很小（一般要求小于一万条），并且内表在Join字段上建有索引（这点非常非常非常重要）。</p>
<ul>
<li><strong>在大表上创建聚簇索引</strong></li>
</ul>
<h4 id="Query-1-Test-4：强制使用Merge-Join，耗时1660-228-ms"><a href="#Query-1-Test-4：强制使用Merge-Join，耗时1660-228-ms" class="headerlink" title="Query 1 Test 4：强制使用Merge Join，耗时1660.228 ms"></a><strong>Query 1 Test 4：</strong>强制使用Merge Join，耗时1660.228 ms</h4><p><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge_Cluster_Explain.png" alt="Merge join"></p>
<p>　　如下图所示，执行器通过聚簇索引对大表（nbar_test）排序，直接通过快排对无索引的小表（mse_test_test）排序，之后对二才进行Merge Join。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge_Cluster.png" alt="Merge join"></p>
<h4 id="Query-1-总结-2："><a href="#Query-1-总结-2：" class="headerlink" title="Query 1 总结 2："></a><strong>Query 1 总结 2：</strong></h4><p>通过对比<code>Query 1 Test 3</code>和<code>Query 1 Test 4</code>可以看出，Merge Join的主要开销是排序开销，如果能通过建立聚簇索引（如果Query必须显示排序），可以极大提高Merge Join的性能。从这两个实验可以看出，创建聚簇索引后，查询时间从4956.768 ms缩减到了1815.238 ms。</p>
<ul>
<li><strong>在两表上同时创建聚簇索引</strong></li>
</ul>
<h4 id="Query-1-Test-5：强制使用Merge-Join，耗时2575-498-ms。"><a href="#Query-1-Test-5：强制使用Merge-Join，耗时2575-498-ms。" class="headerlink" title="Query 1 Test 5：强制使用Merge Join，耗时2575.498 ms。"></a><strong>Query 1 Test 5：</strong>强制使用Merge Join，耗时2575.498 ms。</h4><p><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge_Cluster_Cluster_Explain.png" alt="Merge join with cluster index"></p>
<p>　　如下图所示，执行器通过聚簇索引对大表（nbar_test）和小表（mse_test_test）排序，之后才进行Merge Join。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Merge_Cluster_Cluster.png" alt="Merge join"></p>
<h4 id="Query-1-总结-3："><a href="#Query-1-总结-3：" class="headerlink" title="Query 1 总结 3："></a><strong>Query 1 总结 3：</strong></h4><p>对比<code>Query 1 Test 4</code>和<code>Query 1 Test 5</code>，可以看出二者唯一的不同在于对小表（mse_test_test）的访问方式不同，前者使用快排，后者因为聚簇索引的存在而使用Index Only Scan，在表数据量比较小的情况下前者比后者效率更高。由此可看出如果通过索引排序再查找相应的记录比直接在原记录上排序效率还低，则直接在原记录上排序后Merge Join效率更高。</p>
<ul>
<li><p><strong>删除nbar_test上的索引</strong></p>
<h4 id="Query-1-Test-6：强制使用Hash-Join，耗时1815-238-ms"><a href="#Query-1-Test-6：强制使用Hash-Join，耗时1815-238-ms" class="headerlink" title="Query 1 Test 6：强制使用Hash Join，耗时1815.238 ms"></a><strong>Query 1 Test 6：</strong>强制使用Hash Join，耗时1815.238 ms</h4><p>时间与<code>Query 1 Test 2</code>几乎相等。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Hash_Explain_No_Index.png" alt="Hash join without index"> </p>
<p> 如下图所示，与<code>Query 1 Test 2</code>相同，执行器选择一张表将其映射成散列表，再遍历另外一张表并从散列表中匹配相应记录。<br><img src="http://www.jasongj.com/img/sql/Join/Nest_Hash_No_Index.png" alt="Hash join"></p>
</li>
</ul>
<h4 id="Query-1-总结-4-："><a href="#Query-1-总结-4-：" class="headerlink" title="Query 1 总结 4 ："></a><strong>Query 1 总结 4 ：</strong></h4><p>通过对比<code>Query 1 Test 2</code>，<code>Query 1 Test 6</code>可以看出Hash Join不要求表在Join字段上建立索引。</p>
<h2 id="两大表Join"><a href="#两大表Join" class="headerlink" title="两大表Join"></a>两大表Join</h2><p>mse_test约100万条记录，nbar_test约165万条记录</p>
<p>###<strong>Query 2:</strong>不等值Join<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">   <span class="keyword">select</span> </div><div class="line">   	<span class="keyword">count</span>(*)</div><div class="line">   <span class="keyword">from</span> </div><div class="line">   	mse_test, </div><div class="line">   	nbar_test </div><div class="line">   <span class="keyword">where</span> </div><div class="line">   	mse_test.client_key = nbar_test.client_key</div><div class="line"><span class="keyword">and</span></div><div class="line">	mse_test.client_key <span class="keyword">between</span> <span class="number">100000</span> <span class="keyword">and</span> <span class="number">300000</span>;</div></pre></td></tr></table></figure></p>
<h4 id="Query-2-Test-1：强制使用Hash-Join，失败"><a href="#Query-2-Test-1：强制使用Hash-Join，失败" class="headerlink" title="Query 2 Test 1：强制使用Hash Join，失败"></a><strong>Query 2 Test 1：</strong>强制使用Hash Join，失败</h4><p>本次实验通过设置<code>enable_hashjoin=true</code>，<code>enable_nestloop=false</code>，<code>enable_mergejoin=false</code>来试图强制使用Hash Join，但是失败了。<br><img src="http://www.jasongj.com/img/sql/Join/Query2_Test1_Explain.png" alt="Nested loop"></p>
<h1 id="SQL优化系列"><a href="#SQL优化系列" class="headerlink" title="SQL优化系列"></a>SQL优化系列</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/07/Join1/">SQL优化（一） Merge Join vs. Hash Join vs. Nested Loop</a></li>
<li><a href="http://www.jasongj.com/2015/03/15/count_distinct/">SQL优化（二） 快速计算Distinct Count</a></li>
<li><a href="http://www.jasongj.com/2015/12/13/SQL3_partition/">SQL优化（三） PostgreSQL Table Partitioning</a></li>
<li><a href="http://www.jasongj.com/2015/12/27/SQL4_%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B_Store%20Procedure/">SQL优化（四） Postgre Sql存储过程</a></li>
<li><a href="http://www.jasongj.com/sql/cte/">SQL优化（五） PostgreSQL （递归）CTE 通用表表达式</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      本文介绍了Merge Join，Hash Join，Nested Loop这三种数据库Join方式的工作原理，并通过实验进一步说明了其适用范围。
    
    </summary>
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/categories/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/categories/PostgreSQL/Database/SQL%E4%BC%98%E5%8C%96/SQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://www.jasongj.com/tags/PostgreSQL/"/>
    
      <category term="Database" scheme="http://www.jasongj.com/tags/Database/"/>
    
      <category term="SQL优化" scheme="http://www.jasongj.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
      <category term="SQL" scheme="http://www.jasongj.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Java高性能异步处理框架-Disruptor</title>
    <link href="http://www.jasongj.com/2015/01/25/Disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/"/>
    <id>http://www.jasongj.com/2015/01/25/Disruptor高性能异步处理框架/</id>
    <published>2015-01-25T13:44:15.000Z</published>
    <updated>2017-02-18T02:53:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>#Disruptor简介</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;#Disruptor简介&lt;/p&gt;

    
    </summary>
    
      <category term="Message Queue" scheme="http://www.jasongj.com/categories/Message-Queue/"/>
    
      <category term="Disruptor" scheme="http://www.jasongj.com/categories/Message-Queue/Disruptor/"/>
    
    
      <category term="Disruptor" scheme="http://www.jasongj.com/tags/Disruptor/"/>
    
  </entry>
  
  <entry>
    <title>Kafka深度解析</title>
    <link href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/"/>
    <id>http://www.jasongj.com/2015/01/02/Kafka深度解析/</id>
    <published>2015-01-02T07:30:25.000Z</published>
    <updated>2017-03-15T13:17:39.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>原创文章，转载请务必将下面这段话置于文章开头处（保留超链接）。<br>本文转发自<a href="http://www.jasongj.com"><strong>技术世界</strong></a>，<a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90">原文链接</a>　<a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90">http://www.jasongj.com/2015/01/02/Kafka深度解析</a></p>
</blockquote>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><h2 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h2><p>　　Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：</p>
<ul>
<li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能</li>
<li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输</li>
<li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输</li>
<li>同时支持离线数据处理和实时数据处理</li>
</ul>
<h2 id="为什么要用消息系统"><a href="#为什么要用消息系统" class="headerlink" title="为什么要用消息系统"></a>为什么要用消息系统</h2><ul>
<li><p><b>解耦</b><br>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息队列在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束</p>
</li>
<li><p><strong>冗余</strong><br>有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。在被许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的数据被安全的保存直到你使用完毕。</p>
</li>
<li><p><strong>扩展性</strong><br>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的；只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。</p>
</li>
<li><p><strong>灵活性 &amp; 峰值处理能力</strong><br>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
</li>
<li><p><strong>可恢复性</strong><br>当体系的一部分组件失效，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。而这种允许重试或者延后处理请求的能力通常是造就一个略感不便的用户和一个沮丧透顶的用户之间的区别。</p>
</li>
<li><p><strong>送达保证</strong><br>消息队列提供的冗余机制保证了消息能被实际的处理，只要一个进程读取了该队列即可。在此基础上，部分消息系统提供了一个”只送达一次”保证。无论有多少进程在从队列中领取数据，每一个消息只能被处理一次。这之所以成为可能，是因为获取一个消息只是”预定”了这个消息，暂时把它移出了队列。除非客户端明确的表示已经处理完了这个消息，否则这个消息会被放回队列中去，在一段可配置的时间之后可再次被处理。</p>
</li>
</ul>
<ul>
<li><p><strong>顺序保证</strong><br>在大多使用场景下，数据处理的顺序都很重要。消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。部分消息系统保证消息通过FIFO（先进先出）的顺序来处理，因此消息在队列中的位置就是从队列中检索他们的位置。</p>
</li>
<li><p><strong>缓冲</strong><br>在任何重要的系统中，都会有需要不同的处理时间的元素。例如,加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行–写入队列的处理会尽可能的快速，而不受从队列读的预备处理的约束。该缓冲有助于控制和优化数据流经过系统的速度。</p>
</li>
<li><p><strong>理解数据流</strong><br>在一个分布式系统里，要得到一个关于用户操作会用多长时间及其原因的总体印象，是个巨大的挑战。消息队列通过消息被处理的频率，来方便的辅助确定那些表现不佳的处理过程或领域，这些地方的数据流都不够优化。</p>
</li>
<li><p><strong>异步通信</strong><br>很多时候，你不想也不需要立即处理消息。消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它。你想向队列中放入多少消息就放多少，然后在你乐意的时候再去处理它们。</p>
</li>
</ul>
<h2 id="常用Message-Queue对比"><a href="#常用Message-Queue对比" class="headerlink" title="常用Message Queue对比"></a>常用Message Queue对比</h2><ul>
<li><p><strong>RabbitMQ</strong><br>RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</p>
</li>
<li><p><strong>Redis</strong><br>Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p>
</li>
<li><p><strong>ZeroMQ</strong><br>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演了这个服务角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。</p>
</li>
<li><p><strong>ActiveMQ</strong><br>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。</p>
</li>
<li><p><strong>Kafka/Jafka</strong><br>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制来统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。</p>
</li>
</ul>
<h1 id="Kafka解析"><a href="#Kafka解析" class="headerlink" title="Kafka解析"></a>Kafka解析</h1><h2 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h2><ul>
<li><strong>Broker</strong><br>Kafka集群包含一个或多个服务器，这种服务器被称为broker</li>
<li><strong>Topic</strong><br>每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）</li>
<li><strong>Partition</strong><br>parition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件</li>
<li><strong>Producer</strong><br>负责发布消息到Kafka broker</li>
<li><strong>Consumer</strong><br>消费消息。每个consumer属于一个特定的consumer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。</li>
</ul>
<h2 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h2><p><img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/KafkaArchitecture.png" alt="kafka architecture 架构"><br>　　如上图所示，一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个<a href="http://zookeeper.apache.org/" target="_blank" rel="external">Zookeeper</a>集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。
　　</p>
<h3 id="Push-vs-Pull"><a href="#Push-vs-Pull" class="headerlink" title="Push vs. Pull"></a>Push vs. Pull</h3><p>　　作为一个messaging system，Kafka遵循了传统的方式，选择由producer向broker push消息并由consumer从broker pull消息。一些logging-centric system，比如Facebook的<a href="https://github.com/facebookarchive/scribe" target="_blank" rel="external">Scribe</a>和Cloudera的<a href="http://flume.apache.org/" target="_blank" rel="external">Flume</a>,采用非常不同的push模式。事实上，push模式和pull模式各有优劣。<br>　　push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p>
<h3 id="Topic-amp-Partition"><a href="#Topic-amp-Partition" class="headerlink" title="Topic &amp; Partition"></a>Topic &amp; Partition</h3><p>　　Topic在逻辑上可以被认为是一个queue。每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition，每个partition在物理上对应一个文件夹，该文件夹下存储这个partition的所有消息和索引文件。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/topic-partition.png" alt="kafka topic partition"><br>　　每个日志文件都是“log entries”序列，每一个<code>log entry</code>包含一个4字节整型数（值为N），其后跟N个字节的消息体。每条消息都有一个当前partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：<br>　　message length    ：   4 bytes (value: 1+4+n)<br>　　“magic” value         ：   1 byte<br>　　crc               ：   4 bytes<br>　　payload           ：   n bytes<br>　　这个“log entries”并非由一个文件构成，而是分成多个segment，每个segment名为该segment第一条消息的offset和“.kafka”组成。另外会有一个索引文件，它标明了每个segment下包含的<code>log entry</code>的offset范围，如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/partition_segment.png" alt="kafka partition segment"><br>　　因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/partition.png" alt="kafka partition"><br>　　每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个partition。如果partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而partition解决了这个问题）。在创建topic时可以在<code>$KAFKA_HOME/config/server.properties</code>中指定这个partition的数量(如下所示)，当然也可以在topic创建之后去修改parition数量。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># The default number of log partitions per topic. More partitions allow greater</span></div><div class="line"><span class="comment"># parallelism for consumption, but this will also result in more files across</span></div><div class="line"><span class="comment"># the brokers.</span></div><div class="line">num.partitions=3</div></pre></td></tr></table></figure></p>
<p>　　在发送一条消息时，可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。paritition机制可以通过指定producer的paritition. class这一参数来指定，该class必须实现<code>kafka.producer.Partitioner</code>接口。本例中如果key可以被解析为整数则将对应的整数与partition总数取余，该消息会被发送到该数对应的partition。（每个parition都会有个序号）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> kafka.producer.Partitioner;</div><div class="line"><span class="keyword">import</span> kafka.utils.VerifiableProperties;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JasonPartitioner</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">JasonPartitioner</span><span class="params">(VerifiableProperties verifiableProperties)</span> </span>&#123;&#125;</div><div class="line">    </div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Object key, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">int</span> partitionNum = Integer.parseInt((String) key);</div><div class="line">            <span class="keyword">return</span> Math.abs(Integer.parseInt((String) key) % numPartitions);</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            <span class="keyword">return</span> Math.abs(key.hashCode() % numPartitions);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　如果将上例中的class作为partitioner.class，并通过如下代码发送20条消息（key分别为0，1，2，3）至topic2（包含4个partition）。<br>　　<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>&#123;</div><div class="line">　　<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</div><div class="line">　　      List messageList = <span class="keyword">new</span> ArrayList&lt;KeyedMessage&lt;String, String&gt;&gt;();</div><div class="line">　　      <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; j++）&#123;</div><div class="line">　　          messageList.add(<span class="keyword">new</span> KeyedMessage&lt;String, String&gt;(<span class="string">"topic2"</span>, j+<span class="string">""</span>, <span class="string">"The "</span> + i + <span class="string">" message for key "</span> + j));</div><div class="line">　　      &#125;</div><div class="line">　　      producer.send(messageList);</div><div class="line">    &#125;</div><div class="line">　　producer.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　则key相同的消息会被发送并存储到同一个partition里，而且key的序号正好和partition序号相同。（partition序号从0开始，本例中的key也正好从0开始）。如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/partition_key.png" alt="kafka partition key"><br>　　对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间，二是基于partition文件大小。例如可以通过配置<code>$KAFKA_HOME/config/server.properties</code>，让Kafka删除一周前的数据，也可通过配置让Kafka在partition文件超过1GB时删除旧数据，如下所示。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">　　<span class="comment">############################# Log Retention Policy #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The following configurations control the disposal of log segments. The policy can</span></div><div class="line"><span class="comment"># be set to delete segments after a period of time, or after a given size has accumulated.</span></div><div class="line"><span class="comment"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></div><div class="line"><span class="comment"># from the end of the log.</span></div><div class="line"></div><div class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></div><div class="line">log.retention.hours=168</div><div class="line"></div><div class="line"><span class="comment"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></div><div class="line"><span class="comment"># segments don't drop below log.retention.bytes.</span></div><div class="line"><span class="comment">#log.retention.bytes=1073741824</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></div><div class="line">log.segment.bytes=1073741824</div><div class="line"></div><div class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according</span></div><div class="line"><span class="comment"># to the retention policies</span></div><div class="line">log.retention.check.interval.ms=300000</div><div class="line"></div><div class="line"><span class="comment"># By default the log cleaner is disabled and the log retention policy will default to </span></div><div class="line"><span class="comment">#just delete segments after their retention expires.</span></div><div class="line"><span class="comment"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs </span></div><div class="line"><span class="comment">#can then be marked for log compaction.</span></div><div class="line">log.cleaner.enable=<span class="literal">false</span></div></pre></td></tr></table></figure></p>
<p>　　这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除文件与Kafka性能无关，选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个consumer group保留一些metadata信息–当前消费的消息的position，也即offset。这个offset由consumer控制。正常情况下consumer会在消费完一条消息后线性增加这个offset。当然，consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些consumer过，不需要通过broker去保证同一个consumer group只有一个consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。
　　
　　</p>
<h3 id="Replication-amp-Leader-election"><a href="#Replication-amp-Leader-election" class="headerlink" title="Replication &amp; Leader election"></a>Replication &amp; Leader election</h3><p>　　Kafka从0.8开始提供partition级别的replication，replication的数量可在<code>$KAFKA_HOME/config/server.properties</code>中配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">default.replication.factor = 1</div></pre></td></tr></table></figure></p>
<p>　　该 Replication与leader election配合提供了自动的failover机制。replication对Kafka的吞吐率是有一定影响的，但极大的增强了可用性。默认情况下，Kafka的replication数量为1。　　每个partition都有一个唯一的leader，所有的读写操作都在leader上完成，leader批量从leader上pull数据。一般情况下partition的数量大于等于broker的数量，并且所有partition的leader均匀分布在broker上。follower上的日志和其leader上的完全一样。<br>　　和大部分分布式系统一样，Kakfa处理失败需要明确定义一个broker是否alive。对于Kafka而言，Kafka存活包含两个条件，一是它必须维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。二是follower必须能够及时将leader的writing复制过来，不能“落后太多”。<br>　　leader会track“in sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”in sync” list中移除。这里所描述的“落后太多”指follower复制的消息落后于leader后的条数超过预定值，该值可在<code>$KAFKA_HOME/config/server.properties</code>中配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead</span></div><div class="line">replica.lag.max.messages=4000</div><div class="line"></div><div class="line"><span class="comment">#If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as dead</span></div><div class="line">replica.lag.time.max.ms=10000</div></pre></td></tr></table></figure></p>
<p>　　需要说明的是，Kafka只解决”fail/recover”，不处理“Byzantine”（“拜占庭”）问题。<br>　　一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）。而对于producer而言，它可以选择是否等待消息commit，这可以通过<code>request.required.acks</code>来设置。这种机制确保了只要“in sync” list有一个或以上的flollower，一条被commit的消息就不会丢失。<br>　　这里的复制机制即不是同步复制，也不是单纯的异步复制。事实上，同步复制要求“活着的”follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follwer都落后于leader，而leader突然宕机，则会丢失数据。而Kafka的这种使用“in sync” list的方式则很好的均衡了确保数据不丢失以及吞吐率。follower可以批量的从leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了follower与leader的差距（前文有说到，只要follower落后leader不太远，则被认为在“in sync” list里）。<br>　　<br>　　上文说明了Kafka是如何做replication的，另外一个很重要的问题是当leader宕机了，怎样在follower中选举出新的leader。因为follower可能落后许多或者crash了，所以必须确保选择“最新”的follower作为新的leader。一个基本的原则就是，如果leader不在了，新的leader必须拥有原来的leader commit的所有消息。这就需要作一个折衷，如果leader在标明一条消息被commit前等待更多的follower确认，那在它die之后就有更多的follower可以作为新的leader，但这也会造成吞吐率的下降。<br>　　一种非常常用的选举leader的方式是“majority vote”（“少数服从多数”），但Kafka并未采用这种方式。这种模式下，如果我们有2f+1个replica（包含leader和follower），那在commit之前必须保证有f+1个replica复制完消息，为了保证正确选出新的leader，fail的replica不能超过f个。因为在剩下的任意f+1个replica里，至少有一个replica包含有最新的所有消息。这种方式有个很大的优势，系统的latency只取决于最快的几台server，也就是说，如果replication factor是3，那latency就取决于最快的那个follower而非最慢那个。majority vote也有一些劣势，为了保证leader election的正常进行，它所能容忍的fail的follower个数比较少。如果要容忍1个follower挂掉，必须要有3个以上的replica，如果要容忍2个follower挂掉，必须要有5个以上的replica。也就是说，在生产环境下为了保证较高的容错程度，必须要有大量的replica，而大量的replica又会在大数据量下导致性能的急剧下降。这就是这种算法更多用在<a href="http://zookeeper.apache.org/" target="_blank" rel="external">Zookeeper</a>这种共享集群配置的系统中而很少在需要存储大量数据的系统中使用的原因。例如HDFS的HA feature是基于<a href="http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1" target="_blank" rel="external">majority-vote-based journal</a>，但是它的数据存储并没有使用这种expensive的方式。<br>　　实际上，leader election算法非常多，比如Zookeper的<a href="http://web.stanford.edu/class/cs347/reading/zab.pdf" target="_blank" rel="external">Zab</a>, <a href="https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf" target="_blank" rel="external">Raft</a>和<a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf" target="_blank" rel="external">Viewstamped Replication</a>。而Kafka所使用的leader election算法更像微软的<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=66814" target="_blank" rel="external">PacificA</a>算法。<br>　　Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas） set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。在这种模式下，对于f+1个replica，一个Kafka topic能在保证不丢失已经ommit的消息的前提下容忍f个replica的失败。在大多数使用场景中，这种模式是非常有利的。事实上，为了容忍f个replica的失败，majority vote和ISR在commit前需要等待的replica数量是一样的，但是ISR需要的总的replica的个数几乎是majority vote的一半。<br>　　虽然majority vote与ISR相比有不需等待最慢的server这一优势，但是Kafka作者认为Kafka可以通过producer选择是否被commit阻塞来改善这一问题，并且节省下来的replica和磁盘使得ISR模式仍然值得。<br>　　<br>　　上文提到，在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>等待ISR中的任一个replica“活”过来，并且选它作为leader</li>
<li>选择第一个“活”过来的replica（不一定是ISR中的）作为leader</li>
</ul>
<p>　　这就需要在可用性和一致性当中作出一个简单的平衡。如果一定要等待ISR中的replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有replica都无法“活”过来了，或者数据都丢失了，这个partition将永远不可用。选择第一个“活”过来的replica作为leader，而这个replica不是ISR中的replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为leader而作为consumer的数据源（前文有说明，所有读写都由leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。<br>　　<br>　　上文说明了一个parition的replication过程，然尔Kafka集群需要管理成百上千个partition，Kafka通过round-robin的方式来平衡partition从而避免大量partition集中在了少数几个节点上。同时Kafka也需要平衡leader的分布，尽可能的让所有partition的leader均匀分布在不同broker上。另一方面，优化leadership election的过程也是很重要的，毕竟这段时间相应的partition处于不可用状态。一种简单的实现是暂停宕机的broker上的所有partition，并为之选举leader。实际上，Kafka选举一个broker作为controller，这个controller通过watch Zookeeper检测所有的broker failure，并负责为所有受影响的parition选举leader，再将相应的leader调整命令发送至受影响的broker，过程如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/controller.png" alt="kafka controller"><br>　　<br>　　这样做的好处是，可以批量的通知leadership的变化，从而使得选举过程成本更低，尤其对大量的partition而言。如果controller失败了，幸存的所有broker都会尝试在Zookeeper中创建/controller-&gt;{this broker id}，如果创建成功（只可能有一个创建成功），则该broker会成为controller，若创建不成功，则该broker会等待新controller的命令。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/controller_failover.png" alt="kafka controller failover"></p>
<h3 id="Consumer-group"><a href="#Consumer-group" class="headerlink" title="Consumer group"></a>Consumer group</h3><p>　　（本节所有描述都是基于consumer hight level API而非low level API）。<br>　　每一个consumer实例都属于一个consumer group，每一条消息只会被同一个consumer group里的一个consumer实例消费。（不同consumer group可以同时消费同一条消息）<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/consumer_group.png" alt="kafka consumer group"><br>　　<br>　　很多传统的message queue都会在消息被消费完后将消息删除，一方面避免重复消费，另一方面可以保证queue的长度比较少，提高效率。而如上文所将，Kafka并不删除已消费的消息，为了实现传统message queue消息只被消费一次的语义，Kafka保证保证同一个consumer group里只有一个consumer会消费一条消息。与传统message queue不同的是，Kafka还允许不同consumer group同时消费同一条消息，这一特性可以为消息的多元化处理提供了支持。实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的consumer在不同的consumer group即可。下图展示了Kafka在Linkedin的一种简化部署。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/kafka_in_linkedin.png" alt="kafka deployment in linkedin"><br>　　为了更清晰展示Kafka consumer group的特性，笔者作了一项测试。创建一个topic (名为topic1)，创建一个属于group1的consumer实例，并创建三个属于group2的consumer实例，然后通过producer向topic1发送key分别为1，2，3r的消息。结果发现属于group1的consumer收到了所有的这三条消息，同时group2中的3个consumer分别收到了key为1，2，3的消息。如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/consumer_group_test.png" alt="kafka consumer group"></p>
<h3 id="Consumer-Rebalance"><a href="#Consumer-Rebalance" class="headerlink" title="Consumer Rebalance"></a>Consumer Rebalance</h3><p>　　（本节所讲述内容均基于Kafka consumer high level API）<br>　　Kafka保证同一consumer group中只有一个consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个consumer实例只会消费某一个或多个特定partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。这样设计的劣势是无法让同一个consumer group里的consumer均匀消费数据，优势是每个consumer不用都跟大量的broker通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个partition里的数据是有序的，这种设计可以保证每个partition里的数据也是有序被消费。<br>　　如果某consumer group中consumer数量少于partition数量，则至少有一个consumer会消费多个partition的数据，如果consumer的数量与partition数量相同，则正好一个consumer消费一个partition的数据，而如果consumer的数量多于partition的数量时，会有部分consumer无法消费该topic下任何一条消息。<br>　　如下例所示，如果topic1有0，1，2共三个partition，当group1只有一个consumer(名为consumer1)时，该 consumer可消费这3个partition的所有数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer1.png" alt="kafka consumer group rebalance"><br>　　增加一个consumer(consumer2)后，其中一个consumer（consumer1）可消费2个partition的数据，另外一个consumer(consumer2)可消费另外一个partition的数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2.png" alt="kafka consumer group rebalance"><br>　　再增加一个consumer(consumer3)后，每个consumer可消费一个partition的数据。consumer1消费partition0，consumer2消费partition1，consumer3消费partition2<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2_3.png" alt="kafka consumer group rebalance"><br>　　再增加一个consumer（consumer4）后，其中3个consumer可分别消费一个partition的数据，另外一个consumer（consumer4）不能消费topic1任何数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_1_2_3_4.png" alt="kafka consumer group rebalance"><br>　　此时关闭consumer1，剩下的consumer可分别消费一个partition的数据。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_2_3_4.png" alt="kafka consumer group"><br>　　接着关闭consumer2，剩下的consumer3可消费2个partition，consumer4可消费1个partition。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_3_4.png" alt="kafka consumer group"><br>　　再关闭consumer3，剩下的consumer4可同时消费topic1的3个partition。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/group1_consumer_4.png" alt="kafka consumer group"></p>
<p>　　consumer rebalance算法如下：
　　</p>
<ul>
<li>Sort PT (all partitions in topic T) </li>
<li>Sort CG(all consumers in consumer group G)</li>
<li>Let i be the index position of Ci in CG and let N=size(PT)/size(CG)</li>
<li>Remove current entries owned by Ci from the partition owner registry </li>
<li>Assign partitions from i<em>N to (i+1)</em>N-1 to consumer Ci </li>
<li>Add newly assigned partitions to the partition owner registry</li>
</ul>
<p>　　目前consumer rebalance的控制策略是由每一个consumer通过Zookeeper完成的。具体的控制方式如下：</p>
<ul>
<li>Register itself in the consumer id registry under its group.</li>
<li>Register a watch on changes under the consumer id registry.</li>
<li>Register a watch on changes under the broker id registry.</li>
<li>If the consumer creates a message stream using a topic filter, it also registers a watch on changes under the broker topic registry.</li>
<li>Force itself to rebalance within in its consumer group.<br>　　<br>　　在这种策略下，每一个consumer或者broker的增加或者减少都会触发consumer rebalance。因为每个consumer只负责调整自己所消费的partition，为了保证整个consumer group的一致性，所以当一个consumer触发了rebalance时，该consumer group内的其它所有consumer也应该同时触发rebalance。</li>
</ul>
<p>　　目前（2015-01-19）最新版（0.8.2）Kafka采用的是上述方式。但该方式有不利的方面：</p>
<ul>
<li><b>Herd effect</b><br>　　任何broker或者consumer的增减都会触发所有的consumer的rebalance</li>
<li><b>Split Brain</b><br>　　每个consumer分别单独通过Zookeeper判断哪些partition down了，那么不同consumer从Zookeeper“看”到的view就可能不一样，这就会造成错误的reblance尝试。而且有可能所有的consumer都认为rebalance已经完成了，但实际上可能并非如此。</li>
</ul>
<p>　　根据Kafka官方文档，Kafka作者正在考虑在还未发布的<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design" target="_blank" rel="external">0.9.x版本中使用中心协调器(coordinator)</a>。大体思想是选举出一个broker作为coordinator，由它watch Zookeeper，从而判断是否有partition或者consumer的增减，然后生成rebalance命令，并检查是否这些rebalance在所有相关的consumer中被执行成功，如果不成功则重试，若成功则认为此次rebalance成功（这个过程跟replication controller非常类似，所以我很奇怪为什么当初设计replication controller时没有使用类似方式来解决consumer rebalance的问题）。流程如下：<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/coordinator.png" alt="kafka coordinator">
　　
　　</p>
<h3 id="消息Deliver-guarantee"><a href="#消息Deliver-guarantee" class="headerlink" title="消息Deliver guarantee"></a>消息Deliver guarantee</h3><p>　　通过上文介绍，想必读者已经明天了producer和consumer是如何工作的，以及Kafka是如何做replication的，接下来要讨论的是Kafka如何确保消息在producer和consumer之间传输。有这么几种可能的delivery guarantee：</p>
<ul>
<li><code>At most once</code> 消息可能会丢，但绝不会重复传输</li>
<li><code>At least one</code> 消息绝不会丢，但可能会重复传输</li>
<li><code>Exactly once</code> 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。<br>　　<br>　　Kafka的delivery guarantee semantic非常直接。当producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果producer发送数据给broker后，遇到的网络问题而造成通信中断，那producer就无法判断该条消息是否已经commit。这一点有点像向一个自动生成primary key的数据库表中插入数据。虽然Kafka无法确定网络故障期间发生了什么，但是producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次，这样就做到了<code>Exactly one</code>。截止到目前(Kafka 0.8.2版本，2015-01-25)，这一feature还并未实现，有希望在Kafka未来的版本中实现。（所以目前默认情况下一条消息从producer和broker是确保了<code>At least once</code>，但可通过设置producer异步发送实现<code>At most once</code>）。<br>　　接下来讨论的是消息从broker到consumer的delivery guarantee semantic。（仅针对Kafka consumer high level API）。consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该partition下读取的消息的offset。该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将consumer设置为autocommit，即consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了<code>Exactly once</code>。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</li>
<li>读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于<code>At most once</code></li>
<li>读完消息先处理再commit。这种模式下，如果处理完了消息在commit之前consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了。这就对应于<code>At least once</code>。在很多情况使用场景下，消息都有一个primary key，所以消息的处理往往具有幂等性，即多次处理这一条消息跟只处理一次是等效的，那就可以认为是<code>Exactly once</code>。（人个感觉这种说法有些牵强，毕竟它不是Kafka本身提供的机制，而且primary key本身不保证操作的幂等性。而且实际上我们说delivery guarantee semantic是讨论被处理多少次，而非处理结果怎样，因为处理方式多种多样，我们的系统不应该把处理过程的特性–如是否幂等性，当成Kafka本身的feature）</li>
<li>如果一定要做到<code>Exactly once</code>，就需要协调offset和实际操作的输出。精典的做法是引入两阶段提交。如果能让offset和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现<code>Exactly once</code>。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）<br>　　总之，Kafka默认保证<code>At least once</code>，并且允许通过设置producer异步提交来实现<code>At most once</code>。而<code>Exactly once</code>要求与目标存储系统协作，幸运的是Kafka提供的offset可以使用这种方式非常直接非常容易。</li>
</ul>
<h1 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h1><p>　　纸上得来终觉浅，绝知些事要躬行。笔者希望能亲自测一下Kafka的性能，而非从网上找一些测试数据。所以笔者曾在0.8发布前两个月做过详细的Kafka0.8性能测试，不过很可惜测试报告不慎丢失。所幸在网上找到了Kafka的创始人之一的<a href="http://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines" target="_blank" rel="external">Jay Kreps的bechmark</a>。以下描述皆基于该benchmark。（该benchmark基于Kafka0.8.1）</p>
<h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>　　该benchmark用到了六台机器，机器配置如下</p>
<ul>
<li>Intel Xeon 2.5 GHz processor with six cores</li>
<li>Six 7200 RPM SATA drives</li>
<li>32GB of RAM</li>
<li>1Gb Ethernet<br>　　<br>　　这6台机器其中3台用来搭建Kafka broker集群，另外3台用来安装Zookeeper及生成测试数据。6个drive都直接以非RAID方式挂载。实际上kafka对机器的需求与Hadoop的类似。</li>
</ul>
<h2 id="Producer吞吐率"><a href="#Producer吞吐率" class="headerlink" title="Producer吞吐率"></a>Producer吞吐率</h2><p>　　该项测试只测producer的吞吐率，也就是数据只被持久化，没有consumer读数据。</p>
<h3 id="1个producer线程，无replication"><a href="#1个producer线程，无replication" class="headerlink" title="1个producer线程，无replication"></a>1个producer线程，无replication</h3><p>　　在这一测试中，创建了一个包含6个partition且没有replication的topic。然后通过一个线程尽可能快的生成50 million条比较短（payload100字节长）的消息。测试结果是<strong><em>821,557 records/second</em></strong>（<strong><em>78.3MB/second</em></strong>）。<br>　　之所以使用短消息，是因为对于消息系统来说这种使用场景更难。因为如果使用MB/second来表征吞吐率，那发送长消息无疑能使得测试结果更好。<br>　　整个测试中，都是用每秒钟delivery的消息的数量乘以payload的长度来计算MB/second的，没有把消息的元信息算在内，所以实际的网络使用量会比这个大。对于本测试来说，每次还需传输额外的22个字节，包括一个可选的key，消息长度描述，CRC等。另外，还包含一些请求相关的overhead，比如topic，partition，acknowledgement等。这就导致我们比较难判断是否已经达到网卡极限，但是把这些overhead都算在吞吐率里面应该更合理一些。因此，我们已经基本达到了网卡的极限。<br>　　初步观察此结果会认为它比人们所预期的要高很多，尤其当考虑到Kafka要把数据持久化到磁盘当中。实际上，如果使用随机访问数据系统，比如RDBMS，或者key-velue store，可预期的最高访问频率大概是5000到50000个请求每秒，这和一个好的RPC层所能接受的远程请求量差不多。而该测试中远超于此的原因有两个。</p>
<ul>
<li>Kafka确保写磁盘的过程是线性磁盘I/O，测试中使用的6块廉价磁盘线性I/O的最大吞吐量是822MB/second，这已经远大于1Gb网卡所能带来的吞吐量了。许多消息系统把数据持久化到磁盘当成是一个开销很大的事情，这是因为他们对磁盘的操作都不是线性I/O。</li>
<li>在每一个阶段，Kafka都尽量使用批量处理。如果想了解批处理在I/O操作中的重要性，可以参考David Patterson的”<a href="http://www.ll.mit.edu/HPEC/agendas/proc04/invited/patterson_keynote.pdf" target="_blank" rel="external">Latency Lags Bandwidth</a>“</li>
</ul>
<h3 id="1个producer线程，3个异步replication"><a href="#1个producer线程，3个异步replication" class="headerlink" title="1个producer线程，3个异步replication"></a>1个producer线程，3个异步replication</h3><p>　　该项测试与上一测试基本一样，唯一的区别是每个partition有3个replica（所以网络传输的和写入磁盘的总的数据量增加了3倍）。每一个broker即要写作为leader的partition，也要读（从leader读数据）写（将数据写到磁盘）作为follower的partition。测试结果为<strong><em>786,980 records/second</em></strong>（<strong><em>75.1MB/second</em></strong>）。<br>　　该项测试中replication是异步的，也就是说broker收到数据并写入本地磁盘后就acknowledge producer，而不必等所有replica都完成replication。也就是说，如果leader crash了，可能会丢掉一些最新的还未备份的数据。但这也会让message acknowledgement延迟更少，实时性更好。<br>　　这项测试说明，replication可以很快。整个集群的写能力可能会由于3倍的replication而只有原来的三分之一，但是对于每一个producer来说吞吐率依然足够好。
　　</p>
<h3 id="1个producer线程，3个同步replication"><a href="#1个producer线程，3个同步replication" class="headerlink" title="1个producer线程，3个同步replication"></a>1个producer线程，3个同步replication</h3><p>　　该项测试与上一测试的唯一区别是replication是同步的，每条消息只有在被<code>in sync</code>集合里的所有replica都复制过去后才会被置为committed（此时broker会向producer发送acknowledgement）。在这种模式下，Kafka可以保证即使leader crash了，也不会有数据丢失。测试结果为<strong><em>421,823 records/second</em></strong>（<strong><em>40.2MB/second</em></strong>）。<br>　　Kafka同步复制与异步复制并没有本质的不同。leader会始终track follower replica从而监控它们是否还alive，只有所有<code>in sync</code>集合里的replica都acknowledge的消息才可能被consumer所消费。而对follower的等待影响了吞吐率。可以通过增大batch size来改善这种情况，但为了避免特定的优化而影响测试结果的可比性，本次测试并没有做这种调整。
　　</p>
<h3 id="3个producer-3个异步replication"><a href="#3个producer-3个异步replication" class="headerlink" title="3个producer,3个异步replication"></a>3个producer,3个异步replication</h3><p>　　该测试相当于把上文中的1个producer,复制到了3台不同的机器上（在1台机器上跑多个实例对吞吐率的增加不会有太大帮忙，因为网卡已经基本饱和了），这3个producer同时发送数据。整个集群的吞吐率为<strong><em>2,024,032 records/second</em></strong>（<strong><em>193,0MB/second</em></strong>）。</p>
<h2 id="Producer-Throughput-Vs-Stored-Data"><a href="#Producer-Throughput-Vs-Stored-Data" class="headerlink" title="Producer Throughput Vs. Stored Data"></a>Producer Throughput Vs. Stored Data</h2><p>　　消息系统的一个潜在的危险是当数据能都存于内存时性能很好，但当数据量太大无法完全存于内存中时（然后很多消息系统都会删除已经被消费的数据，但当消费速度比生产速度慢时，仍会造成数据的堆积），数据会被转移到磁盘，从而使得吞吐率下降，这又反过来造成系统无法及时接收数据。这样就非常糟糕，而实际上很多情景下使用queue的目的就是解决数据消费速度和生产速度不一致的问题。<br>　　但Kafka不存在这一问题，因为Kafka始终以O（1）的时间复杂度将数据持久化到磁盘，所以其吞吐率不受磁盘上所存储的数据量的影响。为了验证这一特性，做了一个长时间的大数据量的测试，下图是吞吐率与数据量大小的关系图。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/throughput_size.png" alt="kafka throughput"><br>　　上图中有一些variance的存在，并可以明显看到，吞吐率并不受磁盘上所存数据量大小的影响。实际上从上图可以看到，当磁盘数据量达到1TB时，吞吐率和磁盘数据只有几百MB时没有明显区别。<br>　　这个variance是由Linux I/O管理造成的，它会把数据缓存起来再批量flush。上图的测试结果是在生产环境中对Kafka集群做了些tuning后得到的，这些tuning方法可参考<a href="http://kafka.apache.org/documentation.html#hwandos" target="_blank" rel="external">这里</a>。
　　</p>
<h2 id="consumer吞吐率"><a href="#consumer吞吐率" class="headerlink" title="consumer吞吐率"></a>consumer吞吐率</h2><p>　　需要注意的是，replication factor并不会影响consumer的吞吐率测试，因为consumer只会从每个partition的leader读数据，而与replicaiton factor无关。同样，consumer吞吐率也与同步复制还是异步复制无关。
　　</p>
<h3 id="1个consumer"><a href="#1个consumer" class="headerlink" title="1个consumer"></a>1个consumer</h3><p>　　该测试从有6个partition，3个replication的topic消费50 million的消息。测试结果为<strong><em>940,521 records/second</em></strong>（<strong><em>89.7MB/second</em></strong>）。<br>　　可以看到，Kafkar的consumer是非常高效的。它直接从broker的文件系统里读取文件块。Kafka使用<a href="http://www.ibm.com/developerworks/library/j-zerocopy/" target="_blank" rel="external">sendfile API</a>来直接通过操作系统直接传输，而不用把数据拷贝到用户空间。该项测试实际上从log的起始处开始读数据，所以它做了真实的I/O。在生产环境下，consumer可以直接读取producer刚刚写下的数据（它可能还在缓存中）。实际上，如果在生产环境下跑<a href="http://en.wikipedia.org/wiki/Iostat" target="_blank" rel="external">I/O stat</a>，你可以看到基本上没有物理“读”。也就是说生产环境下consumer的吞吐率会比该项测试中的要高。</p>
<h3 id="3个consumer"><a href="#3个consumer" class="headerlink" title="3个consumer"></a>3个consumer</h3><p>　　将上面的consumer复制到3台不同的机器上，并且并行运行它们（从同一个topic上消费数据）。测试结果为<strong><em>2,615,968 records/second</em></strong>（<strong><em>249.5MB/second</em></strong>）。<br>　　正如所预期的那样，consumer的吞吐率几乎线性增涨。
　　</p>
<h2 id="Producer-and-Consumer"><a href="#Producer-and-Consumer" class="headerlink" title="Producer and Consumer"></a>Producer and Consumer</h2><p>　　上面的测试只是把producer和consumer分开测试，而该项测试同时运行producer和consumer，这更接近使用场景。实际上目前的replication系统中follower就相当于consumer在工作。<br>　　该项测试，在具有6个partition和3个replica的topic上同时使用1个producer和1个consumer，并且使用异步复制。测试结果为<strong><em>795,064 records/second</em></strong>（<strong><em>75.8MB/second</em></strong>）。<br>　　可以看到，该项测试结果与单独测试1个producer时的结果几乎一致。所以说consumer非常轻量级。
　　</p>
<h2 id="消息长度对吞吐率的影响"><a href="#消息长度对吞吐率的影响" class="headerlink" title="消息长度对吞吐率的影响"></a>消息长度对吞吐率的影响</h2><p>　　上面的所有测试都基于短消息（payload 100字节），而正如上文所说，短消息对Kafka来说是更难处理的使用方式，可以预期，随着消息长度的增大，records/second会减小，但MB/second会有所提高。下图是records/second与消息长度的关系图。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/record_size_throughput.png" alt="kafka throughput"><br>　　正如我们所预期的那样，随着消息长度的增加，每秒钟所能发送的消息的数量逐渐减小。但是如果看每秒钟发送的消息的总大小，它会随着消息长度的增加而增加，如下图所示。<br>　　<img src="http://www.jasongj.com/img/kafka/KafkaAnalysis/records_MB.png" alt="kafka benchmark"><br>　　从上图可以看出，当消息长度为10字节时，因为要频繁入队，花了太多时间获取锁，CPU成了瓶颈，并不能充分利用带宽。但从100字节开始，我们可以看到带宽的使用逐渐趋于饱和（虽然MB/second还是会随着消息长度的增加而增加，但增加的幅度也越来越小）。
　　</p>
<h2 id="端到端的Latency"><a href="#端到端的Latency" class="headerlink" title="端到端的Latency"></a>端到端的Latency</h2><p>　　上文中讨论了吞吐率，那消息传输的latency如何呢？也就是说消息从producer到consumer需要多少时间呢？该项测试创建1个producer和1个consumer并反复计时。结果是，<strong><em>2 ms (median), 3ms (99th percentile, 14ms (99.9th percentile)</em></strong>。<br>　　（这里并没有说明topic有多少个partition，也没有说明有多少个replica，replication是同步还是异步。实际上这会极大影响producer发送的消息被commit的latency，而只有committed的消息才能被consumer所消费，所以它会最终影响端到端的latency）
　　</p>
<h2 id="重现该benchmark"><a href="#重现该benchmark" class="headerlink" title="重现该benchmark"></a>重现该benchmark</h2><p>　　如果读者想要在自己的机器上重现本次benchmark测试，可以参考<a href="https://gist.github.com/jkreps/c7ddb4041ef62a900e6c" target="_blank" rel="external">本次测试的配置和所使用的命令</a>。<br>　　实际上Kafka Distribution提供了producer性能测试工具，可通过<code>bin/kafka-producer-perf-test.sh</code>脚本来启动。所使用的命令如下<br>　　<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">Producer</div><div class="line">Setup</div><div class="line">bin/kafka-topics.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --create --topic <span class="built_in">test</span>-rep-one --partitions 6 --replication-factor 1</div><div class="line">bin/kafka-topics.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --create --topic <span class="built_in">test</span> --partitions 6 --replication-factor 3</div><div class="line"></div><div class="line">Single thread, no replication</div><div class="line"></div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span>7 50000000 100 -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=8196</div><div class="line"></div><div class="line">Single-thread, async 3x replication</div><div class="line"></div><div class="line">bin/kafktopics.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --create --topic <span class="built_in">test</span> --partitions 6 --replication-factor 3</div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span>6 50000000 100 -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=8196</div><div class="line"></div><div class="line">Single-thread, sync 3x replication</div><div class="line"></div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span> 50000000 100 -1 acks=-1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=64000</div><div class="line"></div><div class="line">Three Producers, 3x async replication</div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span> 50000000 100 -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=8196</div><div class="line"></div><div class="line">Throughput Versus Stored Data</div><div class="line"></div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span> 50000000000 100 -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=8196</div><div class="line"></div><div class="line">Effect of message size</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> 10 100 1000 10000 100000;</div><div class="line"><span class="keyword">do</span></div><div class="line"><span class="built_in">echo</span> <span class="string">""</span></div><div class="line"><span class="built_in">echo</span> <span class="variable">$i</span></div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span> $((1000*1024*1024/<span class="variable">$i</span>)) <span class="variable">$i</span> -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=128000</div><div class="line"><span class="keyword">done</span>;</div><div class="line"></div><div class="line">Consumer</div><div class="line">Consumer throughput</div><div class="line"></div><div class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --messages 50000000 --topic <span class="built_in">test</span> --threads 1</div><div class="line"></div><div class="line">3 Consumers</div><div class="line"></div><div class="line">On three servers, run:</div><div class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --messages 50000000 --topic <span class="built_in">test</span> --threads 1</div><div class="line"></div><div class="line">End-to-end Latency</div><div class="line"></div><div class="line">bin/kafka-run-class.sh kafka.tools.TestEndToEndLatency esv4-hcl198.grid.linkedin.com:9092 esv4-hcl197.grid.linkedin.com:2181 <span class="built_in">test</span> 5000</div><div class="line"></div><div class="line">Producer and consumer</div><div class="line"></div><div class="line">bin/kafka-run-class.sh org.apache.kafka.clients.tools.ProducerPerformance <span class="built_in">test</span> 50000000 100 -1 acks=1 bootstrap.servers=esv4-hcl198.grid.linkedin.com:9092 buffer.memory=67108864 batch.size=8196</div><div class="line"></div><div class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:2181 --messages 50000000 --topic <span class="built_in">test</span> --threads 1</div></pre></td></tr></table></figure></p>
<p>　　broker配置如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line"><span class="comment">############################# Server Basics #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The id of the broker. This must be set to a unique integer for each broker.</span></div><div class="line">broker.id=0</div><div class="line"></div><div class="line"><span class="comment">############################# Socket Server Settings #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The port the socket server listens on</span></div><div class="line">port=9092</div><div class="line"></div><div class="line"><span class="comment"># Hostname the broker will bind to and advertise to producers and consumers.</span></div><div class="line"><span class="comment"># If not set, the server will bind to all interfaces and advertise the value returned from</span></div><div class="line"><span class="comment"># from java.net.InetAddress.getCanonicalHostName().</span></div><div class="line"><span class="comment">#host.name=localhost</span></div><div class="line"></div><div class="line"><span class="comment"># The number of threads handling network requests</span></div><div class="line">num.network.threads=4</div><div class="line"> </div><div class="line"><span class="comment"># The number of threads doing disk I/O</span></div><div class="line">num.io.threads=8</div><div class="line"></div><div class="line"><span class="comment"># The send buffer (SO_SNDBUF) used by the socket server</span></div><div class="line">socket.send.buffer.bytes=1048576</div><div class="line"></div><div class="line"><span class="comment"># The receive buffer (SO_RCVBUF) used by the socket server</span></div><div class="line">socket.receive.buffer.bytes=1048576</div><div class="line"></div><div class="line"><span class="comment"># The maximum size of a request that the socket server will accept (protection against OOM)</span></div><div class="line">socket.request.max.bytes=104857600</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">############################# Log Basics #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The directory under which to store log files</span></div><div class="line">log.dirs=/grid/a/dfs-data/kafka-logs,/grid/b/dfs-data/kafka-logs,/grid/c/dfs-data/kafka-logs,/grid/d/dfs-data/kafka-logs,/grid/e/dfs-data/kafka-logs,/grid/f/dfs-data/kafka-logs</div><div class="line"></div><div class="line"><span class="comment"># The number of logical partitions per topic per server. More partitions allow greater parallelism</span></div><div class="line"><span class="comment"># for consumption, but also mean more files.</span></div><div class="line">num.partitions=8</div><div class="line"></div><div class="line"><span class="comment">############################# Log Flush Policy #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The following configurations control the flush of data to disk. This is the most</span></div><div class="line"><span class="comment"># important performance knob in kafka.</span></div><div class="line"><span class="comment"># There are a few important trade-offs here:</span></div><div class="line"><span class="comment">#    1. Durability: Unflushed data is at greater risk of loss in the event of a crash.</span></div><div class="line"><span class="comment">#    2. Latency: Data is not made available to consumers until it is flushed (which adds latency).</span></div><div class="line"><span class="comment">#    3. Throughput: The flush is generally the most expensive operation. </span></div><div class="line"><span class="comment"># The settings below allow one to configure the flush policy to flush data after a period of time or</span></div><div class="line"><span class="comment"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span></div><div class="line"></div><div class="line"><span class="comment"># Per-topic overrides for log.flush.interval.ms</span></div><div class="line"><span class="comment">#log.flush.intervals.ms.per.topic=topic1:1000, topic2:3000</span></div><div class="line"></div><div class="line"><span class="comment">############################# Log Retention Policy #############################</span></div><div class="line"></div><div class="line"><span class="comment"># The following configurations control the disposal of log segments. The policy can</span></div><div class="line"><span class="comment"># be set to delete segments after a period of time, or after a given size has accumulated.</span></div><div class="line"><span class="comment"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></div><div class="line"><span class="comment"># from the end of the log.</span></div><div class="line"></div><div class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></div><div class="line">log.retention.hours=168</div><div class="line"></div><div class="line"><span class="comment"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></div><div class="line"><span class="comment"># segments don't drop below log.retention.bytes.</span></div><div class="line"><span class="comment">#log.retention.bytes=1073741824</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></div><div class="line">log.segment.bytes=536870912</div><div class="line"></div><div class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according </span></div><div class="line"><span class="comment"># to the retention policies</span></div><div class="line">log.cleanup.interval.mins=1</div><div class="line"></div><div class="line"><span class="comment">############################# Zookeeper #############################</span></div><div class="line"></div><div class="line"><span class="comment"># Zookeeper connection string (see zookeeper docs for details).</span></div><div class="line"><span class="comment"># This is a comma separated host:port pairs, each corresponding to a zk</span></div><div class="line"><span class="comment"># server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".</span></div><div class="line"><span class="comment"># You can also append an optional chroot string to the urls to specify the</span></div><div class="line"><span class="comment"># root directory for all kafka znodes.</span></div><div class="line">zookeeper.connect=esv4-hcl197.grid.linkedin.com:2181</div><div class="line"></div><div class="line"><span class="comment"># Timeout in ms for connecting to zookeeper</span></div><div class="line">zookeeper.connection.timeout.ms=1000000</div><div class="line"></div><div class="line"><span class="comment"># metrics reporter properties</span></div><div class="line">kafka.metrics.polling.interval.secs=5</div><div class="line">kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter</div><div class="line">kafka.csv.metrics.dir=/tmp/kafka_metrics</div><div class="line"><span class="comment"># Disable csv reporting by default.</span></div><div class="line">kafka.csv.metrics.reporter.enabled=<span class="literal">false</span></div><div class="line"></div><div class="line">replica.lag.max.messages=10000000</div></pre></td></tr></table></figure></p>
<p>　　读者也可参考另外一份<a href="http://liveramp.com/blog/kafka-0-8-producer-performance-2/" target="_blank" rel="external">Kafka性能测试报告</a></p>
<h1 id="Kafka系列文章"><a href="#Kafka系列文章" class="headerlink" title="Kafka系列文章"></a>Kafka系列文章</h1><ul>
<li><a href="http://www.jasongj.com/2015/03/10/KafkaColumn1/">Kafka设计解析（一）- Kafka背景及架构介绍</a></li>
<li><a href="http://www.jasongj.com/2015/04/24/KafkaColumn2/">Kafka设计解析（二）- Kafka High Availability （上）</a></li>
<li><a href="http://www.jasongj.com/2015/06/08/KafkaColumn3/">Kafka设计解析（三）- Kafka High Availability （下）</a></li>
<li><a href="http://www.jasongj.com/2015/08/09/KafkaColumn4/">Kafka设计解析（四）- Kafka Consumer设计解析</a></li>
<li><a href="http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/">Kafka设计解析（五）- Kafka性能测试方法及Benchmark报告</a></li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.oschina.net/translate/top-10-uses-for-message-queue" target="_blank" rel="external">使用消息队列的 10 个理由</a></li>
<li><a href="http://kafka.apache.org/" target="_blank" rel="external">Apache Kafka</a></li>
<li><a href="http://www.ibm.com/developerworks/library/j-zerocopy/" target="_blank" rel="external">Efficient data transfer through zero copy</a></li>
<li><a href="http://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines" target="_blank" rel="external">Benchmarking Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines)</a></li>
<li><a href="http://liveramp.com/blog/kafka-0-8-producer-performance-2/" target="_blank" rel="external">Kafka 0.8 Producer Performance</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      介绍Kafka背景，使用消息系统的优势，常用消息系统对比，Kafka架构介绍，Kafka实现语义分析，Replication及Leader Election机制剖析，Consumer Group Rebalance实现原理介绍，以及Benchmark测试。
    
    </summary>
    
      <category term="Kafka" scheme="http://www.jasongj.com/categories/Kafka/"/>
    
      <category term="big data" scheme="http://www.jasongj.com/categories/Kafka/big-data/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/categories/Kafka/big-data/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="big data" scheme="http://www.jasongj.com/tags/big-data/"/>
    
      <category term="分布式" scheme="http://www.jasongj.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="大数据" scheme="http://www.jasongj.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Kafka" scheme="http://www.jasongj.com/tags/Kafka/"/>
    
  </entry>
  
</feed>
